// Dafny program the_program compiled into C#
// To recompile, you will need the libraries
//     System.Runtime.Numerics.dll System.Collections.Immutable.dll
// but the 'dotnet' tool in net6.0 should pick those up automatically.
// Optionally, you may want to include compiler switches like
//     /debug /nowarn:162,164,168,183,219,436,1717,1718

using System;
using System.Numerics;
using System.Collections;
[assembly: DafnyAssembly.DafnySourceAttribute(@"// dafny 4.8.1.0
// Command-line arguments: test --standard-libraries ReadBytesFromFile.dfy
// the_program

method {:verify false} {:main} _Test__Main_(_noArgsParameter: seq<seq<char>>)
{
  var success: bool := true;
  print @""ReadBytesFromFile.Test: "";
    [[ try { ]]
{
      Test()
      {
        print @""PASSED
"";
      }
    }
  [[ } recover (haltMessage) { ]]
{
      print @""FAILED
	"", haltMessage, @""
"";
      success := false;
    }[[ } ]]
  expect success, @""Test failures occurred: see above.
"";
}

module ReadBytesFromFile {
  method {:test} Test()
  {
    theMain(""/Users/pari/pcc-llms/filesystems-api/Standard-fileIO/data.txt"", """");
  }

  method theMain(dataPath: string, expectedErrorPrefix: string)
    decreases dataPath, expectedErrorPrefix
  {
    {
      var expectedStr := ""Hello world"";
      var expectedBytes := seq(|expectedStr|, (i: int) requires 0 <= i < |expectedStr| => expectedStr[i] as int);
      var res := FileIO.ReadBytesFromFile(dataPath);
      expect res.Success?, ""unexpected failure: "" + res.error;
      var readBytes := seq(|res.value|, (i: int) requires 0 <= i < |res.value| => res.value[i] as int);
      expect readBytes == expectedBytes, ""read unexpected byte sequence"";
    }
    {
      var res := FileIO.ReadBytesFromFile("""");
      expect res.Failure?, ""unexpected success"";
      expect expectedErrorPrefix <= res.error, ""unexpected error message: "" + res.error;
    }
  }

  import FileIO = Std.FileIO
}

module Std {

  
  replaceable module Concurrent {

    import opened Wrappers
    class Lock {
      ghost var isLocked: bool

      constructor ()
        ensures !isLocked

      method Lock()
        requires !isLocked
        reads this
        modifies this
        ensures isLocked

      method Unlock()
        requires isLocked
        reads this
        modifies this
        ensures !isLocked
    }

    class AtomicBox<T> {
      ghost const inv: T -> bool

      constructor (ghost inv: T -> bool, t: T)
        requires inv(t)
        ensures this.inv == inv

      method Get() returns (t: T)
        reads {}
        ensures inv(t)

      method Put(t: T)
        requires inv(t)
        reads {}
    }

    class MutableMap<K(==), V(==)> {
      ghost const inv: (K, V) -> bool

      constructor (ghost inv: (K, V) -> bool)
        ensures this.inv == inv

      method Keys() returns (keys: set<K>)
        reads {}
        ensures forall k: K {:trigger k in keys} | k in keys :: exists v: V {:trigger inv(k, v)} :: inv(k, v)

      method HasKey(k: K) returns (used: bool)
        reads {}
        ensures used ==> exists v: V {:trigger inv(k, v)} :: inv(k, v)

      method Values() returns (values: set<V>)
        reads {}
        ensures forall v: V {:trigger v in values} | v in values :: exists k: K {:trigger inv(k, v)} :: inv(k, v)

      method Items() returns (items: set<(K, V)>)
        reads {}
        ensures forall t: (K, V) {:trigger t.1} {:trigger t.0} {:trigger t in items} | t in items :: inv(t.0, t.1)

      method Put(k: K, v: V)
        requires inv(k, v)
        reads {}

      method Get(k: K) returns (r: Option<V>)
        reads {}
        ensures r.Some? ==> inv(k, r.value)

      method Remove(k: K)
        requires exists v: V {:trigger inv(k, v)} :: inv(k, v)
        reads {}

      method Size() returns (c: nat)
        reads {}
    }
  }

  module {:extern} JavaCsJsFileIOInternalExterns replaces FileIOInternalExterns {
    method {:extern} INTERNAL_ReadBytesFromFile(path: string)
        returns (isError: bool, bytesRead: seq<bv8>, errorMsg: string)
      decreases path

    method {:extern} INTERNAL_WriteBytesToFile(path: string, bytes: seq<bv8>)
        returns (isError: bool, errorMsg: string)
      decreases path, bytes
  }

  replaceable module FileIOInternalExterns {
    method INTERNAL_ReadBytesFromFile(path: string)
        returns (isError: bool, bytesRead: seq<bv8>, errorMsg: string)
      decreases path

    method INTERNAL_WriteBytesToFile(path: string, bytes: seq<bv8>)
        returns (isError: bool, errorMsg: string)
      decreases path, bytes
  }

  module FileIO {
    method ReadBytesFromFile(path: string) returns (res: Result<seq<bv8>, string>)
      decreases path
    {
      var isError, bytesRead, errorMsg := FileIOInternalExterns.INTERNAL_ReadBytesFromFile(path);
      return if isError then Failure(errorMsg) else Success(bytesRead);
    }

    method WriteBytesToFile(path: string, bytes: seq<bv8>) returns (res: Result<(), string>)
      decreases path, bytes
    {
      var isError, errorMsg := FileIOInternalExterns.INTERNAL_WriteBytesToFile(path, bytes);
      return if isError then Failure(errorMsg) else Success(());
    }

    import opened Wrappers

    import FileIOInternalExterns

    export
      provides ReadBytesFromFile, WriteBytesToFile, Wrappers

  }

  module Base64 {
    opaque predicate IsBase64Char(c: char)
      decreases c
    {
      c == '+' || c == '/' || '0' <= c <= '9' || 'A' <= c <= 'Z' || 'a' <= c <= 'z'
    }

    lemma Base64CharIs7Bit(c: char)
      requires IsBase64Char(c)
      ensures c < 128 as char
      decreases c
    {
      reveal IsBase64Char();
    }

    opaque predicate IsUnpaddedBase64String(s: string)
      decreases s
    {
      |s| % 4 == 0 &&
      forall k: char {:trigger IsBase64Char(k)} {:trigger k in s} :: 
        k in s ==>
          IsBase64Char(k)
    }

    opaque function IndexToChar(i: index): (c: char)
      ensures IsBase64Char(c)
      decreases i
    {
      reveal IsBase64Char();
      if i == 63 then
        '/'
      else if i == 62 then
        '+'
      else if 52 <= i <= 61 then
        (i - 4) as int as char
      else if 26 <= i <= 51 then
        i as int as char + 71 as char
      else
        i as int as char + 65 as char
    }

    lemma IndexToCharIsBase64(i: index)
      ensures IsBase64Char(IndexToChar(i))
      decreases i
    {
      reveal IndexToChar();
      reveal IsBase64Char();
    }

    opaque function CharToIndex(c: char): (i: index)
      requires IsBase64Char(c)
      decreases c
    {
      reveal IsBase64Char();
      reveal IndexToChar();
      if c == '/' then
        63
      else if c == '+' then
        62
      else if '0' <= c <= '9' then
        (c + 4 as char) as int as index
      else if 'a' <= c <= 'z' then
        (c - 71 as char) as int as index
      else
        (c - 65 as char) as int as index
    }

    lemma {:resource_limit 2000000} {:isolate_assertions} CharToIndexToChar(c: char)
      requires IsBase64Char(c)
      ensures IndexToChar(CharToIndex(c)) == c
      decreases c
    {
      Base64CharIs7Bit(c);
      reveal IsBase64Char();
      reveal IndexToChar();
      reveal CharToIndex();
      if c == '/' {
        assert IndexToChar(CharToIndex(c)) == c;
      } else if c == '+' {
        assert IndexToChar(CharToIndex(c)) == c;
      } else if '0' <= c <= '9' {
        assert IndexToChar(CharToIndex(c)) == c;
      } else if 'a' <= c < 'm' {
        assert IndexToChar(CharToIndex(c)) == c;
      } else if 'm' <= c <= 'z' {
        assert IndexToChar(CharToIndex(c)) == c;
      } else {
        assert IndexToChar(CharToIndex(c)) == c;
      }
    }

    lemma {:isolate_assertions} IndexToCharToIndex(i: index)
      ensures (IndexToCharIsBase64(i); CharToIndex(IndexToChar(i)) == i)
      decreases i
    {
      reveal IsBase64Char();
      reveal IndexToChar();
      reveal CharToIndex();
      IndexToCharIsBase64(i);
      if i == 63 {
        assert CharToIndex(IndexToChar(i)) == i;
      } else if i == 62 {
        assert CharToIndex(IndexToChar(i)) == i;
      } else if 52 <= i <= 61 {
        assert CharToIndex(IndexToChar(i)) == i;
      } else if 26 <= i <= 51 {
        assert CharToIndex(IndexToChar(i)) == i;
      } else {
        assert CharToIndex(IndexToChar(i)) == i;
      }
    }

    lemma IndexToCharToIndexAuto()
      ensures forall x: bv6 {:trigger IndexToChar(x)} :: (IndexToCharIsBase64(x); CharToIndex(IndexToChar(x)) == x)
    {
      forall x: index | true
        ensures (IndexToCharIsBase64(x); CharToIndex(IndexToChar(x)) == x)
      {
        IndexToCharToIndex(x);
      }
    }

    lemma CharToIndexToCharAuto()
      ensures forall c: char {:trigger CharToIndex(c)} {:trigger IsBase64Char(c)} | IsBase64Char(c) :: IndexToChar(CharToIndex(c)) == c
    {
      forall c: char | IsBase64Char(c)
        ensures IndexToChar(CharToIndex(c)) == c
      {
        CharToIndexToChar(c);
      }
    }

    opaque function BV24ToSeq(x: bv24): (ret: seq<bv8>)
      ensures |ret| == 3
      decreases x
    {
      var b0: bv8 := ((x >> 16 as bv5) & 255) as bv8;
      var b1: bv8 := ((x >> 8 as bv5) & 255) as bv8;
      var b2: bv8 := (x & 255) as bv8;
      [b0, b1, b2]
    }

    opaque function SeqToBV24(x: seq<bv8>): (ret: bv24)
      requires |x| == 3
      decreases x
    {
      (x[0] as bv24 << 16 as bv5) | (x[1] as bv24 << 8 as bv5) | x[2] as bv24
    }

    lemma BV24ToSeqToBV24(x: bv24)
      ensures SeqToBV24(BV24ToSeq(x)) == x
      decreases x
    {
      reveal BV24ToSeq();
      reveal SeqToBV24();
    }

    lemma SeqToBV24ToSeq(s: seq<bv8>)
      requires |s| == 3
      ensures BV24ToSeq(SeqToBV24(s)) == s
      decreases s
    {
      reveal SeqToBV24();
      reveal BV24ToSeq();
    }

    opaque function BV24ToIndexSeq(x: bv24): (ret: seq<index>)
      ensures |ret| == 4
      decreases x
    {
      var b0: index := ((x >> 18 as bv5) & 63) as index;
      var b1: index := ((x >> 12 as bv5) & 63) as index;
      var b2: index := ((x >> 6 as bv5) & 63) as index;
      var b3: index := (x & 63) as index;
      [b0, b1, b2, b3]
    }

    opaque function IndexSeqToBV24(x: seq<index>): (ret: bv24)
      requires |x| == 4
      decreases x
    {
      (x[0] as bv24 << 18 as bv5) | (x[1] as bv24 << 12 as bv5) | (x[2] as bv24 << 6 as bv5) | x[3] as bv24
    }

    lemma BV24ToIndexSeqToBV24(x: bv24)
      ensures IndexSeqToBV24(BV24ToIndexSeq(x)) == x
      decreases x
    {
      reveal IndexSeqToBV24();
      reveal BV24ToIndexSeq();
    }

    lemma IndexSeqToBV24ToIndexSeq(s: seq<index>)
      requires |s| == 4
      ensures BV24ToIndexSeq(IndexSeqToBV24(s)) == s
      decreases s
    {
      reveal IndexSeqToBV24();
      reveal BV24ToIndexSeq();
    }

    opaque function DecodeBlock(s: seq<index>): (ret: seq<bv8>)
      requires |s| == 4
      ensures |ret| == 3
      decreases s
    {
      BV24ToSeq(IndexSeqToBV24(s))
    }

    opaque function EncodeBlock(s: seq<bv8>): (ret: seq<index>)
      requires |s| == 3
      ensures |ret| == 4
      decreases s
    {
      BV24ToIndexSeq(SeqToBV24(s))
    }

    lemma EncodeDecodeBlock(s: seq<bv8>)
      requires |s| == 3
      ensures DecodeBlock(EncodeBlock(s)) == s
      decreases s
    {
      reveal EncodeBlock();
      reveal DecodeBlock();
      ghost var b := SeqToBV24(s);
      BV24ToIndexSeqToBV24(b);
      SeqToBV24ToSeq(s);
    }

    lemma DecodeEncodeBlock(s: seq<index>)
      requires |s| == 4
      ensures EncodeBlock(DecodeBlock(s)) == s
      decreases s
    {
      reveal EncodeBlock();
      reveal DecodeBlock();
      ghost var b := IndexSeqToBV24(s);
      BV24ToSeqToBV24(b);
      IndexSeqToBV24ToIndexSeq(s);
    }

    opaque function {:isolate_assertions} DecodeRecursively(s: seq<index>): (b: seq<bv8>)
      requires |s| % 4 == 0
      decreases |s|
    {
      if |s| == 0 then
        []
      else
        DecodeBlock(s[..4]) + DecodeRecursively(s[4..])
    } by method {
      var resultLength := |s| / 4 * 3;
      var result := new bv8[resultLength] ((i: nat) => 0);
      var i := |s|;
      var j := resultLength;
      reveal DecodeRecursively();
      while i > 0
        invariant i % 4 == 0
        invariant 0 <= i <= |s|
        invariant i * 3 == j * 4
        invariant 0 <= j <= resultLength
        invariant result[j..] == DecodeRecursively(s[i..])
        decreases i - 0
      {
        i := i - 4;
        j := j - 3;
        var block := DecodeBlock(s[i .. i + 4]);
        result[j] := block[0];
        result[j + 1] := block[1];
        result[j + 2] := block[2];
        assert s[i..][..4] == s[i .. i + 4];
        assert s[i..][4..] == s[i + 4..];
        assert result[j .. j + 3] == block;
        calc {
          DecodeBlock(s[i .. i + 4]) + DecodeRecursively(s[i + 4..]);
          DecodeBlock(s[i..][..4]) + DecodeRecursively(s[i..][4..]);
          DecodeRecursively(s[i..]);
        }
      }
      b := result[..];
    }

    lemma /*{:_induction s}*/ DecodeRecursivelyBounds(s: seq<index>)
      requires |s| % 4 == 0
      ensures |DecodeRecursively(s)| == |s| / 4 * 3
      ensures |DecodeRecursively(s)| % 3 == 0
      ensures |DecodeRecursively(s)| == 0 ==> |s| == 0
      decreases s
    {
      reveal DecodeRecursively();
    }

    lemma /*{:_induction s}*/ DecodeRecursivelyBlock(s: seq<index>)
      requires |s| % 4 == 0
      ensures (DecodeRecursivelyBounds(s); ghost var b: seq<bv8> := DecodeRecursively(s); |b| != 0 ==> EncodeBlock(b[..3]) == s[..4])
      decreases s
    {
      DecodeRecursivelyBounds(s);
      if |s| == 0 {
      } else {
        DecodeEncodeBlock(s[..4]);
        reveal DecodeRecursively();
      }
    }

    opaque function {:isolate_assertions} EncodeRecursively(b: seq<bv8>): (s: seq<index>)
      requires |b| % 3 == 0
      decreases b
    {
      if |b| == 0 then
        []
      else
        EncodeBlock(b[..3]) + EncodeRecursively(b[3..])
    } by method {
      var resultLength := |b| / 3 * 4;
      var result := new index[resultLength] ((i: nat) => 0);
      var i := |b|;
      var j := resultLength;
      reveal EncodeRecursively();
      while i > 0
        invariant i % 3 == 0
        invariant 0 <= i <= |b|
        invariant i * 4 == j * 3
        invariant 0 <= j <= resultLength
        invariant result[j..] == EncodeRecursively(b[i..])
        decreases i - 0
      {
        i := i - 3;
        j := j - 4;
        var block := EncodeBlock(b[i .. i + 3]);
        result[j] := block[0];
        result[j + 1] := block[1];
        result[j + 2] := block[2];
        result[j + 3] := block[3];
        assert b[i..][..3] == b[i .. i + 3];
        assert b[i..][3..] == b[i + 3..];
        assert result[j .. j + 4] == block;
        calc {
          EncodeBlock(b[i .. i + 3]) + EncodeRecursively(b[i + 3..]);
          EncodeBlock(b[i..][..3]) + EncodeRecursively(b[i..][3..]);
          EncodeRecursively(b[i..]);
        }
      }
      s := result[..];
    }

    lemma /*{:_induction b}*/ EncodeRecursivelyBounds(b: seq<bv8>)
      requires |b| % 3 == 0
      ensures |EncodeRecursively(b)| == |b| / 3 * 4
      ensures |EncodeRecursively(b)| % 4 == 0
      ensures |EncodeRecursively(b)| == 0 ==> |b| == 0
      decreases b
    {
      reveal EncodeRecursively();
    }

    lemma /*{:_induction b}*/ EncodeRecursivelyBlock(b: seq<bv8>)
      requires |b| % 3 == 0
      ensures (EncodeRecursivelyBounds(b); ghost var s: seq<index> := EncodeRecursively(b); |s| != 0 ==> DecodeBlock(s[..4]) == b[..3])
      decreases b
    {
      EncodeRecursivelyBounds(b);
      if |b| == 0 {
      } else {
        EncodeDecodeBlock(b[..3]);
        reveal EncodeRecursively();
      }
    }

    lemma /*{:_induction b}*/ EncodeDecodeRecursively(b: seq<bv8>)
      requires |b| % 3 == 0
      ensures (EncodeRecursivelyBounds(b); DecodeRecursively(EncodeRecursively(b)) == b)
      decreases b
    {
      ghost var s := EncodeRecursively(b);
      EncodeRecursivelyBounds(b);
      DecodeRecursivelyBounds(s);
      if |b| == 0 {
      } else {
        calc {
          DecodeRecursively(EncodeRecursively(b));
        ==
          DecodeRecursively(s);
        ==
          {
            reveal DecodeRecursively();
          }
          DecodeBlock(s[..4]) + DecodeRecursively(s[4..]);
        ==
          {
            EncodeRecursivelyBlock(b);
          }
          b[..3] + DecodeRecursively(s[4..]);
        ==
          {
            reveal EncodeRecursively();
          }
          b[..3] + DecodeRecursively(EncodeRecursively(b[3..]));
        ==
          {
            EncodeDecodeRecursively(b[3..]);
          }
          b[..3] + b[3..];
        ==
          b;
        }
      }
    }

    lemma /*{:_induction s}*/ DecodeEncodeRecursively(s: seq<index>)
      requires |s| % 4 == 0
      ensures (DecodeRecursivelyBounds(s); EncodeRecursively(DecodeRecursively(s)) == s)
      decreases s
    {
      ghost var b := DecodeRecursively(s);
      DecodeRecursivelyBounds(s);
      EncodeRecursivelyBounds(b);
      if |s| == 0 {
      } else {
        calc {
          EncodeRecursively(DecodeRecursively(s));
        ==
          EncodeRecursively(b);
        ==
          {
            reveal EncodeRecursively();
          }
          EncodeBlock(b[..3]) + EncodeRecursively(b[3..]);
        ==
          {
            DecodeRecursivelyBlock(s);
          }
          s[..4] + EncodeRecursively(b[3..]);
        ==
          {
            reveal DecodeRecursively();
          }
          s[..4] + EncodeRecursively(DecodeRecursively(s[4..]));
        ==
          {
            DecodeEncodeRecursively(s[4..]);
          }
          s[..4] + s[4..];
        ==
          s;
        }
      }
    }

    opaque function FromCharsToIndices(s: seq<char>): (b: seq<index>)
      requires forall k: char {:trigger IsBase64Char(k)} {:trigger k in s} :: k in s ==> IsBase64Char(k)
      ensures |b| == |s|
      decreases s
    {
      seq(|s|, (i: int) requires 0 <= i < |s| => CharToIndex(s[i]))
    }

    opaque function FromIndicesToChars(b: seq<index>): (s: seq<char>)
      ensures forall k: char {:trigger IsBase64Char(k)} {:trigger k in s} :: k in s ==> IsBase64Char(k)
      ensures |s| == |b|
      decreases b
    {
      seq(|b|, (i: int) requires 0 <= i < |b| => IndexToChar(b[i]))
    }

    lemma FromCharsToIndicesToChars(s: seq<char>)
      requires forall k: char {:trigger IsBase64Char(k)} {:trigger k in s} :: k in s ==> IsBase64Char(k)
      ensures FromIndicesToChars(FromCharsToIndices(s)) == s
      decreases s
    {
      reveal FromIndicesToChars();
      reveal FromCharsToIndices();
      CharToIndexToCharAuto();
    }

    lemma FromIndicesToCharsToIndices(b: seq<index>)
      ensures FromCharsToIndices(FromIndicesToChars(b)) == b
      decreases b
    {
      reveal FromIndicesToChars();
      reveal FromCharsToIndices();
      IndexToCharToIndexAuto();
    }

    opaque function DecodeUnpadded(s: seq<char>): (b: seq<bv8>)
      requires IsUnpaddedBase64String(s)
      decreases s
    {
      reveal IsUnpaddedBase64String();
      DecodeRecursively(FromCharsToIndices(s))
    }

    lemma DecodeUnpaddedBounds(s: seq<char>)
      requires IsUnpaddedBase64String(s)
      ensures |DecodeUnpadded(s)| == |s| / 4 * 3
      ensures |DecodeUnpadded(s)| % 3 == 0
      decreases s
    {
      reveal DecodeUnpadded();
      reveal IsUnpaddedBase64String();
      reveal IsBase64String();
      ghost var indices := FromCharsToIndices(s);
      assert |indices| == |s|;
      DecodeRecursivelyBounds(indices);
    }

    opaque function EncodeUnpadded(b: seq<bv8>): (s: seq<char>)
      requires |b| % 3 == 0
      decreases b
    {
      EncodeDecodeRecursively(b);
      FromIndicesToChars(EncodeRecursively(b))
    }

    lemma EncodeUnpaddedNotPadded(b: seq<bv8>)
      requires |b| % 3 == 0
      requires b != []
      ensures (EncodeUnpaddedBounds(b); ghost var s: seq<char> := EncodeUnpadded(b); !Is1Padding(s[|s| - 4..]) && !Is2Padding(s[|s| - 4..]))
      decreases b
    {
      ghost var s := EncodeUnpadded(b);
      EncodeUnpaddedBounds(b);
      ghost var suffix := s[|s| - 4..];
      reveal EncodeUnpadded();
      assert forall c: char {:trigger IsBase64Char(c)} {:trigger c in s} :: c in s ==> IsBase64Char(c);
      assert IsBase64Char(s[|s| - 1]);
      assert s[|s| - 1] != '=' by {
        reveal IsBase64Char();
      }
      reveal Is1Padding();
      reveal Is2Padding();
    }

    lemma EncodeUnpaddedBounds(b: seq<bv8>)
      requires |b| % 3 == 0
      ensures |EncodeUnpadded(b)| == |b| / 3 * 4
      ensures |EncodeUnpadded(b)| % 4 == 0
      decreases b
    {
      reveal EncodeUnpadded();
      EncodeRecursivelyBounds(b);
    }

    lemma EncodeUnpaddedBase64(b: seq<bv8>)
      requires |b| % 3 == 0
      ensures IsUnpaddedBase64String(EncodeUnpadded(b))
      decreases b
    {
      reveal EncodeUnpadded();
      EncodeRecursivelyBounds(b);
      reveal IsUnpaddedBase64String();
    }

    lemma EncodeDecodeUnpadded(b: seq<bv8>)
      requires |b| % 3 == 0
      ensures (EncodeUnpaddedBounds(b); EncodeUnpaddedBase64(b); DecodeUnpadded(EncodeUnpadded(b)) == b)
      decreases b
    {
      EncodeUnpaddedBase64(b);
      calc {
        DecodeUnpadded(EncodeUnpadded(b));
      ==
        {
          reveal EncodeUnpadded();
        }
        DecodeUnpadded(FromIndicesToChars(EncodeRecursively(b)));
      ==
        {
          reveal DecodeUnpadded();
          EncodeRecursivelyBounds(b);
        }
        DecodeRecursively(FromCharsToIndices(FromIndicesToChars(EncodeRecursively(b))));
      ==
        {
          FromIndicesToCharsToIndices(EncodeRecursively(b));
        }
        DecodeRecursively(EncodeRecursively(b));
      ==
        {
          EncodeDecodeRecursively(b);
        }
        b;
      }
    }

    lemma DecodeEncodeUnpadded(s: seq<char>)
      requires |s| % 4 == 0
      requires IsUnpaddedBase64String(s)
      ensures (DecodeUnpaddedBounds(s); EncodeUnpadded(DecodeUnpadded(s)) == s)
      decreases s
    {
      DecodeUnpaddedBounds(s);
      reveal IsUnpaddedBase64String();
      ghost var fromCharsToIndicesS := FromCharsToIndices(s);
      calc {
        EncodeUnpadded(DecodeUnpadded(s));
      ==
        {
          reveal DecodeUnpadded();
        }
        EncodeUnpadded(DecodeRecursively(FromCharsToIndices(s)));
      ==
        EncodeUnpadded(DecodeRecursively(fromCharsToIndicesS));
      ==
        {
          reveal EncodeUnpadded();
        }
        assert |fromCharsToIndicesS| % 4 == 0; FromIndicesToChars(EncodeRecursively(DecodeRecursively(fromCharsToIndicesS)));
      ==
        {
          DecodeEncodeRecursively(fromCharsToIndicesS);
        }
        FromIndicesToChars(fromCharsToIndicesS);
      ==
        FromIndicesToChars(FromCharsToIndices(s));
      ==
        {
          FromCharsToIndicesToChars(s);
        }
        s;
      }
    }

    opaque predicate Is1Padding(s: seq<char>)
      decreases s
    {
      |s| == 4 &&
      IsBase64Char(s[0]) &&
      IsBase64Char(s[1]) &&
      IsBase64Char(s[2]) &&
      CharToIndex(s[2]) & 3 == 0 &&
      s[3] == '='
    }

    opaque function Decode1Padding(s: seq<char>): (b: seq<bv8>)
      requires Is1Padding(s)
      ensures |b| == 2
      decreases s
    {
      reveal Is1Padding();
      var d: seq<bv8> := DecodeBlock([CharToIndex(s[0]), CharToIndex(s[1]), CharToIndex(s[2]), 0]);
      [d[0], d[1]]
    }

    opaque function Encode1Padding(b: seq<bv8>): (s: seq<char>)
      requires |b| == 2
      ensures |s| % 4 == 0
      ensures |s| == 4
      decreases b
    {
      var e: seq<index> := EncodeBlock([b[0], b[1], 0]);
      IndexToCharIsBase64(e[0]);
      IndexToCharIsBase64(e[1]);
      IndexToCharIsBase64(e[2]);
      [IndexToChar(e[0]), IndexToChar(e[1]), IndexToChar(e[2]), '=']
    }

    lemma EncodeDecodeBlock1Padding(b: seq<bv8>)
      requires |b| == 2
      ensures ghost var e: seq<index> := EncodeBlock([b[0], b[1], 0]); ghost var d: seq<bv8> := DecodeBlock([e[0], e[1], e[2], 0]); [d[0], d[1]] == b
      decreases b
    {
      reveal EncodeBlock();
      reveal DecodeBlock();
      reveal BV24ToSeq();
      reveal SeqToBV24();
      reveal IndexSeqToBV24();
      reveal BV24ToIndexSeq();
    }

    lemma Encode1PaddingIs1Padding(b: seq<bv8>)
      requires |b| == 2
      ensures Is1Padding(Encode1Padding(b))
      decreases b
    {
      ghost var s := Encode1Padding(b);
      ghost var e := EncodeBlock([b[0], b[1], 0]);
      assert s == [IndexToChar(e[0]), IndexToChar(e[1]), IndexToChar(e[2]), '='] by {
        reveal Encode1Padding();
      }
      IndexToCharIsBase64(e[0]);
      IndexToCharIsBase64(e[1]);
      IndexToCharIsBase64(e[2]);
      assert CharToIndex(s[2]) & 3 == 0 by {
        reveal Encode1Padding();
        reveal EncodeBlock();
        reveal IndexToChar();
        reveal CharToIndex();
        reveal BV24ToIndexSeq();
        reveal SeqToBV24();
      }
      assert Is1Padding(s) by {
        reveal Is1Padding();
      }
    }

    lemma EncodeDecode1Padding(b: seq<bv8>)
      requires |b| == 2
      ensures (Encode1PaddingIs1Padding(b); Decode1Padding(Encode1Padding(b)) == b)
      decreases b
    {
      Encode1PaddingIs1Padding(b);
      ghost var e := EncodeBlock([b[0], b[1], 0]);
      ghost var s := [CharToIndex(IndexToChar(e[0])), CharToIndex(IndexToChar(e[1])), CharToIndex(IndexToChar(e[2])), 0];
      ghost var s' := [e[0], e[1], e[2], 0];
      ghost var d := DecodeBlock(s);
      ghost var d' := DecodeBlock(s');
      calc {
        Decode1Padding(Encode1Padding(b));
      ==
        {
          reveal Encode1Padding();
        }
        Decode1Padding([IndexToChar(e[0]), IndexToChar(e[1]), IndexToChar(e[2]), '=']);
      ==
        {
          reveal Decode1Padding();
        }
        [d[0], d[1]];
      ==
        {
          IndexToCharToIndex(e[0]);
          IndexToCharToIndex(e[1]);
          IndexToCharToIndex(e[2]);
        }
        [d'[0], d'[1]];
      ==
        {
          EncodeDecodeBlock1Padding(b);
        }
        b;
      }
    }

    lemma {:isolate_assertions} DecodeEncode1Padding(s: seq<char>)
      requires Is1Padding(s)
      ensures Encode1Padding(Decode1Padding(s)) == s
      decreases s
    {
      reveal Is1Padding();
      ghost var i := [CharToIndex(s[0]), CharToIndex(s[1]), CharToIndex(s[2]), 0];
      ghost var d := DecodeBlock(i);
      ghost var e := EncodeBlock([d[0], d[1], 0]);
      ghost var d' := [IndexToChar(e[0]), IndexToChar(e[1]), IndexToChar(e[2]), '='];
      calc {
        Encode1Padding(Decode1Padding(s));
      ==
        {
          reveal Decode1Padding();
        }
        Encode1Padding([d[0], d[1]]);
      ==
        {
          reveal Encode1Padding();
        }
        d';
      ==
        {
          reveal EncodeBlock();
          reveal DecodeBlock();
          reveal BV24ToSeq();
          reveal SeqToBV24();
          reveal IndexSeqToBV24();
          reveal BV24ToIndexSeq();
          assert d'[0] == IndexToChar(CharToIndex(s[0]));
          assert d'[1] == IndexToChar(CharToIndex(s[1]));
          assert d'[2] == IndexToChar(CharToIndex(s[2]));
        }
        [IndexToChar(CharToIndex(s[0])), IndexToChar(CharToIndex(s[1])), IndexToChar(CharToIndex(s[2])), '='];
      ==
        {
          CharToIndexToChar(s[0]);
          CharToIndexToChar(s[1]);
          CharToIndexToChar(s[2]);
        }
        s;
      }
    }

    opaque predicate Is2Padding(s: seq<char>)
      decreases s
    {
      |s| == 4 &&
      IsBase64Char(s[0]) &&
      IsBase64Char(s[1]) &&
      CharToIndex(s[1]) % 16 == 0 &&
      s[2] == '=' &&
      s[3] == '='
    }

    opaque function Decode2Padding(s: seq<char>): (b: seq<bv8>)
      requires Is2Padding(s)
      ensures |b| == 1
      decreases s
    {
      reveal Is2Padding();
      var d: seq<bv8> := DecodeBlock([CharToIndex(s[0]), CharToIndex(s[1]), 0, 0]);
      [d[0]]
    }

    opaque function Encode2Padding(b: seq<bv8>): (s: seq<char>)
      requires |b| == 1
      ensures |s| % 4 == 0
      ensures |s| == 4
      decreases b
    {
      var e: seq<index> := EncodeBlock([b[0], 0, 0]);
      IndexToCharIsBase64(e[0]);
      IndexToCharIsBase64(e[1]);
      [IndexToChar(e[0]), IndexToChar(e[1]), '=', '=']
    }

    lemma Encode2PaddingIs2Padding(b: seq<bv8>)
      requires |b| == 1
      ensures Is2Padding(Encode2Padding(b))
      decreases b
    {
      reveal IndexToChar();
      reveal Is2Padding();
      reveal CharToIndex();
      reveal Encode2Padding();
      reveal EncodeBlock();
      reveal BV24ToSeq();
      reveal SeqToBV24();
      reveal IndexSeqToBV24();
      reveal BV24ToIndexSeq();
      reveal IsBase64Char();
    }

    lemma DecodeEncodeBlock2Padding(b: seq<bv8>)
      requires |b| == 1
      ensures ghost var e: seq<index> := EncodeBlock([b[0], 0, 0]); ghost var d: seq<bv8> := DecodeBlock([e[0], e[1], 0, 0]); [d[0]] == b
      decreases b
    {
      reveal EncodeBlock();
      reveal DecodeBlock();
      reveal BV24ToSeq();
      reveal SeqToBV24();
      reveal IndexSeqToBV24();
      reveal BV24ToIndexSeq();
    }

    lemma EncodeDecode2Padding(b: seq<bv8>)
      requires |b| == 1
      ensures (Encode2PaddingIs2Padding(b); Decode2Padding(Encode2Padding(b)) == b)
      decreases b
    {
      Encode2PaddingIs2Padding(b);
      ghost var e := EncodeBlock([b[0], 0, 0]);
      calc {
        Decode2Padding(Encode2Padding(b));
      ==
        {
          reveal Encode2Padding();
        }
        Decode2Padding([IndexToChar(e[0]), IndexToChar(e[1]), '=', '=']);
      ==
        {
          reveal Decode2Padding();
        }
        [DecodeBlock([CharToIndex(IndexToChar(e[0])), CharToIndex(IndexToChar(e[1])), 0, 0])[0]];
      ==
        {
          IndexToCharToIndex(e[0]);
          IndexToCharToIndex(e[1]);
        }
        [DecodeBlock([e[0], e[1], 0, 0])[0]];
      ==
        {
          DecodeEncodeBlock2Padding(b);
        }
        b;
      }
    }

    lemma DecodeEncode2Padding(s: seq<char>)
      requires Is2Padding(s)
      ensures Encode2Padding(Decode2Padding(s)) == s
      decreases s
    {
      reveal Is2Padding();
      ghost var i := [CharToIndex(s[0]), CharToIndex(s[1]), 0, 0];
      ghost var d := DecodeBlock(i);
      ghost var e := EncodeBlock([d[0], 0, 0]);
      ghost var d' := [IndexToChar(e[0]), IndexToChar(e[1]), '=', '='];
      calc {
        Encode2Padding(Decode2Padding(s));
      ==
        {
          reveal Decode2Padding();
        }
        Encode2Padding([d[0]]);
      ==
        {
          reveal Encode2Padding();
        }
        d';
      ==
        {
          reveal EncodeBlock();
          reveal DecodeBlock();
          reveal BV24ToSeq();
          reveal SeqToBV24();
          reveal IndexSeqToBV24();
          reveal BV24ToIndexSeq();
        }
        [IndexToChar(CharToIndex(s[0])), IndexToChar(CharToIndex(s[1])), '=', '='];
      ==
        {
          CharToIndexToChar(s[0]);
          CharToIndexToChar(s[1]);
        }
        s;
      }
    }

    opaque predicate IsBase64String(s: string)
      decreases s
    {
      reveal IsUnpaddedBase64String();
      reveal Is2Padding();
      var finalBlockStart: int := |s| - 4;
      |s| % 4 == 0 &&
      (IsUnpaddedBase64String(s) || (IsUnpaddedBase64String(s[..finalBlockStart]) && (Is1Padding(s[finalBlockStart..]) || Is2Padding(s[finalBlockStart..]))))
    }

    opaque function DecodeValid(s: seq<char>): (b: seq<bv8>)
      requires IsBase64String(s)
      decreases s
    {
      reveal IsUnpaddedBase64String();
      reveal IsBase64String();
      if s == [] then
        []
      else
        var finalBlockStart: int := |s| - 4; var prefix: seq<char>, suffix: seq<char> := s[..finalBlockStart], s[finalBlockStart..]; if Is1Padding(suffix) then DecodeUnpadded(prefix) + Decode1Padding(suffix) else if Is2Padding(suffix) then DecodeUnpadded(prefix) + Decode2Padding(suffix) else DecodeUnpadded(s)
    }

    lemma AboutDecodeValid(s: seq<char>, b: seq<bv8>)
      requires IsBase64String(s) && b == DecodeValid(s)
      ensures 4 <= |s| ==> ghost var finalBlockStart: int := |s| - 4; ghost var prefix: seq<char>, suffix: seq<char> := s[..finalBlockStart], s[finalBlockStart..]; (Is1Padding(suffix) && IsUnpaddedBase64String(prefix) <==> |b| % 3 == 2 && |b| > 1) && (Is2Padding(suffix) && IsUnpaddedBase64String(prefix) <==> |b| % 3 == 1 && |b| > 0) && (!Is1Padding(suffix) && !Is2Padding(suffix) && IsUnpaddedBase64String(s) <==> |b| % 3 == 0 && |b| > 1)
      decreases s, b
    {
      reveal DecodeValid();
      reveal IsUnpaddedBase64String();
      reveal IsBase64String();
      if 4 <= |s| {
        ghost var finalBlockStart := |s| - 4;
        ghost var prefix, suffix := s[..finalBlockStart], s[finalBlockStart..];
        if s == [] {
        } else if Is1Padding(suffix) {
          assert !Is2Padding(suffix) by {
            reveal IsBase64Char();
            reveal Is1Padding();
            reveal Is2Padding();
          }
          ghost var x, y := DecodeUnpadded(prefix), Decode1Padding(suffix);
          assert b == x + y;
          assert |x| == |x| / 3 * 3 && |y| == 2 && |b| > 1 by {
            DecodeUnpaddedBounds(prefix);
          }
          Mod3(|x| / 3, |y|, |b|);
        } else if Is2Padding(suffix) {
          ghost var x, y := DecodeUnpadded(prefix), Decode2Padding(suffix);
          assert b == x + y;
          assert |x| == |x| / 3 * 3 && |y| == 1 && |b| > 0 by {
            DecodeUnpaddedBounds(prefix);
          }
          Mod3(|x| / 3, |y|, |b|);
        } else {
          assert b == DecodeUnpadded(s);
          assert |b| % 3 == 0 && |b| > 1 by {
            DecodeUnpaddedBounds(s);
          }
        }
      }
    }

    lemma Mod3(x: nat, k: nat, n: nat)
      requires k < 3 && n == 3 * x + k
      ensures n % 3 == k
      decreases x, k, n
    {
    }

    opaque function DecodeBV(s: seq<char>): (b: Result<seq<bv8>, string>)
      ensures IsBase64String(s) ==> b.Success?
      decreases s
    {
      if IsBase64String(s) then
        Success(DecodeValid(s))
      else
        Failure(""The encoding is malformed"")
    }

    lemma DecodeBVFailure(s: seq<char>)
      ensures !IsBase64String(s) ==> DecodeBV(s).Failure?
      decreases s
    {
      reveal DecodeBV();
    }

    opaque ghost predicate StringIs7Bit(s: string)
      decreases s
    {
      forall c: char {:trigger c in s} :: 
        c in s ==>
          c < 128 as char
    }

    lemma UnpaddedBase64StringIs7Bit(s: string)
      requires IsUnpaddedBase64String(s)
      ensures StringIs7Bit(s)
      decreases s
    {
      reveal IsUnpaddedBase64String();
      reveal IsBase64Char();
      reveal StringIs7Bit();
    }

    lemma Is7Bit1Padding(s: string)
      requires Is1Padding(s)
      ensures StringIs7Bit(s)
      decreases s
    {
      reveal IsBase64Char();
      reveal Is1Padding();
      reveal StringIs7Bit();
    }

    lemma Is7Bit2Padding(s: string)
      requires Is2Padding(s)
      ensures StringIs7Bit(s)
      decreases s
    {
      reveal IsBase64Char();
      reveal Is2Padding();
      reveal StringIs7Bit();
    }

    opaque function EncodeBV(b: seq<bv8>): (s: seq<char>)
      decreases b
    {
      if |b| % 3 == 0 then
        EncodeUnpaddedBounds(b);
        EncodeUnpadded(b)
      else if |b| % 3 == 1 then
        assert |b| >= 1;
        EncodeUnpaddedBounds(b[..|b| - 1]);
        var s1: seq<char>, s2: seq<char> := EncodeUnpadded(b[..|b| - 1]), Encode2Padding(b[|b| - 1..]);
        s1 + s2
      else
        assert |b| % 3 == 2; assert |b| >= 2; EncodeUnpaddedBounds(b[..|b| - 2]); var s1: seq<char>, s2: seq<char> := EncodeUnpadded(b[..|b| - 2]), Encode1Padding(b[|b| - 2..]); s1 + s2
    }

    lemma EncodeBVIsUnpadded(b: seq<bv8>)
      requires |b| % 3 == 0
      ensures EncodeBV(b) == EncodeUnpadded(b)
      decreases b
    {
      reveal EncodeBV();
    }

    lemma EncodeBVIs2Padded(b: seq<bv8>)
      requires |b| % 3 == 1
      ensures EncodeBV(b) == EncodeUnpadded(b[..|b| - 1]) + Encode2Padding(b[|b| - 1..])
      decreases b
    {
      reveal EncodeBV();
    }

    lemma EncodeBVIs1Padded(b: seq<bv8>)
      requires |b| % 3 == 2
      ensures EncodeBV(b) == EncodeUnpadded(b[..|b| - 2]) + Encode1Padding(b[|b| - 2..])
      decreases b
    {
      reveal EncodeBV();
    }

    lemma EncodeBVLengthCongruentToZeroMod4(b: seq<bv8>)
      ensures |EncodeBV(b)| % 4 == 0
      decreases b
    {
      reveal EncodeBV();
      if |b| % 3 == 0 {
        EncodeUnpaddedBounds(b);
      } else if |b| % 3 == 1 {
        EncodeUnpaddedBounds(b[..|b| - 1]);
      } else {
        EncodeUnpaddedBounds(b[..|b| - 2]);
      }
    }

    lemma EncodeBVIsBase64(b: seq<bv8>)
      ensures IsBase64String(EncodeBV(b))
      decreases b
    {
      reveal EncodeBV();
      reveal IsBase64String();
      EncodeBVLengthExact(b);
      if |EncodeBV(b)| < 4 {
        reveal IsUnpaddedBase64String();
      } else if |b| % 3 == 0 {
        EncodeUnpaddedBase64(b);
      } else if |b| % 3 == 1 {
        ghost var bStart := b[..|b| - 1];
        ghost var bEnd := b[|b| - 1..];
        EncodeUnpaddedBase64(bStart);
        Encode2PaddingIs2Padding(bEnd);
      } else {
        ghost var bStart := b[..|b| - 2];
        ghost var bEnd := b[|b| - 2..];
        EncodeUnpaddedBase64(bStart);
        Encode1PaddingIs1Padding(bEnd);
      }
    }

    lemma EncodeBVLengthExact(b: seq<bv8>)
      ensures ghost var s: seq<char> := EncodeBV(b); (|b| % 3 == 0 ==> |s| == |b| / 3 * 4) && (|b| % 3 != 0 ==> |s| == |b| / 3 * 4 + 4)
      decreases b
    {
      reveal EncodeBV();
      reveal Is1Padding();
      reveal Is2Padding();
      ghost var s := EncodeBV(b);
      if |b| % 3 == 0 {
        assert s == EncodeUnpadded(b);
        EncodeUnpaddedBounds(b);
        assert |s| == |b| / 3 * 4;
      } else if |b| % 3 == 1 {
        EncodeUnpaddedBounds(b[..|b| - 1]);
        assert s == EncodeUnpadded(b[..|b| - 1]) + Encode2Padding(b[|b| - 1..]);
        calc {
          |s|;
        ==
          |EncodeUnpadded(b[..|b| - 1])| + |Encode2Padding(b[|b| - 1..])|;
        ==
          {
            assert |Encode2Padding(b[|b| - 1..])| == 4;
          }
          |EncodeUnpadded(b[..|b| - 1])| + 4;
        ==
          {
            assert |EncodeUnpadded(b[..|b| - 1])| == |b[..|b| - 1]| / 3 * 4;
          }
          |b[..|b| - 1]| / 3 * 4 + 4;
        ==
          {
            assert |b[..|b| - 1]| == |b| - 1;
          }
          (|b| - 1) / 3 * 4 + 4;
        ==
          {
            assert (|b| - 1) / 3 == |b| / 3;
          }
          |b| / 3 * 4 + 4;
        }
      } else {
        EncodeUnpaddedBounds(b[..|b| - 2]);
        assert s == EncodeUnpadded(b[..|b| - 2]) + Encode1Padding(b[|b| - 2..]);
        Encode1PaddingIs1Padding(b[|b| - 2..]);
        calc {
          |s|;
        ==
          |EncodeUnpadded(b[..|b| - 2])| + |Encode1Padding(b[|b| - 2..])|;
        ==
          {
            assert |Encode1Padding(b[|b| - 2..])| == 4;
          }
          |EncodeUnpadded(b[..|b| - 2])| + 4;
        ==
          {
            assert |EncodeUnpadded(b[..|b| - 2])| == |b[..|b| - 2]| / 3 * 4;
          }
          |b[..|b| - 2]| / 3 * 4 + 4;
        ==
          {
            assert |b[..|b| - 2]| == |b| - 2;
          }
          (|b| - 2) / 3 * 4 + 4;
        ==
          {
            assert (|b| - 2) / 3 == |b| / 3;
          }
          |b| / 3 * 4 + 4;
        }
      }
    }

    lemma EncodeBVLengthBound(b: seq<bv8>)
      ensures ghost var s: seq<char> := EncodeBV(b); |s| <= |b| / 3 * 4 + 4
      decreases b
    {
      EncodeBVLengthExact(b);
    }

    lemma SeqPartsMakeWhole<T>(s: seq<T>, i: nat)
      requires i <= |s|
      ensures s[..i] + s[i..] == s
      decreases s, i
    {
    }

    lemma DecodeValidEncodeEmpty(s: seq<char>)
      requires s == []
      ensures (reveal IsUnpaddedBase64String(); reveal IsBase64String(); EncodeBV(DecodeValid(s)) == s)
      decreases s
    {
      assert IsBase64String(s) by {
        reveal IsBase64String();
        reveal IsUnpaddedBase64String();
      }
      ghost var b := DecodeValid(s);
      assert b == [] by {
        reveal DecodeValid();
      }
      assert EncodeBV(b) == [] by {
        reveal EncodeBV();
        reveal EncodeUnpadded();
        reveal EncodeRecursively();
        reveal FromIndicesToChars();
      }
    }

    lemma EncodeDecodeValidEmpty(b: seq<bv8>)
      requires b == []
      ensures (EncodeBVIsBase64(b); DecodeValid(EncodeBV(b)) == b)
      decreases b
    {
      assert EncodeBV(b) == [] by {
        reveal EncodeBV();
        reveal EncodeUnpadded();
        reveal EncodeRecursively();
        reveal FromIndicesToChars();
      }
      EncodeBVIsBase64(b);
      assert DecodeValid([]) == [] by {
        reveal DecodeValid();
      }
    }

    lemma DecodeValidEncodeUnpadded(s: seq<char>)
      requires IsBase64String(s)
      requires |s| >= 4
      requires !Is1Padding(s[|s| - 4..])
      requires !Is2Padding(s[|s| - 4..])
      ensures EncodeBV(DecodeValid(s)) == s
      decreases s
    {
      reveal EncodeBV();
      reveal DecodeValid();
      reveal IsBase64String();
      DecodeUnpaddedBounds(s);
      calc {
        EncodeBV(DecodeValid(s));
      ==
        EncodeBV(DecodeUnpadded(s));
      ==
        EncodeUnpadded(DecodeUnpadded(s));
      ==
        {
          DecodeEncodeUnpadded(s);
        }
        s;
      }
    }

    lemma EncodeDecodeValidUnpadded(b: seq<bv8>)
      requires |b| % 3 == 0
      requires b != []
      ensures ghost var s: seq<char> := EncodeBV(b); IsUnpaddedBase64String(s) && |s| >= 4 && !Is1Padding(s[|s| - 4..]) && !Is2Padding(s[|s| - 4..]) && s == EncodeUnpadded(b)
      decreases b
    {
      EncodeUnpaddedBase64(b);
      EncodeUnpaddedBounds(b);
      ghost var s := EncodeBV(b);
      assert s == EncodeUnpadded(b) by {
        EncodeBVIsUnpadded(b);
      }
      assert !Is1Padding(s[|s| - 4..]) by {
        EncodeUnpaddedNotPadded(b);
      }
      assert !Is2Padding(s[|s| - 4..]) by {
        EncodeUnpaddedNotPadded(b);
      }
    }

    lemma EncodeDecodeValid2Padded(b: seq<bv8>)
      requires |b| % 3 == 1
      ensures ghost var s: seq<char> := EncodeBV(b); s == EncodeUnpadded(b[..|b| - 1]) + Encode2Padding(b[|b| - 1..]) && Is2Padding(s[|s| - 4..])
      decreases b
    {
      EncodeUnpaddedBase64(b[..|b| - 1]);
      EncodeUnpaddedBounds(b[..|b| - 1]);
      reveal EncodeBV();
      ghost var s := EncodeBV(b);
      Encode2PaddingIs2Padding(b[|b| - 1..]);
      assert Is2Padding(s[|s| - 4..]);
    }

    lemma EncodeDecodeValid1Padded(b: seq<bv8>)
      requires |b| % 3 == 2
      ensures ghost var s: seq<char> := EncodeBV(b); s == EncodeUnpadded(b[..|b| - 2]) + Encode1Padding(b[|b| - 2..]) && |s| >= 4 && IsUnpaddedBase64String(s[..|s| - 4]) && Is1Padding(s[|s| - 4..])
      decreases b
    {
      EncodeUnpaddedBase64(b[..|b| - 2]);
      EncodeUnpaddedBounds(b[..|b| - 2]);
      reveal EncodeBV();
      ghost var s := EncodeBV(b);
      Encode1PaddingIs1Padding(b[|b| - 2..]);
      assert Is1Padding(s[|s| - 4..]);
    }

    lemma DecodeValidUnpaddedPartialFrom1PaddedSeq(s: seq<char>)
      requires IsBase64String(s)
      requires |s| >= 4
      requires Is1Padding(s[|s| - 4..])
      ensures (reveal IsUnpaddedBase64String(); reveal IsBase64String(); reveal DecodeValid(); DecodeValid(s)[..|DecodeValid(s)| - 2] == DecodeUnpadded(s[..|s| - 4]))
      decreases s
    {
      reveal IsBase64String();
      reveal DecodeValid();
    }

    lemma DecodeValid1PaddedPartialFrom1PaddedSeq(s: seq<char>)
      requires IsBase64String(s)
      requires |s| >= 4
      requires Is1Padding(s[|s| - 4..])
      ensures (reveal DecodeValid(); DecodeValid(s)[|DecodeValid(s)| - 2..] == Decode1Padding(s[|s| - 4..]))
      decreases s
    {
      reveal DecodeValid();
    }

    lemma DecodeValid1PaddingLengthMod3(s: seq<char>)
      requires IsBase64String(s)
      requires |s| >= 4
      requires Is1Padding(s[|s| - 4..])
      ensures |DecodeValid(s)| % 3 == 2
      decreases s
    {
      assert IsUnpaddedBase64String(s[..|s| - 4]) by {
        UnpaddedBase64Prefix(s);
      }
      AboutDecodeValid(s, DecodeValid(s));
    }

    lemma {:resource_limit 12000000} DecodeValidEncode1Padding(s: seq<char>)
      requires IsBase64String(s)
      requires |s| >= 4
      requires Is1Padding(s[|s| - 4..])
      ensures EncodeBV(DecodeValid(s)) == s
      decreases s
    {
      assert |DecodeValid(s)| % 3 == 2 by {
        DecodeValid1PaddingLengthMod3(s);
      }
      calc {
        EncodeBV(DecodeValid(s));
      ==
        {
          reveal EncodeBV();
        }
        EncodeUnpadded(DecodeValid(s)[..|DecodeValid(s)| - 2]) + Encode1Padding(DecodeValid(s)[|DecodeValid(s)| - 2..]);
      ==
        {
          DecodeValidUnpaddedPartialFrom1PaddedSeq(s);
          reveal IsBase64String();
          reveal IsUnpaddedBase64String();
        }
        EncodeUnpadded(DecodeUnpadded(s[..|s| - 4])) + Encode1Padding(DecodeValid(s)[|DecodeValid(s)| - 2..]);
      ==
        {
          reveal IsUnpaddedBase64String();
          DecodeEncodeUnpadded(s[..|s| - 4]);
        }
        s[..|s| - 4] + Encode1Padding(DecodeValid(s)[|DecodeValid(s)| - 2..]);
      ==
        {
          DecodeValid1PaddedPartialFrom1PaddedSeq(s);
        }
        s[..|s| - 4] + Encode1Padding(Decode1Padding(s[|s| - 4..]));
      ==
        {
          DecodeEncode1Padding(s[|s| - 4..]);
        }
        s[..|s| - 4] + s[|s| - 4..];
      ==
        {
          SeqPartsMakeWhole(s, |s| - 4);
        }
        s;
      }
    }

    lemma DecodeValidPartialsFrom2PaddedSeq(s: seq<char>)
      requires IsBase64String(s)
      requires |s| >= 4
      requires Is2Padding(s[|s| - 4..])
      ensures (reveal IsUnpaddedBase64String(); reveal DecodeValid(); reveal IsBase64String(); ghost var b: seq<bv8> := DecodeValid(s); b[..|b| - 1] == DecodeUnpadded(s[..|s| - 4]) && b[|b| - 1..] == Decode2Padding(s[|s| - 4..]))
      decreases s
    {
      reveal IsUnpaddedBase64String();
      reveal IsBase64String();
      reveal DecodeValid();
      AboutDecodeValid(s, DecodeValid(s));
      assert Is2Padding(s[|s| - 4..]);
    }

    lemma DecodeValidPartialsFrom1PaddedSeq(s: seq<char>)
      requires IsBase64String(s)
      requires |s| >= 4
      requires Is1Padding(s[|s| - 4..])
      ensures (reveal IsUnpaddedBase64String(); reveal DecodeValid(); reveal IsBase64String(); ghost var b: seq<bv8> := DecodeValid(s); b[..|b| - 2] == DecodeUnpadded(s[..|s| - 4]) && b[|b| - 2..] == Decode1Padding(s[|s| - 4..]))
      decreases s
    {
      reveal IsUnpaddedBase64String();
      reveal DecodeValid();
      reveal IsBase64String();
      AboutDecodeValid(s, DecodeValid(s));
    }

    lemma UnpaddedBase64Prefix(s: string)
      requires IsBase64String(s)
      requires |s| >= 4
      ensures IsUnpaddedBase64String(s[..|s| - 4])
      decreases s
    {
      reveal IsBase64String();
      reveal IsUnpaddedBase64String();
    }

    lemma DecodeValid2PaddingLengthMod3(s: seq<char>)
      requires IsBase64String(s)
      requires |s| >= 4
      requires Is2Padding(s[|s| - 4..])
      ensures |DecodeValid(s)| % 3 == 1
      decreases s
    {
      assert IsUnpaddedBase64String(s[..|s| - 4]) by {
        UnpaddedBase64Prefix(s);
      }
      AboutDecodeValid(s, DecodeValid(s));
    }

    lemma DecodeValidEncode2Padding(s: seq<char>)
      requires IsBase64String(s)
      requires |s| >= 4
      requires Is2Padding(s[|s| - 4..])
      ensures EncodeBV(DecodeValid(s)) == s
      decreases s
    {
      assert |DecodeValid(s)| % 3 == 1 by {
        DecodeValid2PaddingLengthMod3(s);
      }
      calc {
        EncodeBV(DecodeValid(s));
      ==
        {
          reveal EncodeBV();
        }
        EncodeUnpadded(DecodeValid(s)[..|DecodeValid(s)| - 1]) + Encode2Padding(DecodeValid(s)[|DecodeValid(s)| - 1..]);
      ==
        {
          DecodeValidPartialsFrom2PaddedSeq(s);
          reveal IsUnpaddedBase64String();
          reveal IsBase64String();
        }
        EncodeUnpadded(DecodeUnpadded(s[..|s| - 4])) + Encode2Padding(DecodeValid(s)[|DecodeValid(s)| - 1..]);
      ==
        {
          reveal IsBase64String();
          DecodeEncodeUnpadded(s[..|s| - 4]);
        }
        s[..|s| - 4] + Encode2Padding(DecodeValid(s)[|DecodeValid(s)| - 1..]);
      ==
        {
          DecodeValidPartialsFrom2PaddedSeq(s);
        }
        s[..|s| - 4] + Encode2Padding(Decode2Padding(s[|s| - 4..]));
      ==
        {
          DecodeEncode2Padding(s[|s| - 4..]);
        }
        s[..|s| - 4] + s[|s| - 4..];
      ==
        {
          SeqPartsMakeWhole(s, |s| - 4);
        }
        s;
      }
    }

    lemma DecodeValidEncode(s: seq<char>)
      requires IsBase64String(s)
      ensures EncodeBV(DecodeValid(s)) == s
      decreases s
    {
      reveal IsBase64String();
      if s == [] {
        calc {
          EncodeBV(DecodeValid(s));
        ==
          {
            DecodeValidEncodeEmpty(s);
          }
          s;
        }
      } else if |s| >= 4 && Is1Padding(s[|s| - 4..]) {
        calc {
          EncodeBV(DecodeValid(s));
        ==
          {
            DecodeValidEncode1Padding(s);
          }
          s;
        }
      } else if |s| >= 4 && Is2Padding(s[|s| - 4..]) {
        calc {
          EncodeBV(DecodeValid(s));
        ==
          {
            DecodeValidEncode2Padding(s);
          }
          s;
        }
      } else {
        calc {
          EncodeBV(DecodeValid(s));
        ==
          {
            DecodeValidEncodeUnpadded(s);
          }
          s;
        }
      }
    }

    lemma EncodeDecodeValid(b: seq<bv8>)
      ensures (EncodeBVIsBase64(b); DecodeValid(EncodeBV(b)) == b)
      decreases b
    {
      EncodeBVIsBase64(b);
      ghost var s := EncodeBV(b);
      if b == [] {
        calc {
          DecodeValid(EncodeBV(b));
        ==
          {
            EncodeDecodeValidEmpty(b);
          }
          b;
        }
      } else if |b| % 3 == 0 {
        calc {
          DecodeValid(EncodeBV(b));
        ==
          {
            EncodeBVIsUnpadded(b);
          }
          DecodeValid(EncodeUnpadded(b));
        ==
          {
            EncodeDecodeValidUnpadded(b);
            reveal DecodeValid();
          }
          DecodeUnpadded(EncodeUnpadded(b));
        ==
          {
            EncodeDecodeUnpadded(b);
          }
          b;
        }
      } else if |b| % 3 == 1 {
        EncodeDecodeValid2Padded(b);
        ghost var prefix := b[..|b| - 1];
        ghost var suffix := b[|b| - 1..];
        EncodeUnpaddedBase64(prefix);
        calc {
          DecodeValid(EncodeBV(b));
        ==
          {
            reveal EncodeBV();
          }
          DecodeValid(EncodeUnpadded(prefix) + Encode2Padding(suffix));
        ==
          {
            reveal DecodeValid();
            DecodeValidPartialsFrom2PaddedSeq(s);
          }
          DecodeUnpadded(EncodeUnpadded(prefix)) + Decode2Padding(Encode2Padding(suffix));
        ==
          {
            EncodeDecodeUnpadded(prefix);
            EncodeDecode2Padding(suffix);
          }
          prefix + suffix;
        ==
          b;
        }
      } else if |b| % 3 == 2 {
        EncodeDecodeValid1Padded(b);
        ghost var prefix := b[..|b| - 2];
        ghost var suffix := b[|b| - 2..];
        EncodeUnpaddedBase64(prefix);
        calc {
          DecodeValid(EncodeBV(b));
        ==
          {
            reveal EncodeBV();
          }
          DecodeValid(EncodeUnpadded(prefix) + Encode1Padding(suffix));
        ==
          {
            reveal DecodeValid();
            DecodeValidPartialsFrom1PaddedSeq(s);
          }
          DecodeUnpadded(EncodeUnpadded(prefix)) + Decode1Padding(Encode1Padding(suffix));
        ==
          {
            EncodeDecodeUnpadded(prefix);
            EncodeDecode1Padding(suffix);
          }
          prefix + suffix;
        ==
          b;
        }
      }
    }

    lemma DecodeEncodeBV(s: seq<char>)
      requires IsBase64String(s)
      ensures EncodeBV(DecodeBV(s).value) == s
      decreases s
    {
      reveal DecodeBV();
      calc {
        EncodeBV(DecodeBV(s).value);
      ==
        {
          DecodeValidEncode(s);
        }
        s;
      }
    }

    lemma EncodeDecodeBV(b: seq<bv8>)
      ensures DecodeBV(EncodeBV(b)) == Success(b)
      decreases b
    {
      reveal DecodeBV();
      EncodeBVIsBase64(b);
      calc {
        DecodeBV(EncodeBV(b));
      ==
        {
          assert IsBase64String(EncodeBV(b));
        }
        Success(DecodeValid(EncodeBV(b)));
      ==
        {
          EncodeDecodeValid(b);
        }
        Success(b);
      }
    }

    opaque function UInt8sToBVs(u: seq<uint8>): (r: seq<bv8>)
      ensures |r| == |u|
      ensures forall i: int {:trigger u[i]} {:trigger r[i]} :: 0 <= i < |u| ==> r[i] == u[i] as bv8
      decreases u
    {
      seq(|u|, (i: int) requires 0 <= i < |u| => u[i] as bv8)
    }

    opaque function BVsToUInt8s(b: seq<bv8>): (r: seq<uint8>)
      ensures |r| == |b|
      ensures forall i: int {:trigger b[i]} {:trigger r[i]} :: 0 <= i < |b| ==> r[i] == b[i] as uint8
      decreases b
    {
      seq(|b|, (i: int) requires 0 <= i < |b| => b[i] as uint8)
    }

    lemma {:isolate_assertions} {:resource_limit 1000000000} UInt8sToBVsToUInt8s(u: seq<uint8>)
      ensures BVsToUInt8s(UInt8sToBVs(u)) == u
      decreases u
    {
      ghost var b := UInt8sToBVs(u);
      assert |b| == |u|;
      ghost var u' := BVsToUInt8s(b);
      assert |u'| == |b|;
    }

    lemma BVsToUInt8sToBVs(b: seq<bv8>)
      ensures UInt8sToBVs(BVsToUInt8s(b)) == b
      decreases b
    {
      ghost var u := BVsToUInt8s(b);
      assert |b| == |u|;
      ghost var b' := UInt8sToBVs(u);
      assert |b'| == |u|;
    }

    opaque function Encode(u: seq<uint8>): seq<char>
      decreases u
    {
      EncodeBV(UInt8sToBVs(u))
    }

    opaque function Decode(s: seq<char>): (b: Result<seq<uint8>, string>)
      ensures IsBase64String(s) ==> b.Success?
      decreases s
    {
      if IsBase64String(s) then
        var b: seq<bv8> := DecodeValid(s);
        Success(BVsToUInt8s(b))
      else
        Failure(""The encoding is malformed"")
    }

    lemma EncodeDecode(b: seq<uint8>)
      ensures Decode(Encode(b)) == Success(b)
      decreases b
    {
      ghost var bvs := UInt8sToBVs(b);
      ghost var s := EncodeBV(bvs);
      assert Encode(b) == s by {
        reveal Encode();
      }
      assert IsBase64String(s) by {
        EncodeBVIsBase64(bvs);
      }
      ghost var b' := DecodeValid(s);
      assert b' == bvs by {
        EncodeDecodeValid(bvs);
      }
      ghost var us := BVsToUInt8s(b');
      assert Decode(s) == Success(us) by {
        reveal Decode();
      }
      assert b' == bvs;
      assert b == us by {
        UInt8sToBVsToUInt8s(b);
      }
    }

    lemma DecodeEncode(s: seq<char>)
      requires IsBase64String(s)
      ensures Encode(Decode(s).value) == s
      decreases s
    {
      ghost var b := DecodeValid(s);
      ghost var u := BVsToUInt8s(b);
      assert Decode(s) == Success(u) by {
        reveal Decode();
      }
      ghost var s' := EncodeBV(UInt8sToBVs(u));
      assert s' == Encode(u) by {
        reveal Encode();
      }
      assert UInt8sToBVs(BVsToUInt8s(b)) == b by {
        BVsToUInt8sToBVs(b);
      }
      assert s == s' by {
        DecodeValidEncode(s);
      }
    }

    import opened Wrappers

    import opened BoundedInts

    export
      reveals IsBase64Char, index, CharToIndex, IndexToChar, IsBase64String, IsUnpaddedBase64String, Is1Padding, Is2Padding
      provides Encode, Decode, EncodeBV, DecodeBV, EncodeDecode, DecodeEncode, EncodeDecodeBV, DecodeEncodeBV, BoundedInts, Wrappers


    export Internals
      reveals *
      reveals IsBase64Char
      provides Base64CharIs7Bit
      reveals IsUnpaddedBase64String, IndexToChar
      provides IndexToCharIsBase64
      reveals CharToIndex
      provides CharToIndexToChar, IndexToCharToIndex, IndexToCharToIndexAuto, CharToIndexToCharAuto
      reveals BV24ToSeq, SeqToBV24
      provides BV24ToSeqToBV24, SeqToBV24ToSeq
      reveals BV24ToIndexSeq, IndexSeqToBV24
      provides BV24ToIndexSeqToBV24, IndexSeqToBV24ToIndexSeq
      reveals DecodeBlock, EncodeBlock
      provides EncodeDecodeBlock, DecodeEncodeBlock
      reveals DecodeRecursively
      provides DecodeRecursivelyBounds, DecodeRecursivelyBlock
      reveals EncodeRecursively
      provides EncodeRecursivelyBounds, EncodeRecursivelyBlock, EncodeDecodeRecursively, DecodeEncodeRecursively
      reveals FromCharsToIndices, FromIndicesToChars
      provides FromCharsToIndicesToChars, FromIndicesToCharsToIndices
      reveals DecodeUnpadded
      provides DecodeUnpaddedBounds
      reveals EncodeUnpadded
      provides EncodeUnpaddedNotPadded, EncodeUnpaddedBounds, EncodeUnpaddedBase64, EncodeDecodeUnpadded, DecodeEncodeUnpadded
      reveals Is1Padding, Decode1Padding, Encode1Padding
      provides EncodeDecodeBlock1Padding, Encode1PaddingIs1Padding, EncodeDecode1Padding, DecodeEncode1Padding
      reveals Is2Padding, Decode2Padding, Encode2Padding
      provides Encode2PaddingIs2Padding, DecodeEncodeBlock2Padding, EncodeDecode2Padding, DecodeEncode2Padding
      reveals IsBase64String, DecodeValid
      provides AboutDecodeValid, Mod3
      reveals DecodeBV
      provides DecodeBVFailure
      reveals StringIs7Bit
      provides UnpaddedBase64StringIs7Bit, Is7Bit1Padding, Is7Bit2Padding
      reveals EncodeBV
      provides EncodeBVIsUnpadded, EncodeBVIs2Padded, EncodeBVIs1Padded, EncodeBVLengthCongruentToZeroMod4, EncodeBVIsBase64, EncodeBVLengthExact, EncodeBVLengthBound, SeqPartsMakeWhole, DecodeValidEncodeEmpty, EncodeDecodeValidEmpty, DecodeValidEncodeUnpadded, EncodeDecodeValidUnpadded, EncodeDecodeValid2Padded, EncodeDecodeValid1Padded, DecodeValidUnpaddedPartialFrom1PaddedSeq, DecodeValid1PaddedPartialFrom1PaddedSeq, DecodeValid1PaddingLengthMod3, DecodeValidEncode1Padding, DecodeValidPartialsFrom2PaddedSeq, DecodeValidPartialsFrom1PaddedSeq, UnpaddedBase64Prefix, DecodeValid2PaddingLengthMod3, DecodeValidEncode2Padding, DecodeValidEncode, EncodeDecodeValid, DecodeEncodeBV, EncodeDecodeBV
      reveals UInt8sToBVs, BVsToUInt8s
      provides UInt8sToBVsToUInt8s, BVsToUInt8sToBVs
      reveals Encode, Decode
      provides EncodeDecode, DecodeEncode, reveal_IsBase64Char, reveal_IsUnpaddedBase64String, reveal_IndexToChar, reveal_CharToIndex, reveal_BV24ToSeq, reveal_SeqToBV24, reveal_BV24ToIndexSeq, reveal_IndexSeqToBV24, reveal_DecodeBlock, reveal_EncodeBlock, reveal_DecodeRecursively, reveal_EncodeRecursively, reveal_FromCharsToIndices, reveal_FromIndicesToChars, reveal_DecodeUnpadded, reveal_EncodeUnpadded, reveal_Is1Padding, reveal_Decode1Padding, reveal_Encode1Padding, reveal_Is2Padding, reveal_Decode2Padding, reveal_Encode2Padding, reveal_IsBase64String, reveal_DecodeValid, reveal_DecodeBV, reveal_StringIs7Bit, reveal_EncodeBV, reveal_UInt8sToBVs, reveal_BVsToUInt8s, reveal_Encode, reveal_Decode, Wrappers, BoundedInts
      reveals index


    type index = bv6
  }

  module BoundedInts {
    const TWO_TO_THE_0: int := 1
    const TWO_TO_THE_1: int := 2
    const TWO_TO_THE_2: int := 4
    const TWO_TO_THE_4: int := 16
    const TWO_TO_THE_5: int := 32
    const TWO_TO_THE_7: int := 128
    const TWO_TO_THE_8: int := 256
    const TWO_TO_THE_15: int := 32768
    const TWO_TO_THE_16: int := 65536
    const TWO_TO_THE_24: int := 16777216
    const TWO_TO_THE_31: int := 2147483648
    const TWO_TO_THE_32: int := 4294967296
    const TWO_TO_THE_40: int := 1099511627776
    const TWO_TO_THE_48: int := 281474976710656
    const TWO_TO_THE_56: int := 72057594037927936
    const TWO_TO_THE_63: int := 9223372036854775808
    const TWO_TO_THE_64: int := 18446744073709551616
    const TWO_TO_THE_127: int := 170141183460469231731687303715884105728
    const TWO_TO_THE_128: int := 340282366920938463463374607431768211456
    const TWO_TO_THE_256: int := 115792089237316195423570985008687907853269984665640564039457584007913129639936
    const TWO_TO_THE_512: int := 13407807929942597099574024998205846127479365820592393377723561443721764030073546976801874298166903427690031858186486050853753882811946569946433649006084096
    const UINT8_MAX: uint8 := 255
    const UINT16_MAX: uint16 := 65535
    const UINT32_MAX: uint32 := 4294967295
    const UINT64_MAX: uint64 := 18446744073709551615
    const INT8_MIN: int8 := -128
    const INT8_MAX: int8 := 127
    const INT16_MIN: int16 := -32768
    const INT16_MAX: int16 := 32767
    const INT32_MIN: int32 := -2147483648
    const INT32_MAX: int32 := 2147483647
    const INT64_MIN: int64 := -9223372036854775808
    const INT64_MAX: int64 := 9223372036854775807
    const NAT8_MAX: nat8 := 127
    const NAT16_MAX: nat16 := 32767
    const NAT32_MAX: nat32 := 2147483647
    const NAT64_MAX: nat64 := 9223372036854775807

    newtype uint8 = x: int
      | 0 <= x < TWO_TO_THE_8

    newtype uint16 = x: int
      | 0 <= x < TWO_TO_THE_16

    newtype uint32 = x: int
      | 0 <= x < TWO_TO_THE_32

    newtype uint64 = x: int
      | 0 <= x < TWO_TO_THE_64

    newtype uint128 = x: int
      | 0 <= x < TWO_TO_THE_128

    newtype int8 = x: int
      | -TWO_TO_THE_7 <= x < TWO_TO_THE_7

    newtype int16 = x: int
      | -TWO_TO_THE_15 <= x < TWO_TO_THE_15

    newtype int32 = x: int
      | -TWO_TO_THE_31 <= x < TWO_TO_THE_31

    newtype int64 = x: int
      | -TWO_TO_THE_63 <= x < TWO_TO_THE_63

    newtype int128 = x: int
      | -TWO_TO_THE_127 <= x < TWO_TO_THE_127

    newtype nat8 = x: int
      | 0 <= x < TWO_TO_THE_7

    newtype nat16 = x: int
      | 0 <= x < TWO_TO_THE_15

    newtype nat32 = x: int
      | 0 <= x < TWO_TO_THE_31

    newtype nat64 = x: int
      | 0 <= x < TWO_TO_THE_63

    newtype nat128 = x: int
      | 0 <= x < TWO_TO_THE_127

    type byte = uint8

    type bytes = seq<byte>

    newtype opt_byte = c: int
      | -1 <= c < TWO_TO_THE_8
  }

  module Collections {

    module Array {
      method BinarySearch<T(!new)>(a: array<T>, key: T, less: (T, T) -> bool)
          returns (r: Option<nat>)
        requires SortedBy((x: T, y: T) => less(x, y) || x == y, a[..])
        requires StrictTotalOrdering(less)
        ensures r.Some? ==> r.value < a.Length && a[r.value] == key
        ensures r.None? ==> key !in a[..]
        decreases a
      {
        var lo, hi: nat := 0, a.Length;
        while lo < hi
          invariant 0 <= lo <= hi <= a.Length
          invariant key !in a[..lo] && key !in a[hi..]
          invariant a[..] == old(a[..])
          decreases hi - lo
        {
          var mid := (lo + hi) / 2;
          if less(key, a[mid]) {
            hi := mid;
          } else if less(a[mid], key) {
            lo := mid + 1;
          } else {
            return Some(mid);
          }
        }
        return None;
      }

      import opened Wrappers

      import opened Relations

      import opened Seq
    }

    module Imap {
      function Get<X, Y>(m: imap<X, Y>, x: X): Option<Y>
      {
        if x in m then
          Some(m[x])
        else
          None
      }

      ghost function {:opaque} RemoveKeys<X, Y>(m: imap<X, Y>, xs: iset<X>): (m': imap<X, Y>)
        ensures forall x: X {:trigger m'[x]} :: (x in m && x !in xs ==> x in m') && (x in m && x !in xs ==> m'[x] == m[x])
        ensures forall x: X {:trigger x in m'} :: (x in m' ==> x in m) && (x in m' ==> x !in xs)
        ensures m'.Keys == m.Keys - xs
      {
        imap x: X {:trigger m[x]} {:trigger x in xs} {:trigger x in m} | x in m && x !in xs :: m[x]
      }

      ghost function {:opaque} RemoveKey<X, Y>(m: imap<X, Y>, x: X): (m': imap<X, Y>)
        ensures m' == RemoveKeys(m, iset{x})
        ensures forall x': X {:trigger m'[x']} :: x' in m' ==> m'[x'] == m[x']
      {
        imap i: X {:trigger m[i]} {:trigger i in m} | i in m && i != x :: m[i]
      }

      ghost function {:opaque} Restrict<X, Y>(m: imap<X, Y>, xs: iset<X>): (m': imap<X, Y>)
        ensures m' == RemoveKeys(m, m.Keys - xs)
      {
        imap x: X {:trigger m[x]} {:trigger x in m} {:trigger x in xs} | x in xs && x in m :: m[x]
      }

      ghost predicate EqualOnKey<X, Y>(m: imap<X, Y>, m': imap<X, Y>, x: X)
      {
        (x !in m && x !in m') || (x in m && x in m' && m[x] == m'[x])
      }

      ghost predicate IsSubset<X, Y>(m: imap<X, Y>, m': imap<X, Y>)
      {
        m.Keys <= m'.Keys &&
        forall x: X {:trigger EqualOnKey(m, m', x)} {:trigger x in m} :: 
          x in m ==>
            EqualOnKey(m, m', x)
      }

      ghost function {:opaque} Union<X, Y>(m: imap<X, Y>, m': imap<X, Y>): (r: imap<X, Y>)
        ensures r.Keys == m.Keys + m'.Keys
        ensures forall x: X {:trigger r[x]} :: x in m' ==> r[x] == m'[x]
        ensures forall x: X {:trigger r[x]} :: x in m && x !in m' ==> r[x] == m[x]
      {
        m + m'
      }

      ghost predicate {:opaque} Injective<X, Y>(m: imap<X, Y>)
      {
        forall x: X, x': X {:trigger m[x], m[x']} :: 
          x != x' &&
          x in m &&
          x' in m ==>
            m[x] != m[x']
      }

      ghost function {:opaque} Invert<X, Y>(m: imap<X, Y>): imap<Y, X>
      {
        imap y: Y {:trigger y in m.Values} | y in m.Values :: ghost var x: X :| x in m.Keys && m[x] == y; x
      }

      lemma LemmaInvertIsInjective<X, Y>(m: imap<X, Y>)
        ensures Injective(Invert(m))
      {
        reveal Injective();
        reveal Invert();
      }

      ghost predicate {:opaque} Total<X(!new), Y>(m: imap<X, Y>)
      {
        forall i: X {:trigger m[i]} {:trigger i in m} :: 
          i in m
      }

      ghost predicate {:opaque} Monotonic(m: imap<int, int>)
      {
        forall x: int, x': int {:trigger m[x], m[x']} :: 
          x in m &&
          x' in m &&
          x <= x' ==>
            m[x] <= m[x']
      }

      ghost predicate {:opaque} MonotonicFrom(m: imap<int, int>, start: int)
        decreases start
      {
        forall x: int, x': int {:trigger m[x], m[x']} :: 
          x in m &&
          x' in m &&
          start <= x <= x' ==>
            m[x] <= m[x']
      }

      import opened Wrappers
    }

    module Iset {
      lemma LemmaSubset<T>(x: iset<T>, y: iset<T>)
        requires forall e: T {:trigger e in y} :: e in x ==> e in y
        ensures x <= y
      {
      }

      ghost function {:opaque} Map<X(!new), Y>(xs: iset<X>, f: X --> Y): (ys: iset<Y>)
        requires forall x: X {:trigger f.requires(x)} :: f.requires(x)
        requires Injective(f)
        reads set _x0: X, _obj: object? /*{:_reads}*/ {:trigger _obj in f.reads(_x0)} | _obj in f.reads(_x0) :: _obj
        ensures forall x: X {:trigger f(x)} :: x in xs <==> f(x) in ys
        decreases set _x0: X, _obj: object? /*{:_reads}*/ {:trigger _obj in f.reads(_x0)} | _obj in f.reads(_x0) :: _obj
      {
        ghost var ys: iset<Y> := iset x: X {:trigger f(x)} {:trigger x in xs} | x in xs :: f(x);
        ys
      }

      ghost function {:opaque} Filter<X(!new)>(xs: iset<X>, f: X ~> bool): (ys: iset<X>)
        requires forall x: X {:trigger f.requires(x)} {:trigger x in xs} :: x in xs ==> f.requires(x)
        reads set x: X, o: object? {:trigger o in f.reads(x)} | x in xs && o in f.reads(x) :: o
        ensures forall y: X {:trigger f(y)} {:trigger y in xs} :: y in ys <==> y in xs && f(y)
        decreases set x: X, o: object? {:trigger o in f.reads(x)} | x in xs && o in f.reads(x) :: o
      {
        ghost var ys: iset<X> := iset x: X {:trigger f(x)} {:trigger x in xs} | x in xs && f(x);
        ys
      }

      import opened Functions

      import opened Relations
    }

    module Map {
      function Get<X, Y>(m: map<X, Y>, x: X): Option<Y>
        decreases m
      {
        if x in m then
          Some(m[x])
        else
          None
      }

      function {:opaque} ToImap<X, Y>(m: map<X, Y>): (m': imap<X, Y>)
        ensures forall x: X {:trigger m'[x]} :: (x in m ==> x in m') && (x in m ==> m'[x] == m[x])
        ensures forall x: X {:trigger x in m'} :: x in m' ==> x in m
        decreases m
      {
        imap x: X {:trigger m[x]} {:trigger x in m} | x in m :: m[x]
      }

      function {:opaque} RemoveKeys<X, Y>(m: map<X, Y>, xs: set<X>): (m': map<X, Y>)
        ensures forall x: X {:trigger m'[x]} :: (x in m && x !in xs ==> x in m') && (x in m && x !in xs ==> m'[x] == m[x])
        ensures forall x: X {:trigger x in m'} :: (x in m' ==> x in m) && (x in m' ==> x !in xs)
        ensures m'.Keys == m.Keys - xs
        decreases m, xs
      {
        m - xs
      }

      function {:opaque} Remove<X, Y>(m: map<X, Y>, x: X): (m': map<X, Y>)
        ensures m' == RemoveKeys(m, {x})
        ensures |m'.Keys| <= |m.Keys|
        ensures x in m ==> |m'| == |m| - 1
        ensures x !in m ==> |m'| == |m|
        decreases m
      {
        var m': map<X, Y> := map x': X {:trigger m[x']} {:trigger x' in m} | x' in m && x' != x :: m[x'];
        assert m'.Keys == m.Keys - {x};
        m'
      }

      function {:opaque} Restrict<X, Y>(m: map<X, Y>, xs: set<X>): (m': map<X, Y>)
        ensures m' == RemoveKeys(m, m.Keys - xs)
        decreases m, xs
      {
        map x: X {:trigger m[x]} {:trigger x in m} {:trigger x in xs} | x in xs && x in m :: m[x]
      }

      ghost predicate EqualOnKey<X, Y>(m: map<X, Y>, m': map<X, Y>, x: X)
        decreases m, m'
      {
        (x !in m && x !in m') || (x in m && x in m' && m[x] == m'[x])
      }

      ghost predicate IsSubset<X, Y>(m: map<X, Y>, m': map<X, Y>)
        decreases m, m'
      {
        m.Keys <= m'.Keys &&
        forall x: X {:trigger EqualOnKey(m, m', x)} {:trigger x in m} :: 
          x in m ==>
            EqualOnKey(m, m', x)
      }

      function {:opaque} Union<X, Y>(m: map<X, Y>, m': map<X, Y>): (r: map<X, Y>)
        ensures r.Keys == m.Keys + m'.Keys
        ensures forall x: X {:trigger r[x]} :: x in m' ==> r[x] == m'[x]
        ensures forall x: X {:trigger r[x]} :: x in m && x !in m' ==> r[x] == m[x]
        decreases m, m'
      {
        m + m'
      }

      lemma LemmaDisjointUnionSize<X, Y>(m: map<X, Y>, m': map<X, Y>)
        requires m.Keys !! m'.Keys
        ensures |Union(m, m')| == |m| + |m'|
        decreases m, m'
      {
        ghost var u := Union(m, m');
        assert |u.Keys| == |m.Keys| + |m'.Keys|;
      }

      ghost predicate {:opaque} Injective<X, Y>(m: map<X, Y>)
        decreases m
      {
        forall x: X, x': X {:trigger m[x], m[x']} :: 
          x != x' &&
          x in m &&
          x' in m ==>
            m[x] != m[x']
      }

      ghost function {:opaque} Invert<X, Y>(m: map<X, Y>): map<Y, X>
        decreases m
      {
        map y: Y {:trigger y in m.Values} | y in m.Values :: ghost var x: X :| x in m.Keys && m[x] == y; x
      }

      lemma LemmaInvertIsInjective<X, Y>(m: map<X, Y>)
        ensures Injective(Invert(m))
        decreases m
      {
        reveal Injective();
        reveal Invert();
      }

      ghost predicate {:opaque} Total<X(!new), Y>(m: map<X, Y>)
        decreases m
      {
        forall i: X {:trigger m[i]} {:trigger i in m} :: 
          i in m
      }

      ghost predicate {:opaque} Monotonic(m: map<int, int>)
        decreases m
      {
        forall x: int, x': int {:trigger m[x], m[x']} :: 
          x in m &&
          x' in m &&
          x <= x' ==>
            m[x] <= m[x']
      }

      ghost predicate {:opaque} MonotonicFrom(m: map<int, int>, start: int)
        decreases m, start
      {
        forall x: int, x': int {:trigger m[x], m[x']} :: 
          x in m &&
          x' in m &&
          start <= x <= x' ==>
            m[x] <= m[x']
      }

      import opened Wrappers
    }

    module Seq {
      function First<T>(xs: seq<T>): T
        requires |xs| > 0
        decreases xs
      {
        xs[0]
      }

      function DropFirst<T>(xs: seq<T>): seq<T>
        requires |xs| > 0
        decreases xs
      {
        xs[1..]
      }

      function Last<T>(xs: seq<T>): T
        requires |xs| > 0
        decreases xs
      {
        xs[|xs| - 1]
      }

      function DropLast<T>(xs: seq<T>): seq<T>
        requires |xs| > 0
        decreases xs
      {
        xs[..|xs| - 1]
      }

      lemma LemmaLast<T>(xs: seq<T>)
        requires |xs| > 0
        ensures DropLast(xs) + [Last(xs)] == xs
        decreases xs
      {
      }

      lemma LemmaAppendLast<T>(xs: seq<T>, ys: seq<T>)
        requires 0 < |ys|
        ensures Last(xs + ys) == Last(ys)
        decreases xs, ys
      {
      }

      lemma LemmaConcatIsAssociative<T>(xs: seq<T>, ys: seq<T>, zs: seq<T>)
        ensures xs + (ys + zs) == xs + ys + zs == xs + ys + zs
        decreases xs, ys, zs
      {
      }

      lemma LemmaConcatIsAssociative2<T>(a: seq<T>, b: seq<T>, c: seq<T>, d: seq<T>)
        ensures a + b + c + d == a + (b + c + d)
        decreases a, b, c, d
      {
      }

      lemma EmptySequenceIsRightIdentity(l: seq)
        ensures l == l + []
        decreases l
      {
      }

      ghost predicate IsPrefix<T>(xs: seq<T>, ys: seq<T>)
        ensures IsPrefix(xs, ys) ==> |xs| <= |ys| && xs == ys[..|xs|]
        decreases xs, ys
      {
        xs <= ys
      }

      ghost predicate IsSuffix<T>(xs: seq<T>, ys: seq<T>)
        decreases xs, ys
      {
        |xs| <= |ys| &&
        xs == ys[|ys| - |xs|..]
      }

      lemma LemmaSplitAt<T>(xs: seq<T>, pos: nat)
        requires pos < |xs|
        ensures xs[..pos] + xs[pos..] == xs
        decreases xs, pos
      {
      }

      lemma LemmaElementFromSlice<T>(xs: seq<T>, xs': seq<T>, a: int, b: int, pos: nat)
        requires 0 <= a <= pos < b <= |xs|
        requires xs' == xs[a .. b]
        ensures pos - a < |xs'|
        ensures xs'[pos - a] == xs[pos]
        decreases xs, xs', a, b, pos
      {
      }

      lemma LemmaSliceOfSlice<T>(xs: seq<T>, s1: int, e1: int, s2: int, e2: int)
        requires 0 <= s1 <= e1 <= |xs|
        requires 0 <= s2 <= e2 <= e1 - s1
        ensures xs[s1 .. e1][s2 .. e2] == xs[s1 + s2 .. s1 + e2]
        decreases xs, s1, e1, s2, e2
      {
        ghost var r1 := xs[s1 .. e1];
        ghost var r2 := r1[s2 .. e2];
        ghost var r3 := xs[s1 + s2 .. s1 + e2];
        assert |r2| == |r3|;
        forall i: int {:trigger r2[i], r3[i]} | 0 <= i < |r2|
          ensures r2[i] == r3[i]
        {
        }
      }

      method ToArray<T>(xs: seq<T>) returns (a: array<T>)
        ensures fresh(a)
        ensures a.Length == |xs|
        ensures forall i: int {:trigger xs[i]} {:trigger a[i]} :: 0 <= i < |xs| ==> a[i] == xs[i]
        decreases xs
      {
        a := new T[|xs|] ((i: int) requires 0 <= i < |xs| => xs[i]);
      }

      function {:opaque} ToSet<T>(xs: seq<T>): set<T>
        decreases xs
      {
        set x: T {:trigger x in xs} | x in xs
      }

      lemma LemmaCardinalityOfSet<T>(xs: seq<T>)
        ensures |ToSet(xs)| <= |xs|
        decreases xs
      {
        reveal ToSet();
        if |xs| == 0 {
        } else {
          assert ToSet(xs) == ToSet(DropLast(xs)) + {Last(xs)};
          LemmaCardinalityOfSet(DropLast(xs));
        }
      }

      lemma LemmaCardinalityOfEmptySetIs0<T>(xs: seq<T>)
        ensures |ToSet(xs)| == 0 <==> |xs| == 0
        decreases xs
      {
        reveal ToSet();
        if |xs| != 0 {
          assert xs[0] in ToSet(xs);
        }
      }

      ghost predicate {:opaque} HasNoDuplicates<T>(xs: seq<T>)
        decreases xs
      {
        forall i: int, j: int {:trigger xs[j], xs[i]} :: 
          0 <= i < |xs| &&
          0 <= j < |xs| &&
          i != j ==>
            xs[i] != xs[j]
      }

      lemma {:timeLimitMultiplier 3} /*{:_timeLimit 30}*/ LemmaNoDuplicatesInConcat<T>(xs: seq<T>, ys: seq<T>)
        requires HasNoDuplicates(xs)
        requires HasNoDuplicates(ys)
        requires multiset(xs) !! multiset(ys)
        ensures HasNoDuplicates(xs + ys)
        decreases xs, ys
      {
        reveal HasNoDuplicates();
        ghost var zs := xs + ys;
        if |zs| > 1 {
          assert forall i: int {:trigger zs[i]} :: 0 <= i < |xs| ==> zs[i] in multiset(xs);
          assert forall j: int {:trigger zs[j]} :: |xs| <= j < |zs| ==> zs[j] in multiset(ys);
          assert forall i: int, j: int {:trigger zs[j], zs[i]} :: 0 <= i < |xs| <= j < |zs| ==> zs[i] != zs[j];
        }
      }

      lemma LemmaCardinalityOfSetNoDuplicates<T>(xs: seq<T>)
        requires HasNoDuplicates(xs)
        ensures |ToSet(xs)| == |xs|
        decreases xs
      {
        reveal HasNoDuplicates();
        reveal ToSet();
        if |xs| == 0 {
        } else {
          LemmaCardinalityOfSetNoDuplicates(DropLast(xs));
          assert ToSet(xs) == ToSet(DropLast(xs)) + {Last(xs)};
        }
      }

      lemma LemmaNoDuplicatesCardinalityOfSet<T>(xs: seq<T>)
        requires |ToSet(xs)| == |xs|
        ensures HasNoDuplicates(xs)
        decreases xs
      {
        reveal HasNoDuplicates();
        reveal ToSet();
        if |xs| == 0 {
        } else {
          assert xs == [First(xs)] + DropFirst(xs);
          assert ToSet(xs) == {First(xs)} + ToSet(DropFirst(xs));
          if First(xs) in DropFirst(xs) {
            assert ToSet(xs) == ToSet(DropFirst(xs));
            LemmaCardinalityOfSet(DropFirst(xs));
          } else {
            assert |ToSet(xs)| == 1 + |ToSet(DropFirst(xs))|;
            LemmaNoDuplicatesCardinalityOfSet(DropFirst(xs));
          }
        }
      }

      lemma LemmaMultisetHasNoDuplicates<T>(xs: seq<T>)
        requires HasNoDuplicates(xs)
        ensures forall x: T {:trigger multiset(xs)[x]} | x in multiset(xs) :: multiset(xs)[x] == 1
        decreases xs
      {
        if |xs| == 0 {
        } else {
          assert xs == DropLast(xs) + [Last(xs)];
          assert Last(xs) !in DropLast(xs) by {
            reveal HasNoDuplicates();
          }
          assert HasNoDuplicates(DropLast(xs)) by {
            reveal HasNoDuplicates();
          }
          LemmaMultisetHasNoDuplicates(DropLast(xs));
        }
      }

      function {:opaque} IndexOf<T(==)>(xs: seq<T>, v: T): (i: nat)
        requires v in xs
        ensures i < |xs| && xs[i] == v
        ensures forall j: int {:trigger xs[j]} :: 0 <= j < i ==> xs[j] != v
        decreases xs
      {
        if xs[0] == v then
          0
        else
          1 + IndexOf(xs[1..], v)
      }

      function {:opaque} IndexOfOption<T(==)>(xs: seq<T>, v: T): (o: Option<nat>)
        ensures if o.Some? then o.value < |xs| && xs[o.value] == v && forall j: int {:trigger xs[j]} :: 0 <= j < o.value ==> xs[j] != v else v !in xs
        decreases xs
      {
        IndexByOption(xs, (x: T) => x == v)
      }

      function {:opaque} IndexByOption<T(==)>(xs: seq<T>, p: T -> bool): (o: Option<nat>)
        ensures if o.Some? then o.value < |xs| && p(xs[o.value]) && forall j: int {:trigger xs[j]} :: 0 <= j < o.value ==> !p(xs[j]) else forall x: T {:trigger p(x)} {:trigger x in xs} | x in xs :: !p(x)
        decreases xs
      {
        if |xs| == 0 then
          None()
        else if p(xs[0]) then
          Some(0)
        else
          var o': Option<nat> := IndexByOption(xs[1..], p); if o'.Some? then Some(o'.value + 1) else None()
      }

      function {:opaque} LastIndexOf<T(==)>(xs: seq<T>, v: T): (i: nat)
        requires v in xs
        ensures i < |xs| && xs[i] == v
        ensures forall j: int {:trigger xs[j]} :: i < j < |xs| ==> xs[j] != v
        decreases xs
      {
        if xs[|xs| - 1] == v then
          |xs| - 1
        else
          LastIndexOf(xs[..|xs| - 1], v)
      }

      function {:opaque} LastIndexOfOption<T(==)>(xs: seq<T>, v: T): (o: Option<nat>)
        ensures if o.Some? then o.value < |xs| && xs[o.value] == v && forall j: int {:trigger xs[j]} :: o.value < j < |xs| ==> xs[j] != v else v !in xs
        decreases xs
      {
        LastIndexByOption(xs, (x: T) => x == v)
      }

      function {:opaque} LastIndexByOption<T(==)>(xs: seq<T>, p: T -> bool): (o: Option<nat>)
        ensures if o.Some? then o.value < |xs| && p(xs[o.value]) && forall j: int {:trigger xs[j]} :: o.value < j < |xs| ==> !p(xs[j]) else forall x: T {:trigger p(x)} {:trigger x in xs} | x in xs :: !p(x)
        decreases xs
      {
        if |xs| == 0 then
          None()
        else if p(xs[|xs| - 1]) then
          Some(|xs| - 1)
        else
          LastIndexByOption(xs[..|xs| - 1], p)
      }

      function {:opaque} Remove<T>(xs: seq<T>, pos: nat): (ys: seq<T>)
        requires pos < |xs|
        ensures |ys| == |xs| - 1
        ensures forall i: int {:trigger ys[i], xs[i]} | 0 <= i < pos :: ys[i] == xs[i]
        ensures forall i: int {:trigger ys[i]} | pos <= i < |xs| - 1 :: ys[i] == xs[i + 1]
        decreases xs, pos
      {
        xs[..pos] + xs[pos + 1..]
      }

      function {:opaque} RemoveValue<T(==)>(xs: seq<T>, v: T): (ys: seq<T>)
        ensures v !in xs ==> xs == ys
        ensures v in xs ==> |multiset(ys)| == |multiset(xs)| - 1
        ensures v in xs ==> multiset(ys)[v] == multiset(xs)[v] - 1
        ensures HasNoDuplicates(xs) ==> HasNoDuplicates(ys) && ToSet(ys) == ToSet(xs) - {v}
        decreases xs
      {
        reveal HasNoDuplicates();
        reveal ToSet();
        if v !in xs then
          xs
        else
          var i: nat := IndexOf(xs, v); assert xs == xs[..i] + [v] + xs[i + 1..]; xs[..i] + xs[i + 1..]
      }

      function {:opaque} Insert<T>(xs: seq<T>, a: T, pos: nat): seq<T>
        requires pos <= |xs|
        ensures |Insert(xs, a, pos)| == |xs| + 1
        ensures forall i: int {:trigger Insert(xs, a, pos)[i], xs[i]} :: 0 <= i < pos ==> Insert(xs, a, pos)[i] == xs[i]
        ensures forall i: int {:trigger xs[i]} :: pos <= i < |xs| ==> Insert(xs, a, pos)[i + 1] == xs[i]
        ensures Insert(xs, a, pos)[pos] == a
        ensures multiset(Insert(xs, a, pos)) == multiset(xs) + multiset{a}
        decreases xs, pos
      {
        assert xs == xs[..pos] + xs[pos..];
        xs[..pos] + [a] + xs[pos..]
      }

      function {:opaque} Reverse<T>(xs: seq<T>): (ys: seq<T>)
        ensures |ys| == |xs|
        ensures forall i: int {:trigger ys[i]} {:trigger xs[|xs| - i - 1]} :: 0 <= i < |xs| ==> ys[i] == xs[|xs| - i - 1]
        decreases xs
      {
        if xs == [] then
          []
        else
          [xs[|xs| - 1]] + Reverse(xs[0 .. |xs| - 1])
      }

      function {:opaque} Repeat<T>(v: T, length: nat): (xs: seq<T>)
        ensures |xs| == length
        ensures forall i: nat {:trigger xs[i]} | i < |xs| :: xs[i] == v
        decreases length
      {
        if length == 0 then
          []
        else
          [v] + Repeat(v, length - 1)
      }

      function {:opaque} Unzip<A, B>(xs: seq<(A, B)>): (seq<A>, seq<B>)
        ensures |Unzip(xs).0| == |Unzip(xs).1| == |xs|
        ensures forall i: int {:trigger Unzip(xs).0[i]} {:trigger Unzip(xs).1[i]} :: 0 <= i < |xs| ==> (Unzip(xs).0[i], Unzip(xs).1[i]) == xs[i]
        decreases xs
      {
        if |xs| == 0 then
          ([], [])
        else
          var (a: seq<A>, b: seq<B>) := Unzip(DropLast(xs)); (a + [Last(xs).0], b + [Last(xs).1])
      }

      function {:opaque} Zip<A, B>(xs: seq<A>, ys: seq<B>): seq<(A, B)>
        requires |xs| == |ys|
        ensures |Zip(xs, ys)| == |xs|
        ensures forall i: int {:trigger Zip(xs, ys)[i]} :: 0 <= i < |Zip(xs, ys)| ==> Zip(xs, ys)[i] == (xs[i], ys[i])
        ensures Unzip(Zip(xs, ys)).0 == xs
        ensures Unzip(Zip(xs, ys)).1 == ys
        decreases xs, ys
      {
        if |xs| == 0 then
          []
        else
          Zip(DropLast(xs), DropLast(ys)) + [(Last(xs), Last(ys))]
      }

      lemma /*{:_induction xs}*/ LemmaZipOfUnzip<A, B>(xs: seq<(A, B)>)
        ensures Zip(Unzip(xs).0, Unzip(xs).1) == xs
        decreases xs
      {
      }

      lemma MembershipImpliesIndexing<T>(p: T -> bool, xs: seq<T>)
        requires forall t: T {:trigger p(t)} {:trigger t in xs} | t in xs :: p(t)
        ensures forall i: int {:trigger xs[i]} | 0 <= i < |xs| :: p(xs[i])
        decreases xs
      {
      }

      function {:opaque} Max(xs: seq<int>): int
        requires 0 < |xs|
        ensures forall k: int {:trigger k in xs} :: k in xs ==> Max(xs) >= k
        ensures Max(xs) in xs
        decreases xs
      {
        assert xs == [xs[0]] + xs[1..];
        if |xs| == 1 then
          xs[0]
        else
          Math.Max(xs[0], Max(xs[1..]))
      }

      lemma /*{:_induction xs, ys}*/ LemmaMaxOfConcat(xs: seq<int>, ys: seq<int>)
        requires 0 < |xs| && 0 < |ys|
        ensures Max(xs + ys) >= Max(xs)
        ensures Max(xs + ys) >= Max(ys)
        ensures forall i: int {:trigger i in [Max(xs + ys)]} :: i in xs + ys ==> Max(xs + ys) >= i
        decreases xs, ys
      {
        reveal Max();
        if |xs| == 1 {
        } else {
          assert xs[1..] + ys == (xs + ys)[1..];
          LemmaMaxOfConcat(xs[1..], ys);
        }
      }

      function {:opaque} Min(xs: seq<int>): int
        requires 0 < |xs|
        ensures forall k: int {:trigger k in xs} :: k in xs ==> Min(xs) <= k
        ensures Min(xs) in xs
        decreases xs
      {
        assert xs == [xs[0]] + xs[1..];
        if |xs| == 1 then
          xs[0]
        else
          Math.Min(xs[0], Min(xs[1..]))
      }

      lemma /*{:_induction xs, ys}*/ LemmaMinOfConcat(xs: seq<int>, ys: seq<int>)
        requires 0 < |xs| && 0 < |ys|
        ensures Min(xs + ys) <= Min(xs)
        ensures Min(xs + ys) <= Min(ys)
        ensures forall i: int {:trigger i in xs + ys} :: i in xs + ys ==> Min(xs + ys) <= i
        decreases xs, ys
      {
        reveal Min();
        if |xs| == 1 {
        } else {
          assert xs[1..] + ys == (xs + ys)[1..];
          LemmaMinOfConcat(xs[1..], ys);
        }
      }

      lemma /*{:_induction xs}*/ LemmaSubseqMax(xs: seq<int>, from: nat, to: nat)
        requires from < to <= |xs|
        ensures Max(xs[from .. to]) <= Max(xs)
        decreases xs, from, to
      {
        ghost var subseq := xs[from .. to];
        ghost var subseqMax := Max(subseq);
        assert forall x: int {:trigger x in xs[from..]} {:trigger x in subseq} | x in subseq :: x in xs[from..];
        assert subseqMax in subseq;
        assert subseqMax in xs;
      }

      lemma /*{:_induction xs}*/ LemmaSubseqMin(xs: seq<int>, from: nat, to: nat)
        requires from < to <= |xs|
        ensures Min(xs[from .. to]) >= Min(xs)
        decreases xs, from, to
      {
        ghost var subseq := xs[from .. to];
        ghost var subseqMin := Min(subseq);
        assert forall x: int {:trigger x in xs[from..]} {:trigger x in subseq} | x in subseq :: x in xs[from..];
        assert subseqMin in subseq;
        assert subseqMin in xs;
      }

      function Flatten<T>(xs: seq<seq<T>>): seq<T>
        decreases |xs|
      {
        if |xs| == 0 then
          []
        else
          xs[0] + Flatten(xs[1..])
      }

      lemma {:isolate_assertions} /*{:_induction xs, ys}*/ LemmaFlattenConcat<T>(xs: seq<seq<T>>, ys: seq<seq<T>>)
        ensures Flatten(xs + ys) == Flatten(xs) + Flatten(ys)
        decreases xs, ys
      {
        if |xs| == 0 {
          assert xs + ys == ys;
        } else {
          calc == {
            Flatten(xs + ys);
            {
              assert (xs + ys)[0] == xs[0];
              assert (xs + ys)[1..] == xs[1..] + ys;
            }
            xs[0] + Flatten(xs[1..] + ys);
            xs[0] + Flatten(xs[1..]) + Flatten(ys);
            Flatten(xs) + Flatten(ys);
          }
        }
      }

      function FlattenReverse<T>(xs: seq<seq<T>>): seq<T>
        decreases |xs|
      {
        if |xs| == 0 then
          []
        else
          FlattenReverse(DropLast(xs)) + Last(xs)
      }

      lemma /*{:_induction xs, ys}*/ LemmaFlattenReverseConcat<T>(xs: seq<seq<T>>, ys: seq<seq<T>>)
        ensures FlattenReverse(xs + ys) == FlattenReverse(xs) + FlattenReverse(ys)
        decreases xs, ys
      {
        if |ys| == 0 {
          assert FlattenReverse(ys) == [];
          assert xs + ys == xs;
        } else {
          calc == {
            FlattenReverse(xs + ys);
            {
              assert Last(xs + ys) == Last(ys);
              assert DropLast(xs + ys) == xs + DropLast(ys);
            }
            FlattenReverse(xs + DropLast(ys)) + Last(ys);
            FlattenReverse(xs) + FlattenReverse(DropLast(ys)) + Last(ys);
            FlattenReverse(xs) + FlattenReverse(ys);
          }
        }
      }

      lemma /*{:_induction xs}*/ LemmaFlattenAndFlattenReverseAreEquivalent<T>(xs: seq<seq<T>>)
        ensures Flatten(xs) == FlattenReverse(xs)
        decreases xs
      {
        if |xs| == 0 {
        } else {
          calc == {
            FlattenReverse(xs);
            FlattenReverse(DropLast(xs)) + Last(xs);
            {
              LemmaFlattenAndFlattenReverseAreEquivalent(DropLast(xs));
            }
            Flatten(DropLast(xs)) + Last(xs);
            Flatten(DropLast(xs)) + Flatten([Last(xs)]);
            {
              LemmaFlattenConcat(DropLast(xs), [Last(xs)]);
              assert xs == DropLast(xs) + [Last(xs)];
            }
            Flatten(xs);
          }
        }
      }

      lemma /*{:_induction xs}*/ LemmaFlattenLengthGeSingleElementLength<T>(xs: seq<seq<T>>, i: int)
        requires 0 <= i < |xs|
        ensures |FlattenReverse(xs)| >= |xs[i]|
        decreases xs, i
      {
        if i < |xs| - 1 {
          LemmaFlattenLengthGeSingleElementLength(xs[..|xs| - 1], i);
        }
      }

      lemma /*{:_induction xs}*/ LemmaFlattenLengthLeMul<T>(xs: seq<seq<T>>, j: int)
        requires forall i: int {:trigger xs[i]} | 0 <= i < |xs| :: |xs[i]| <= j
        ensures |FlattenReverse(xs)| <= |xs| * j
        decreases xs, j
      {
        if |xs| == 0 {
        } else {
          LemmaFlattenLengthLeMul(xs[..|xs| - 1], j);
          assert |FlattenReverse(xs[..|xs| - 1])| <= (|xs| - 1) * j;
        }
      }

      function Join<T>(seqs: seq<seq<T>>, separator: seq<T>): seq<T>
        decreases seqs, separator
      {
        if |seqs| == 0 then
          []
        else if |seqs| == 1 then
          seqs[0]
        else
          seqs[0] + separator + Join(seqs[1..], separator)
      }

      lemma /*{:_induction seqs}*/ LemmaJoinWithEmptySeparator(seqs: seq<string>)
        ensures Flatten(seqs) == Join(seqs, [])
        decreases seqs
      {
      }

      function {:tailrecursion} Split<T(==)>(s: seq<T>, delim: T): (res: seq<seq<T>>)
        ensures delim !in s ==> res == [s]
        ensures s == [] ==> res == [[]]
        ensures 0 < |res|
        ensures forall i: int {:trigger res[i]} :: 0 <= i < |res| ==> delim !in res[i]
        ensures Join(res, [delim]) == s
        decreases |s|
      {
        var i: Option<nat> := IndexOfOption(s, delim);
        if i.Some? then
          [s[..i.value]] + Split(s[i.value + 1..], delim)
        else
          [s]
      }

      function {:tailrecursion} SplitOnce<T(==)>(s: seq<T>, delim: T): (res: (seq<T>, seq<T>))
        requires delim in s
        ensures res.0 + [delim] + res.1 == s
        ensures !(delim in res.0)
        decreases s
      {
        var i: Option<nat> := IndexOfOption(s, delim);
        assert i.Some?;
        (s[..i.value], s[i.value + 1..])
      }

      function {:tailrecursion} SplitOnceOption<T(==)>(s: seq<T>, delim: T): (res: Option<(seq<T>, seq<T>)>)
        ensures res.Some? ==> res.value.0 + [delim] + res.value.1 == s
        ensures res.None? ==> !(delim in s)
        ensures res.Some? ==> !(delim in res.value.0)
        decreases s
      {
        var i: nat :- IndexOfOption(s, delim); Some((s[..i], s[i + 1..]))
      }

      lemma {:rlimit 1000} {:vcs_split_on_every_assert} /*{:_induction s}*/ WillSplitOnDelim<T>(s: seq<T>, delim: T, prefix: seq<T>)
        requires |prefix| < |s|
        requires forall i: int {:trigger s[i]} {:trigger prefix[i]} :: 0 <= i < |prefix| ==> prefix[i] == s[i]
        requires delim !in prefix && s[|prefix|] == delim
        ensures Split(s, delim) == [prefix] + Split(s[|prefix| + 1..], delim)
        decreases s, prefix
      {
        calc {
          Split(s, delim);
        ==
          ghost var i: Option<nat> := IndexOfOption(s, delim); if i.Some? then [s[..i.value]] + Split(s[i.value + 1..], delim) else [s];
        ==
          {
            IndexOfOptionLocatesElem(s, delim, |prefix|);
            assert IndexOfOption(s, delim).Some?;
          }
          [s[..|prefix|]] + Split(s[|prefix| + 1..], delim);
        ==
          {
            assert s[..|prefix|] == prefix;
          }
          [prefix] + Split(s[|prefix| + 1..], delim);
        }
      }

      lemma /*{:_induction s}*/ WillNotSplitWithOutDelim<T>(s: seq<T>, delim: T)
        requires delim !in s
        ensures Split(s, delim) == [s]
        decreases s
      {
        calc {
          Split(s, delim);
        ==
          ghost var i: Option<nat> := IndexOfOption(s, delim); if i.Some? then [s[..i.value]] + Split(s[i.value + 1..], delim) else [s];
        ==
          {
            IndexOfOptionLocatesElem(s, delim, |s|);
          }
          [s];
        }
      }

      lemma IndexOfOptionLocatesElem<T>(s: seq<T>, c: T, elemIndex: nat)
        requires 0 <= elemIndex <= |s|
        requires forall i: int {:trigger s[i]} :: 0 <= i < elemIndex ==> s[i] != c
        requires elemIndex == |s| || s[elemIndex] == c
        ensures IndexOfOption(s, c) == if elemIndex == |s| then None else Some(elemIndex)
        decreases elemIndex
      {
      }

      function {:opaque} Map<T, R>(f: T ~> R, xs: seq<T>): (result: seq<R>)
        requires forall i: int {:trigger xs[i]} :: 0 <= i < |xs| ==> f.requires(xs[i])
        reads set i: int, o: object? {:trigger o in f.reads(xs[i])} | 0 <= i < |xs| && o in f.reads(xs[i]) :: o
        ensures |result| == |xs|
        ensures forall i: int {:trigger result[i]} :: 0 <= i < |xs| ==> result[i] == f(xs[i])
        decreases set i: int, o: object? {:trigger o in f.reads(xs[i])} | 0 <= i < |xs| && o in f.reads(xs[i]) :: o, xs
      {
        if |xs| == 0 then
          []
        else
          [f(xs[0])] + Map(f, xs[1..])
      }

      function {:opaque} MapWithResult<T, R, E>(f: T ~> Result<R, E>, xs: seq<T>): (result: Result<seq<R>, E>)
        requires forall i: int {:trigger xs[i]} :: 0 <= i < |xs| ==> f.requires(xs[i])
        reads set i: int, o: object? {:trigger o in f.reads(xs[i])} | 0 <= i < |xs| && o in f.reads(xs[i]) :: o
        ensures result.Success? ==> |result.value| == |xs| && forall i: int {:trigger result.value[i]} {:trigger xs[i]} :: (0 <= i < |xs| ==> f(xs[i]).Success?) && (0 <= i < |xs| ==> result.value[i] == f(xs[i]).value)
        decreases set i: int, o: object? {:trigger o in f.reads(xs[i])} | 0 <= i < |xs| && o in f.reads(xs[i]) :: o, xs
      {
        if |xs| == 0 then
          Success([])
        else
          var head: R :- f(xs[0]); var tail: seq<R> :- MapWithResult(f, xs[1..]); Success([head] + tail)
      }

      lemma {:resource_limit 1000000000} /*{:_induction f, xs, ys}*/ LemmaMapDistributesOverConcat<T, R>(f: T ~> R, xs: seq<T>, ys: seq<T>)
        requires forall i: int {:trigger xs[i]} :: 0 <= i < |xs| ==> f.requires(xs[i])
        requires forall j: int {:trigger ys[j]} :: 0 <= j < |ys| ==> f.requires(ys[j])
        ensures Map(f, xs + ys) == Map(f, xs) + Map(f, ys)
        decreases xs, ys
      {
        reveal Map();
        if |xs| == 0 {
          assert xs + ys == ys;
        } else {
          calc {
            Map(f, xs + ys);
            {
              assert (xs + ys)[0] == xs[0];
              assert (xs + ys)[1..] == xs[1..] + ys;
            }
            Map(f, [xs[0]]) + Map(f, xs[1..] + ys);
            Map(f, [xs[0]]) + Map(f, xs[1..]) + Map(f, ys);
            {
              assert [(xs + ys)[0]] + xs[1..] + ys == xs + ys;
            }
            Map(f, xs) + Map(f, ys);
          }
        }
      }

      function {:opaque} Filter<T>(f: T ~> bool, xs: seq<T>): (result: seq<T>)
        requires forall i: int {:trigger xs[i]} :: 0 <= i < |xs| ==> f.requires(xs[i])
        reads set i: int, o: object? {:trigger o in f.reads(xs[i])} | 0 <= i < |xs| && o in f.reads(xs[i]) :: o
        ensures |result| <= |xs|
        ensures forall i: nat {:trigger result[i]} :: i < |result| && f.requires(result[i]) ==> f(result[i])
        decreases set i: int, o: object? {:trigger o in f.reads(xs[i])} | 0 <= i < |xs| && o in f.reads(xs[i]) :: o, xs
      {
        if |xs| == 0 then
          []
        else
          (if f(xs[0]) then [xs[0]] else []) + Filter(f, xs[1..])
      }

      lemma {:isolate_assertions} /*{:_induction f, xs, ys}*/ LemmaFilterDistributesOverConcat<T(!new)>(f: T ~> bool, xs: seq<T>, ys: seq<T>)
        requires forall i: int {:trigger xs[i]} :: 0 <= i < |xs| ==> f.requires(xs[i])
        requires forall j: int {:trigger ys[j]} :: 0 <= j < |ys| ==> f.requires(ys[j])
        ensures Filter(f, xs + ys) == Filter(f, xs) + Filter(f, ys)
        decreases xs, ys
      {
        reveal Filter();
        if |xs| == 0 {
          assert xs + ys == ys;
        } else {
          calc {
            Filter(f, xs + ys);
            {
              assert {:split_here} (xs + ys)[0] == xs[0];
              assert (xs + ys)[1..] == xs[1..] + ys;
            }
            Filter(f, [xs[0]]) + Filter(f, xs[1..] + ys);
            Filter(f, [xs[0]]) + (Filter(f, xs[1..]) + Filter(f, ys));
            {
              assert {:split_here} [(xs + ys)[0]] + (xs[1..] + ys) == xs + ys;
            }
            Filter(f, xs) + Filter(f, ys);
          }
        }
      }

      function {:opaque} FoldLeft<A, T>(f: (A, T) -> A, init: A, xs: seq<T>): A
        decreases xs
      {
        if |xs| == 0 then
          init
        else
          FoldLeft(f, f(init, xs[0]), xs[1..])
      }

      lemma /*{:_induction f, xs, ys}*/ LemmaFoldLeftDistributesOverConcat<A, T>(f: (A, T) -> A, init: A, xs: seq<T>, ys: seq<T>)
        ensures FoldLeft(f, init, xs + ys) == FoldLeft(f, FoldLeft(f, init, xs), ys)
        decreases xs, ys
      {
        reveal FoldLeft();
        if |xs| == 0 {
          assert xs + ys == ys;
        } else {
          assert |xs| >= 1;
          assert ([xs[0]] + xs[1..] + ys)[0] == xs[0];
          calc {
            FoldLeft(f, FoldLeft(f, init, xs), ys);
            FoldLeft(f, FoldLeft(f, f(init, xs[0]), xs[1..]), ys);
            {
              LemmaFoldLeftDistributesOverConcat(f, f(init, xs[0]), xs[1..], ys);
            }
            FoldLeft(f, f(init, xs[0]), xs[1..] + ys);
            {
              assert (xs + ys)[0] == xs[0];
              assert (xs + ys)[1..] == xs[1..] + ys;
            }
            FoldLeft(f, init, xs + ys);
          }
        }
      }

      ghost predicate InvFoldLeft<A(!new), B(!new)>(inv: (B, seq<A>) -> bool, stp: (B, A, B) -> bool)
      {
        forall x: A, xs: seq<A>, b: B, b': B {:trigger stp(b, x, b'), [x] + xs} :: 
          inv(b, [x] + xs) &&
          stp(b, x, b') ==>
            inv(b', xs)
      }

      lemma /*{:_induction f, xs}*/ LemmaInvFoldLeft<A(!new), B(!new)>(inv: (B, seq<A>) -> bool, stp: (B, A, B) -> bool, f: (B, A) -> B, b: B, xs: seq<A>)
        requires InvFoldLeft(inv, stp)
        requires forall b: B, a: A {:trigger f(b, a)} :: stp(b, a, f(b, a))
        requires inv(b, xs)
        ensures inv(FoldLeft(f, b, xs), [])
        decreases xs
      {
        reveal FoldLeft();
        if xs == [] {
        } else {
          assert [xs[0]] + xs[1..] == xs;
          LemmaInvFoldLeft(inv, stp, f, f(b, xs[0]), xs[1..]);
        }
      }

      function {:opaque} FoldRight<A, T>(f: (T, A) -> A, xs: seq<T>, init: A): A
        decreases xs
      {
        if |xs| == 0 then
          init
        else
          f(xs[0], FoldRight(f, xs[1..], init))
      }

      lemma /*{:_induction f, xs, ys}*/ LemmaFoldRightDistributesOverConcat<A, T>(f: (T, A) -> A, init: A, xs: seq<T>, ys: seq<T>)
        ensures FoldRight(f, xs + ys, init) == FoldRight(f, xs, FoldRight(f, ys, init))
        decreases xs, ys
      {
        reveal FoldRight();
        if |xs| == 0 {
          assert xs + ys == ys;
        } else {
          calc {
            FoldRight(f, xs, FoldRight(f, ys, init));
            f(xs[0], FoldRight(f, xs[1..], FoldRight(f, ys, init)));
            f(xs[0], FoldRight(f, xs[1..] + ys, init));
            {
              assert (xs + ys)[0] == xs[0];
              assert (xs + ys)[1..] == xs[1..] + ys;
            }
            FoldRight(f, xs + ys, init);
          }
        }
      }

      ghost predicate InvFoldRight<A(!new), B(!new)>(inv: (seq<A>, B) -> bool, stp: (A, B, B) -> bool)
      {
        forall x: A, xs: seq<A>, b: B, b': B {:trigger [x] + xs, stp(x, b, b')} :: 
          inv(xs, b) &&
          stp(x, b, b') ==>
            inv([x] + xs, b')
      }

      lemma /*{:_induction f, xs}*/ LemmaInvFoldRight<A(!new), B(!new)>(inv: (seq<A>, B) -> bool, stp: (A, B, B) -> bool, f: (A, B) -> B, b: B, xs: seq<A>)
        requires InvFoldRight(inv, stp)
        requires forall a: A, b: B {:trigger f(a, b)} :: stp(a, b, f(a, b))
        requires inv([], b)
        ensures inv(xs, FoldRight(f, xs, b))
        decreases xs
      {
        reveal FoldRight();
        if xs == [] {
        } else {
          assert [xs[0]] + xs[1..] == xs;
        }
      }

      ghost function SetToSeqSpec<T>(s: set<T>): (xs: seq<T>)
        ensures multiset(s) == multiset(xs)
        decreases s
      {
        if s == {} then
          []
        else
          ghost var x: T :| x in s; [x] + SetToSeqSpec(s - {x})
      }

      method SetToSeq<T>(s: set<T>) returns (xs: seq<T>)
        ensures multiset(s) == multiset(xs)
        decreases s
      {
        xs := [];
        var left: set<T> := s;
        while left != {}
          invariant multiset(left) + multiset(xs) == multiset(s)
          decreases left
        {
          var x :| x in left;
          left := left - {x};
          xs := xs + [x];
        }
      }

      lemma SortedUnique<T(!new)>(xs: seq<T>, ys: seq<T>, R: (T, T) -> bool)
        requires SortedBy(R, xs)
        requires SortedBy(R, ys)
        requires TotalOrdering(R)
        requires multiset(xs) == multiset(ys)
        ensures xs == ys
        decreases xs, ys
      {
        if xs == [] {
          assert multiset(xs) == multiset{};
          assert multiset(ys) == multiset{};
          assert ys == [];
        } else {
          assert xs == [xs[0]] + xs[1..];
          assert ys == [ys[0]] + ys[1..];
          assert multiset(xs[1..]) == multiset(xs) - multiset{xs[0]};
          assert multiset(ys[1..]) == multiset(ys) - multiset{ys[0]};
          assert multiset(xs[1..]) == multiset(ys[1..]);
          SortedUnique(xs[1..], ys[1..], R);
        }
      }

      ghost function SetToSortedSeqSpec<T(!new)>(s: set<T>, R: (T, T) -> bool): (xs: seq<T>)
        requires TotalOrdering(R)
        ensures multiset(s) == multiset(xs)
        ensures SortedBy(R, xs)
        decreases s
      {
        MergeSortBy(R, SetToSeqSpec(s))
      }

      method SetToSortedSeq<T(!new)>(s: set<T>, R: (T, T) -> bool) returns (xs: seq<T>)
        requires TotalOrdering(R)
        ensures multiset(s) == multiset(xs)
        ensures SortedBy(R, xs)
        decreases s
      {
        xs := SetToSeq(s);
        xs := MergeSortBy(R, xs);
        SortedUnique(xs, SetToSortedSeqSpec(s, R), R);
      }

      function MergeSortBy<T(!new)>(lessThanOrEq: (T, T) -> bool, a: seq<T>): (result: seq<T>)
        requires TotalOrdering(lessThanOrEq)
        ensures multiset(a) == multiset(result)
        ensures SortedBy(lessThanOrEq, result)
        decreases a
      {
        if |a| <= 1 then
          a
        else
          var splitIndex: int := |a| / 2; var left: seq<T>, right: seq<T> := a[..splitIndex], a[splitIndex..]; assert a == left + right; var leftSorted: seq<T> := MergeSortBy(lessThanOrEq, left); var rightSorted: seq<T> := MergeSortBy(lessThanOrEq, right); MergeSortedWith(leftSorted, rightSorted, lessThanOrEq)
      }

      function {:tailrecursion} MergeSortedWith<T(!new)>(left: seq<T>, right: seq<T>, lessThanOrEq: (T, T) -> bool): (result: seq<T>)
        requires SortedBy(lessThanOrEq, left)
        requires SortedBy(lessThanOrEq, right)
        requires TotalOrdering(lessThanOrEq)
        ensures multiset(left + right) == multiset(result)
        ensures SortedBy(lessThanOrEq, result)
        decreases left, right
      {
        if |left| == 0 then
          right
        else if |right| == 0 then
          left
        else if lessThanOrEq(left[0], right[0]) then
          LemmaNewFirstElementStillSortedBy(left[0], MergeSortedWith(left[1..], right, lessThanOrEq), lessThanOrEq);
          assert left == [left[0]] + left[1..];
          [left[0]] + MergeSortedWith(left[1..], right, lessThanOrEq)
        else
          LemmaNewFirstElementStillSortedBy(right[0], MergeSortedWith(left, right[1..], lessThanOrEq), lessThanOrEq); assert right == [right[0]] + right[1..]; [right[0]] + MergeSortedWith(left, right[1..], lessThanOrEq)
      }

      lemma LemmaNewFirstElementStillSortedBy<T(!new)>(newFirst: T, s: seq<T>, lessOrEqual: (T, T) -> bool)
        requires SortedBy(lessOrEqual, s)
        requires |s| == 0 || lessOrEqual(newFirst, s[0])
        requires TotalOrdering(lessOrEqual)
        ensures SortedBy(lessOrEqual, [newFirst] + s)
        decreases s
      {
      }

      import opened Wrappers

      import opened Relations

      import Math
    }

    module Set {
      lemma LemmaSubset<T>(x: set<T>, y: set<T>)
        requires forall e: T {:trigger e in y} :: e in x ==> e in y
        ensures x <= y
        decreases x, y
      {
      }

      lemma LemmaSubsetSize<T>(x: set<T>, y: set<T>)
        ensures x < y ==> |x| < |y|
        ensures x <= y ==> |x| <= |y|
        decreases x, y
      {
        if x != {} {
          ghost var e :| e in x;
          LemmaSubsetSize(x - {e}, y - {e});
        }
      }

      lemma LemmaSubsetEquality<T>(x: set<T>, y: set<T>)
        requires x <= y
        requires |x| == |y|
        ensures x == y
        decreases x, y
      {
        if x == {} {
        } else {
          ghost var e :| e in x;
          LemmaSubsetEquality(x - {e}, y - {e});
        }
      }

      lemma LemmaSingletonSize<T>(x: set<T>, e: T)
        requires x == {e}
        ensures |x| == 1
        decreases x
      {
      }

      lemma LemmaSingletonEquality<T>(x: set<T>, a: T, b: T)
        requires |x| == 1
        requires a in x
        requires b in x
        ensures a == b
        decreases x
      {
        if a != b {
          assert {a} < x;
          LemmaSubsetSize({a}, x);
          assert false;
        }
      }

      ghost predicate IsSingleton<T>(s: set<T>)
        decreases s
      {
        (exists x: T {:trigger x in s} :: 
          x in s) &&
        forall x: T, y: T {:trigger y in s, x in s} | x in s && y in s :: 
          x == y
      }

      lemma LemmaIsSingleton<T>(s: set<T>)
        ensures |s| == 1 <==> IsSingleton(s)
        decreases s
      {
        if |s| == 1 {
          forall x: T, y: T | x in s && y in s
            ensures x == y
          {
            LemmaSingletonEquality(s, x, y);
          }
        }
        if IsSingleton(s) {
          ghost var x :| x in s;
          assert s == {x};
          assert |s| == 1;
        }
      }

      ghost function ExtractFromNonEmptySet<T>(s: set<T>): (x: T)
        requires |s| != 0
        ensures x in s
        decreases s
      {
        ghost var x: T :| x in s;
        x
      }

      function ExtractFromSingleton<T>(s: set<T>): (x: T)
        requires |s| == 1
        ensures s == {x}
        decreases s
      {
        LemmaIsSingleton(s);
        var x: T :| x in s;
        x
      }

      lemma LemmaMapSize<X(!new), Y>(xs: set<X>, ys: set<Y>, f: X --> Y)
        requires forall x: X {:trigger f.requires(x)} :: f.requires(x)
        requires Injective(f)
        requires forall x: X {:trigger f(x)} :: x in xs <==> f(x) in ys
        requires forall y: Y {:trigger y in ys} :: y in ys ==> exists x: X {:trigger f(x)} {:trigger x in xs} :: x in xs && y == f(x)
        ensures |xs| == |ys|
        decreases xs, ys
      {
        if xs != {} {
          ghost var x :| x in xs;
          ghost var xs' := xs - {x};
          ghost var ys' := ys - {f(x)};
          LemmaMapSize(xs', ys', f);
        }
      }

      function {:opaque} Map<X(!new), Y>(f: X --> Y, xs: set<X>): (ys: set<Y>)
        requires forall x: X {:trigger f.requires(x)} :: f.requires(x)
        requires Injective(f)
        reads set _x0: X, _obj: object? /*{:_reads}*/ {:trigger _obj in f.reads(_x0)} | _obj in f.reads(_x0) :: _obj
        ensures forall x: X {:trigger f(x)} :: x in xs <==> f(x) in ys
        ensures |xs| == |ys|
        decreases set _x0: X, _obj: object? /*{:_reads}*/ {:trigger _obj in f.reads(_x0)} | _obj in f.reads(_x0) :: _obj, xs
      {
        var ys: set<Y> := set x: X {:trigger f(x)} {:trigger x in xs} | x in xs :: f(x);
        LemmaMapSize(xs, ys, f);
        ys
      }

      lemma LemmaFilterSize<X>(xs: set<X>, ys: set<X>, f: X ~> bool)
        requires forall x: X {:trigger f.requires(x)} {:trigger x in xs} :: x in xs ==> f.requires(x)
        requires forall y: X {:trigger f(y)} {:trigger y in xs} :: (y in ys ==> y in xs) && (y in ys ==> f(y))
        ensures |ys| <= |xs|
        decreases xs, ys
      {
        if ys != {} {
          ghost var y :| y in ys;
          ghost var xs' := xs - {y};
          ghost var ys' := ys - {y};
          LemmaFilterSize(xs', ys', f);
        }
      }

      function {:opaque} Filter<X(!new)>(f: X ~> bool, xs: set<X>): (ys: set<X>)
        requires forall x: X {:trigger f.requires(x)} {:trigger x in xs} :: x in xs ==> f.requires(x)
        reads set x: X, o: object? {:trigger o in f.reads(x)} | x in xs && o in f.reads(x) :: o
        ensures forall y: X {:trigger f(y)} {:trigger y in xs} :: y in ys <==> y in xs && f(y)
        ensures |ys| <= |xs|
        decreases set x: X, o: object? {:trigger o in f.reads(x)} | x in xs && o in f.reads(x) :: o, xs
      {
        var ys: set<X> := set x: X {:trigger f(x)} {:trigger x in xs} | x in xs && f(x);
        LemmaFilterSize(xs, ys, f);
        ys
      }

      lemma LemmaUnionSize<X>(xs: set<X>, ys: set<X>)
        ensures |xs + ys| >= |xs|
        ensures |xs + ys| >= |ys|
        decreases xs, ys
      {
        if ys == {} {
        } else {
          ghost var y :| y in ys;
          if y in xs {
            ghost var xr := xs - {y};
            ghost var yr := ys - {y};
            assert xr + yr == xs + ys - {y};
            LemmaUnionSize(xr, yr);
          } else {
            ghost var yr := ys - {y};
            assert xs + yr == xs + ys - {y};
            LemmaUnionSize(xs, yr);
          }
        }
      }

      function {:opaque} SetRange(a: int, b: int): (s: set<int>)
        requires a <= b
        ensures forall i: int {:trigger i in s} :: a <= i < b <==> i in s
        ensures |s| == b - a
        decreases b - a
      {
        if a == b then
          {}
        else
          {a} + SetRange(a + 1, b)
      }

      function {:opaque} SetRangeZeroBound(n: int): (s: set<int>)
        requires n >= 0
        ensures forall i: int {:trigger i in s} :: 0 <= i < n <==> i in s
        ensures |s| == n
        decreases n
      {
        SetRange(0, n)
      }

      lemma LemmaBoundedSetSize(x: set<int>, a: int, b: int)
        requires forall i: int {:trigger i in x} :: (i in x ==> a <= i) && (i in x ==> i < b)
        requires a <= b
        ensures |x| <= b - a
        decreases x, a, b
      {
        ghost var range := SetRange(a, b);
        forall e: int {:trigger e in range} {:trigger e in x} | e in x
          ensures e in range
        {
        }
        assert x <= range;
        LemmaSubsetSize(x, range);
      }

      lemma LemmaGreatestImpliesMaximal<T(!new)>(R: (T, T) -> bool, max: T, s: set<T>)
        requires IsGreatest(R, max, s)
        ensures IsMaximal(R, max, s)
        decreases s
      {
      }

      lemma LemmaLeastImpliesMinimal<T(!new)>(R: (T, T) -> bool, min: T, s: set<T>)
        requires IsLeast(R, min, s)
        ensures IsMinimal(R, min, s)
        decreases s
      {
      }

      lemma LemmaMaximalEquivalentGreatest<T(!new)>(R: (T, T) -> bool, max: T, s: set<T>)
        requires TotalOrdering(R)
        ensures IsGreatest(R, max, s) <==> IsMaximal(R, max, s)
        decreases s
      {
      }

      lemma LemmaMinimalEquivalentLeast<T(!new)>(R: (T, T) -> bool, min: T, s: set<T>)
        requires TotalOrdering(R)
        ensures IsLeast(R, min, s) <==> IsMinimal(R, min, s)
        decreases s
      {
      }

      lemma LemmaLeastIsUnique<T(!new)>(R: (T, T) -> bool, s: set<T>)
        requires PartialOrdering(R)
        ensures forall min: T, min': T {:trigger IsLeast(R, min', s), IsLeast(R, min, s)} | IsLeast(R, min, s) && IsLeast(R, min', s) :: min == min'
        decreases s
      {
      }

      lemma LemmaGreatestIsUnique<T(!new)>(R: (T, T) -> bool, s: set<T>)
        requires PartialOrdering(R)
        ensures forall max: T, max': T {:trigger IsGreatest(R, max', s), IsGreatest(R, max, s)} | IsGreatest(R, max, s) && IsGreatest(R, max', s) :: max == max'
        decreases s
      {
      }

      lemma LemmaMinimalIsUnique<T(!new)>(R: (T, T) -> bool, s: set<T>)
        requires TotalOrdering(R)
        ensures forall min: T, min': T {:trigger IsMinimal(R, min', s), IsMinimal(R, min, s)} | IsMinimal(R, min, s) && IsMinimal(R, min', s) :: min == min'
        decreases s
      {
      }

      lemma LemmaMaximalIsUnique<T(!new)>(R: (T, T) -> bool, s: set<T>)
        requires TotalOrdering(R)
        ensures forall max: T, max': T {:trigger IsMaximal(R, max', s), IsMaximal(R, max, s)} | IsMaximal(R, max, s) && IsMaximal(R, max', s) :: max == max'
        decreases s
      {
      }

      lemma LemmaFindUniqueMinimal<T(!new)>(R: (T, T) -> bool, s: set<T>) returns (min: T)
        requires |s| > 0 && TotalOrdering(R)
        ensures IsMinimal(R, min, s) && forall min': T {:trigger IsMinimal(R, min', s)} | IsMinimal(R, min', s) :: min == min'
        decreases s
      {
        ghost var x :| x in s;
        if s == {x} {
          min := x;
        } else {
          ghost var min' := LemmaFindUniqueMinimal(R, s - {x});
          if
          case R(min', x) =>
            min := min';
          case R(x, min') =>
            min := x;
        }
      }

      lemma LemmaFindUniqueMaximal<T(!new)>(R: (T, T) -> bool, s: set<T>) returns (max: T)
        requires |s| > 0 && TotalOrdering(R)
        ensures IsMaximal(R, max, s) && forall max': T {:trigger IsMaximal(R, max', s)} | IsMaximal(R, max', s) :: max == max'
        decreases s
      {
        ghost var x :| x in s;
        if s == {x} {
          max := x;
        } else {
          ghost var max' := LemmaFindUniqueMaximal(R, s - {x});
          if
          case R(max', x) =>
            max := x;
          case R(x, max') =>
            max := max';
        }
      }

      import opened Functions

      import opened Relations
    }
  }

  module DynamicArray {

    import opened BoundedInts

    import opened Wrappers

    export
      reveals DynamicArray
      provides BoundedInts, DynamicArray.items, DynamicArray.capacity, DynamicArray.Repr, DynamicArray.Valid?, DynamicArray.size, DynamicArray.At, DynamicArray.Put, DynamicArray.Push, DynamicArray.PushFast, DynamicArray.PopFast, DynamicArray.Ensure

    class DynamicArray<A> {
      ghost var items: seq<A>
      ghost var Repr: set<object>
      var size: nat
      var capacity: nat
      var data: array<A>

      ghost predicate Valid?()
        reads this, Repr
        decreases Repr + {this}
      {
        Repr == {this, data} &&
        data.Length == capacity as int &&
        size <= capacity &&
        size as int == |items| &&
        items == data[..size]
      }

      constructor ()
        ensures size == 0
        ensures items == []
        ensures fresh(Repr)
        ensures capacity == 0
        ensures Valid?()
      {
        items := [];
        size := 0;
        capacity := 0;
        data := new A[0];
        Repr := {this, data};
      }

      function At(index: nat): (element: A)
        requires index < size
        requires Valid?()
        reads this, Repr
        ensures element == items[index]
        decreases Repr + {this}, index
      {
        data[index]
      }

      method Put(index: nat, element: A)
        requires index < size
        requires Valid?()
        modifies Repr, `items
        ensures Valid?()
        ensures fresh(Repr - old(Repr))
        ensures size == old(size)
        ensures items == old(items)[index := element]
        decreases index
      {
        data[index] := element;
        items := items[index := element];
      }

      method Ensure(reserved: nat, defaultValue: A)
        requires Valid?()
        modifies Repr
        ensures Valid?()
        ensures size == old(size)
        ensures items == old(items)
        ensures fresh(Repr - old(Repr))
        ensures reserved <= capacity - size
        decreases reserved
      {
        var newCapacity := capacity;
        while reserved > newCapacity - size
          invariant newCapacity >= capacity
          decreases reserved - (newCapacity - size)
        {
          newCapacity := DefaultNewCapacity(newCapacity);
        }
        if newCapacity > capacity {
          Realloc(defaultValue, newCapacity);
        }
      }

      method PopFast()
        requires Valid?()
        requires size > 0
        modifies `size, `items
        ensures Valid?()
        ensures size < capacity
        ensures size == old(size) - 1
        ensures capacity == old(capacity)
        ensures items == old(items[..|items| - 1])
      {
        size := size - 1;
        items := items[..|items| - 1];
      }

      method PushFast(element: A)
        requires Valid?()
        requires size < capacity
        modifies Repr
        ensures Valid?()
        ensures fresh(Repr - old(Repr))
        ensures size == old(size) + 1
        ensures capacity == old(capacity)
        ensures items == old(items) + [element]
      {
        data[size] := element;
        size := size + 1;
        items := items + [element];
      }

      method Push(element: A)
        requires Valid?()
        modifies Repr
        ensures Valid?()
        ensures fresh(Repr - old(Repr))
        ensures size == old(size) + 1
        ensures items == old(items) + [element]
        ensures capacity >= old(capacity)
      {
        if size == capacity {
          ReallocDefault(element);
        }
        PushFast(element);
      }

      method Realloc(defaultValue: A, newCapacity: nat)
        requires Valid?()
        requires newCapacity > capacity
        modifies `capacity, `data, `Repr, data
        ensures Valid?()
        ensures capacity == newCapacity
        ensures fresh(data)
        decreases newCapacity
      {
        var oldData, oldCapacity := data, capacity;
        data, capacity := new A[newCapacity] ((_ /* _v0 */: nat) => defaultValue), newCapacity;
        CopyFrom(oldData, oldCapacity);
        Repr := {this, data};
      }

      function DefaultNewCapacity(capacity: nat): nat
        decreases capacity
      {
        if capacity == 0 then
          8
        else
          2 * capacity
      }

      method ReallocDefault(defaultValue: A)
        requires Valid?()
        modifies `capacity, `data, `Repr, data
        ensures Valid?()
        ensures fresh(data)
        ensures capacity == old(DefaultNewCapacity(capacity))
      {
        Realloc(defaultValue, DefaultNewCapacity(capacity));
      }

      method CopyFrom(newData: array<A>, count: nat)
        requires count as int <= newData.Length
        requires count <= capacity
        requires data.Length == capacity as int
        modifies data
        ensures data[..count] == newData[..count]
        ensures data[count..] == old(data[count..])
        decreases newData, count
      {
        forall index: int | 0 <= index < count {
          data[index] := newData[index];
        }
      }
    }
  }

  module Functions {
    ghost predicate Injective<X(!new), Y>(f: X --> Y)
      requires forall x: X {:trigger f.requires(x)} :: f.requires(x)
      reads set _x0: X, _obj: object? /*{:_reads}*/ {:trigger _obj in f.reads(_x0)} | _obj in f.reads(_x0) :: _obj
      decreases set _x0: X, _obj: object? /*{:_reads}*/ {:trigger _obj in f.reads(_x0)} | _obj in f.reads(_x0) :: _obj
    {
      forall x1: X, x2: X {:trigger f(x2), f(x1)} :: 
        f(x1) == f(x2) ==>
          x1 == x2
    }

    ghost predicate Commutative<T(!new), U(!new)>(f: (T, T) -> U)
      requires forall x: T, y: T {:trigger f.requires(y, x)} {:trigger f.requires(x, y)} :: f.requires(x, y) && f.requires(y, x)
      reads set _x0: T, _x1: T, _obj: object? /*{:_reads}*/ {:trigger _obj in f.reads(_x0, _x1)} | _obj in f.reads(_x0, _x1) :: _obj
      decreases set _x0: T, _x1: T, _obj: object? /*{:_reads}*/ {:trigger _obj in f.reads(_x0, _x1)} | _obj in f.reads(_x0, _x1) :: _obj
    {
      forall x: T, y: T {:trigger f(y, x)} {:trigger f(x, y)} :: 
        f(x, y) == f(y, x)
    }

    ghost predicate Associative<T(!new)>(f: (T, T) -> T)
      requires forall x: T, y: T, z: T {:trigger f.requires(x, z), f.requires(y, z)} {:trigger f.requires(y, z), f.requires(x, y)} :: f.requires(x, y) && f.requires(y, z) && f.requires(x, z)
      reads set _x0: T, _x1: T, _obj: object? /*{:_reads}*/ {:trigger _obj in f.reads(_x0, _x1)} | _obj in f.reads(_x0, _x1) :: _obj
      decreases set _x0: T, _x1: T, _obj: object? /*{:_reads}*/ {:trigger _obj in f.reads(_x0, _x1)} | _obj in f.reads(_x0, _x1) :: _obj
    {
      forall x: T, y: T, z: T {:trigger f(f(x, y), z)} {:trigger f(x, f(y, z))} :: 
        f(x, f(y, z)) == f(f(x, y), z)
    }
  }

  module Math {
    function Min(a: int, b: int): int
      decreases a, b
    {
      if a < b then
        a
      else
        b
    }

    function Min3(a: int, b: int, c: int): int
      decreases a, b, c
    {
      Min(a, Min(b, c))
    }

    function Max(a: int, b: int): int
      decreases a, b
    {
      if a < b then
        b
      else
        a
    }

    function Max3(a: int, b: int, c: int): int
      decreases a, b, c
    {
      Max(a, Max(b, c))
    }

    function Abs(a: int): int
      decreases a
    {
      if a < 0 then
        -a
      else
        a
    }
  }

  module Relations {
    ghost predicate Reflexive<T(!new)>(relation: (T, T) -> bool)
    {
      forall x: T {:trigger relation(x, x)} :: 
        relation(x, x)
    }

    ghost predicate Irreflexive<T(!new)>(relation: (T, T) -> bool)
    {
      forall x: T {:trigger relation(x, x)} :: 
        !relation(x, x)
    }

    ghost predicate Symmetric<T(!new)>(relation: (T, T) -> bool)
    {
      forall x: T, y: T {:trigger relation(y, x)} {:trigger relation(x, y)} :: 
        relation(x, y) <==> relation(y, x)
    }

    ghost predicate AntiSymmetric<T(!new)>(relation: (T, T) -> bool)
    {
      forall x: T, y: T {:trigger relation(y, x)} {:trigger relation(x, y)} :: 
        relation(x, y) &&
        relation(y, x) ==>
          x == y
    }

    ghost predicate Asymmetric<T(!new)>(relation: (T, T) -> bool)
    {
      forall x: T, y: T {:trigger relation(y, x)} {:trigger relation(x, y)} :: 
        relation(x, y) ==>
          !relation(y, x)
    }

    lemma AsymmetricIsAntiSymmetric<T(!new)>(relation: (T, T) -> bool)
      ensures Asymmetric(relation) ==> AntiSymmetric(relation)
    {
    }

    lemma AsymmetricIsIrreflexive<T(!new)>(relation: (T, T) -> bool)
      ensures Asymmetric(relation) ==> Irreflexive(relation)
    {
    }

    ghost predicate Connected<T(!new)>(relation: (T, T) -> bool)
    {
      forall x: T, y: T {:trigger relation(y, x)} {:trigger relation(x, y)} :: 
        x != y ==>
          relation(x, y) || relation(y, x)
    }

    ghost predicate StronglyConnected<T(!new)>(relation: (T, T) -> bool)
    {
      forall x: T, y: T {:trigger relation(y, x)} {:trigger relation(x, y)} :: 
        relation(x, y) || relation(y, x)
    }

    ghost predicate Transitive<T(!new)>(relation: (T, T) -> bool)
    {
      forall x: T, y: T, z: T {:trigger relation(x, z), relation(y, z)} {:trigger relation(y, z), relation(x, y)} :: 
        relation(x, y) &&
        relation(y, z) ==>
          relation(x, z)
    }

    ghost predicate TotalOrdering<T(!new)>(relation: (T, T) -> bool)
    {
      Reflexive(relation) &&
      AntiSymmetric(relation) &&
      Transitive(relation) &&
      StronglyConnected(relation)
    }

    ghost predicate StrictTotalOrdering<T(!new)>(relation: (T, T) -> bool)
    {
      Irreflexive(relation) &&
      AntiSymmetric(relation) &&
      Transitive(relation) &&
      Connected(relation)
    }

    ghost predicate PreOrdering<T(!new)>(relation: (T, T) -> bool)
    {
      Reflexive(relation) &&
      Transitive(relation)
    }

    ghost predicate PartialOrdering<T(!new)>(relation: (T, T) -> bool)
    {
      Reflexive(relation) &&
      Transitive(relation) &&
      AntiSymmetric(relation)
    }

    ghost predicate EquivalenceRelation<T(!new)>(relation: (T, T) -> bool)
    {
      Reflexive(relation) &&
      Symmetric(relation) &&
      Transitive(relation)
    }

    ghost predicate IsLeast<T>(lessOrEqual: (T, T) -> bool, least: T, s: set<T>)
      decreases s
    {
      least in s &&
      forall x: T {:trigger lessOrEqual(least, x)} {:trigger x in s} | x in s :: 
        lessOrEqual(least, x)
    }

    ghost predicate IsMinimal<T>(lessOrEqual: (T, T) -> bool, minimal: T, s: set<T>)
      decreases s
    {
      minimal in s &&
      forall x: T {:trigger lessOrEqual(minimal, x)} {:trigger lessOrEqual(x, minimal)} {:trigger x in s} | x in s && lessOrEqual(x, minimal) :: 
        lessOrEqual(minimal, x)
    }

    ghost predicate IsGreatest<T>(lessOrEqual: (T, T) -> bool, greatest: T, s: set<T>)
      decreases s
    {
      greatest in s &&
      forall x: T {:trigger lessOrEqual(x, greatest)} {:trigger x in s} | x in s :: 
        lessOrEqual(x, greatest)
    }

    ghost predicate IsMaximal<T>(lessOrEqual: (T, T) -> bool, maximal: T, s: set<T>)
      decreases s
    {
      maximal in s &&
      forall x: T {:trigger lessOrEqual(x, maximal)} {:trigger lessOrEqual(maximal, x)} {:trigger x in s} | x in s && lessOrEqual(maximal, x) :: 
        lessOrEqual(x, maximal)
    }

    ghost predicate SortedBy<T>(lessOrEqual: (T, T) -> bool, xs: seq<T>)
      decreases xs
    {
      forall i: int, j: int {:trigger xs[j], xs[i]} | 0 <= i < j < |xs| :: 
        lessOrEqual(xs[i], xs[j])
    }
  }

  module {:disableNonlinearArithmetic} Strings {
    function OfNat(n: nat): (str: string)
      ensures |str| == Log(DecimalConversion.base, n) + 1
      ensures forall c: char {:trigger c in DecimalConversion.chars} {:trigger c in str} | c in str :: c in DecimalConversion.chars
      decreases n
    {
      DecimalConversion.OfNat(n)
    }

    function OfInt(n: int): (str: string)
      ensures DecimalConversion.IsNumberStr(str, '-')
      decreases n
    {
      DecimalConversion.OfInt(n, '-')
    }

    function ToNat(str: string): (n: nat)
      requires forall c: Char {:trigger _default.IsDigitChar(c)} {:trigger c in str} | c in str :: _default.IsDigitChar(c)
      ensures n < Pow(DecimalConversion.base, |str|)
      decreases str
    {
      DecimalConversion.ToNatBound(str);
      DecimalConversion.ToNat(str)
    }

    function ToInt(str: string): (n: int)
      requires str != ""-""
      requires DecimalConversion.IsNumberStr(str, '-')
      decreases str
    {
      DecimalConversion.ToInt(str, '-')
    }

    function EscapeQuotes(str: string): string
      decreases str
    {
      CharStrEscaping.Escape(str, {'\""', '\''}, '\\')
    }

    function UnescapeQuotes(str: string): Option<string>
      decreases str
    {
      CharStrEscaping.Unescape(str, '\\')
    }

    function OfBool(b: bool): string
      decreases b
    {
      if b then
        ""true""
      else
        ""false""
    }

    function OfChar(c: char): string
      decreases c
    {
      [c]
    }

    import opened Wrappers

    import opened Power = Arithmetic.Power

    import opened Logarithm = Arithmetic.Logarithm

    import Arithmetic

    abstract module {:disableNonlinearArithmetic} ParametricConversion refines Arithmetic.LittleEndianNat {
      const chars: CharSeq
      const base := |chars|
      const charToDigit: map<Char, digit>

      lemma CharsConsistent()
        ensures forall c: Char {:trigger charToDigit[c]} {:trigger c in charToDigit} {:trigger c in chars} | c in chars :: c in charToDigit && chars[charToDigit[c]] == c

      function BASE(): nat
        ensures BASE() > 1
      {
        base
      }

      predicate IsDigitChar(c: Char)
      {
        c in charToDigit
      }

      function OfDigits(digits: seq<digit>): (str: String)
        ensures forall c: Char {:trigger c in chars} {:trigger c in str} | c in str :: c in chars
        ensures |str| == |digits|
        decreases digits
      {
        if digits == [] then
          []
        else
          assert digits[0] in digits; assert forall d: int {:trigger d in digits} {:trigger d in digits[1..]} | d in digits[1..] :: d in digits; OfDigits(digits[1..]) + [chars[digits[0]]]
      }

      function OfNat(n: nat): (str: String)
        ensures |str| == Log(base, n) + 1
        ensures forall c: Char {:trigger c in chars} {:trigger c in str} | c in str :: c in chars
        decreases n
      {
        if n == 0 then
          reveal Log();
          [chars[0]]
        else
          LemmaFromNatLen2(n); OfDigits(FromNat(n))
      }

      predicate IsNumberStr(str: String, minus: Char)
        decreases str
      {
        str != [] ==>
          (str[0] == minus || str[0] in charToDigit) &&
          forall c: Char {:trigger IsDigitChar(c)} {:trigger c in str[1..]} | c in str[1..] :: 
            IsDigitChar(c)
      }

      function OfInt(n: int, minus: Char): (str: String)
        ensures IsNumberStr(str, minus)
        decreases n
      {
        CharsConsistent();
        if n >= 0 then
          OfNat(n)
        else
          [minus] + OfNat(-n)
      }

      function {:isolate_assertions} ToNat(str: String): (n: nat)
        requires forall c: Char {:trigger IsDigitChar(c)} {:trigger c in str} | c in str :: IsDigitChar(c)
        decreases str
      {
        if str == [] then
          0
        else
          LemmaMulNonnegativeAuto(); var c: Char := str[|str| - 1]; assert IsDigitChar(c); ToNat(str[..|str| - 1]) * base + charToDigit[c]
      }

      lemma {:induction false} ToNatBound(str: String)
        requires base > 0
        requires forall c: Char {:trigger IsDigitChar(c)} {:trigger c in str} | c in str :: IsDigitChar(c)
        ensures ToNat(str) < Pow(base, |str|)
        decreases str
      {
        if str == [] {
          reveal Pow();
        } else {
          calc <= {
            ToNat(str);
            {
              assert IsDigitChar(str[|str| - 1]);
            }
            ToNat(str[..|str| - 1]) * base + charToDigit[str[|str| - 1]];
            ToNat(str[..|str| - 1]) * base + base - 1;
            {
              ToNatBound(str[..|str| - 1]);
              LemmaMulInequalityAuto();
            }
            (Pow(base, |str| - 1) - 1) * base + base - 1;
            {
              LemmaMulIsDistributiveAuto();
            }
            Pow(base, |str| - 1) * base - 1;
            {
              reveal Pow();
              LemmaMulIsCommutativeAuto();
            }
            Pow(base, |str|) - 1;
          }
        }
      }

      function ToInt(str: String, minus: Char): (s: int)
        requires str != [minus]
        requires IsNumberStr(str, minus)
        decreases str
      {
        if [minus] <= str then
          -(ToNat(str[1..]) as int)
        else
          assert str == [] || str == [str[0]] + str[1..]; ToNat(str)
      }

      function {:opaque} ToNatRight(xs: seq<digit>): nat
        decreases xs
      {
        if |xs| == 0 then
          0
        else
          LemmaMulNonnegativeAuto(); ToNatRight(DropFirst(xs)) * BASE() + First(xs)
      }

      function {:opaque} ToNatLeft(xs: seq<digit>): nat
        decreases xs
      {
        if |xs| == 0 then
          0
        else
          LemmaPowPositiveAuto(); LemmaMulNonnegativeAuto(); ToNatLeft(DropLast(xs)) + Last(xs) * Pow(BASE(), |xs| - 1)
      }

      lemma {:isolate_assertions} /*{:_induction xs}*/ LemmaToNatLeftEqToNatRight(xs: seq<digit>)
        ensures ToNatRight(xs) == ToNatLeft(xs)
        decreases xs
      {
        reveal ToNatRight();
        reveal ToNatLeft();
        if xs == [] {
        } else {
          if DropLast(xs) == [] {
            calc {
              ToNatLeft(xs);
              Last(xs) * Pow(BASE(), |xs| - 1);
              {
                reveal Pow();
              }
              Last(xs);
              First(xs);
              {
                assert ToNatRight(DropFirst(xs)) == 0;
              }
              ToNatRight(xs);
            }
          } else {
            calc {
              ToNatLeft(xs);
              ToNatLeft(DropLast(xs)) + Last(xs) * Pow(BASE(), |xs| - 1);
              {
                LemmaToNatLeftEqToNatRight(DropLast(xs));
              }
              ToNatRight(DropLast(xs)) + Last(xs) * Pow(BASE(), |xs| - 1);
              ToNatRight(DropFirst(DropLast(xs))) * BASE() + First(xs) + Last(xs) * Pow(BASE(), |xs| - 1);
              {
                LemmaToNatLeftEqToNatRight(DropFirst(DropLast(xs)));
              }
              ToNatLeft(DropFirst(DropLast(xs))) * BASE() + First(xs) + Last(xs) * Pow(BASE(), |xs| - 1);
              {
                assert DropFirst(DropLast(xs)) == DropLast(DropFirst(xs));
                reveal Pow();
                LemmaMulProperties();
              }
              ToNatLeft(DropLast(DropFirst(xs))) * BASE() + First(xs) + Last(xs) * Pow(BASE(), |xs| - 2) * BASE();
              {
                LemmaMulIsDistributiveAddOtherWayAuto();
              }
              ToNatLeft(DropFirst(xs)) * BASE() + First(xs);
              {
                LemmaToNatLeftEqToNatRight(DropFirst(xs));
              }
              ToNatRight(xs);
            }
          }
        }
      }

      lemma LemmaToNatLeftEqToNatRightAuto()
        ensures forall xs: seq<digit> {:trigger ToNatLeft(xs)} {:trigger ToNatRight(xs)} :: ToNatRight(xs) == ToNatLeft(xs)
      {
        reveal ToNatRight();
        reveal ToNatLeft();
        forall xs: seq<digit> | true
          ensures ToNatRight(xs) == ToNatLeft(xs)
        {
          LemmaToNatLeftEqToNatRight(xs);
        }
      }

      lemma /*{:_induction xs}*/ LemmaSeqLen1(xs: seq<digit>)
        requires |xs| == 1
        ensures ToNatRight(xs) == First(xs)
        decreases xs
      {
        reveal ToNatRight();
        assert ToNatRight(DropFirst(xs)) == 0;
      }

      lemma /*{:_induction xs}*/ LemmaSeqLen2(xs: seq<digit>)
        requires |xs| == 2
        ensures ToNatRight(xs) == First(xs) + xs[1] * BASE()
        decreases xs
      {
        reveal ToNatRight();
        LemmaSeqLen1(DropLast(xs));
      }

      lemma /*{:_induction xs}*/ LemmaSeqAppendZero(xs: seq<digit>)
        ensures ToNatRight(xs + [0]) == ToNatRight(xs)
        decreases xs
      {
        reveal ToNatLeft();
        LemmaToNatLeftEqToNatRightAuto();
        calc {
          ToNatRight(xs + [0]);
          ToNatLeft(xs + [0]);
          ToNatLeft(xs) + 0 * Pow(BASE(), |xs|);
          {
            LemmaMulBasicsAuto();
          }
          ToNatLeft(xs);
          ToNatRight(xs);
        }
      }

      lemma /*{:_induction xs}*/ LemmaSeqNatBound(xs: seq<digit>)
        ensures ToNatRight(xs) < Pow(BASE(), |xs|)
        decreases xs
      {
        reveal Pow();
        if |xs| == 0 {
          reveal ToNatRight();
        } else {
          ghost var len' := |xs| - 1;
          ghost var pow := Pow(BASE(), len');
          calc {
            ToNatRight(xs);
            {
              LemmaToNatLeftEqToNatRight(xs);
            }
            ToNatLeft(xs);
            {
              reveal ToNatLeft();
            }
            ToNatLeft(DropLast(xs)) + Last(xs) * pow;
          <
            {
              LemmaToNatLeftEqToNatRight(DropLast(xs));
              LemmaSeqNatBound(DropLast(xs));
            }
            pow + Last(xs) * pow;
          <=
            {
              LemmaPowPositiveAuto();
              LemmaMulInequalityAuto();
            }
            pow + (BASE() - 1) * pow;
            {
              LemmaMulIsDistributiveAuto();
            }
            Pow(BASE(), len' + 1);
          }
        }
      }

      lemma {:isolate_assertions} /*{:_induction xs, i}*/ LemmaSeqPrefix(xs: seq<digit>, i: nat)
        requires 0 <= i <= |xs|
        ensures ToNatRight(xs[..i]) + ToNatRight(xs[i..]) * Pow(BASE(), i) == ToNatRight(xs)
        decreases xs, i
      {
        reveal ToNatRight();
        reveal Pow();
        if i == 1 {
          assert ToNatRight(xs[..1]) == First(xs);
        } else if i > 1 {
          calc {
            ToNatRight(xs[..i]) + ToNatRight(xs[i..]) * Pow(BASE(), i);
            ToNatRight(DropFirst(xs[..i])) * BASE() + First(xs) + ToNatRight(xs[i..]) * Pow(BASE(), i);
            {
              assert DropFirst(xs[..i]) == DropFirst(xs)[..i - 1];
              LemmaMulProperties();
            }
            ToNatRight(DropFirst(xs)[..i - 1]) * BASE() + First(xs) + ToNatRight(xs[i..]) * Pow(BASE(), i - 1) * BASE();
            {
              LemmaMulIsDistributiveAddOtherWayAuto();
            }
            (ToNatRight(DropFirst(xs)[..i - 1]) + ToNatRight(DropFirst(xs)[i - 1..]) * Pow(BASE(), i - 1)) * BASE() + First(xs);
            {
              LemmaSeqPrefix(DropFirst(xs), i - 1);
            }
            ToNatRight(xs);
          }
        }
      }

      lemma /*{:_induction xs, ys}*/ LemmaSeqMswInequality(xs: seq<digit>, ys: seq<digit>)
        requires |xs| == |ys| > 0
        requires Last(xs) < Last(ys)
        ensures ToNatRight(xs) < ToNatRight(ys)
        decreases xs, ys
      {
        reveal ToNatLeft();
        LemmaToNatLeftEqToNatRightAuto();
        ghost var len' := |xs| - 1;
        calc {
          ToNatRight(xs);
          ToNatLeft(xs);
        <
          {
            LemmaSeqNatBound(DropLast(xs));
          }
          Pow(BASE(), len') + Last(xs) * Pow(BASE(), len');
        ==
          {
            LemmaMulIsDistributiveAuto();
          }
          (1 + Last(xs)) * Pow(BASE(), len');
        <=
          {
            LemmaPowPositiveAuto();
            LemmaMulInequalityAuto();
          }
          ToNatLeft(ys);
          ToNatRight(ys);
        }
      }

      lemma {:isolate_assertions} /*{:_induction xs, ys}*/ LemmaSeqPrefixNeq(xs: seq<digit>, ys: seq<digit>, i: nat)
        requires 0 <= i <= |xs| == |ys|
        requires ToNatRight(xs[..i]) != ToNatRight(ys[..i])
        ensures ToNatRight(xs) != ToNatRight(ys)
        decreases |xs| - i
      {
        if i == |xs| {
          assert xs[..i] == xs;
          assert ys[..i] == ys;
        } else {
          if xs[i] == ys[i] {
            reveal ToNatLeft();
            assert DropLast(xs[..i + 1]) == xs[..i];
            assert DropLast(ys[..i + 1]) == ys[..i];
            LemmaToNatLeftEqToNatRightAuto();
            assert ToNatRight(xs[..i + 1]) == ToNatLeft(xs[..i + 1]);
          } else if xs[i] < ys[i] {
            LemmaSeqMswInequality(xs[..i + 1], ys[..i + 1]);
          } else {
            LemmaSeqMswInequality(ys[..i + 1], xs[..i + 1]);
          }
          reveal ToNatRight();
          LemmaSeqPrefixNeq(xs, ys, i + 1);
        }
      }

      lemma /*{:_induction xs, ys}*/ LemmaSeqNeq(xs: seq<digit>, ys: seq<digit>)
        requires |xs| == |ys|
        requires xs != ys
        ensures ToNatRight(xs) != ToNatRight(ys)
        decreases xs, ys
      {
        ghost var i: nat, n: nat := 0, |xs|;
        while i < n
          invariant 0 <= i < n
          invariant xs[..i] == ys[..i]
          decreases n - i
        {
          if xs[i] != ys[i] {
            break;
          }
          i := i + 1;
        }
        assert ToNatLeft(xs[..i]) == ToNatLeft(ys[..i]);
        reveal ToNatLeft();
        assert xs[..i + 1][..i] == xs[..i];
        assert ys[..i + 1][..i] == ys[..i];
        LemmaPowPositiveAuto();
        LemmaMulStrictInequalityAuto();
        assert ToNatLeft(xs[..i + 1]) != ToNatLeft(ys[..i + 1]);
        LemmaToNatLeftEqToNatRightAuto();
        LemmaSeqPrefixNeq(xs, ys, i + 1);
      }

      lemma /*{:_induction xs, ys}*/ LemmaSeqEq(xs: seq<digit>, ys: seq<digit>)
        requires |xs| == |ys|
        requires ToNatRight(xs) == ToNatRight(ys)
        ensures xs == ys
        decreases xs, ys
      {
        calc ==> {
          xs != ys;
          {
            LemmaSeqNeq(xs, ys);
          }
          ToNatRight(xs) != ToNatRight(ys);
          false;
        }
      }

      lemma {:isolate_assertions} /*{:_induction xs}*/ LemmaSeqLswModEquivalence(xs: seq<digit>)
        requires |xs| >= 1
        ensures IsModEquivalent(ToNatRight(xs), First(xs), BASE())
        decreases xs
      {
        if |xs| == 1 {
          LemmaSeqLen1(xs);
          LemmaModEquivalenceAuto();
        } else {
          assert IsModEquivalent(ToNatRight(xs), First(xs), BASE()) by {
            reveal ToNatRight();
            calc ==> {
              true;
              {
                LemmaModEquivalence(ToNatRight(xs), ToNatRight(DropFirst(xs)) * BASE() + First(xs), BASE());
              }
              IsModEquivalent(ToNatRight(xs), ToNatRight(DropFirst(xs)) * BASE() + First(xs), BASE());
              {
                LemmaModMultiplesBasicAuto();
              }
              IsModEquivalent(ToNatRight(xs), First(xs), BASE());
            }
          }
        }
      }

      function {:opaque} FromNat(n: nat): (xs: seq<digit>)
        decreases n
      {
        if n == 0 then
          []
        else
          LemmaDivBasicsAuto(); LemmaDivDecreasesAuto(); [n % BASE()] + FromNat(n / BASE())
      }

      lemma /*{:_induction n}*/ LemmaFromNatLen2(n: nat)
        ensures n == 0 ==> |FromNat(n)| == 0
        ensures n > 0 ==> |FromNat(n)| == Log(BASE(), n) + 1
        decreases n
      {
        reveal FromNat();
        ghost var digits := FromNat(n);
        if n == 0 {
        } else {
          assert |digits| == Log(BASE(), n) + 1 by {
            LemmaDivBasicsAuto();
            ghost var digits' := FromNat(n / BASE());
            assert |digits| == |digits'| + 1;
            if n < BASE() {
              LemmaLog0(BASE(), n);
              assert n / BASE() == 0 by {
                LemmaBasicDiv(BASE());
              }
            } else {
              LemmaLogS(BASE(), n);
              assert n / BASE() > 0 by {
                LemmaDivNonZeroAuto();
              }
            }
          }
        }
      }

      lemma /*{:_induction n, len}*/ LemmaFromNatLen(n: nat, len: nat)
        requires Pow(BASE(), len) > n
        ensures |FromNat(n)| <= len
        decreases n, len
      {
        reveal FromNat();
        if n == 0 {
        } else {
          calc {
            |FromNat(n)|;
          ==
            {
              LemmaDivBasicsAuto();
            }
            1 + |FromNat(n / BASE())|;
          <=
            {
              LemmaMultiplyDivideLtAuto();
              LemmaDivDecreasesAuto();
              reveal Pow();
              LemmaFromNatLen(n / BASE(), len - 1);
            }
            len;
          }
        }
      }

      lemma /*{:_induction n}*/ LemmaNatSeqNat(n: nat)
        ensures ToNatRight(FromNat(n)) == n
        decreases n
      {
        reveal ToNatRight();
        reveal FromNat();
        if n == 0 {
        } else {
          calc {
            ToNatRight(FromNat(n));
            {
              LemmaDivBasicsAuto();
            }
            ToNatRight([n % BASE()] + FromNat(n / BASE()));
            n % BASE() + ToNatRight(FromNat(n / BASE())) * BASE();
            {
              LemmaDivDecreasesAuto();
              LemmaNatSeqNat(n / BASE());
            }
            n % BASE() + n / BASE() * BASE();
            {
              LemmaFundamentalDivMod(n, BASE());
            }
            n;
          }
        }
      }

      function {:opaque} SeqExtend(xs: seq<digit>, n: nat): (ys: seq<digit>)
        requires |xs| <= n
        ensures |ys| == n
        ensures ToNatRight(ys) == ToNatRight(xs)
        decreases n - |xs|
      {
        if |xs| >= n then
          xs
        else
          LemmaSeqAppendZero(xs); SeqExtend(xs + [0], n)
      }

      function {:opaque} SeqExtendMultiple(xs: seq<digit>, n: nat): (ys: seq<digit>)
        requires n > 0
        ensures |ys| % n == 0
        ensures ToNatRight(ys) == ToNatRight(xs)
        decreases xs, n
      {
        var newLen: int := |xs| + n - |xs| % n;
        LemmaSubModNoopRight(|xs| + n, |xs|, n);
        LemmaModBasicsAuto();
        assert newLen % n == 0;
        LemmaSeqNatBound(xs);
        LemmaPowIncreasesAuto();
        SeqExtend(xs, newLen)
      }

      function {:opaque} FromNatWithLen(n: nat, len: nat): (xs: seq<digit>)
        requires Pow(BASE(), len) > n
        ensures |xs| == len
        ensures ToNatRight(xs) == n
        decreases n, len
      {
        LemmaFromNatLen(n, len);
        LemmaNatSeqNat(n);
        SeqExtend(FromNat(n), len)
      }

      lemma {:resource_limit ""10e6""} /*{:_induction xs}*/ LemmaSeqZero(xs: seq<digit>)
        requires ToNatRight(xs) == 0
        ensures forall i: int {:trigger xs[i]} :: 0 <= i < |xs| ==> xs[i] == 0
        decreases xs
      {
        reveal ToNatRight();
        if |xs| == 0 {
        } else {
          LemmaMulNonnegativeAuto();
          assert First(xs) == 0;
          LemmaMulNonzeroAuto();
          LemmaSeqZero(DropFirst(xs));
        }
      }

      function {:opaque} SeqZero(len: nat): (xs: seq<digit>)
        ensures |xs| == len
        ensures forall i: int {:trigger xs[i]} :: 0 <= i < |xs| ==> xs[i] == 0
        ensures ToNatRight(xs) == 0
        decreases len
      {
        LemmaPowPositive(BASE(), len);
        var xs: seq<digit> := FromNatWithLen(0, len);
        LemmaSeqZero(xs);
        xs
      }

      lemma /*{:_induction xs}*/ LemmaSeqNatSeq(xs: seq<digit>)
        ensures Pow(BASE(), |xs|) > ToNatRight(xs)
        ensures FromNatWithLen(ToNatRight(xs), |xs|) == xs
        decreases xs
      {
        reveal FromNat();
        reveal ToNatRight();
        LemmaSeqNatBound(xs);
        if |xs| > 0 {
          calc {
            FromNatWithLen(ToNatRight(xs), |xs|) != xs;
            {
              LemmaSeqNeq(FromNatWithLen(ToNatRight(xs), |xs|), xs);
            }
            ToNatRight(FromNatWithLen(ToNatRight(xs), |xs|)) != ToNatRight(xs);
            ToNatRight(xs) != ToNatRight(xs);
            false;
          }
        }
      }

      function {:opaque} SeqAdd(xs: seq<digit>, ys: seq<digit>): (seq<digit>, nat)
        requires |xs| == |ys|
        ensures var (zs: seq<digit>, cout: nat) := SeqAdd(xs, ys); |zs| == |xs| && 0 <= cout <= 1
        decreases xs
      {
        if |xs| == 0 then
          ([], 0)
        else
          var (zs': seq<digit>, cin: nat) := SeqAdd(DropLast(xs), DropLast(ys)); var sum: int := Last(xs) + Last(ys) + cin; var (sum_out: int, cout: int) := if sum < BASE() then (sum, 0) else (sum - BASE(), 1); (zs' + [sum_out], cout)
      }

      lemma {:isolate_assertions} /*{:_induction xs, ys, zs}*/ LemmaSeqAdd(xs: seq<digit>, ys: seq<digit>, zs: seq<digit>, cout: nat)
        requires |xs| == |ys|
        requires SeqAdd(xs, ys) == (zs, cout)
        ensures ToNatRight(xs) + ToNatRight(ys) == ToNatRight(zs) + cout * Pow(BASE(), |xs|)
        decreases xs, ys, zs, cout
      {
        reveal SeqAdd();
        if |xs| == 0 {
          reveal ToNatRight();
        } else {
          ghost var pow := Pow(BASE(), |xs| - 1);
          var (zs', cin) := SeqAdd(DropLast(xs), DropLast(ys));
          ghost var sum: int := Last(xs) + Last(ys) + cin;
          ghost var z := if sum < BASE() then sum else sum - BASE();
          assert sum == z + cout * BASE();
          reveal ToNatLeft();
          LemmaToNatLeftEqToNatRightAuto();
          calc {
            ToNatRight(zs);
            ToNatLeft(zs);
            ToNatLeft(zs') + z * pow;
            {
              LemmaSeqAdd(DropLast(xs), DropLast(ys), zs', cin);
            }
            ToNatLeft(DropLast(xs)) + ToNatLeft(DropLast(ys)) - cin * pow + z * pow;
            {
              LemmaMulEquality(sum, z + cout * BASE(), pow);
              assert sum * pow == (z + cout * BASE()) * pow;
              LemmaMulIsDistributiveAuto();
            }
            ToNatLeft(xs) + ToNatLeft(ys) - cout * BASE() * pow;
            {
              LemmaMulIsAssociative(cout, BASE(), pow);
              reveal Pow();
            }
            ToNatLeft(xs) + ToNatLeft(ys) - cout * Pow(BASE(), |xs|);
            ToNatRight(xs) + ToNatRight(ys) - cout * Pow(BASE(), |xs|);
          }
        }
      }

      function {:opaque} SeqSub(xs: seq<digit>, ys: seq<digit>): (seq<digit>, nat)
        requires |xs| == |ys|
        ensures var (zs: seq<digit>, cout: nat) := SeqSub(xs, ys); |zs| == |xs| && 0 <= cout <= 1
        decreases xs
      {
        if |xs| == 0 then
          ([], 0)
        else
          var (zs: seq<digit>, cin: nat) := SeqSub(DropLast(xs), DropLast(ys)); var (diff_out: int, cout: int) := if Last(xs) >= Last(ys) + cin then (Last(xs) - Last(ys) - cin, 0) else (BASE() + Last(xs) - Last(ys) - cin, 1); (zs + [diff_out], cout)
      }

      lemma {:isolate_assertions} /*{:_induction xs, ys, zs}*/ LemmaSeqSub(xs: seq<digit>, ys: seq<digit>, zs: seq<digit>, cout: nat)
        requires |xs| == |ys|
        requires SeqSub(xs, ys) == (zs, cout)
        ensures ToNatRight(xs) - ToNatRight(ys) + cout * Pow(BASE(), |xs|) == ToNatRight(zs)
        decreases xs, ys, zs, cout
      {
        reveal SeqSub();
        if |xs| == 0 {
          reveal ToNatRight();
        } else {
          ghost var pow := Pow(BASE(), |xs| - 1);
          var (zs', cin) := SeqSub(DropLast(xs), DropLast(ys));
          ghost var z := if Last(xs) >= Last(ys) + cin then Last(xs) - Last(ys) - cin else BASE() + Last(xs) - Last(ys) - cin;
          assert cout * BASE() + Last(xs) - cin - Last(ys) == z;
          reveal ToNatLeft();
          LemmaToNatLeftEqToNatRightAuto();
          calc {
            ToNatRight(zs);
            ToNatLeft(zs);
            ToNatLeft(zs') + z * pow;
            {
              LemmaSeqSub(DropLast(xs), DropLast(ys), zs', cin);
            }
            ToNatLeft(DropLast(xs)) - ToNatLeft(DropLast(ys)) + cin * pow + z * pow;
            {
              LemmaMulEquality(cout * BASE() + Last(xs) - cin - Last(ys), z, pow);
              assert pow * (cout * BASE() + Last(xs) - cin - Last(ys)) == pow * z;
              LemmaMulIsDistributiveAuto();
            }
            ToNatLeft(xs) - ToNatLeft(ys) + cout * BASE() * pow;
            {
              LemmaMulIsAssociative(cout, BASE(), pow);
              reveal Pow();
            }
            ToNatLeft(xs) - ToNatLeft(ys) + cout * Pow(BASE(), |xs|);
            ToNatRight(xs) - ToNatRight(ys) + cout * Pow(BASE(), |xs|);
          }
        }
      }

      import opened Wrappers

      type Char(==)

      type String = seq<Char>

      type CharSeq = chars: seq<Char>
        | |chars| > 1
        witness *

      import opened DivMod

      import opened Mul

      import opened Power

      import opened Seq = Collections.Seq

      import opened Logarithm

      type digit = i: nat
        | 0 <= i < BASE()
    }

    abstract module ParametricEscaping {
      function Escape(str: String, mustEscape: set<Char>, escape: Char): String
        decreases str, mustEscape
      {
        if str == [] then
          str
        else if str[0] in mustEscape then
          [escape, str[0]] + Escape(str[1..], mustEscape, escape)
        else
          [str[0]] + Escape(str[1..], mustEscape, escape)
      }

      function Unescape(str: String, escape: Char): Option<String>
        decreases str
      {
        if str == [] then
          Some(str)
        else if str[0] == escape then
          if |str| > 1 then
            var tl: String :- Unescape(str[2..], escape); Some([str[1]] + tl)
          else
            None
        else
          var tl: String :- Unescape(str[1..], escape); Some([str[0]] + tl)
      }

      lemma {:induction false} Unescape_Escape(str: String, special: set<Char>, escape: Char)
        requires escape in special
        ensures Unescape(Escape(str, special, escape), escape) == Some(str)
        decreases str, special
      {
        if str == [] {
        } else {
          assert str == [str[0]] + str[1..];
          Unescape_Escape(str[1..], special, escape);
        }
      }

      import opened Wrappers

      type Char(==)

      type String = seq<Char>
    }

    module {:disableNonlinearArithmetic} HexConversion refines ParametricConversion {
      const HEX_DIGITS: seq<char> := ""0123456789ABCDEF""
      const chars: CharSeq := HEX_DIGITS
      const charToDigit: map<Char, digit> := map['0' := 0, '1' := 1, '2' := 2, '3' := 3, '4' := 4, '5' := 5, '6' := 6, '7' := 7, '8' := 8, '9' := 9, 'a' := 10, 'b' := 11, 'c' := 12, 'd' := 13, 'e' := 14, 'f' := 15, 'A' := 10, 'B' := 11, 'C' := 12, 'D' := 13, 'E' := 14, 'F' := 15]

      lemma {:axiom} CharsConsistent()
        ensures forall c: char {:trigger charToDigit[c]} {:trigger c in charToDigit} {:trigger c in chars} | c in chars :: c in charToDigit && chars[charToDigit[c]] == c
        ensures forall c: char {:trigger charToDigit[c]} {:trigger c in charToDigit} {:trigger c in chars} | c in chars :: c in charToDigit && chars[charToDigit[c]] == c

      const base := |chars|

      function BASE(): nat
        ensures BASE() > 1
      {
        base
      }

      predicate IsDigitChar(c: Char)
        decreases c
      {
        c in charToDigit
      }

      function OfDigits(digits: seq<digit>): (str: String)
        ensures forall c: char {:trigger c in chars} {:trigger c in str} | c in str :: c in chars
        ensures |str| == |digits|
        decreases digits
      {
        if digits == [] then
          []
        else
          assert digits[0] in digits; assert forall d: int {:trigger d in digits} {:trigger d in digits[1..]} | d in digits[1..] :: d in digits; OfDigits(digits[1..]) + [chars[digits[0]]]
      }

      function OfNat(n: nat): (str: String)
        ensures |str| == Log(base, n) + 1
        ensures forall c: char {:trigger c in chars} {:trigger c in str} | c in str :: c in chars
        decreases n
      {
        if n == 0 then
          reveal Log();
          [chars[0]]
        else
          LemmaFromNatLen2(n); OfDigits(FromNat(n))
      }

      predicate IsNumberStr(str: String, minus: Char)
        decreases str
      {
        str != [] ==>
          (str[0] == minus || str[0] in charToDigit) &&
          forall c: Char {:trigger IsDigitChar(c)} {:trigger c in str[1..]} | c in str[1..] :: 
            IsDigitChar(c)
      }

      function OfInt(n: int, minus: Char): (str: String)
        ensures IsNumberStr(str, minus)
        decreases n
      {
        CharsConsistent();
        if n >= 0 then
          OfNat(n)
        else
          [minus] + OfNat(-n)
      }

      function {:isolate_assertions} ToNat(str: String): (n: nat)
        requires forall c: Char {:trigger IsDigitChar(c)} {:trigger c in str} | c in str :: IsDigitChar(c)
        decreases str
      {
        if str == [] then
          0
        else
          LemmaMulNonnegativeAuto(); var c: char := str[|str| - 1]; assert IsDigitChar(c); ToNat(str[..|str| - 1]) * base + charToDigit[c]
      }

      lemma {:induction false} ToNatBound(str: String)
        requires base > 0
        requires forall c: Char {:trigger IsDigitChar(c)} {:trigger c in str} | c in str :: IsDigitChar(c)
        ensures ToNat(str) < Pow(base, |str|)
        decreases str
      {
        if str == [] {
          reveal Pow();
        } else {
          calc <= {
            ToNat(str);
            {
              assert IsDigitChar(str[|str| - 1]);
            }
            ToNat(str[..|str| - 1]) * base + charToDigit[str[|str| - 1]];
            ToNat(str[..|str| - 1]) * base + base - 1;
            {
              ToNatBound(str[..|str| - 1]);
              LemmaMulInequalityAuto();
            }
            (Pow(base, |str| - 1) - 1) * base + base - 1;
            {
              LemmaMulIsDistributiveAuto();
            }
            Pow(base, |str| - 1) * base - 1;
            {
              reveal Pow();
              LemmaMulIsCommutativeAuto();
            }
            Pow(base, |str|) - 1;
          }
        }
      }

      function ToInt(str: String, minus: Char): (s: int)
        requires str != [minus]
        requires IsNumberStr(str, minus)
        decreases str
      {
        if [minus] <= str then
          -(ToNat(str[1..]) as int)
        else
          assert str == [] || str == [str[0]] + str[1..]; ToNat(str)
      }

      function {:opaque} ToNatRight(xs: seq<digit>): nat
        decreases xs
      {
        if |xs| == 0 then
          0
        else
          LemmaMulNonnegativeAuto(); ToNatRight(DropFirst(xs)) * BASE() + First(xs)
      }

      function {:opaque} ToNatLeft(xs: seq<digit>): nat
        decreases xs
      {
        if |xs| == 0 then
          0
        else
          LemmaPowPositiveAuto(); LemmaMulNonnegativeAuto(); ToNatLeft(DropLast(xs)) + Last(xs) * Pow(BASE(), |xs| - 1)
      }

      lemma {:isolate_assertions} /*{:_induction xs}*/ LemmaToNatLeftEqToNatRight(xs: seq<digit>)
        ensures ToNatRight(xs) == ToNatLeft(xs)
        decreases xs
      {
        reveal ToNatRight();
        reveal ToNatLeft();
        if xs == [] {
        } else {
          if DropLast(xs) == [] {
            calc {
              ToNatLeft(xs);
              Last(xs) * Pow(BASE(), |xs| - 1);
              {
                reveal Pow();
              }
              Last(xs);
              First(xs);
              {
                assert ToNatRight(DropFirst(xs)) == 0;
              }
              ToNatRight(xs);
            }
          } else {
            calc {
              ToNatLeft(xs);
              ToNatLeft(DropLast(xs)) + Last(xs) * Pow(BASE(), |xs| - 1);
              {
                LemmaToNatLeftEqToNatRight(DropLast(xs));
              }
              ToNatRight(DropLast(xs)) + Last(xs) * Pow(BASE(), |xs| - 1);
              ToNatRight(DropFirst(DropLast(xs))) * BASE() + First(xs) + Last(xs) * Pow(BASE(), |xs| - 1);
              {
                LemmaToNatLeftEqToNatRight(DropFirst(DropLast(xs)));
              }
              ToNatLeft(DropFirst(DropLast(xs))) * BASE() + First(xs) + Last(xs) * Pow(BASE(), |xs| - 1);
              {
                assert DropFirst(DropLast(xs)) == DropLast(DropFirst(xs));
                reveal Pow();
                LemmaMulProperties();
              }
              ToNatLeft(DropLast(DropFirst(xs))) * BASE() + First(xs) + Last(xs) * Pow(BASE(), |xs| - 2) * BASE();
              {
                LemmaMulIsDistributiveAddOtherWayAuto();
              }
              ToNatLeft(DropFirst(xs)) * BASE() + First(xs);
              {
                LemmaToNatLeftEqToNatRight(DropFirst(xs));
              }
              ToNatRight(xs);
            }
          }
        }
      }

      lemma LemmaToNatLeftEqToNatRightAuto()
        ensures forall xs: seq<digit> {:trigger ToNatLeft(xs)} {:trigger ToNatRight(xs)} :: ToNatRight(xs) == ToNatLeft(xs)
      {
        reveal ToNatRight();
        reveal ToNatLeft();
        forall xs: seq<digit> | true
          ensures ToNatRight(xs) == ToNatLeft(xs)
        {
          LemmaToNatLeftEqToNatRight(xs);
        }
      }

      lemma /*{:_induction xs}*/ LemmaSeqLen1(xs: seq<digit>)
        requires |xs| == 1
        ensures ToNatRight(xs) == First(xs)
        decreases xs
      {
        reveal ToNatRight();
        assert ToNatRight(DropFirst(xs)) == 0;
      }

      lemma /*{:_induction xs}*/ LemmaSeqLen2(xs: seq<digit>)
        requires |xs| == 2
        ensures ToNatRight(xs) == First(xs) + xs[1] * BASE()
        decreases xs
      {
        reveal ToNatRight();
        LemmaSeqLen1(DropLast(xs));
      }

      lemma /*{:_induction xs}*/ LemmaSeqAppendZero(xs: seq<digit>)
        ensures ToNatRight(xs + [0]) == ToNatRight(xs)
        decreases xs
      {
        reveal ToNatLeft();
        LemmaToNatLeftEqToNatRightAuto();
        calc {
          ToNatRight(xs + [0]);
          ToNatLeft(xs + [0]);
          ToNatLeft(xs) + 0 * Pow(BASE(), |xs|);
          {
            LemmaMulBasicsAuto();
          }
          ToNatLeft(xs);
          ToNatRight(xs);
        }
      }

      lemma /*{:_induction xs}*/ LemmaSeqNatBound(xs: seq<digit>)
        ensures ToNatRight(xs) < Pow(BASE(), |xs|)
        decreases xs
      {
        reveal Pow();
        if |xs| == 0 {
          reveal ToNatRight();
        } else {
          ghost var len' := |xs| - 1;
          ghost var pow := Pow(BASE(), len');
          calc {
            ToNatRight(xs);
            {
              LemmaToNatLeftEqToNatRight(xs);
            }
            ToNatLeft(xs);
            {
              reveal ToNatLeft();
            }
            ToNatLeft(DropLast(xs)) + Last(xs) * pow;
          <
            {
              LemmaToNatLeftEqToNatRight(DropLast(xs));
              LemmaSeqNatBound(DropLast(xs));
            }
            pow + Last(xs) * pow;
          <=
            {
              LemmaPowPositiveAuto();
              LemmaMulInequalityAuto();
            }
            pow + (BASE() - 1) * pow;
            {
              LemmaMulIsDistributiveAuto();
            }
            Pow(BASE(), len' + 1);
          }
        }
      }

      lemma {:isolate_assertions} /*{:_induction xs, i}*/ LemmaSeqPrefix(xs: seq<digit>, i: nat)
        requires 0 <= i <= |xs|
        ensures ToNatRight(xs[..i]) + ToNatRight(xs[i..]) * Pow(BASE(), i) == ToNatRight(xs)
        decreases xs, i
      {
        reveal ToNatRight();
        reveal Pow();
        if i == 1 {
          assert ToNatRight(xs[..1]) == First(xs);
        } else if i > 1 {
          calc {
            ToNatRight(xs[..i]) + ToNatRight(xs[i..]) * Pow(BASE(), i);
            ToNatRight(DropFirst(xs[..i])) * BASE() + First(xs) + ToNatRight(xs[i..]) * Pow(BASE(), i);
            {
              assert DropFirst(xs[..i]) == DropFirst(xs)[..i - 1];
              LemmaMulProperties();
            }
            ToNatRight(DropFirst(xs)[..i - 1]) * BASE() + First(xs) + ToNatRight(xs[i..]) * Pow(BASE(), i - 1) * BASE();
            {
              LemmaMulIsDistributiveAddOtherWayAuto();
            }
            (ToNatRight(DropFirst(xs)[..i - 1]) + ToNatRight(DropFirst(xs)[i - 1..]) * Pow(BASE(), i - 1)) * BASE() + First(xs);
            {
              LemmaSeqPrefix(DropFirst(xs), i - 1);
            }
            ToNatRight(xs);
          }
        }
      }

      lemma /*{:_induction xs, ys}*/ LemmaSeqMswInequality(xs: seq<digit>, ys: seq<digit>)
        requires |xs| == |ys| > 0
        requires Last(xs) < Last(ys)
        ensures ToNatRight(xs) < ToNatRight(ys)
        decreases xs, ys
      {
        reveal ToNatLeft();
        LemmaToNatLeftEqToNatRightAuto();
        ghost var len' := |xs| - 1;
        calc {
          ToNatRight(xs);
          ToNatLeft(xs);
        <
          {
            LemmaSeqNatBound(DropLast(xs));
          }
          Pow(BASE(), len') + Last(xs) * Pow(BASE(), len');
        ==
          {
            LemmaMulIsDistributiveAuto();
          }
          (1 + Last(xs)) * Pow(BASE(), len');
        <=
          {
            LemmaPowPositiveAuto();
            LemmaMulInequalityAuto();
          }
          ToNatLeft(ys);
          ToNatRight(ys);
        }
      }

      lemma {:isolate_assertions} /*{:_induction xs, ys}*/ LemmaSeqPrefixNeq(xs: seq<digit>, ys: seq<digit>, i: nat)
        requires 0 <= i <= |xs| == |ys|
        requires ToNatRight(xs[..i]) != ToNatRight(ys[..i])
        ensures ToNatRight(xs) != ToNatRight(ys)
        decreases |xs| - i
      {
        if i == |xs| {
          assert xs[..i] == xs;
          assert ys[..i] == ys;
        } else {
          if xs[i] == ys[i] {
            reveal ToNatLeft();
            assert DropLast(xs[..i + 1]) == xs[..i];
            assert DropLast(ys[..i + 1]) == ys[..i];
            LemmaToNatLeftEqToNatRightAuto();
            assert ToNatRight(xs[..i + 1]) == ToNatLeft(xs[..i + 1]);
          } else if xs[i] < ys[i] {
            LemmaSeqMswInequality(xs[..i + 1], ys[..i + 1]);
          } else {
            LemmaSeqMswInequality(ys[..i + 1], xs[..i + 1]);
          }
          reveal ToNatRight();
          LemmaSeqPrefixNeq(xs, ys, i + 1);
        }
      }

      lemma /*{:_induction xs, ys}*/ LemmaSeqNeq(xs: seq<digit>, ys: seq<digit>)
        requires |xs| == |ys|
        requires xs != ys
        ensures ToNatRight(xs) != ToNatRight(ys)
        decreases xs, ys
      {
        ghost var i: nat, n: nat := 0, |xs|;
        while i < n
          invariant 0 <= i < n
          invariant xs[..i] == ys[..i]
          decreases n - i
        {
          if xs[i] != ys[i] {
            break;
          }
          i := i + 1;
        }
        assert ToNatLeft(xs[..i]) == ToNatLeft(ys[..i]);
        reveal ToNatLeft();
        assert xs[..i + 1][..i] == xs[..i];
        assert ys[..i + 1][..i] == ys[..i];
        LemmaPowPositiveAuto();
        LemmaMulStrictInequalityAuto();
        assert ToNatLeft(xs[..i + 1]) != ToNatLeft(ys[..i + 1]);
        LemmaToNatLeftEqToNatRightAuto();
        LemmaSeqPrefixNeq(xs, ys, i + 1);
      }

      lemma /*{:_induction xs, ys}*/ LemmaSeqEq(xs: seq<digit>, ys: seq<digit>)
        requires |xs| == |ys|
        requires ToNatRight(xs) == ToNatRight(ys)
        ensures xs == ys
        decreases xs, ys
      {
        calc ==> {
          xs != ys;
          {
            LemmaSeqNeq(xs, ys);
          }
          ToNatRight(xs) != ToNatRight(ys);
          false;
        }
      }

      lemma {:isolate_assertions} /*{:_induction xs}*/ LemmaSeqLswModEquivalence(xs: seq<digit>)
        requires |xs| >= 1
        ensures IsModEquivalent(ToNatRight(xs), First(xs), BASE())
        decreases xs
      {
        if |xs| == 1 {
          LemmaSeqLen1(xs);
          LemmaModEquivalenceAuto();
        } else {
          assert IsModEquivalent(ToNatRight(xs), First(xs), BASE()) by {
            reveal ToNatRight();
            calc ==> {
              true;
              {
                LemmaModEquivalence(ToNatRight(xs), ToNatRight(DropFirst(xs)) * BASE() + First(xs), BASE());
              }
              IsModEquivalent(ToNatRight(xs), ToNatRight(DropFirst(xs)) * BASE() + First(xs), BASE());
              {
                LemmaModMultiplesBasicAuto();
              }
              IsModEquivalent(ToNatRight(xs), First(xs), BASE());
            }
          }
        }
      }

      function {:opaque} FromNat(n: nat): (xs: seq<digit>)
        decreases n
      {
        if n == 0 then
          []
        else
          LemmaDivBasicsAuto(); LemmaDivDecreasesAuto(); [n % BASE()] + FromNat(n / BASE())
      }

      lemma /*{:_induction n}*/ LemmaFromNatLen2(n: nat)
        ensures n == 0 ==> |FromNat(n)| == 0
        ensures n > 0 ==> |FromNat(n)| == Log(BASE(), n) + 1
        decreases n
      {
        reveal FromNat();
        ghost var digits := FromNat(n);
        if n == 0 {
        } else {
          assert |digits| == Log(BASE(), n) + 1 by {
            LemmaDivBasicsAuto();
            ghost var digits' := FromNat(n / BASE());
            assert |digits| == |digits'| + 1;
            if n < BASE() {
              LemmaLog0(BASE(), n);
              assert n / BASE() == 0 by {
                LemmaBasicDiv(BASE());
              }
            } else {
              LemmaLogS(BASE(), n);
              assert n / BASE() > 0 by {
                LemmaDivNonZeroAuto();
              }
            }
          }
        }
      }

      lemma /*{:_induction n, len}*/ LemmaFromNatLen(n: nat, len: nat)
        requires Pow(BASE(), len) > n
        ensures |FromNat(n)| <= len
        decreases n, len
      {
        reveal FromNat();
        if n == 0 {
        } else {
          calc {
            |FromNat(n)|;
          ==
            {
              LemmaDivBasicsAuto();
            }
            1 + |FromNat(n / BASE())|;
          <=
            {
              LemmaMultiplyDivideLtAuto();
              LemmaDivDecreasesAuto();
              reveal Pow();
              LemmaFromNatLen(n / BASE(), len - 1);
            }
            len;
          }
        }
      }

      lemma /*{:_induction n}*/ LemmaNatSeqNat(n: nat)
        ensures ToNatRight(FromNat(n)) == n
        decreases n
      {
        reveal ToNatRight();
        reveal FromNat();
        if n == 0 {
        } else {
          calc {
            ToNatRight(FromNat(n));
            {
              LemmaDivBasicsAuto();
            }
            ToNatRight([n % BASE()] + FromNat(n / BASE()));
            n % BASE() + ToNatRight(FromNat(n / BASE())) * BASE();
            {
              LemmaDivDecreasesAuto();
              LemmaNatSeqNat(n / BASE());
            }
            n % BASE() + n / BASE() * BASE();
            {
              LemmaFundamentalDivMod(n, BASE());
            }
            n;
          }
        }
      }

      function {:opaque} SeqExtend(xs: seq<digit>, n: nat): (ys: seq<digit>)
        requires |xs| <= n
        ensures |ys| == n
        ensures ToNatRight(ys) == ToNatRight(xs)
        decreases n - |xs|
      {
        if |xs| >= n then
          xs
        else
          LemmaSeqAppendZero(xs); SeqExtend(xs + [0], n)
      }

      function {:opaque} SeqExtendMultiple(xs: seq<digit>, n: nat): (ys: seq<digit>)
        requires n > 0
        ensures |ys| % n == 0
        ensures ToNatRight(ys) == ToNatRight(xs)
        decreases xs, n
      {
        var newLen: int := |xs| + n - |xs| % n;
        LemmaSubModNoopRight(|xs| + n, |xs|, n);
        LemmaModBasicsAuto();
        assert newLen % n == 0;
        LemmaSeqNatBound(xs);
        LemmaPowIncreasesAuto();
        SeqExtend(xs, newLen)
      }

      function {:opaque} FromNatWithLen(n: nat, len: nat): (xs: seq<digit>)
        requires Pow(BASE(), len) > n
        ensures |xs| == len
        ensures ToNatRight(xs) == n
        decreases n, len
      {
        LemmaFromNatLen(n, len);
        LemmaNatSeqNat(n);
        SeqExtend(FromNat(n), len)
      }

      lemma {:resource_limit ""10e6""} /*{:_induction xs}*/ LemmaSeqZero(xs: seq<digit>)
        requires ToNatRight(xs) == 0
        ensures forall i: int {:trigger xs[i]} :: 0 <= i < |xs| ==> xs[i] == 0
        decreases xs
      {
        reveal ToNatRight();
        if |xs| == 0 {
        } else {
          LemmaMulNonnegativeAuto();
          assert First(xs) == 0;
          LemmaMulNonzeroAuto();
          LemmaSeqZero(DropFirst(xs));
        }
      }

      function {:opaque} SeqZero(len: nat): (xs: seq<digit>)
        ensures |xs| == len
        ensures forall i: int {:trigger xs[i]} :: 0 <= i < |xs| ==> xs[i] == 0
        ensures ToNatRight(xs) == 0
        decreases len
      {
        LemmaPowPositive(BASE(), len);
        var xs: seq<digit> := FromNatWithLen(0, len);
        LemmaSeqZero(xs);
        xs
      }

      lemma /*{:_induction xs}*/ LemmaSeqNatSeq(xs: seq<digit>)
        ensures Pow(BASE(), |xs|) > ToNatRight(xs)
        ensures FromNatWithLen(ToNatRight(xs), |xs|) == xs
        decreases xs
      {
        reveal FromNat();
        reveal ToNatRight();
        LemmaSeqNatBound(xs);
        if |xs| > 0 {
          calc {
            FromNatWithLen(ToNatRight(xs), |xs|) != xs;
            {
              LemmaSeqNeq(FromNatWithLen(ToNatRight(xs), |xs|), xs);
            }
            ToNatRight(FromNatWithLen(ToNatRight(xs), |xs|)) != ToNatRight(xs);
            ToNatRight(xs) != ToNatRight(xs);
            false;
          }
        }
      }

      function {:opaque} SeqAdd(xs: seq<digit>, ys: seq<digit>): (seq<digit>, nat)
        requires |xs| == |ys|
        ensures var (zs: seq<digit>, cout: nat) := SeqAdd(xs, ys); |zs| == |xs| && 0 <= cout <= 1
        decreases xs
      {
        if |xs| == 0 then
          ([], 0)
        else
          var (zs': seq<digit>, cin: nat) := SeqAdd(DropLast(xs), DropLast(ys)); var sum: int := Last(xs) + Last(ys) + cin; var (sum_out: int, cout: int) := if sum < BASE() then (sum, 0) else (sum - BASE(), 1); (zs' + [sum_out], cout)
      }

      lemma {:isolate_assertions} /*{:_induction xs, ys, zs}*/ LemmaSeqAdd(xs: seq<digit>, ys: seq<digit>, zs: seq<digit>, cout: nat)
        requires |xs| == |ys|
        requires SeqAdd(xs, ys) == (zs, cout)
        ensures ToNatRight(xs) + ToNatRight(ys) == ToNatRight(zs) + cout * Pow(BASE(), |xs|)
        decreases xs, ys, zs, cout
      {
        reveal SeqAdd();
        if |xs| == 0 {
          reveal ToNatRight();
        } else {
          ghost var pow := Pow(BASE(), |xs| - 1);
          var (zs', cin) := SeqAdd(DropLast(xs), DropLast(ys));
          ghost var sum: int := Last(xs) + Last(ys) + cin;
          ghost var z := if sum < BASE() then sum else sum - BASE();
          assert sum == z + cout * BASE();
          reveal ToNatLeft();
          LemmaToNatLeftEqToNatRightAuto();
          calc {
            ToNatRight(zs);
            ToNatLeft(zs);
            ToNatLeft(zs') + z * pow;
            {
              LemmaSeqAdd(DropLast(xs), DropLast(ys), zs', cin);
            }
            ToNatLeft(DropLast(xs)) + ToNatLeft(DropLast(ys)) - cin * pow + z * pow;
            {
              LemmaMulEquality(sum, z + cout * BASE(), pow);
              assert sum * pow == (z + cout * BASE()) * pow;
              LemmaMulIsDistributiveAuto();
            }
            ToNatLeft(xs) + ToNatLeft(ys) - cout * BASE() * pow;
            {
              LemmaMulIsAssociative(cout, BASE(), pow);
              reveal Pow();
            }
            ToNatLeft(xs) + ToNatLeft(ys) - cout * Pow(BASE(), |xs|);
            ToNatRight(xs) + ToNatRight(ys) - cout * Pow(BASE(), |xs|);
          }
        }
      }

      function {:opaque} SeqSub(xs: seq<digit>, ys: seq<digit>): (seq<digit>, nat)
        requires |xs| == |ys|
        ensures var (zs: seq<digit>, cout: nat) := SeqSub(xs, ys); |zs| == |xs| && 0 <= cout <= 1
        decreases xs
      {
        if |xs| == 0 then
          ([], 0)
        else
          var (zs: seq<digit>, cin: nat) := SeqSub(DropLast(xs), DropLast(ys)); var (diff_out: int, cout: int) := if Last(xs) >= Last(ys) + cin then (Last(xs) - Last(ys) - cin, 0) else (BASE() + Last(xs) - Last(ys) - cin, 1); (zs + [diff_out], cout)
      }

      lemma {:isolate_assertions} /*{:_induction xs, ys, zs}*/ LemmaSeqSub(xs: seq<digit>, ys: seq<digit>, zs: seq<digit>, cout: nat)
        requires |xs| == |ys|
        requires SeqSub(xs, ys) == (zs, cout)
        ensures ToNatRight(xs) - ToNatRight(ys) + cout * Pow(BASE(), |xs|) == ToNatRight(zs)
        decreases xs, ys, zs, cout
      {
        reveal SeqSub();
        if |xs| == 0 {
          reveal ToNatRight();
        } else {
          ghost var pow := Pow(BASE(), |xs| - 1);
          var (zs', cin) := SeqSub(DropLast(xs), DropLast(ys));
          ghost var z := if Last(xs) >= Last(ys) + cin then Last(xs) - Last(ys) - cin else BASE() + Last(xs) - Last(ys) - cin;
          assert cout * BASE() + Last(xs) - cin - Last(ys) == z;
          reveal ToNatLeft();
          LemmaToNatLeftEqToNatRightAuto();
          calc {
            ToNatRight(zs);
            ToNatLeft(zs);
            ToNatLeft(zs') + z * pow;
            {
              LemmaSeqSub(DropLast(xs), DropLast(ys), zs', cin);
            }
            ToNatLeft(DropLast(xs)) - ToNatLeft(DropLast(ys)) + cin * pow + z * pow;
            {
              LemmaMulEquality(cout * BASE() + Last(xs) - cin - Last(ys), z, pow);
              assert pow * (cout * BASE() + Last(xs) - cin - Last(ys)) == pow * z;
              LemmaMulIsDistributiveAuto();
            }
            ToNatLeft(xs) - ToNatLeft(ys) + cout * BASE() * pow;
            {
              LemmaMulIsAssociative(cout, BASE(), pow);
              reveal Pow();
            }
            ToNatLeft(xs) - ToNatLeft(ys) + cout * Pow(BASE(), |xs|);
            ToNatRight(xs) - ToNatRight(ys) + cout * Pow(BASE(), |xs|);
          }
        }
      }

      type Char = char

      import opened Wrappers

      type String = seq<Char>

      type CharSeq = chars: seq<Char>
        | |chars| > 1
        witness *

      import opened DivMod

      import opened Mul

      import opened Power

      import opened Seq = Collections.Seq

      import opened Logarithm

      type digit = i: nat
        | 0 <= i < BASE()
    }

    module {:disableNonlinearArithmetic} DecimalConversion refines ParametricConversion {
      const DIGITS: seq<char> := ""0123456789""
      const chars: CharSeq := DIGITS
      const charToDigit: map<Char, digit> := map['0' := 0, '1' := 1, '2' := 2, '3' := 3, '4' := 4, '5' := 5, '6' := 6, '7' := 7, '8' := 8, '9' := 9]

      lemma CharsConsistent()
        ensures forall c: char {:trigger charToDigit[c]} {:trigger c in charToDigit} {:trigger c in chars} | c in chars :: c in charToDigit && chars[charToDigit[c]] == c
        ensures forall c: char {:trigger charToDigit[c]} {:trigger c in charToDigit} {:trigger c in chars} | c in chars :: c in charToDigit && chars[charToDigit[c]] == c
      {
      }

      const base := |chars|

      function BASE(): nat
        ensures BASE() > 1
      {
        base
      }

      predicate IsDigitChar(c: Char)
        decreases c
      {
        c in charToDigit
      }

      function OfDigits(digits: seq<digit>): (str: String)
        ensures forall c: char {:trigger c in chars} {:trigger c in str} | c in str :: c in chars
        ensures |str| == |digits|
        decreases digits
      {
        if digits == [] then
          []
        else
          assert digits[0] in digits; assert forall d: int {:trigger d in digits} {:trigger d in digits[1..]} | d in digits[1..] :: d in digits; OfDigits(digits[1..]) + [chars[digits[0]]]
      }

      function OfNat(n: nat): (str: String)
        ensures |str| == Log(base, n) + 1
        ensures forall c: char {:trigger c in chars} {:trigger c in str} | c in str :: c in chars
        decreases n
      {
        if n == 0 then
          reveal Log();
          [chars[0]]
        else
          LemmaFromNatLen2(n); OfDigits(FromNat(n))
      }

      predicate IsNumberStr(str: String, minus: Char)
        decreases str
      {
        str != [] ==>
          (str[0] == minus || str[0] in charToDigit) &&
          forall c: Char {:trigger IsDigitChar(c)} {:trigger c in str[1..]} | c in str[1..] :: 
            IsDigitChar(c)
      }

      function OfInt(n: int, minus: Char): (str: String)
        ensures IsNumberStr(str, minus)
        decreases n
      {
        CharsConsistent();
        if n >= 0 then
          OfNat(n)
        else
          [minus] + OfNat(-n)
      }

      function {:isolate_assertions} ToNat(str: String): (n: nat)
        requires forall c: Char {:trigger IsDigitChar(c)} {:trigger c in str} | c in str :: IsDigitChar(c)
        decreases str
      {
        if str == [] then
          0
        else
          LemmaMulNonnegativeAuto(); var c: char := str[|str| - 1]; assert IsDigitChar(c); ToNat(str[..|str| - 1]) * base + charToDigit[c]
      }

      lemma {:induction false} ToNatBound(str: String)
        requires base > 0
        requires forall c: Char {:trigger IsDigitChar(c)} {:trigger c in str} | c in str :: IsDigitChar(c)
        ensures ToNat(str) < Pow(base, |str|)
        decreases str
      {
        if str == [] {
          reveal Pow();
        } else {
          calc <= {
            ToNat(str);
            {
              assert IsDigitChar(str[|str| - 1]);
            }
            ToNat(str[..|str| - 1]) * base + charToDigit[str[|str| - 1]];
            ToNat(str[..|str| - 1]) * base + base - 1;
            {
              ToNatBound(str[..|str| - 1]);
              LemmaMulInequalityAuto();
            }
            (Pow(base, |str| - 1) - 1) * base + base - 1;
            {
              LemmaMulIsDistributiveAuto();
            }
            Pow(base, |str| - 1) * base - 1;
            {
              reveal Pow();
              LemmaMulIsCommutativeAuto();
            }
            Pow(base, |str|) - 1;
          }
        }
      }

      function ToInt(str: String, minus: Char): (s: int)
        requires str != [minus]
        requires IsNumberStr(str, minus)
        decreases str
      {
        if [minus] <= str then
          -(ToNat(str[1..]) as int)
        else
          assert str == [] || str == [str[0]] + str[1..]; ToNat(str)
      }

      function {:opaque} ToNatRight(xs: seq<digit>): nat
        decreases xs
      {
        if |xs| == 0 then
          0
        else
          LemmaMulNonnegativeAuto(); ToNatRight(DropFirst(xs)) * BASE() + First(xs)
      }

      function {:opaque} ToNatLeft(xs: seq<digit>): nat
        decreases xs
      {
        if |xs| == 0 then
          0
        else
          LemmaPowPositiveAuto(); LemmaMulNonnegativeAuto(); ToNatLeft(DropLast(xs)) + Last(xs) * Pow(BASE(), |xs| - 1)
      }

      lemma {:isolate_assertions} /*{:_induction xs}*/ LemmaToNatLeftEqToNatRight(xs: seq<digit>)
        ensures ToNatRight(xs) == ToNatLeft(xs)
        decreases xs
      {
        reveal ToNatRight();
        reveal ToNatLeft();
        if xs == [] {
        } else {
          if DropLast(xs) == [] {
            calc {
              ToNatLeft(xs);
              Last(xs) * Pow(BASE(), |xs| - 1);
              {
                reveal Pow();
              }
              Last(xs);
              First(xs);
              {
                assert ToNatRight(DropFirst(xs)) == 0;
              }
              ToNatRight(xs);
            }
          } else {
            calc {
              ToNatLeft(xs);
              ToNatLeft(DropLast(xs)) + Last(xs) * Pow(BASE(), |xs| - 1);
              {
                LemmaToNatLeftEqToNatRight(DropLast(xs));
              }
              ToNatRight(DropLast(xs)) + Last(xs) * Pow(BASE(), |xs| - 1);
              ToNatRight(DropFirst(DropLast(xs))) * BASE() + First(xs) + Last(xs) * Pow(BASE(), |xs| - 1);
              {
                LemmaToNatLeftEqToNatRight(DropFirst(DropLast(xs)));
              }
              ToNatLeft(DropFirst(DropLast(xs))) * BASE() + First(xs) + Last(xs) * Pow(BASE(), |xs| - 1);
              {
                assert DropFirst(DropLast(xs)) == DropLast(DropFirst(xs));
                reveal Pow();
                LemmaMulProperties();
              }
              ToNatLeft(DropLast(DropFirst(xs))) * BASE() + First(xs) + Last(xs) * Pow(BASE(), |xs| - 2) * BASE();
              {
                LemmaMulIsDistributiveAddOtherWayAuto();
              }
              ToNatLeft(DropFirst(xs)) * BASE() + First(xs);
              {
                LemmaToNatLeftEqToNatRight(DropFirst(xs));
              }
              ToNatRight(xs);
            }
          }
        }
      }

      lemma LemmaToNatLeftEqToNatRightAuto()
        ensures forall xs: seq<digit> {:trigger ToNatLeft(xs)} {:trigger ToNatRight(xs)} :: ToNatRight(xs) == ToNatLeft(xs)
      {
        reveal ToNatRight();
        reveal ToNatLeft();
        forall xs: seq<digit> | true
          ensures ToNatRight(xs) == ToNatLeft(xs)
        {
          LemmaToNatLeftEqToNatRight(xs);
        }
      }

      lemma /*{:_induction xs}*/ LemmaSeqLen1(xs: seq<digit>)
        requires |xs| == 1
        ensures ToNatRight(xs) == First(xs)
        decreases xs
      {
        reveal ToNatRight();
        assert ToNatRight(DropFirst(xs)) == 0;
      }

      lemma /*{:_induction xs}*/ LemmaSeqLen2(xs: seq<digit>)
        requires |xs| == 2
        ensures ToNatRight(xs) == First(xs) + xs[1] * BASE()
        decreases xs
      {
        reveal ToNatRight();
        LemmaSeqLen1(DropLast(xs));
      }

      lemma /*{:_induction xs}*/ LemmaSeqAppendZero(xs: seq<digit>)
        ensures ToNatRight(xs + [0]) == ToNatRight(xs)
        decreases xs
      {
        reveal ToNatLeft();
        LemmaToNatLeftEqToNatRightAuto();
        calc {
          ToNatRight(xs + [0]);
          ToNatLeft(xs + [0]);
          ToNatLeft(xs) + 0 * Pow(BASE(), |xs|);
          {
            LemmaMulBasicsAuto();
          }
          ToNatLeft(xs);
          ToNatRight(xs);
        }
      }

      lemma /*{:_induction xs}*/ LemmaSeqNatBound(xs: seq<digit>)
        ensures ToNatRight(xs) < Pow(BASE(), |xs|)
        decreases xs
      {
        reveal Pow();
        if |xs| == 0 {
          reveal ToNatRight();
        } else {
          ghost var len' := |xs| - 1;
          ghost var pow := Pow(BASE(), len');
          calc {
            ToNatRight(xs);
            {
              LemmaToNatLeftEqToNatRight(xs);
            }
            ToNatLeft(xs);
            {
              reveal ToNatLeft();
            }
            ToNatLeft(DropLast(xs)) + Last(xs) * pow;
          <
            {
              LemmaToNatLeftEqToNatRight(DropLast(xs));
              LemmaSeqNatBound(DropLast(xs));
            }
            pow + Last(xs) * pow;
          <=
            {
              LemmaPowPositiveAuto();
              LemmaMulInequalityAuto();
            }
            pow + (BASE() - 1) * pow;
            {
              LemmaMulIsDistributiveAuto();
            }
            Pow(BASE(), len' + 1);
          }
        }
      }

      lemma {:isolate_assertions} /*{:_induction xs, i}*/ LemmaSeqPrefix(xs: seq<digit>, i: nat)
        requires 0 <= i <= |xs|
        ensures ToNatRight(xs[..i]) + ToNatRight(xs[i..]) * Pow(BASE(), i) == ToNatRight(xs)
        decreases xs, i
      {
        reveal ToNatRight();
        reveal Pow();
        if i == 1 {
          assert ToNatRight(xs[..1]) == First(xs);
        } else if i > 1 {
          calc {
            ToNatRight(xs[..i]) + ToNatRight(xs[i..]) * Pow(BASE(), i);
            ToNatRight(DropFirst(xs[..i])) * BASE() + First(xs) + ToNatRight(xs[i..]) * Pow(BASE(), i);
            {
              assert DropFirst(xs[..i]) == DropFirst(xs)[..i - 1];
              LemmaMulProperties();
            }
            ToNatRight(DropFirst(xs)[..i - 1]) * BASE() + First(xs) + ToNatRight(xs[i..]) * Pow(BASE(), i - 1) * BASE();
            {
              LemmaMulIsDistributiveAddOtherWayAuto();
            }
            (ToNatRight(DropFirst(xs)[..i - 1]) + ToNatRight(DropFirst(xs)[i - 1..]) * Pow(BASE(), i - 1)) * BASE() + First(xs);
            {
              LemmaSeqPrefix(DropFirst(xs), i - 1);
            }
            ToNatRight(xs);
          }
        }
      }

      lemma /*{:_induction xs, ys}*/ LemmaSeqMswInequality(xs: seq<digit>, ys: seq<digit>)
        requires |xs| == |ys| > 0
        requires Last(xs) < Last(ys)
        ensures ToNatRight(xs) < ToNatRight(ys)
        decreases xs, ys
      {
        reveal ToNatLeft();
        LemmaToNatLeftEqToNatRightAuto();
        ghost var len' := |xs| - 1;
        calc {
          ToNatRight(xs);
          ToNatLeft(xs);
        <
          {
            LemmaSeqNatBound(DropLast(xs));
          }
          Pow(BASE(), len') + Last(xs) * Pow(BASE(), len');
        ==
          {
            LemmaMulIsDistributiveAuto();
          }
          (1 + Last(xs)) * Pow(BASE(), len');
        <=
          {
            LemmaPowPositiveAuto();
            LemmaMulInequalityAuto();
          }
          ToNatLeft(ys);
          ToNatRight(ys);
        }
      }

      lemma {:isolate_assertions} /*{:_induction xs, ys}*/ LemmaSeqPrefixNeq(xs: seq<digit>, ys: seq<digit>, i: nat)
        requires 0 <= i <= |xs| == |ys|
        requires ToNatRight(xs[..i]) != ToNatRight(ys[..i])
        ensures ToNatRight(xs) != ToNatRight(ys)
        decreases |xs| - i
      {
        if i == |xs| {
          assert xs[..i] == xs;
          assert ys[..i] == ys;
        } else {
          if xs[i] == ys[i] {
            reveal ToNatLeft();
            assert DropLast(xs[..i + 1]) == xs[..i];
            assert DropLast(ys[..i + 1]) == ys[..i];
            LemmaToNatLeftEqToNatRightAuto();
            assert ToNatRight(xs[..i + 1]) == ToNatLeft(xs[..i + 1]);
          } else if xs[i] < ys[i] {
            LemmaSeqMswInequality(xs[..i + 1], ys[..i + 1]);
          } else {
            LemmaSeqMswInequality(ys[..i + 1], xs[..i + 1]);
          }
          reveal ToNatRight();
          LemmaSeqPrefixNeq(xs, ys, i + 1);
        }
      }

      lemma /*{:_induction xs, ys}*/ LemmaSeqNeq(xs: seq<digit>, ys: seq<digit>)
        requires |xs| == |ys|
        requires xs != ys
        ensures ToNatRight(xs) != ToNatRight(ys)
        decreases xs, ys
      {
        ghost var i: nat, n: nat := 0, |xs|;
        while i < n
          invariant 0 <= i < n
          invariant xs[..i] == ys[..i]
          decreases n - i
        {
          if xs[i] != ys[i] {
            break;
          }
          i := i + 1;
        }
        assert ToNatLeft(xs[..i]) == ToNatLeft(ys[..i]);
        reveal ToNatLeft();
        assert xs[..i + 1][..i] == xs[..i];
        assert ys[..i + 1][..i] == ys[..i];
        LemmaPowPositiveAuto();
        LemmaMulStrictInequalityAuto();
        assert ToNatLeft(xs[..i + 1]) != ToNatLeft(ys[..i + 1]);
        LemmaToNatLeftEqToNatRightAuto();
        LemmaSeqPrefixNeq(xs, ys, i + 1);
      }

      lemma /*{:_induction xs, ys}*/ LemmaSeqEq(xs: seq<digit>, ys: seq<digit>)
        requires |xs| == |ys|
        requires ToNatRight(xs) == ToNatRight(ys)
        ensures xs == ys
        decreases xs, ys
      {
        calc ==> {
          xs != ys;
          {
            LemmaSeqNeq(xs, ys);
          }
          ToNatRight(xs) != ToNatRight(ys);
          false;
        }
      }

      lemma {:isolate_assertions} /*{:_induction xs}*/ LemmaSeqLswModEquivalence(xs: seq<digit>)
        requires |xs| >= 1
        ensures IsModEquivalent(ToNatRight(xs), First(xs), BASE())
        decreases xs
      {
        if |xs| == 1 {
          LemmaSeqLen1(xs);
          LemmaModEquivalenceAuto();
        } else {
          assert IsModEquivalent(ToNatRight(xs), First(xs), BASE()) by {
            reveal ToNatRight();
            calc ==> {
              true;
              {
                LemmaModEquivalence(ToNatRight(xs), ToNatRight(DropFirst(xs)) * BASE() + First(xs), BASE());
              }
              IsModEquivalent(ToNatRight(xs), ToNatRight(DropFirst(xs)) * BASE() + First(xs), BASE());
              {
                LemmaModMultiplesBasicAuto();
              }
              IsModEquivalent(ToNatRight(xs), First(xs), BASE());
            }
          }
        }
      }

      function {:opaque} FromNat(n: nat): (xs: seq<digit>)
        decreases n
      {
        if n == 0 then
          []
        else
          LemmaDivBasicsAuto(); LemmaDivDecreasesAuto(); [n % BASE()] + FromNat(n / BASE())
      }

      lemma /*{:_induction n}*/ LemmaFromNatLen2(n: nat)
        ensures n == 0 ==> |FromNat(n)| == 0
        ensures n > 0 ==> |FromNat(n)| == Log(BASE(), n) + 1
        decreases n
      {
        reveal FromNat();
        ghost var digits := FromNat(n);
        if n == 0 {
        } else {
          assert |digits| == Log(BASE(), n) + 1 by {
            LemmaDivBasicsAuto();
            ghost var digits' := FromNat(n / BASE());
            assert |digits| == |digits'| + 1;
            if n < BASE() {
              LemmaLog0(BASE(), n);
              assert n / BASE() == 0 by {
                LemmaBasicDiv(BASE());
              }
            } else {
              LemmaLogS(BASE(), n);
              assert n / BASE() > 0 by {
                LemmaDivNonZeroAuto();
              }
            }
          }
        }
      }

      lemma /*{:_induction n, len}*/ LemmaFromNatLen(n: nat, len: nat)
        requires Pow(BASE(), len) > n
        ensures |FromNat(n)| <= len
        decreases n, len
      {
        reveal FromNat();
        if n == 0 {
        } else {
          calc {
            |FromNat(n)|;
          ==
            {
              LemmaDivBasicsAuto();
            }
            1 + |FromNat(n / BASE())|;
          <=
            {
              LemmaMultiplyDivideLtAuto();
              LemmaDivDecreasesAuto();
              reveal Pow();
              LemmaFromNatLen(n / BASE(), len - 1);
            }
            len;
          }
        }
      }

      lemma /*{:_induction n}*/ LemmaNatSeqNat(n: nat)
        ensures ToNatRight(FromNat(n)) == n
        decreases n
      {
        reveal ToNatRight();
        reveal FromNat();
        if n == 0 {
        } else {
          calc {
            ToNatRight(FromNat(n));
            {
              LemmaDivBasicsAuto();
            }
            ToNatRight([n % BASE()] + FromNat(n / BASE()));
            n % BASE() + ToNatRight(FromNat(n / BASE())) * BASE();
            {
              LemmaDivDecreasesAuto();
              LemmaNatSeqNat(n / BASE());
            }
            n % BASE() + n / BASE() * BASE();
            {
              LemmaFundamentalDivMod(n, BASE());
            }
            n;
          }
        }
      }

      function {:opaque} SeqExtend(xs: seq<digit>, n: nat): (ys: seq<digit>)
        requires |xs| <= n
        ensures |ys| == n
        ensures ToNatRight(ys) == ToNatRight(xs)
        decreases n - |xs|
      {
        if |xs| >= n then
          xs
        else
          LemmaSeqAppendZero(xs); SeqExtend(xs + [0], n)
      }

      function {:opaque} SeqExtendMultiple(xs: seq<digit>, n: nat): (ys: seq<digit>)
        requires n > 0
        ensures |ys| % n == 0
        ensures ToNatRight(ys) == ToNatRight(xs)
        decreases xs, n
      {
        var newLen: int := |xs| + n - |xs| % n;
        LemmaSubModNoopRight(|xs| + n, |xs|, n);
        LemmaModBasicsAuto();
        assert newLen % n == 0;
        LemmaSeqNatBound(xs);
        LemmaPowIncreasesAuto();
        SeqExtend(xs, newLen)
      }

      function {:opaque} FromNatWithLen(n: nat, len: nat): (xs: seq<digit>)
        requires Pow(BASE(), len) > n
        ensures |xs| == len
        ensures ToNatRight(xs) == n
        decreases n, len
      {
        LemmaFromNatLen(n, len);
        LemmaNatSeqNat(n);
        SeqExtend(FromNat(n), len)
      }

      lemma {:resource_limit ""10e6""} /*{:_induction xs}*/ LemmaSeqZero(xs: seq<digit>)
        requires ToNatRight(xs) == 0
        ensures forall i: int {:trigger xs[i]} :: 0 <= i < |xs| ==> xs[i] == 0
        decreases xs
      {
        reveal ToNatRight();
        if |xs| == 0 {
        } else {
          LemmaMulNonnegativeAuto();
          assert First(xs) == 0;
          LemmaMulNonzeroAuto();
          LemmaSeqZero(DropFirst(xs));
        }
      }

      function {:opaque} SeqZero(len: nat): (xs: seq<digit>)
        ensures |xs| == len
        ensures forall i: int {:trigger xs[i]} :: 0 <= i < |xs| ==> xs[i] == 0
        ensures ToNatRight(xs) == 0
        decreases len
      {
        LemmaPowPositive(BASE(), len);
        var xs: seq<digit> := FromNatWithLen(0, len);
        LemmaSeqZero(xs);
        xs
      }

      lemma /*{:_induction xs}*/ LemmaSeqNatSeq(xs: seq<digit>)
        ensures Pow(BASE(), |xs|) > ToNatRight(xs)
        ensures FromNatWithLen(ToNatRight(xs), |xs|) == xs
        decreases xs
      {
        reveal FromNat();
        reveal ToNatRight();
        LemmaSeqNatBound(xs);
        if |xs| > 0 {
          calc {
            FromNatWithLen(ToNatRight(xs), |xs|) != xs;
            {
              LemmaSeqNeq(FromNatWithLen(ToNatRight(xs), |xs|), xs);
            }
            ToNatRight(FromNatWithLen(ToNatRight(xs), |xs|)) != ToNatRight(xs);
            ToNatRight(xs) != ToNatRight(xs);
            false;
          }
        }
      }

      function {:opaque} SeqAdd(xs: seq<digit>, ys: seq<digit>): (seq<digit>, nat)
        requires |xs| == |ys|
        ensures var (zs: seq<digit>, cout: nat) := SeqAdd(xs, ys); |zs| == |xs| && 0 <= cout <= 1
        decreases xs
      {
        if |xs| == 0 then
          ([], 0)
        else
          var (zs': seq<digit>, cin: nat) := SeqAdd(DropLast(xs), DropLast(ys)); var sum: int := Last(xs) + Last(ys) + cin; var (sum_out: int, cout: int) := if sum < BASE() then (sum, 0) else (sum - BASE(), 1); (zs' + [sum_out], cout)
      }

      lemma {:isolate_assertions} /*{:_induction xs, ys, zs}*/ LemmaSeqAdd(xs: seq<digit>, ys: seq<digit>, zs: seq<digit>, cout: nat)
        requires |xs| == |ys|
        requires SeqAdd(xs, ys) == (zs, cout)
        ensures ToNatRight(xs) + ToNatRight(ys) == ToNatRight(zs) + cout * Pow(BASE(), |xs|)
        decreases xs, ys, zs, cout
      {
        reveal SeqAdd();
        if |xs| == 0 {
          reveal ToNatRight();
        } else {
          ghost var pow := Pow(BASE(), |xs| - 1);
          var (zs', cin) := SeqAdd(DropLast(xs), DropLast(ys));
          ghost var sum: int := Last(xs) + Last(ys) + cin;
          ghost var z := if sum < BASE() then sum else sum - BASE();
          assert sum == z + cout * BASE();
          reveal ToNatLeft();
          LemmaToNatLeftEqToNatRightAuto();
          calc {
            ToNatRight(zs);
            ToNatLeft(zs);
            ToNatLeft(zs') + z * pow;
            {
              LemmaSeqAdd(DropLast(xs), DropLast(ys), zs', cin);
            }
            ToNatLeft(DropLast(xs)) + ToNatLeft(DropLast(ys)) - cin * pow + z * pow;
            {
              LemmaMulEquality(sum, z + cout * BASE(), pow);
              assert sum * pow == (z + cout * BASE()) * pow;
              LemmaMulIsDistributiveAuto();
            }
            ToNatLeft(xs) + ToNatLeft(ys) - cout * BASE() * pow;
            {
              LemmaMulIsAssociative(cout, BASE(), pow);
              reveal Pow();
            }
            ToNatLeft(xs) + ToNatLeft(ys) - cout * Pow(BASE(), |xs|);
            ToNatRight(xs) + ToNatRight(ys) - cout * Pow(BASE(), |xs|);
          }
        }
      }

      function {:opaque} SeqSub(xs: seq<digit>, ys: seq<digit>): (seq<digit>, nat)
        requires |xs| == |ys|
        ensures var (zs: seq<digit>, cout: nat) := SeqSub(xs, ys); |zs| == |xs| && 0 <= cout <= 1
        decreases xs
      {
        if |xs| == 0 then
          ([], 0)
        else
          var (zs: seq<digit>, cin: nat) := SeqSub(DropLast(xs), DropLast(ys)); var (diff_out: int, cout: int) := if Last(xs) >= Last(ys) + cin then (Last(xs) - Last(ys) - cin, 0) else (BASE() + Last(xs) - Last(ys) - cin, 1); (zs + [diff_out], cout)
      }

      lemma {:isolate_assertions} /*{:_induction xs, ys, zs}*/ LemmaSeqSub(xs: seq<digit>, ys: seq<digit>, zs: seq<digit>, cout: nat)
        requires |xs| == |ys|
        requires SeqSub(xs, ys) == (zs, cout)
        ensures ToNatRight(xs) - ToNatRight(ys) + cout * Pow(BASE(), |xs|) == ToNatRight(zs)
        decreases xs, ys, zs, cout
      {
        reveal SeqSub();
        if |xs| == 0 {
          reveal ToNatRight();
        } else {
          ghost var pow := Pow(BASE(), |xs| - 1);
          var (zs', cin) := SeqSub(DropLast(xs), DropLast(ys));
          ghost var z := if Last(xs) >= Last(ys) + cin then Last(xs) - Last(ys) - cin else BASE() + Last(xs) - Last(ys) - cin;
          assert cout * BASE() + Last(xs) - cin - Last(ys) == z;
          reveal ToNatLeft();
          LemmaToNatLeftEqToNatRightAuto();
          calc {
            ToNatRight(zs);
            ToNatLeft(zs);
            ToNatLeft(zs') + z * pow;
            {
              LemmaSeqSub(DropLast(xs), DropLast(ys), zs', cin);
            }
            ToNatLeft(DropLast(xs)) - ToNatLeft(DropLast(ys)) + cin * pow + z * pow;
            {
              LemmaMulEquality(cout * BASE() + Last(xs) - cin - Last(ys), z, pow);
              assert pow * (cout * BASE() + Last(xs) - cin - Last(ys)) == pow * z;
              LemmaMulIsDistributiveAuto();
            }
            ToNatLeft(xs) - ToNatLeft(ys) + cout * BASE() * pow;
            {
              LemmaMulIsAssociative(cout, BASE(), pow);
              reveal Pow();
            }
            ToNatLeft(xs) - ToNatLeft(ys) + cout * Pow(BASE(), |xs|);
            ToNatRight(xs) - ToNatRight(ys) + cout * Pow(BASE(), |xs|);
          }
        }
      }

      type Char = char

      import opened Wrappers

      type String = seq<Char>

      type CharSeq = chars: seq<Char>
        | |chars| > 1
        witness *

      import opened DivMod

      import opened Mul

      import opened Power

      import opened Seq = Collections.Seq

      import opened Logarithm

      type digit = i: nat
        | 0 <= i < BASE()
    }

    module CharStrEscaping refines ParametricEscaping {
      function Escape(str: String, mustEscape: set<Char>, escape: Char): String
        decreases str, mustEscape
      {
        if str == [] then
          str
        else if str[0] in mustEscape then
          [escape, str[0]] + Escape(str[1..], mustEscape, escape)
        else
          [str[0]] + Escape(str[1..], mustEscape, escape)
      }

      function Unescape(str: String, escape: Char): Option<String>
        decreases str
      {
        if str == [] then
          Some(str)
        else if str[0] == escape then
          if |str| > 1 then
            var tl: String :- Unescape(str[2..], escape); Some([str[1]] + tl)
          else
            None
        else
          var tl: String :- Unescape(str[1..], escape); Some([str[0]] + tl)
      }

      lemma {:induction false} Unescape_Escape(str: String, special: set<Char>, escape: Char)
        requires escape in special
        ensures Unescape(Escape(str, special, escape), escape) == Some(str)
        decreases str, special
      {
        if str == [] {
        } else {
          assert str == [str[0]] + str[1..];
          Unescape_Escape(str[1..], special, escape);
        }
      }

      type Char = char

      import opened Wrappers

      type String = seq<Char>
    }
  }

  module Unicode {

    module Base {
      const HIGH_SURROGATE_MIN: CodePoint := 55296
      const HIGH_SURROGATE_MAX: CodePoint := 56319
      const LOW_SURROGATE_MIN: CodePoint := 56320
      const LOW_SURROGATE_MAX: CodePoint := 57343
      const ASSIGNED_PLANES: set<bv8> := {0, 1, 2, 3, 14, 15, 16}

      opaque predicate IsInAssignedPlane(i: CodePoint)
        decreases i
      {
        var plane: bv8 := (i >> 16 as bv5) as bv8;
        plane in ASSIGNED_PLANES
      }

      type CodePoint = i: bv24
        | 0 <= i <= 1114111

      type HighSurrogateCodePoint = p: CodePoint
        | HIGH_SURROGATE_MIN <= p <= HIGH_SURROGATE_MAX
        witness HIGH_SURROGATE_MIN

      type LowSurrogateCodePoint = p: CodePoint
        | LOW_SURROGATE_MIN <= p <= LOW_SURROGATE_MAX
        witness LOW_SURROGATE_MIN

      type ScalarValue = p: CodePoint
        | (p < HIGH_SURROGATE_MIN || p > HIGH_SURROGATE_MAX) && (p < LOW_SURROGATE_MIN || p > LOW_SURROGATE_MAX)

      type AssignedCodePoint = p: CodePoint
        | IsInAssignedPlane(p)
        witness *
    }

    abstract module UnicodeEncodingForm {
      function IsMinimalWellFormedCodeUnitSubsequence(s: CodeUnitSeq): (b: bool)
        ensures b ==> |s| > 0 && forall i: int {:trigger s[..i]} | 0 < i < |s| :: !IsMinimalWellFormedCodeUnitSubsequence(s[..i])
        decreases |s|

      function SplitPrefixMinimalWellFormedCodeUnitSubsequence(s: CodeUnitSeq): (maybePrefix: Option<MinimalWellFormedCodeUnitSeq>)
        ensures |s| == 0 ==> maybePrefix.None?
        ensures (exists i: int {:trigger s[..i]} | 0 < i <= |s| :: IsMinimalWellFormedCodeUnitSubsequence(s[..i])) <==> true && maybePrefix.Some?
        ensures maybePrefix.Some? ==> true && var prefix: MinimalWellFormedCodeUnitSeq := maybePrefix.Extract(); 0 < |prefix| <= |s| && prefix == s[..|prefix|] && forall i: int {:trigger s[..i]} | 0 < i < |prefix| :: !IsMinimalWellFormedCodeUnitSubsequence(s[..i])
        decreases s

      function EncodeScalarValue(v: ScalarValue): (m: MinimalWellFormedCodeUnitSeq)
        decreases v

      function DecodeMinimalWellFormedCodeUnitSubsequence(m: MinimalWellFormedCodeUnitSeq): (v: ScalarValue)
        ensures EncodeScalarValue(v) == m
        decreases m

      lemma LemmaUniquePrefixMinimalWellFormedCodeUnitSeq(s: CodeUnitSeq, m1: MinimalWellFormedCodeUnitSeq, m2: MinimalWellFormedCodeUnitSeq)
        requires m1 <= s
        requires m2 <= s
        ensures m1 == m2
        decreases |s|, |m1|, |m2|
      {
        if |m1| > |m2| {
          LemmaUniquePrefixMinimalWellFormedCodeUnitSeq(s, m2, m1);
        } else {
          assert m1 <= m2;
          assert m1 == m2 by {
            if m1 < m2 {
              assert false by {
                assert m1 == m2[..|m1|];
              }
            }
          }
        }
      }

      lemma LemmaSplitPrefixMinimalWellFormedCodeUnitSubsequenceInvertsPrepend(m: MinimalWellFormedCodeUnitSeq, s: CodeUnitSeq)
        ensures SplitPrefixMinimalWellFormedCodeUnitSubsequence(m + s) == Some(m)
        decreases m, s
      {
        ghost var ms := m + s;
        ghost var maybePrefix := SplitPrefixMinimalWellFormedCodeUnitSubsequence(ms);
        assert maybePrefix.Some? by {
          assert IsMinimalWellFormedCodeUnitSubsequence(ms[..|m|]);
        }
        ghost var prefix := maybePrefix.Extract();
        assert m <= ms;
        assert prefix <= ms;
        LemmaUniquePrefixMinimalWellFormedCodeUnitSeq(ms, m, prefix);
      }

      function PartitionCodeUnitSequenceChecked(s: CodeUnitSeq): (maybeParts: Option<seq<MinimalWellFormedCodeUnitSeq>>)
        ensures maybeParts.Some? ==> Seq.Flatten(maybeParts.Extract()) == s
        decreases |s|
      {
        if s == [] then
          Some([])
        else
          var prefix: MinimalWellFormedCodeUnitSeq :- SplitPrefixMinimalWellFormedCodeUnitSubsequence(s); var restParts: seq<MinimalWellFormedCodeUnitSeq> :- PartitionCodeUnitSequenceChecked(s[|prefix|..]); Some([prefix] + restParts)
      } by method {
        if s == [] {
          return Some([]);
        }
        var result: seq<MinimalWellFormedCodeUnitSeq> := [];
        var rest := s;
        while |rest| > 0
          invariant PartitionCodeUnitSequenceChecked(s).Some? <==> PartitionCodeUnitSequenceChecked(rest).Some?
          invariant PartitionCodeUnitSequenceChecked(s).Some? ==> true && PartitionCodeUnitSequenceChecked(s).value == result + PartitionCodeUnitSequenceChecked(rest).value
          decreases |rest| - 0
        {
          var prefix :- SplitPrefixMinimalWellFormedCodeUnitSubsequence(rest);
          result := result + [prefix];
          rest := rest[|prefix|..];
        }
        assert result + [] == result;
        return Some(result);
      }

      function PartitionCodeUnitSequence(s: WellFormedCodeUnitSeq): (parts: seq<MinimalWellFormedCodeUnitSeq>)
        ensures Seq.Flatten(parts) == s
        decreases s
      {
        PartitionCodeUnitSequenceChecked(s).Extract()
      }

      lemma /*{:_induction m}*/ LemmaPartitionMinimalWellFormedCodeUnitSubsequence(m: MinimalWellFormedCodeUnitSeq)
        ensures PartitionCodeUnitSequenceChecked(m) == Some([m])
        decreases m
      {
        LemmaSplitPrefixMinimalWellFormedCodeUnitSubsequenceInvertsPrepend(m, []);
        calc == {
          Some(m);
          SplitPrefixMinimalWellFormedCodeUnitSubsequence(m + []);
          {
            assert m + [] == m;
          }
          SplitPrefixMinimalWellFormedCodeUnitSubsequence(m);
        }
        calc == {
          PartitionCodeUnitSequenceChecked(m);
          Some([m] + []);
          {
            assert [m] + [] == [m];
          }
          Some([m]);
        }
      }

      function IsWellFormedCodeUnitSequence(s: CodeUnitSeq): (b: bool)
        decreases s
      {
        PartitionCodeUnitSequenceChecked(s).Some?
      }

      lemma LemmaMinimalWellFormedCodeUnitSubsequenceIsWellFormedSequence(m: MinimalWellFormedCodeUnitSeq)
        ensures IsWellFormedCodeUnitSequence(m)
        decreases m
      {
        LemmaPartitionMinimalWellFormedCodeUnitSubsequence(m);
      }

      lemma LemmaPrependMinimalWellFormedCodeUnitSubsequence(m: MinimalWellFormedCodeUnitSeq, s: WellFormedCodeUnitSeq)
        ensures IsWellFormedCodeUnitSequence(m + s)
        decreases m, s
      {
        LemmaPartitionMinimalWellFormedCodeUnitSubsequence(m);
        LemmaSplitPrefixMinimalWellFormedCodeUnitSubsequenceInvertsPrepend(m, s);
      }

      lemma /*{:_induction ms}*/ LemmaFlattenMinimalWellFormedCodeUnitSubsequences(ms: seq<MinimalWellFormedCodeUnitSeq>)
        ensures IsWellFormedCodeUnitSequence(Seq.Flatten(ms))
        decreases ms
      {
        if |ms| == 0 {
        } else {
          ghost var head := ms[0];
          ghost var tail := ms[1..];
          LemmaFlattenMinimalWellFormedCodeUnitSubsequences(tail);
          ghost var flatTail := Seq.Flatten(tail);
          LemmaPrependMinimalWellFormedCodeUnitSubsequence(head, flatTail);
        }
      }

      lemma LemmaConcatWellFormedCodeUnitSubsequences(s: WellFormedCodeUnitSeq, t: WellFormedCodeUnitSeq)
        ensures IsWellFormedCodeUnitSequence(s + t)
        decreases s, t
      {
        ghost var partsS := PartitionCodeUnitSequence(s);
        ghost var partsT := PartitionCodeUnitSequence(t);
        ghost var partsST := partsS + partsT;
        Seq.LemmaFlattenConcat(partsS, partsT);
        LemmaFlattenMinimalWellFormedCodeUnitSubsequences(partsST);
      }

      function EncodeScalarSequence(vs: seq<ScalarValue>): (s: WellFormedCodeUnitSeq)
        decreases vs
      {
        var ms: seq<MinimalWellFormedCodeUnitSeq> := Seq.Map(EncodeScalarValue, vs);
        LemmaFlattenMinimalWellFormedCodeUnitSubsequences(ms);
        Seq.Flatten(ms)
      } by method {
        s := [];
        ghost var unflattened: seq<MinimalWellFormedCodeUnitSeq> := [];
        for i: int := |vs| downto 0
          invariant unflattened == Seq.Map(EncodeScalarValue, vs[i..])
          invariant s == Seq.Flatten(unflattened)
        {
          var next: MinimalWellFormedCodeUnitSeq := EncodeScalarValue(vs[i]);
          unflattened := [next] + unflattened;
          LemmaPrependMinimalWellFormedCodeUnitSubsequence(next, s);
          s := next + s;
        }
      }

      function DecodeCodeUnitSequence(s: WellFormedCodeUnitSeq): (vs: seq<ScalarValue>)
        ensures EncodeScalarSequence(vs) == s
        decreases s
      {
        var parts: seq<MinimalWellFormedCodeUnitSeq> := PartitionCodeUnitSequence(s);
        var vs: seq<ScalarValue> := Seq.Map(DecodeMinimalWellFormedCodeUnitSubsequence, parts);
        calc == {
          s;
          Seq.Flatten(parts);
          {
            assert parts == Seq.Map(EncodeScalarValue, vs);
          }
          Seq.Flatten(Seq.Map(EncodeScalarValue, vs));
          EncodeScalarSequence(vs);
        }
        vs
      }

      function DecodeCodeUnitSequenceChecked(s: CodeUnitSeq): (maybeVs: Option<seq<ScalarValue>>)
        ensures IsWellFormedCodeUnitSequence(s) ==> maybeVs.Some? && maybeVs.Extract() == DecodeCodeUnitSequence(s)
        ensures !IsWellFormedCodeUnitSequence(s) ==> true && maybeVs.None?
        decreases s
      {
        if IsWellFormedCodeUnitSequence(s) then
          Some(DecodeCodeUnitSequence(s))
        else
          None
      } by method {
        var maybeParts := PartitionCodeUnitSequenceChecked(s);
        if maybeParts.None? {
          return None;
        }
        var parts := maybeParts.value;
        var vs := Seq.Map(DecodeMinimalWellFormedCodeUnitSubsequence, parts);
        calc == {
          s;
          Seq.Flatten(parts);
          {
            assert parts == Seq.Map(EncodeScalarValue, vs);
          }
          Seq.Flatten(Seq.Map(EncodeScalarValue, vs));
          EncodeScalarSequence(vs);
        }
        return Some(vs);
      }

      import opened Wrappers

      import Functions

      import Seq = Collections.Seq

      import opened Base

      type CodeUnitSeq = seq<CodeUnit>

      type WellFormedCodeUnitSeq = s: CodeUnitSeq
        | IsWellFormedCodeUnitSequence(s)
        witness []

      type MinimalWellFormedCodeUnitSeq = s: CodeUnitSeq
        | IsMinimalWellFormedCodeUnitSubsequence(s)
        witness *

      type CodeUnit
    }

    abstract module AbstractUnicodeStrings {
      function ToUTF8Checked(s: string): Option<seq<uint8>>
        decreases s

      function ASCIIToUTF8(s: string): seq<uint8>
        requires forall i: int {:trigger s[i]} | 0 <= i < |s| :: 0 <= s[i] as int && s[i] as int < 128
        decreases s
      {
        Seq.Map((c: char) requires 0 <= c as int < 128 => c as uint8, s)
      }

      function FromUTF8Checked(bs: seq<uint8>): Option<string>
        decreases bs

      function ToUTF16Checked(s: string): Option<seq<uint16>>
        decreases s

      function ASCIIToUTF16(s: string): seq<uint16>
        requires forall i: int {:trigger s[i]} | 0 <= i < |s| :: 0 <= s[i] as int && s[i] as int < 128
        decreases s
      {
        Seq.Map((c: char) requires 0 <= c as int < 128 => c as uint16, s)
      }

      function FromUTF16Checked(bs: seq<uint16>): Option<string>
        decreases bs

      import Seq = Collections.Seq

      import opened Wrappers

      import opened BoundedInts
    }

    module UnicodeStringsWithUnicodeChar refines AbstractUnicodeStrings {
      lemma {:isolate_assertions} CharIsUnicodeScalarValue(c: char)
        ensures true && ghost var asBits: bv24 := c as int as bv24; asBits <= 1114111 && (0 <= asBits < Base.HIGH_SURROGATE_MIN || Base.LOW_SURROGATE_MAX < asBits)
        decreases c
      {
        assert c as int < 1114112;
        assume {:axiom} c as int as bv24 < 1114112 as bv24;
        ghost var asBits := c as int as bv24;
        assert asBits < 1114112 as bv24;
        assert asBits < Base.HIGH_SURROGATE_MIN || asBits > Base.LOW_SURROGATE_MAX;
        assert asBits <= 1114111;
      }

      lemma UnicodeScalarValueIsChar(sv: Base.ScalarValue)
        ensures true && ghost var asInt: int := sv as int; true && (0 <= asInt < 55296 || 57344 <= asInt < 1114112)
        decreases sv
      {
        ghost var asInt := sv as int;
        assert asInt < 55296 || asInt > 57343;
        assert asInt < 56319 || asInt > 56320;
      }

      function CharAsUnicodeScalarValue(c: char): Base.ScalarValue
        decreases c
      {
        CharIsUnicodeScalarValue(c);
        c as int as Base.ScalarValue
      }

      function CharFromUnicodeScalarValue(sv: Base.ScalarValue): char
        decreases sv
      {
        UnicodeScalarValueIsChar(sv);
        sv as int as char
      }

      function ToUTF8Checked(s: string): Option<seq<uint8>>
        ensures ToUTF8Checked(s).Some?
        decreases s
      {
        var asCodeUnits: seq<Base.ScalarValue> := Seq.Map(CharAsUnicodeScalarValue, s);
        var asUtf8CodeUnits: WellFormedCodeUnitSeq := Utf8EncodingForm.EncodeScalarSequence(asCodeUnits);
        var asBytes: seq<uint8> := Seq.Map((cu: bv8) => cu as uint8, asUtf8CodeUnits);
        Some(asBytes)
      }

      function FromUTF8Checked(bs: seq<uint8>): Option<string>
        decreases bs
      {
        var asCodeUnits: seq<Utf8EncodingForm.CodeUnit> := Seq.Map((c: uint8) => c as Utf8EncodingForm.CodeUnit, bs);
        var utf32: seq<ScalarValue> :- Utf8EncodingForm.DecodeCodeUnitSequenceChecked(asCodeUnits); var asChars: seq<char> := Seq.Map(CharFromUnicodeScalarValue, utf32); Some(asChars)
      }

      function ToUTF16Checked(s: string): Option<seq<uint16>>
        ensures ToUTF16Checked(s).Some?
        decreases s
      {
        var asCodeUnits: seq<Base.ScalarValue> := Seq.Map(CharAsUnicodeScalarValue, s);
        var asUtf16CodeUnits: WellFormedCodeUnitSeq := Utf16EncodingForm.EncodeScalarSequence(asCodeUnits);
        var asBytes: seq<uint16> := Seq.Map((cu: bv16) => cu as uint16, asUtf16CodeUnits);
        Some(asBytes)
      }

      function FromUTF16Checked(bs: seq<uint16>): Option<string>
        decreases bs
      {
        var asCodeUnits: seq<Utf16EncodingForm.CodeUnit> := Seq.Map((c: uint16) => c as Utf16EncodingForm.CodeUnit, bs);
        var utf32: seq<ScalarValue> :- Utf16EncodingForm.DecodeCodeUnitSequenceChecked(asCodeUnits); var asChars: seq<char> := Seq.Map(CharFromUnicodeScalarValue, utf32); Some(asChars)
      }

      function ASCIIToUTF8(s: string): seq<uint8>
        requires forall i: int {:trigger s[i]} | 0 <= i < |s| :: 0 <= s[i] as int && s[i] as int < 128
        decreases s
      {
        Seq.Map((c: char) requires 0 <= c as int < 128 => c as uint8, s)
      }

      function ASCIIToUTF16(s: string): seq<uint16>
        requires forall i: int {:trigger s[i]} | 0 <= i < |s| :: 0 <= s[i] as int && s[i] as int < 128
        decreases s
      {
        Seq.Map((c: char) requires 0 <= c as int < 128 => c as uint16, s)
      }

      import Base

      import Utf8EncodingForm

      import Utf16EncodingForm

      import Seq = Collections.Seq

      import opened Wrappers

      import opened BoundedInts
    }

    module Utf16EncodingForm refines UnicodeEncodingForm {
      function IsMinimalWellFormedCodeUnitSubsequence(s: CodeUnitSeq): (b: bool)
        ensures b ==> |s| > 0 && forall i: int {:trigger s[..i]} | 0 < i < |s| :: !IsMinimalWellFormedCodeUnitSubsequence(s[..i])
        decreases |s|
      {
        if |s| == 1 then
          IsWellFormedSingleCodeUnitSequence(s)
        else if |s| == 2 then
          var b: bool := IsWellFormedDoubleCodeUnitSequence(s);
          assert b ==> forall i: int {:trigger s[..i]} | 0 < i < |s| :: !IsMinimalWellFormedCodeUnitSubsequence(s[..i]);
          b
        else
          false
      }

      function IsWellFormedSingleCodeUnitSequence(s: CodeUnitSeq): (b: bool)
        requires |s| == 1
        decreases s
      {
        var firstWord: bv16 := s[0];
        0 <= firstWord <= 55295 || 57344 <= firstWord <= 65535
      }

      function IsWellFormedDoubleCodeUnitSequence(s: CodeUnitSeq): (b: bool)
        requires |s| == 2
        ensures b ==> !IsWellFormedSingleCodeUnitSequence(s[..1])
        decreases s
      {
        var firstWord: bv16 := s[0];
        var secondWord: bv16 := s[1];
        55296 <= firstWord <= 56319 &&
        56320 <= secondWord <= 57343
      }

      function SplitPrefixMinimalWellFormedCodeUnitSubsequence(s: CodeUnitSeq): (maybePrefix: Option<MinimalWellFormedCodeUnitSeq>)
        ensures |s| == 0 ==> maybePrefix.None?
        ensures (exists i: int {:trigger s[..i]} | 0 < i <= |s| :: IsMinimalWellFormedCodeUnitSubsequence(s[..i])) <==> true && maybePrefix.Some?
        ensures maybePrefix.Some? ==> true && var prefix: MinimalWellFormedCodeUnitSeq := maybePrefix.Extract(); 0 < |prefix| <= |s| && prefix == s[..|prefix|] && forall i: int {:trigger s[..i]} | 0 < i < |prefix| :: !IsMinimalWellFormedCodeUnitSubsequence(s[..i])
        ensures |s| == 0 ==> maybePrefix.None?
        ensures (exists i: int {:trigger s[..i]} | 0 < i <= |s| :: IsMinimalWellFormedCodeUnitSubsequence(s[..i])) <==> true && maybePrefix.Some?
        ensures maybePrefix.Some? ==> true && var prefix: MinimalWellFormedCodeUnitSeq := maybePrefix.Extract(); 0 < |prefix| <= |s| && prefix == s[..|prefix|] && IsMinimalWellFormedCodeUnitSubsequence(prefix)
        decreases s
      {
        if |s| >= 1 && IsWellFormedSingleCodeUnitSequence(s[..1]) then
          Some(s[..1])
        else if |s| >= 2 && IsWellFormedDoubleCodeUnitSequence(s[..2]) then
          Some(s[..2])
        else
          None
      }

      function EncodeScalarValue(v: ScalarValue): (m: MinimalWellFormedCodeUnitSeq)
        decreases v
      {
        if 0 <= v <= 55295 || 57344 <= v <= 65535 then
          EncodeScalarValueSingleWord(v)
        else
          EncodeScalarValueDoubleWord(v)
      }

      function EncodeScalarValueSingleWord(v: ScalarValue): (m: MinimalWellFormedCodeUnitSeq)
        requires 0 <= v <= 55295 || 57344 <= v <= 65535
        ensures |m| == 1
        ensures IsWellFormedSingleCodeUnitSequence(m)
        decreases v
      {
        var firstWord: CodeUnit := v as CodeUnit;
        [firstWord]
      }

      function EncodeScalarValueDoubleWord(v: ScalarValue): (m: MinimalWellFormedCodeUnitSeq)
        requires 65536 <= v <= 1114111
        ensures |m| == 2
        ensures IsWellFormedDoubleCodeUnitSequence(m)
        decreases v
      {
        var x2: bv10 := (v & 1023) as bv10;
        var x1: bv6 := (v & 64512 >> 10 as bv5) as bv6;
        var u: bv5 := (v & 2031616 >> 16 as bv5) as bv5;
        var w: bv4 := (u - 1) as bv4;
        var firstWord: bv16 := 55296 | (w as CodeUnit << 6 as bv5) | x1 as CodeUnit;
        var secondWord: bv16 := 56320 | x2 as CodeUnit;
        [firstWord, secondWord]
      }

      function DecodeMinimalWellFormedCodeUnitSubsequence(m: MinimalWellFormedCodeUnitSeq): (v: ScalarValue)
        ensures EncodeScalarValue(v) == m
        decreases m
      {
        if |m| == 1 then
          DecodeMinimalWellFormedCodeUnitSubsequenceSingleWord(m)
        else
          assert |m| == 2; DecodeMinimalWellFormedCodeUnitSubsequenceDoubleWord(m)
      }

      function DecodeMinimalWellFormedCodeUnitSubsequenceSingleWord(m: MinimalWellFormedCodeUnitSeq): (v: ScalarValue)
        requires |m| == 1
        ensures 0 <= v <= 55295 || 57344 <= v <= 65535
        ensures EncodeScalarValueSingleWord(v) == m
        decreases m
      {
        var firstWord: bv16 := m[0];
        var x: bv16 := firstWord as bv16;
        assert EncodeScalarValueSingleWord(x as ScalarValue) == m;
        x as ScalarValue
      }

      function {:resource_limit 1200000} DecodeMinimalWellFormedCodeUnitSubsequenceDoubleWord(m: MinimalWellFormedCodeUnitSeq): (v: ScalarValue)
        requires |m| == 2
        ensures 65536 <= v <= 1114111
        ensures EncodeScalarValueDoubleWord(v) == m
        decreases m
      {
        var firstWord: bv16 := m[0];
        var secondWord: bv16 := m[1];
        var x2: bv24 := (secondWord & 1023) as bv24;
        var x1: bv24 := (firstWord & 63) as bv24;
        var w: bv24 := (firstWord & 960 >> 6 as bv5) as bv24;
        var u: bv24 := (w + 1) as bv24;
        var v: bv24 := (u << 16 as bv5) | (x1 << 10 as bv5) | x2 as ScalarValue;
        assert {:split_here} true;
        assert EncodeScalarValueDoubleWord(v) == m;
        v
      }

      lemma LemmaUniquePrefixMinimalWellFormedCodeUnitSeq(s: CodeUnitSeq, m1: MinimalWellFormedCodeUnitSeq, m2: MinimalWellFormedCodeUnitSeq)
        requires m1 <= s
        requires m2 <= s
        ensures m1 == m2
        decreases |s|, |m1|, |m2|
      {
        if |m1| > |m2| {
          LemmaUniquePrefixMinimalWellFormedCodeUnitSeq(s, m2, m1);
        } else {
          assert m1 <= m2;
          assert m1 == m2 by {
            if m1 < m2 {
              assert false by {
                assert m1 == m2[..|m1|];
              }
            }
          }
        }
      }

      lemma LemmaSplitPrefixMinimalWellFormedCodeUnitSubsequenceInvertsPrepend(m: MinimalWellFormedCodeUnitSeq, s: CodeUnitSeq)
        ensures SplitPrefixMinimalWellFormedCodeUnitSubsequence(m + s) == Some(m)
        decreases m, s
      {
        ghost var ms := m + s;
        ghost var maybePrefix := SplitPrefixMinimalWellFormedCodeUnitSubsequence(ms);
        assert maybePrefix.Some? by {
          assert IsMinimalWellFormedCodeUnitSubsequence(ms[..|m|]);
        }
        ghost var prefix := maybePrefix.Extract();
        assert m <= ms;
        assert prefix <= ms;
        LemmaUniquePrefixMinimalWellFormedCodeUnitSeq(ms, m, prefix);
      }

      function PartitionCodeUnitSequenceChecked(s: CodeUnitSeq): (maybeParts: Option<seq<MinimalWellFormedCodeUnitSeq>>)
        ensures maybeParts.Some? ==> Seq.Flatten(maybeParts.Extract()) == s
        decreases |s|
      {
        if s == [] then
          Some([])
        else
          var prefix: MinimalWellFormedCodeUnitSeq :- SplitPrefixMinimalWellFormedCodeUnitSubsequence(s); var restParts: seq<MinimalWellFormedCodeUnitSeq> :- PartitionCodeUnitSequenceChecked(s[|prefix|..]); Some([prefix] + restParts)
      } by method {
        if s == [] {
          return Some([]);
        }
        var result: seq<MinimalWellFormedCodeUnitSeq> := [];
        var rest := s;
        while |rest| > 0
          invariant PartitionCodeUnitSequenceChecked(s).Some? <==> PartitionCodeUnitSequenceChecked(rest).Some?
          invariant PartitionCodeUnitSequenceChecked(s).Some? ==> true && PartitionCodeUnitSequenceChecked(s).value == result + PartitionCodeUnitSequenceChecked(rest).value
          decreases |rest| - 0
        {
          var prefix :- SplitPrefixMinimalWellFormedCodeUnitSubsequence(rest);
          result := result + [prefix];
          rest := rest[|prefix|..];
        }
        assert result + [] == result;
        return Some(result);
      }

      function PartitionCodeUnitSequence(s: WellFormedCodeUnitSeq): (parts: seq<MinimalWellFormedCodeUnitSeq>)
        ensures Seq.Flatten(parts) == s
        decreases s
      {
        PartitionCodeUnitSequenceChecked(s).Extract()
      }

      lemma /*{:_induction m}*/ LemmaPartitionMinimalWellFormedCodeUnitSubsequence(m: MinimalWellFormedCodeUnitSeq)
        ensures PartitionCodeUnitSequenceChecked(m) == Some([m])
        decreases m
      {
        LemmaSplitPrefixMinimalWellFormedCodeUnitSubsequenceInvertsPrepend(m, []);
        calc == {
          Some(m);
          SplitPrefixMinimalWellFormedCodeUnitSubsequence(m + []);
          {
            assert m + [] == m;
          }
          SplitPrefixMinimalWellFormedCodeUnitSubsequence(m);
        }
        calc == {
          PartitionCodeUnitSequenceChecked(m);
          Some([m] + []);
          {
            assert [m] + [] == [m];
          }
          Some([m]);
        }
      }

      function IsWellFormedCodeUnitSequence(s: CodeUnitSeq): (b: bool)
        decreases s
      {
        PartitionCodeUnitSequenceChecked(s).Some?
      }

      lemma LemmaMinimalWellFormedCodeUnitSubsequenceIsWellFormedSequence(m: MinimalWellFormedCodeUnitSeq)
        ensures IsWellFormedCodeUnitSequence(m)
        decreases m
      {
        LemmaPartitionMinimalWellFormedCodeUnitSubsequence(m);
      }

      lemma LemmaPrependMinimalWellFormedCodeUnitSubsequence(m: MinimalWellFormedCodeUnitSeq, s: WellFormedCodeUnitSeq)
        ensures IsWellFormedCodeUnitSequence(m + s)
        decreases m, s
      {
        LemmaPartitionMinimalWellFormedCodeUnitSubsequence(m);
        LemmaSplitPrefixMinimalWellFormedCodeUnitSubsequenceInvertsPrepend(m, s);
      }

      lemma /*{:_induction ms}*/ LemmaFlattenMinimalWellFormedCodeUnitSubsequences(ms: seq<MinimalWellFormedCodeUnitSeq>)
        ensures IsWellFormedCodeUnitSequence(Seq.Flatten(ms))
        decreases ms
      {
        if |ms| == 0 {
        } else {
          ghost var head := ms[0];
          ghost var tail := ms[1..];
          LemmaFlattenMinimalWellFormedCodeUnitSubsequences(tail);
          ghost var flatTail := Seq.Flatten(tail);
          LemmaPrependMinimalWellFormedCodeUnitSubsequence(head, flatTail);
        }
      }

      lemma LemmaConcatWellFormedCodeUnitSubsequences(s: WellFormedCodeUnitSeq, t: WellFormedCodeUnitSeq)
        ensures IsWellFormedCodeUnitSequence(s + t)
        decreases s, t
      {
        ghost var partsS := PartitionCodeUnitSequence(s);
        ghost var partsT := PartitionCodeUnitSequence(t);
        ghost var partsST := partsS + partsT;
        Seq.LemmaFlattenConcat(partsS, partsT);
        LemmaFlattenMinimalWellFormedCodeUnitSubsequences(partsST);
      }

      function EncodeScalarSequence(vs: seq<ScalarValue>): (s: WellFormedCodeUnitSeq)
        decreases vs
      {
        var ms: seq<MinimalWellFormedCodeUnitSeq> := Seq.Map(EncodeScalarValue, vs);
        LemmaFlattenMinimalWellFormedCodeUnitSubsequences(ms);
        Seq.Flatten(ms)
      } by method {
        s := [];
        ghost var unflattened: seq<MinimalWellFormedCodeUnitSeq> := [];
        for i: int := |vs| downto 0
          invariant unflattened == Seq.Map(EncodeScalarValue, vs[i..])
          invariant s == Seq.Flatten(unflattened)
        {
          var next: MinimalWellFormedCodeUnitSeq := EncodeScalarValue(vs[i]);
          unflattened := [next] + unflattened;
          LemmaPrependMinimalWellFormedCodeUnitSubsequence(next, s);
          s := next + s;
        }
      }

      function DecodeCodeUnitSequence(s: WellFormedCodeUnitSeq): (vs: seq<ScalarValue>)
        ensures EncodeScalarSequence(vs) == s
        decreases s
      {
        var parts: seq<MinimalWellFormedCodeUnitSeq> := PartitionCodeUnitSequence(s);
        var vs: seq<ScalarValue> := Seq.Map(DecodeMinimalWellFormedCodeUnitSubsequence, parts);
        calc == {
          s;
          Seq.Flatten(parts);
          {
            assert parts == Seq.Map(EncodeScalarValue, vs);
          }
          Seq.Flatten(Seq.Map(EncodeScalarValue, vs));
          EncodeScalarSequence(vs);
        }
        vs
      }

      function DecodeCodeUnitSequenceChecked(s: CodeUnitSeq): (maybeVs: Option<seq<ScalarValue>>)
        ensures IsWellFormedCodeUnitSequence(s) ==> maybeVs.Some? && maybeVs.Extract() == DecodeCodeUnitSequence(s)
        ensures !IsWellFormedCodeUnitSequence(s) ==> true && maybeVs.None?
        decreases s
      {
        if IsWellFormedCodeUnitSequence(s) then
          Some(DecodeCodeUnitSequence(s))
        else
          None
      } by method {
        var maybeParts := PartitionCodeUnitSequenceChecked(s);
        if maybeParts.None? {
          return None;
        }
        var parts := maybeParts.value;
        var vs := Seq.Map(DecodeMinimalWellFormedCodeUnitSubsequence, parts);
        calc == {
          s;
          Seq.Flatten(parts);
          {
            assert parts == Seq.Map(EncodeScalarValue, vs);
          }
          Seq.Flatten(Seq.Map(EncodeScalarValue, vs));
          EncodeScalarSequence(vs);
        }
        return Some(vs);
      }

      type CodeUnit = bv16

      import opened Wrappers

      import Functions

      import Seq = Collections.Seq

      import opened Base

      type CodeUnitSeq = seq<CodeUnit>

      type WellFormedCodeUnitSeq = s: CodeUnitSeq
        | IsWellFormedCodeUnitSequence(s)
        witness []

      type MinimalWellFormedCodeUnitSeq = s: CodeUnitSeq
        | IsMinimalWellFormedCodeUnitSubsequence(s)
        witness *
    }

    module Utf8EncodingForm refines UnicodeEncodingForm {
      function IsMinimalWellFormedCodeUnitSubsequence(s: CodeUnitSeq): (b: bool)
        ensures b ==> |s| > 0 && forall i: int {:trigger s[..i]} | 0 < i < |s| :: !IsMinimalWellFormedCodeUnitSubsequence(s[..i])
        decreases |s|
      {
        if |s| == 1 then
          var b: bool := IsWellFormedSingleCodeUnitSequence(s);
          assert b ==> forall i: int {:trigger s[..i]} | 0 < i < |s| :: !IsMinimalWellFormedCodeUnitSubsequence(s[..i]);
          b
        else if |s| == 2 then
          var b: bool := IsWellFormedDoubleCodeUnitSequence(s);
          assert b ==> forall i: int {:trigger s[..i]} | 0 < i < |s| :: !IsMinimalWellFormedCodeUnitSubsequence(s[..i]);
          b
        else if |s| == 3 then
          var b: bool := IsWellFormedTripleCodeUnitSequence(s);
          assert b ==> forall i: int {:trigger s[..i]} | 0 < i < |s| :: !IsMinimalWellFormedCodeUnitSubsequence(s[..i]);
          b
        else if |s| == 4 then
          var b: bool := IsWellFormedQuadrupleCodeUnitSequence(s);
          assert b ==> forall i: int {:trigger s[..i]} | 0 < i < |s| :: !IsMinimalWellFormedCodeUnitSubsequence(s[..i]);
          b
        else
          false
      }

      function IsWellFormedSingleCodeUnitSequence(s: CodeUnitSeq): (b: bool)
        requires |s| == 1
        decreases s
      {
        var firstByte: bv8 := s[0];
        true &&
        0 <= firstByte <= 127
      }

      function IsWellFormedDoubleCodeUnitSequence(s: CodeUnitSeq): (b: bool)
        requires |s| == 2
        ensures b ==> true && !IsWellFormedSingleCodeUnitSequence(s[..1])
        decreases s
      {
        var firstByte: bv8 := s[0];
        var secondByte: bv8 := s[1];
        194 <= firstByte <= 223 &&
        128 <= secondByte <= 191
      }

      function IsWellFormedTripleCodeUnitSequence(s: CodeUnitSeq): (b: bool)
        requires |s| == 3
        ensures b ==> !IsWellFormedSingleCodeUnitSequence(s[..1]) && !IsWellFormedDoubleCodeUnitSequence(s[..2])
        decreases s
      {
        var firstByte: bv8 := s[0];
        var secondByte: bv8 := s[1];
        var thirdByte: bv8 := s[2];
        ((firstByte == 224 && 160 <= secondByte <= 191) || (225 <= firstByte <= 236 && 128 <= secondByte <= 191) || (firstByte == 237 && 128 <= secondByte <= 159) || (238 <= firstByte <= 239 && 128 <= secondByte <= 191)) &&
        128 <= thirdByte <= 191
      }

      function IsWellFormedQuadrupleCodeUnitSequence(s: CodeUnitSeq): (b: bool)
        requires |s| == 4
        ensures b ==> !IsWellFormedSingleCodeUnitSequence(s[..1]) && !IsWellFormedDoubleCodeUnitSequence(s[..2]) && !IsWellFormedTripleCodeUnitSequence(s[..3])
        decreases s
      {
        var firstByte: bv8 := s[0];
        var secondByte: bv8 := s[1];
        var thirdByte: bv8 := s[2];
        var fourthByte: bv8 := s[3];
        ((firstByte == 240 && 144 <= secondByte <= 191) || (241 <= firstByte <= 243 && 128 <= secondByte <= 191) || (firstByte == 244 && 128 <= secondByte <= 143)) &&
        128 <= thirdByte <= 191 &&
        128 <= fourthByte <= 191
      }

      function SplitPrefixMinimalWellFormedCodeUnitSubsequence(s: CodeUnitSeq): (maybePrefix: Option<MinimalWellFormedCodeUnitSeq>)
        ensures |s| == 0 ==> maybePrefix.None?
        ensures (exists i: int {:trigger s[..i]} | 0 < i <= |s| :: IsMinimalWellFormedCodeUnitSubsequence(s[..i])) <==> true && maybePrefix.Some?
        ensures maybePrefix.Some? ==> true && var prefix: MinimalWellFormedCodeUnitSeq := maybePrefix.Extract(); 0 < |prefix| <= |s| && prefix == s[..|prefix|] && forall i: int {:trigger s[..i]} | 0 < i < |prefix| :: !IsMinimalWellFormedCodeUnitSubsequence(s[..i])
        decreases s
      {
        if |s| >= 1 && IsWellFormedSingleCodeUnitSequence(s[..1]) then
          Some(s[..1])
        else if |s| >= 2 && IsWellFormedDoubleCodeUnitSequence(s[..2]) then
          Some(s[..2])
        else if |s| >= 3 && IsWellFormedTripleCodeUnitSequence(s[..3]) then
          Some(s[..3])
        else if |s| >= 4 && IsWellFormedQuadrupleCodeUnitSequence(s[..4]) then
          Some(s[..4])
        else
          None
      }

      function EncodeScalarValue(v: ScalarValue): (m: MinimalWellFormedCodeUnitSeq)
        decreases v
      {
        if v <= 127 then
          EncodeScalarValueSingleByte(v)
        else if v <= 2047 then
          EncodeScalarValueDoubleByte(v)
        else if v <= 65535 then
          EncodeScalarValueTripleByte(v)
        else
          EncodeScalarValueQuadrupleByte(v)
      }

      function EncodeScalarValueSingleByte(v: ScalarValue): (m: MinimalWellFormedCodeUnitSeq)
        requires 0 <= v <= 127
        ensures |m| == 1
        ensures IsWellFormedSingleCodeUnitSequence(m)
        decreases v
      {
        var x: bv7 := (v & 127) as bv7;
        var firstByte: CodeUnit := x as CodeUnit;
        [firstByte]
      }

      function EncodeScalarValueDoubleByte(v: ScalarValue): (s: CodeUnitSeq)
        requires 128 <= v <= 2047
        ensures |s| == 2
        ensures IsWellFormedDoubleCodeUnitSequence(s)
        decreases v
      {
        var x: bv6 := (v & 63) as bv6;
        var y: bv5 := (v & 1984 >> 6 as bv5) as bv5;
        var firstByte: bv8 := 192 | y as CodeUnit;
        var secondByte: bv8 := 128 | x as CodeUnit;
        [firstByte, secondByte]
      }

      function EncodeScalarValueTripleByte(v: ScalarValue): (s: CodeUnitSeq)
        requires 2048 <= v <= 65535
        ensures |s| == 3
        ensures IsWellFormedTripleCodeUnitSequence(s)
        decreases v
      {
        var x: bv6 := (v & 63) as bv6;
        var y: bv6 := (v & 4032 >> 6 as bv5) as bv6;
        var z: bv4 := (v & 61440 >> 12 as bv5) as bv4;
        var firstByte: bv8 := 224 | z as CodeUnit;
        var secondByte: bv8 := 128 | y as CodeUnit;
        var thirdByte: bv8 := 128 | x as CodeUnit;
        [firstByte, secondByte, thirdByte]
      }

      function EncodeScalarValueQuadrupleByte(v: ScalarValue): (s: CodeUnitSeq)
        requires 65536 <= v <= 1114111
        ensures |s| == 4
        ensures IsWellFormedQuadrupleCodeUnitSequence(s)
        decreases v
      {
        assert v <= 2097151;
        var x: bv6 := (v & 63) as bv6;
        var y: bv6 := (v & 4032 >> 6 as bv5) as bv6;
        var z: bv4 := (v & 61440 >> 12 as bv5) as bv4;
        var u2: bv2 := (v & 196608 >> 16 as bv5) as bv2;
        var u1: bv3 := (v & 1835008 >> 18 as bv5) as bv3;
        var firstByte: bv8 := 240 | u1 as CodeUnit;
        var secondByte: bv8 := 128 | (u2 as CodeUnit << 4 as bv4) | z as CodeUnit;
        var thirdByte: bv8 := 128 | y as CodeUnit;
        var fourthByte: bv8 := 128 | x as CodeUnit;
        [firstByte, secondByte, thirdByte, fourthByte]
      }

      function DecodeMinimalWellFormedCodeUnitSubsequence(m: MinimalWellFormedCodeUnitSeq): (v: ScalarValue)
        ensures EncodeScalarValue(v) == m
        decreases m
      {
        if |m| == 1 then
          DecodeMinimalWellFormedCodeUnitSubsequenceSingleByte(m)
        else if |m| == 2 then
          DecodeMinimalWellFormedCodeUnitSubsequenceDoubleByte(m)
        else if |m| == 3 then
          DecodeMinimalWellFormedCodeUnitSubsequenceTripleByte(m)
        else
          assert |m| == 4; DecodeMinimalWellFormedCodeUnitSubsequenceQuadrupleByte(m)
      }

      function DecodeMinimalWellFormedCodeUnitSubsequenceSingleByte(m: MinimalWellFormedCodeUnitSeq): (v: ScalarValue)
        requires |m| == 1
        ensures 0 <= v <= 127
        ensures EncodeScalarValueSingleByte(v) == m
        decreases m
      {
        var firstByte: bv8 := m[0];
        var x: bv7 := firstByte as bv7;
        x as ScalarValue
      }

      function DecodeMinimalWellFormedCodeUnitSubsequenceDoubleByte(m: MinimalWellFormedCodeUnitSeq): (v: ScalarValue)
        requires |m| == 2
        ensures 128 <= v <= 2047
        ensures EncodeScalarValueDoubleByte(v) == m
        decreases m
      {
        var firstByte: bv8 := m[0];
        var secondByte: bv8 := m[1];
        var y: bv24 := (firstByte & 31) as bv24;
        var x: bv24 := (secondByte & 63) as bv24;
        (y << 6 as bv5) | x as ScalarValue
      }

      function {:resource_limit 115000000} DecodeMinimalWellFormedCodeUnitSubsequenceTripleByte(m: MinimalWellFormedCodeUnitSeq): (v: ScalarValue)
        requires |m| == 3
        ensures 2048 <= v <= 65535
        ensures EncodeScalarValueTripleByte(v) == m
        decreases m
      {
        var firstByte: bv8 := m[0];
        var secondByte: bv8 := m[1];
        var thirdByte: bv8 := m[2];
        var z: bv24 := (firstByte & 15) as bv24;
        var y: bv24 := (secondByte & 63) as bv24;
        var x: bv24 := (thirdByte & 63) as bv24;
        assert {:split_here} true;
        (z << 12 as bv5) | (y << 6 as bv5) | x as ScalarValue
      }

      function {:isolate_assertions} DecodeMinimalWellFormedCodeUnitSubsequenceQuadrupleByte(m: MinimalWellFormedCodeUnitSeq): (v: ScalarValue)
        requires |m| == 4
        ensures 65536 <= v <= 1114111
        ensures EncodeScalarValueQuadrupleByte(v) == m
        decreases m
      {
        var firstByte: bv8 := m[0];
        var secondByte: bv8 := m[1];
        var thirdByte: bv8 := m[2];
        var fourthByte: bv8 := m[3];
        var u1: bv24 := (firstByte & 7) as bv24;
        var u2: bv24 := (secondByte & 48 >> 4 as bv4) as bv24;
        var z: bv24 := (secondByte & 15) as bv24;
        var y: bv24 := (thirdByte & 63) as bv24;
        var x: bv24 := (fourthByte & 63) as bv24;
        assert {:split_here} true;
        var r: bv24 := (u1 << 18 as bv5) | (u2 << 16 as bv5) | (z << 12 as bv5) | (y << 6 as bv5) | x as ScalarValue;
        assert EncodeScalarValueQuadrupleByte(r)[0] == m[0];
        assert EncodeScalarValueQuadrupleByte(r)[1] == m[1];
        assert EncodeScalarValueQuadrupleByte(r)[2] == m[2];
        assert EncodeScalarValueQuadrupleByte(r)[3] == m[3];
        r
      }

      lemma LemmaUniquePrefixMinimalWellFormedCodeUnitSeq(s: CodeUnitSeq, m1: MinimalWellFormedCodeUnitSeq, m2: MinimalWellFormedCodeUnitSeq)
        requires m1 <= s
        requires m2 <= s
        ensures m1 == m2
        decreases |s|, |m1|, |m2|
      {
        if |m1| > |m2| {
          LemmaUniquePrefixMinimalWellFormedCodeUnitSeq(s, m2, m1);
        } else {
          assert m1 <= m2;
          assert m1 == m2 by {
            if m1 < m2 {
              assert false by {
                assert m1 == m2[..|m1|];
              }
            }
          }
        }
      }

      lemma LemmaSplitPrefixMinimalWellFormedCodeUnitSubsequenceInvertsPrepend(m: MinimalWellFormedCodeUnitSeq, s: CodeUnitSeq)
        ensures SplitPrefixMinimalWellFormedCodeUnitSubsequence(m + s) == Some(m)
        decreases m, s
      {
        ghost var ms := m + s;
        ghost var maybePrefix := SplitPrefixMinimalWellFormedCodeUnitSubsequence(ms);
        assert maybePrefix.Some? by {
          assert IsMinimalWellFormedCodeUnitSubsequence(ms[..|m|]);
        }
        ghost var prefix := maybePrefix.Extract();
        assert m <= ms;
        assert prefix <= ms;
        LemmaUniquePrefixMinimalWellFormedCodeUnitSeq(ms, m, prefix);
      }

      function PartitionCodeUnitSequenceChecked(s: CodeUnitSeq): (maybeParts: Option<seq<MinimalWellFormedCodeUnitSeq>>)
        ensures maybeParts.Some? ==> Seq.Flatten(maybeParts.Extract()) == s
        decreases |s|
      {
        if s == [] then
          Some([])
        else
          var prefix: MinimalWellFormedCodeUnitSeq :- SplitPrefixMinimalWellFormedCodeUnitSubsequence(s); var restParts: seq<MinimalWellFormedCodeUnitSeq> :- PartitionCodeUnitSequenceChecked(s[|prefix|..]); Some([prefix] + restParts)
      } by method {
        if s == [] {
          return Some([]);
        }
        var result: seq<MinimalWellFormedCodeUnitSeq> := [];
        var rest := s;
        while |rest| > 0
          invariant PartitionCodeUnitSequenceChecked(s).Some? <==> PartitionCodeUnitSequenceChecked(rest).Some?
          invariant PartitionCodeUnitSequenceChecked(s).Some? ==> true && PartitionCodeUnitSequenceChecked(s).value == result + PartitionCodeUnitSequenceChecked(rest).value
          decreases |rest| - 0
        {
          var prefix :- SplitPrefixMinimalWellFormedCodeUnitSubsequence(rest);
          result := result + [prefix];
          rest := rest[|prefix|..];
        }
        assert result + [] == result;
        return Some(result);
      }

      function PartitionCodeUnitSequence(s: WellFormedCodeUnitSeq): (parts: seq<MinimalWellFormedCodeUnitSeq>)
        ensures Seq.Flatten(parts) == s
        decreases s
      {
        PartitionCodeUnitSequenceChecked(s).Extract()
      }

      lemma /*{:_induction m}*/ LemmaPartitionMinimalWellFormedCodeUnitSubsequence(m: MinimalWellFormedCodeUnitSeq)
        ensures PartitionCodeUnitSequenceChecked(m) == Some([m])
        decreases m
      {
        LemmaSplitPrefixMinimalWellFormedCodeUnitSubsequenceInvertsPrepend(m, []);
        calc == {
          Some(m);
          SplitPrefixMinimalWellFormedCodeUnitSubsequence(m + []);
          {
            assert m + [] == m;
          }
          SplitPrefixMinimalWellFormedCodeUnitSubsequence(m);
        }
        calc == {
          PartitionCodeUnitSequenceChecked(m);
          Some([m] + []);
          {
            assert [m] + [] == [m];
          }
          Some([m]);
        }
      }

      function IsWellFormedCodeUnitSequence(s: CodeUnitSeq): (b: bool)
        decreases s
      {
        PartitionCodeUnitSequenceChecked(s).Some?
      }

      lemma LemmaMinimalWellFormedCodeUnitSubsequenceIsWellFormedSequence(m: MinimalWellFormedCodeUnitSeq)
        ensures IsWellFormedCodeUnitSequence(m)
        decreases m
      {
        LemmaPartitionMinimalWellFormedCodeUnitSubsequence(m);
      }

      lemma LemmaPrependMinimalWellFormedCodeUnitSubsequence(m: MinimalWellFormedCodeUnitSeq, s: WellFormedCodeUnitSeq)
        ensures IsWellFormedCodeUnitSequence(m + s)
        decreases m, s
      {
        LemmaPartitionMinimalWellFormedCodeUnitSubsequence(m);
        LemmaSplitPrefixMinimalWellFormedCodeUnitSubsequenceInvertsPrepend(m, s);
      }

      lemma /*{:_induction ms}*/ LemmaFlattenMinimalWellFormedCodeUnitSubsequences(ms: seq<MinimalWellFormedCodeUnitSeq>)
        ensures IsWellFormedCodeUnitSequence(Seq.Flatten(ms))
        decreases ms
      {
        if |ms| == 0 {
        } else {
          ghost var head := ms[0];
          ghost var tail := ms[1..];
          LemmaFlattenMinimalWellFormedCodeUnitSubsequences(tail);
          ghost var flatTail := Seq.Flatten(tail);
          LemmaPrependMinimalWellFormedCodeUnitSubsequence(head, flatTail);
        }
      }

      lemma LemmaConcatWellFormedCodeUnitSubsequences(s: WellFormedCodeUnitSeq, t: WellFormedCodeUnitSeq)
        ensures IsWellFormedCodeUnitSequence(s + t)
        decreases s, t
      {
        ghost var partsS := PartitionCodeUnitSequence(s);
        ghost var partsT := PartitionCodeUnitSequence(t);
        ghost var partsST := partsS + partsT;
        Seq.LemmaFlattenConcat(partsS, partsT);
        LemmaFlattenMinimalWellFormedCodeUnitSubsequences(partsST);
      }

      function EncodeScalarSequence(vs: seq<ScalarValue>): (s: WellFormedCodeUnitSeq)
        decreases vs
      {
        var ms: seq<MinimalWellFormedCodeUnitSeq> := Seq.Map(EncodeScalarValue, vs);
        LemmaFlattenMinimalWellFormedCodeUnitSubsequences(ms);
        Seq.Flatten(ms)
      } by method {
        s := [];
        ghost var unflattened: seq<MinimalWellFormedCodeUnitSeq> := [];
        for i: int := |vs| downto 0
          invariant unflattened == Seq.Map(EncodeScalarValue, vs[i..])
          invariant s == Seq.Flatten(unflattened)
        {
          var next: MinimalWellFormedCodeUnitSeq := EncodeScalarValue(vs[i]);
          unflattened := [next] + unflattened;
          LemmaPrependMinimalWellFormedCodeUnitSubsequence(next, s);
          s := next + s;
        }
      }

      function DecodeCodeUnitSequence(s: WellFormedCodeUnitSeq): (vs: seq<ScalarValue>)
        ensures EncodeScalarSequence(vs) == s
        decreases s
      {
        var parts: seq<MinimalWellFormedCodeUnitSeq> := PartitionCodeUnitSequence(s);
        var vs: seq<ScalarValue> := Seq.Map(DecodeMinimalWellFormedCodeUnitSubsequence, parts);
        calc == {
          s;
          Seq.Flatten(parts);
          {
            assert parts == Seq.Map(EncodeScalarValue, vs);
          }
          Seq.Flatten(Seq.Map(EncodeScalarValue, vs));
          EncodeScalarSequence(vs);
        }
        vs
      }

      function DecodeCodeUnitSequenceChecked(s: CodeUnitSeq): (maybeVs: Option<seq<ScalarValue>>)
        ensures IsWellFormedCodeUnitSequence(s) ==> maybeVs.Some? && maybeVs.Extract() == DecodeCodeUnitSequence(s)
        ensures !IsWellFormedCodeUnitSequence(s) ==> true && maybeVs.None?
        decreases s
      {
        if IsWellFormedCodeUnitSequence(s) then
          Some(DecodeCodeUnitSequence(s))
        else
          None
      } by method {
        var maybeParts := PartitionCodeUnitSequenceChecked(s);
        if maybeParts.None? {
          return None;
        }
        var parts := maybeParts.value;
        var vs := Seq.Map(DecodeMinimalWellFormedCodeUnitSubsequence, parts);
        calc == {
          s;
          Seq.Flatten(parts);
          {
            assert parts == Seq.Map(EncodeScalarValue, vs);
          }
          Seq.Flatten(Seq.Map(EncodeScalarValue, vs));
          EncodeScalarSequence(vs);
        }
        return Some(vs);
      }

      type CodeUnit = bv8

      import opened Wrappers

      import Functions

      import Seq = Collections.Seq

      import opened Base

      type CodeUnitSeq = seq<CodeUnit>

      type WellFormedCodeUnitSeq = s: CodeUnitSeq
        | IsWellFormedCodeUnitSequence(s)
        witness []

      type MinimalWellFormedCodeUnitSeq = s: CodeUnitSeq
        | IsMinimalWellFormedCodeUnitSubsequence(s)
        witness *
    }

    module Utf8EncodingScheme {
      function Serialize(s: Utf8EncodingForm.CodeUnitSeq): (b: seq<byte>)
        decreases s
      {
        Seq.Map((c: bv8) => c as byte, s)
      }

      function Deserialize(b: seq<byte>): (s: Utf8EncodingForm.CodeUnitSeq)
        decreases b
      {
        Seq.Map((b: BoundedInts.uint8) => b as Utf8EncodingForm.CodeUnit, b)
      }

      lemma LemmaSerializeDeserialize(s: Utf8EncodingForm.CodeUnitSeq)
        ensures Deserialize(Serialize(s)) == s
        decreases s
      {
      }

      lemma {:resource_limit ""30e6""} LemmaDeserializeSerialize(b: seq<byte>)
        ensures Serialize(Deserialize(b)) == b
        decreases b
      {
        calc {
          Serialize(Deserialize(b));
        ==
          Seq.Map((c: bv8) => c as byte, Seq.Map((b: BoundedInts.uint8) => b as Utf8EncodingForm.CodeUnit, b));
        ==
          Seq.Map((b: BoundedInts.uint8) => b as Utf8EncodingForm.CodeUnit as byte, b);
        ==
          Seq.Map((b: BoundedInts.uint8) => b, b);
        ==
          b;
        }
      }

      import opened Wrappers

      import BoundedInts

      import Seq = Collections.Seq

      import Utf8EncodingForm

      type byte = BoundedInts.uint8
    }
  }

  module Wrappers {
    function Need<E>(condition: bool, error: E): (result: OutcomeResult<E>)
      decreases condition
    {
      if condition then
        Pass'
      else
        Fail'(error)
    }

    datatype Option<+T> = None | Some(value: T) {
      predicate IsFailure()
        decreases this
      {
        None?
      }

      function PropagateFailure<U>(): Option<U>
        requires None?
        decreases this
      {
        None
      }

      function Extract(): T
        requires Some?
        decreases this
      {
        value
      }

      function GetOr(default: T): T
        decreases this
      {
        match this
        case Some(v) =>
          v
        case None() =>
          default
      }

      function ToResult<E>(error: E): Result<T, E>
        decreases this
      {
        match this
        case Some(v) =>
          Success(v)
        case None() =>
          Failure(error)
      }

      function ToOutcome<E>(error: E): Outcome<E>
        decreases this
      {
        match this
        case Some(v) =>
          Pass
        case None() =>
          Fail(error)
      }

      function Map<FC>(rewrap: Option<T> -> FC): FC
        decreases this
      {
        rewrap(this)
      }
    }

    datatype Result<+R, +E> = Success(value: R) | Failure(error: E) {
      predicate IsFailure()
        decreases this
      {
        Failure?
      }

      function PropagateFailure<U>(): (r: Result<U, E>)
        requires Failure?
        decreases this
      {
        Failure(this.error)
      }

      function Extract(): R
        requires Success?
        decreases this
      {
        value
      }

      function GetOr(default: R): R
        decreases this
      {
        match this
        case Success(s) =>
          s
        case Failure(e) =>
          default
      }

      function ToOption(): Option<R>
        decreases this
      {
        match this
        case Success(s) =>
          Some(s)
        case Failure(e) =>
          None()
      }

      function ToOutcome(): Outcome<E>
        decreases this
      {
        match this
        case Success(s) =>
          Pass
        case Failure(e) =>
          Fail(e)
      }

      function Map<FC>(rewrap: Result<R, E> -> FC): FC
        decreases this
      {
        rewrap(this)
      }

      function MapFailure<NewE>(reWrap: E -> NewE): Result<R, NewE>
        decreases this
      {
        match this
        case Success(s) =>
          Success(s)
        case Failure(e) =>
          Failure(reWrap(e))
      }
    }

    datatype Outcome<+E> = Pass | Fail(error: E) {
      predicate IsFailure()
        decreases this
      {
        Fail?
      }

      function PropagateFailure(): Outcome<E>
        requires Fail?
        decreases this
      {
        this
      }

      function ToOption<R>(r: R): Option<R>
        decreases this
      {
        match this
        case Pass() =>
          Some(r)
        case Fail(e) =>
          None()
      }

      function ToResult<R>(r: R): Result<R, E>
        decreases this
      {
        match this
        case Pass() =>
          Success(r)
        case Fail(e) =>
          Failure(e)
      }

      function Map<FC>(rewrap: Outcome<E> -> FC): FC
        decreases this
      {
        rewrap(this)
      }

      function MapFailure<T, NewE>(rewrap: E -> NewE, default: T): Result<T, NewE>
        decreases this
      {
        match this
        case Pass() =>
          Success(default)
        case Fail(e) =>
          Failure(rewrap(e))
      }

      static function Need(condition: bool, error: E): (result: Outcome<E>)
        decreases condition
      {
        if condition then
          Pass
        else
          Fail(error)
      }
    }

    datatype OutcomeResult<+E> = Pass' | Fail'(error: E) {
      predicate IsFailure()
        decreases this
      {
        Fail'?
      }

      function PropagateFailure<U>(): Result<U, E>
        requires IsFailure()
        decreases this
      {
        Failure(this.error)
      }
    }
  }

  module Arithmetic {

    module {:disableNonlinearArithmetic} DivMod {
      lemma LemmaDivIsDivRecursive(x: int, d: int)
        requires 0 < d
        ensures DivRecursive(x, d) == x / d
        decreases x, d
      {
        reveal DivPos();
        reveal DivRecursive();
        LemmaDivInductionAuto(d, x, (u: int) => DivRecursive(u, d) == u / d);
      }

      lemma LemmaDivIsDivRecursiveAuto()
        ensures forall x: int, d: int {:trigger x / d} :: d > 0 ==> DivRecursive(x, d) == x / d
      {
        reveal DivPos();
        reveal DivRecursive();
        forall x: int, d: int | d > 0
          ensures DivRecursive(x, d) == x / d
        {
          LemmaDivIsDivRecursive(x, d);
        }
      }

      lemma LemmaDivBySelf(d: int)
        requires d != 0
        ensures d / d == 1
        decreases d
      {
        DivINL.LemmaDivBySelf(d);
      }

      lemma LemmaDivOf0(d: int)
        requires d != 0
        ensures 0 / d == 0
        decreases d
      {
        DivINL.LemmaDivOf0(d);
      }

      lemma LemmaDivBasics(x: int)
        ensures x != 0 ==> 0 / x == 0
        ensures x / 1 == x
        ensures x != 0 ==> x / x == 1
        decreases x
      {
        if x != 0 {
          LemmaDivBySelf(x);
          LemmaDivOf0(x);
        }
      }

      lemma LemmaDivBasicsAuto()
        ensures forall x: int {:trigger 0 / x} :: x != 0 ==> 0 / x == 0
        ensures forall x: int {:trigger x / 1} :: x / 1 == x
        ensures forall x: int, y: int {:trigger x / y} :: x >= 0 && y > 0 ==> x / y >= 0
        ensures forall x: int, y: int {:trigger x / y} :: x >= 0 && y > 0 ==> x / y <= x
      {
        forall x: int | true
          ensures x != 0 ==> 0 / x == 0
          ensures x / 1 == x
        {
          LemmaDivBasics(x);
        }
        forall x: int, y: int | x >= 0 && y > 0
          ensures 0 <= x / y <= x
        {
          LemmaDivPosIsPos(x, y);
          LemmaDivIsOrderedByDenominator(x, 1, y);
        }
      }

      lemma LemmaSmallDivConverseAuto()
        ensures forall x: int, d: int {:trigger x / d} :: 0 <= x && 0 < d && x / d == 0 ==> x < d
      {
        forall x: int, d: int | 0 <= x && 0 < d && x / d == 0
          ensures x < d
        {
          LemmaDivInductionAuto(d, x, (u: int) => 0 <= u && 0 < d && u / d == 0 ==> u < d);
        }
      }

      lemma LemmaDivNonZero(x: int, d: int)
        requires x >= d > 0
        ensures x / d > 0
        decreases x, d
      {
        LemmaDivPosIsPosAuto();
        if x / d == 0 {
          LemmaSmallDivConverseAuto();
        }
      }

      lemma LemmaDivNonZeroAuto()
        ensures forall x: int, d: int {:trigger x / d} | x >= d > 0 :: x / d > 0
      {
        forall x: int, d: int | x >= d > 0 {
          LemmaDivNonZero(x, d);
        }
      }

      lemma LemmaDivIsOrderedByDenominator(x: int, y: int, z: int)
        requires 0 <= x
        requires 1 <= y <= z
        ensures x / y >= x / z
        decreases x
      {
        reveal DivPos();
        reveal DivRecursive();
        LemmaDivIsDivRecursiveAuto();
        assert forall u: int, d: int {:trigger u / d} {:trigger DivRecursive(u, d)} :: d > 0 ==> DivRecursive(u, d) == u / d;
        if x < z {
          LemmaDivIsOrdered(0, x, y);
        } else {
          LemmaDivIsOrdered(x - z, x - y, y);
          LemmaDivIsOrderedByDenominator(x - z, y, z);
        }
      }

      lemma LemmaDivIsOrderedByDenominatorAuto()
        ensures forall z: int, y: int, x: int {:trigger x / y, x / z} :: 0 <= x && 1 <= y <= z ==> x / y >= x / z
      {
        forall x: int, y: int, z: int | 0 <= x && 1 <= y <= z
          ensures x / y >= x / z
        {
          LemmaDivIsOrderedByDenominator(x, y, z);
        }
      }

      lemma LemmaDivIsStrictlyOrderedByDenominator(x: int, d: int)
        requires 0 < x
        requires 1 < d
        ensures x / d < x
        decreases x
      {
        LemmaDivInductionAuto(d, x, (u: int) => 0 < u ==> u / d < u);
      }

      lemma LemmaDivIsStrictlyOrderedByDenominatorAuto()
        ensures forall x: int, d: int {:trigger x / d} :: 0 < x && 1 < d ==> x / d < x
      {
        forall x: int, d: int | 0 < x && 1 < d
          ensures x / d < x
        {
          LemmaDivIsStrictlyOrderedByDenominator(x, d);
        }
      }

      lemma LemmaDividingSums(a: int, b: int, d: int, R: int)
        requires 0 < d
        requires R == a % d + b % d - (a + b) % d
        ensures d * (a + b) / d - R == d * a / d + d * b / d
        decreases a, b, d, R
      {
        calc ==> {
          a % d + b % d == R + (a + b) % d;
          a + b - (a + b) % d - R == a - a % d + b - b % d;
          {
            LemmaFundamentalDivMod(a + b, d);
            LemmaFundamentalDivMod(a, d);
            LemmaFundamentalDivMod(b, d);
          }
          d * (a + b) / d - R == d * a / d + d * b / d;
        }
      }

      lemma LemmaDividingSumsAuto()
        ensures forall a: int, b: int, d: int, R: int {:trigger d * (a + b) / d - R, d * a / d + d * b / d} :: 0 < d && R == a % d + b % d - (a + b) % d ==> d * (a + b) / d - R == d * a / d + d * b / d
      {
        forall a: int, b: int, d: int, R: int {:trigger d * (a + b) / d - R, d * a / d + d * b / d} | 0 < d && R == a % d + b % d - (a + b) % d
          ensures d * (a + b) / d - R == d * a / d + d * b / d
        {
          LemmaDividingSums(a, b, d, R);
        }
      }

      lemma LemmaDivPosIsPos(x: int, d: int)
        requires 0 <= x
        requires 0 < d
        ensures 0 <= x / d
        decreases x, d
      {
        LemmaDivInductionAuto(d, x, (u: int) => 0 <= u ==> u / d >= 0);
      }

      lemma LemmaDivPosIsPosAuto()
        ensures forall x: int, d: int {:trigger x / d} :: 0 <= x && 0 < d ==> 0 <= x / d
      {
        forall x: int, d: int | 0 <= x && 0 < d
          ensures 0 <= x / d
        {
          LemmaDivPosIsPos(x, d);
        }
      }

      lemma LemmaDivPlusOne(x: int, d: int)
        requires 0 < d
        ensures 1 + x / d == (d + x) / d
        decreases x, d
      {
        LemmaDivAuto(d);
      }

      lemma LemmaDivPlusOneAuto()
        ensures forall x: int, d: int {:trigger 1 + x / d, (d + x) / d} :: 0 < d ==> 1 + x / d == (d + x) / d
      {
        forall x: int, d: int | 0 < d
          ensures 1 + x / d == (d + x) / d
        {
          LemmaDivPlusOne(x, d);
        }
      }

      lemma LemmaDivMinusOne(x: int, d: int)
        requires 0 < d
        ensures -1 + x / d == (-d + x) / d
        decreases x, d
      {
        LemmaDivAuto(d);
      }

      lemma LemmaDivMinusOneAuto()
        ensures forall x: int, d: int {:trigger -1 + x / d, (-d + x) / d} :: 0 < d ==> -1 + x / d == (-d + x) / d
      {
        forall x: int, d: int | 0 < d
          ensures -1 + x / d == (-d + x) / d
        {
          LemmaDivMinusOne(x, d);
        }
      }

      lemma LemmaBasicDiv(d: int)
        requires 0 < d
        ensures forall x: int {:trigger x / d} :: 0 <= x < d ==> x / d == 0
        decreases d
      {
        LemmaDivAuto(d);
      }

      lemma LemmaBasicDivAuto()
        ensures forall d: int, x: int {:trigger x / d} :: 0 <= x < d ==> x / d == 0
      {
        forall x: int, d: int | 0 <= x < d
          ensures x / d == 0
        {
          LemmaBasicDiv(d);
        }
      }

      lemma LemmaDivIsOrdered(x: int, y: int, z: int)
        requires x <= y
        requires 0 < z
        ensures x / z <= y / z
        decreases x, y, z
      {
        LemmaDivInductionAuto(z, x - y, (xy: int) => xy <= 0 ==> (xy + y) / z <= y / z);
      }

      lemma LemmaDivIsOrderedAuto()
        ensures forall x: int, y: int, z: int {:trigger x / z, y / z} :: x <= y && 0 < z ==> x / z <= y / z
      {
        forall x: int, y: int, z: int | x <= y && 0 < z
          ensures x / z <= y / z
        {
          LemmaDivIsOrdered(x, y, z);
        }
      }

      lemma LemmaDivDecreases(x: int, d: int)
        requires 0 < x
        requires 1 < d
        ensures x / d < x
        decreases x, d
      {
        LemmaDivInductionAuto(d, x, (u: int) => 0 < u ==> u / d < u);
      }

      lemma LemmaDivDecreasesAuto()
        ensures forall x: int, d: int {:trigger x / d} :: 0 < x && 1 < d ==> x / d < x
      {
        forall x: int, d: int | 0 < x && 1 < d
          ensures x / d < x
        {
          LemmaDivDecreases(x, d);
        }
      }

      lemma LemmaDivNonincreasing(x: int, d: int)
        requires 0 <= x
        requires 0 < d
        ensures x / d <= x
        decreases x, d
      {
        LemmaDivInductionAuto(d, x, (u: int) => 0 <= u ==> u / d <= u);
      }

      lemma LemmaDivNonincreasingAuto()
        ensures forall x: int, d: int {:trigger x / d} :: 0 <= x && 0 < d ==> x / d <= x
      {
        forall x: int, d: int | 0 <= x && 0 < d
          ensures x / d <= x
        {
          LemmaDivNonincreasing(x, d);
        }
      }

      lemma LemmaSmallMod(x: nat, m: nat)
        requires x < m
        requires 0 < m
        ensures x % m == x
        decreases x, m
      {
        ModINL.LemmaSmallMod(x, m);
      }

      lemma LemmaBreakdown(x: int, y: int, z: int)
        requires 0 <= x
        requires 0 < y
        requires 0 < z
        ensures 0 < y * z
        ensures x % (y * z) == y * x / y % z + x % y
        decreases x, y, z
      {
        LemmaMulStrictlyPositiveAuto();
        LemmaDivPosIsPos(x, y);
        assert 0 <= x / y;
        calc {
          y * x / y % (y * z) + x % y % (y * z);
        <=
          {
            LemmaPartBound1(x, y, z);
          }
          y * (z - 1) + x % y % (y * z);
        <
          {
            LemmaPartBound2(x, y, z);
          }
          y * (z - 1) + y;
          {
            LemmaMulBasicsAuto();
          }
          y * (z - 1) + y * 1;
          {
            LemmaMulIsDistributiveAuto();
          }
          y * (z - 1 + 1);
          y * z;
        }
        calc {
          x % (y * z);
          {
            LemmaFundamentalDivMod(x, y);
          }
          (y * x / y + x % y) % (y * z);
          {
            LemmaModPropertiesAuto();
            assert 0 <= x % y;
            LemmaMulNonnegative(y, x / y);
            assert y * x / y % (y * z) + x % y % (y * z) < y * z;
            LemmaModAdds(y * x / y, x % y, y * z);
          }
          y * x / y % (y * z) + x % y % (y * z);
          {
            LemmaModPropertiesAuto();
            LemmaMulIncreases(z, y);
            LemmaMulIsCommutativeAuto();
            assert x % y < y <= y * z;
            LemmaSmallMod(x % y, y * z);
            assert x % y % (y * z) == x % y;
          }
          y * x / y % (y * z) + x % y;
          {
            LemmaTruncateMiddle(x / y, y, z);
          }
          y * x / y % z + x % y;
        }
      }

      lemma LemmaBreakdownAuto()
        ensures (forall x: int, y: int, z: int {:trigger y * z, x % (y * z), y * x / y % z + x % y} :: 0 <= x && 0 < y && 0 < z ==> 0 < y * z) && forall x: int, y: int, z: int {:trigger y * z, x % (y * z), y * x / y % z + x % y} :: 0 <= x && 0 < y && 0 < z ==> x % (y * z) == y * x / y % z + x % y
      {
        forall x: int, y: int, z: int | 0 <= x && 0 < y && 0 < z
          ensures 0 < y * z && x % (y * z) == y * x / y % z + x % y
        {
          LemmaBreakdown(x, y, z);
        }
      }

      lemma LemmaRemainderUpper(x: int, d: int)
        requires 0 <= x
        requires 0 < d
        ensures x - d < x / d * d
        decreases x, d
      {
        LemmaMulAuto();
        LemmaDivInductionAuto(d, x, (u: int) => 0 <= u ==> u - d < u / d * d);
      }

      lemma LemmaRemainderUpperAuto()
        ensures forall x: int, d: int {:trigger x - d, d * d} :: 0 <= x && 0 < d ==> x - d < x / d * d
      {
        forall x: int, d: int | 0 <= x && 0 < d
          ensures x - d < x / d * d
        {
          LemmaRemainderUpper(x, d);
        }
      }

      lemma LemmaRemainderLower(x: int, d: int)
        requires 0 <= x
        requires 0 < d
        ensures x >= x / d * d
        decreases x, d
      {
        LemmaMulAuto();
        LemmaDivInductionAuto(d, x, (u: int) => 0 <= u ==> u >= u / d * d);
      }

      lemma LemmaRemainderLowerAuto()
        ensures forall x: int, d: int {:trigger x / d * d} :: 0 <= x && 0 < d ==> x >= x / d * d
      {
        forall x: int, d: int | 0 <= x && 0 < d
          ensures x >= x / d * d
        {
          LemmaRemainderLower(x, d);
        }
      }

      lemma LemmaRemainder(x: int, d: int)
        requires 0 <= x
        requires 0 < d
        ensures 0 <= x - x / d * d < d
        decreases x, d
      {
        LemmaMulAuto();
        LemmaDivInductionAuto(d, x, (u: int) => 0 <= u - u / d * d < d);
      }

      lemma LemmaRemainderAuto()
        ensures (forall x: int, d: int {:trigger x - x / d * d} :: 0 <= x && 0 < d ==> 0 <= x - x / d * d) && forall x: int, d: int {:trigger x - x / d * d} :: 0 <= x && 0 < d ==> x - x / d * d < d
      {
        forall x: int, d: int | 0 <= x && 0 < d
          ensures 0 <= x - x / d * d < d
        {
          LemmaRemainder(x, d);
        }
      }

      lemma LemmaFundamentalDivMod(x: int, d: int)
        requires d != 0
        ensures x == d * x / d + x % d
        decreases x, d
      {
        ModINL.LemmaFundamentalDivMod(x, d);
      }

      lemma LemmaFundamentalDivModAuto()
        ensures forall x: int, d: int {:trigger d * x / d + x % d} :: d != 0 ==> x == d * x / d + x % d
      {
        forall x: int, d: int | d != 0
          ensures x == d * x / d + x % d
        {
          LemmaFundamentalDivMod(x, d);
        }
      }

      lemma LemmaDivDenominator(x: int, c: nat, d: nat)
        requires 0 <= x
        requires 0 < c
        requires 0 < d
        ensures c * d != 0
        ensures x / c / d == x / (c * d)
        decreases x, c, d
      {
        LemmaMulStrictlyPositiveAuto();
        ghost var R := x % (c * d);
        LemmaModPropertiesAuto();
        LemmaDivPosIsPos(R, c);
        if R / c >= d {
          LemmaFundamentalDivMod(R, c);
          LemmaMulInequality(d, R / c, c);
          LemmaMulIsCommutativeAuto();
          assert false;
        }
        assert R / c < d;
        LemmaMulBasicsAuto();
        LemmaFundamentalDivModConverse(R / c, d, 0, R / c);
        assert R / c % d == R / c;
        LemmaFundamentalDivMod(R, c);
        assert c * R / c + R % c == R;
        assert c * R / c % d + R % c == R;
        ghost var k := x / (c * d);
        LemmaFundamentalDivMod(x, c * d);
        assert x == c * d * x / (c * d) + x % (c * d);
        assert R == x - c * d * x / (c * d);
        assert R == x - c * d * k;
        calc {
          c * x / c % d + x % c;
          {
            LemmaModMultiplesVanish(-k, x / c, d);
            LemmaMulIsCommutativeAuto();
          }
          c * (x / c + -k * d) % d + x % c;
          {
            LemmaHoistOverDenominator(x, -k * d, c);
          }
          c * (x + -k * d * c) / c % d + x % c;
          {
            LemmaMulIsAssociative(-k, d, c);
          }
          c * (x + -k * d * c) / c % d + x % c;
          {
            LemmaMulUnaryNegation(k, d * c);
          }
          c * (x + -(k * d * c)) / c % d + x % c;
          {
            LemmaMulIsAssociative(k, d, c);
          }
          c * (x + -(k * d * c)) / c % d + x % c;
          c * (x - k * d * c) / c % d + x % c;
          {
            LemmaMulIsAssociativeAuto();
            LemmaMulIsCommutativeAuto();
          }
          c * R / c % d + x % c;
          c * R / c + x % c;
          {
            LemmaFundamentalDivMod(R, c);
            assert R == c * R / c + R % c;
            LemmaModMod(x, c, d);
            assert R % c == x % c;
          }
          R;
          {
            LemmaModIsModRecursiveAuto();
          }
          R % (c * d);
          (x - c * d * k) % (c * d);
          {
            LemmaMulUnaryNegation(c * d, k);
          }
          (x + c * d * -k) % (c * d);
          {
            LemmaModMultiplesVanish(-k, x, c * d);
          }
          x % (c * d);
        }
        calc ==> {
          c * x / c + x % c - R == c * x / c - c * x / c % d;
          {
            LemmaFundamentalDivMod(x, c);
          }
          x - R == c * x / c - c * x / c % d;
        }
        calc ==> {
          true;
          {
            LemmaFundamentalDivMod(x / c, d);
          }
          d * x / c / d == x / c - x / c % d;
          c * d * x / c / d == c * (x / c - x / c % d);
          {
            LemmaMulIsAssociativeAuto();
          }
          c * d * x / c / d == c * (x / c - x / c % d);
          {
            LemmaMulIsDistributiveAuto();
          }
          c * d * x / c / d == c * x / c - c * x / c % d;
          c * d * x / c / d == x - R;
          {
            LemmaFundamentalDivMod(x, c * d);
          }
          c * d * x / c / d == c * d * x / (c * d) + x % (c * d) - R;
          c * d * x / c / d == c * d * x / (c * d);
          {
            LemmaMulEqualityConverse(c * d, x / c / d, x / (c * d));
          }
          x / c / d == x / (c * d);
        }
      }

      lemma LemmaDivDenominatorAuto()
        ensures forall c: nat, d: nat {:trigger c * d} :: 0 < c && 0 < d ==> c * d != 0
        ensures forall x: int, c: nat, d: nat {:trigger x / c / d} :: 0 <= x && 0 < c && 0 < d ==> x / c / d == x / (c * d)
      {
        LemmaMulNonzeroAuto();
        forall x: int, c: nat, d: nat | 0 <= x && 0 < c && 0 < d
          ensures x / c / d == x / (c * d)
        {
          LemmaDivDenominator(x, c, d);
        }
      }

      lemma LemmaMulHoistInequality(x: int, y: int, z: int)
        requires 0 <= x
        requires 0 < z
        ensures x * y / z <= x * y / z
        decreases x, y, z
      {
        calc {
          x * y / z;
          {
            LemmaFundamentalDivMod(y, z);
          }
          x * (z * y / z + y % z) / z;
          {
            LemmaMulIsDistributiveAuto();
          }
          (x * z * y / z + x * y % z) / z;
        >=
          {
            LemmaModPropertiesAuto();
            LemmaMulNonnegative(x, y % z);
            LemmaDivIsOrdered(x * z * y / z, x * z * y / z + x * y % z, z);
          }
          x * z * y / z / z;
          {
            LemmaMulIsAssociativeAuto();
            LemmaMulIsCommutativeAuto();
          }
          z * x * y / z / z;
          {
            LemmaDivMultiplesVanish(x * y / z, z);
          }
          x * y / z;
        }
      }

      lemma LemmaMulHoistInequalityAuto()
        ensures forall x: int, y: int, z: int {:trigger x * y / z, x * y / z} :: 0 <= x && 0 < z ==> x * y / z <= x * y / z
      {
        forall x: int, y: int, z: int | 0 <= x && 0 < z
          ensures x * y / z <= x * y / z
        {
          LemmaMulHoistInequality(x, y, z);
        }
      }

      lemma LemmaIndistinguishableQuotients(a: int, b: int, d: int)
        requires 0 < d
        requires 0 <= a - a % d <= b < a + d - a % d
        ensures a / d == b / d
        decreases a, b, d
      {
        LemmaDivInductionAuto(d, a - b, (ab: int) => ghost var u: int := ab + b; 0 <= u - u % d <= b < u + d - u % d ==> u / d == b / d);
      }

      lemma LemmaIndistinguishableQuotientsAuto()
        ensures forall a: int, b: int, d: int {:trigger a / d, b / d} :: 0 < d && 0 <= a - a % d <= b < a + d - a % d ==> a / d == b / d
      {
        forall a: int, b: int, d: int | 0 < d && 0 <= a - a % d <= b < a + d - a % d
          ensures a / d == b / d
        {
          LemmaIndistinguishableQuotients(a, b, d);
        }
      }

      lemma LemmaTruncateMiddle(x: int, b: int, c: int)
        requires 0 <= x
        requires 0 < b
        requires 0 < c
        ensures 0 < b * c
        ensures b * x % (b * c) == b * x % c
        decreases x, b, c
      {
        LemmaMulStrictlyPositiveAuto();
        LemmaMulNonnegativeAuto();
        calc {
          b * x;
          {
            LemmaFundamentalDivMod(b * x, b * c);
          }
          b * c * b * x / (b * c) + b * x % (b * c);
          {
            LemmaDivDenominator(b * x, b, c);
          }
          b * c * b * x / b / c + b * x % (b * c);
          {
            LemmaMulIsCommutativeAuto();
            LemmaDivByMultiple(x, b);
          }
          b * c * x / c + b * x % (b * c);
        }
        calc ==> {
          true;
          {
            LemmaFundamentalDivMod(x, c);
          }
          x == c * x / c + x % c;
          b * x == b * (c * x / c + x % c);
          {
            LemmaMulIsDistributiveAuto();
          }
          b * x == b * c * x / c + b * x % c;
          {
            LemmaMulIsAssociativeAuto();
          }
          b * x == b * c * x / c + b * x % c;
        }
      }

      lemma LemmaTruncateMiddleAuto()
        ensures forall x: int, b: int, c: int {:trigger b * x % c} :: 0 <= x && 0 < b && 0 < c && 0 < b * c ==> b * x % (b * c) == b * x % c
      {
        forall x: int, b: int, c: int | 0 <= x && 0 < b && 0 < c && 0 < b * c
          ensures b * x % (b * c) == b * x % c
        {
          LemmaTruncateMiddle(x, b, c);
        }
      }

      lemma LemmaDivMultiplesVanishQuotient(x: int, a: int, d: int)
        requires 0 < x
        requires 0 <= a
        requires 0 < d
        ensures 0 < x * d
        ensures a / d == x * a / (x * d)
        decreases x, a, d
      {
        LemmaMulStrictlyPositive(x, d);
        calc {
          x * a / (x * d);
          {
            LemmaMulNonnegative(x, a);
            LemmaDivDenominator(x * a, x, d);
          }
          x * a / x / d;
          {
            LemmaDivMultiplesVanish(a, x);
          }
          a / d;
        }
      }

      lemma LemmaDivMultiplesVanishQuotientAuto()
        ensures (forall x: int, a: int, d: int {:trigger a / d, x * d, x * a} :: 0 < x && 0 <= a && 0 < d ==> 0 < x * d) && forall x: int, a: int, d: int {:trigger a / d, x * d, x * a} :: 0 < x && 0 <= a && 0 < d ==> a / d == x * a / (x * d)
      {
        forall x: int, a: int, d: int {:trigger x * d, 0 <= a} | 0 < x && 0 <= a && 0 < d
          ensures 0 < x * d && a / d == x * a / (x * d)
        {
          LemmaDivMultiplesVanishQuotient(x, a, d);
        }
      }

      lemma LemmaRoundDown(a: int, r: int, d: int)
        requires 0 < d
        requires a % d == 0
        requires 0 <= r < d
        ensures a == d * (a + r) / d
        decreases a, r, d
      {
        LemmaMulAuto();
        LemmaDivInductionAuto(d, a, (u: int) => u % d == 0 ==> u == d * (u + r) / d);
      }

      lemma LemmaRoundDownAuto()
        ensures forall d: int, r: int, a: int {:trigger d * (a + r) / d} :: 0 < d && a % d == 0 && 0 <= r < d ==> a == d * (a + r) / d
      {
        forall a: int, r: int, d: int {:trigger a + r, r < d} {:trigger a + r, 0 < d} {:trigger 0 <= r, a % d} | 0 < d && a % d == 0 && 0 <= r < d
          ensures a == d * (a + r) / d
        {
          LemmaRoundDown(a, r, d);
        }
      }

      lemma LemmaDivMultiplesVanishFancy(x: int, b: int, d: int)
        requires 0 < d
        requires 0 <= b < d
        ensures (d * x + b) / d == x
        decreases x, b, d
      {
        LemmaDivAuto(d);
        ghost var f := (u: int) => (d * u + b) / d == u;
        LemmaMulInductionAuto(x, f);
        assert f(x);
      }

      lemma LemmaDivMultiplesVanishFancyAuto()
        ensures forall d: int, b: int, x: int {:trigger (d * x + b) / d} :: 0 < d && 0 <= b < d ==> (d * x + b) / d == x
      {
        forall x: int, b: int, d: int {:trigger d * x, b < d} {:trigger d * x, 0 <= b} | 0 < d && 0 <= b < d
          ensures (d * x + b) / d == x
        {
          LemmaDivMultiplesVanishFancy(x, b, d);
        }
      }

      lemma LemmaDivMultiplesVanish(x: int, d: int)
        requires 0 < d
        ensures d * x / d == x
        decreases x, d
      {
        LemmaDivMultiplesVanishFancy(x, 0, d);
      }

      lemma LemmaDivMultiplesVanishAuto()
        ensures forall x: int, d: int {:trigger d * x / d} :: 0 < d ==> d * x / d == x
      {
        forall x: int, d: int | 0 < d
          ensures d * x / d == x
        {
          LemmaDivMultiplesVanish(x, d);
        }
      }

      lemma LemmaDivByMultiple(b: int, d: int)
        requires 0 <= b
        requires 0 < d
        ensures b * d / d == b
        decreases b, d
      {
        LemmaDivMultiplesVanish(b, d);
      }

      lemma LemmaDivByMultipleAuto()
        ensures forall b: int, d: int {:trigger b * d / d} :: 0 <= b && 0 < d ==> b * d / d == b
      {
        forall b: int, d: int | 0 <= b && 0 < d
          ensures b * d / d == b
        {
          LemmaDivByMultiple(b, d);
        }
      }

      lemma LemmaDivByMultipleIsStronglyOrdered(x: int, y: int, m: int, z: int)
        requires x < y
        requires y == m * z
        requires 0 < z
        ensures x / z < y / z
        decreases x, y, m, z
      {
        LemmaModMultiplesBasic(m, z);
        LemmaDivInductionAuto(z, y - x, (yx: int) => ghost var u: int := yx + x; x < u && u % z == 0 ==> x / z < u / z);
      }

      lemma LemmaDivByMultipleIsStronglyOrderedAuto()
        ensures forall z: int, m: int, y: int, x: int {:trigger x / z, m * z, y / z} :: x < y && y == m * z && 0 < z ==> x / z < y / z
      {
        forall x: int, y: int, m: int, z: int | x < y && y == m * z && 0 < z
          ensures x / z < y / z
        {
          LemmaDivByMultipleIsStronglyOrdered(x, y, m, z);
        }
      }

      lemma LemmaMultiplyDivideLe(a: int, b: int, c: int)
        requires 0 < b
        requires a <= b * c
        ensures a / b <= c
        decreases a, b, c
      {
        LemmaModMultiplesBasic(c, b);
        LemmaDivInductionAuto(b, b * c - a, (i: int) => 0 <= i && (i + a) % b == 0 ==> a / b <= (i + a) / b);
        LemmaDivMultiplesVanish(c, b);
      }

      lemma LemmaMultiplyDivideLeAuto()
        ensures forall a: int, b: int, c: int {:trigger a / b, b * c} :: 0 < b && a <= b * c ==> a / b <= c
      {
        forall a: int, b: int, c: int | 0 < b && a <= b * c
          ensures a / b <= c
        {
          LemmaMultiplyDivideLe(a, b, c);
        }
      }

      lemma LemmaMultiplyDivideLt(a: int, b: int, c: int)
        requires 0 < b
        requires a < b * c
        ensures a / b < c
        decreases a, b, c
      {
        LemmaModMultiplesBasic(c, b);
        LemmaDivInductionAuto(b, b * c - a, (i: int) => 0 < i && (i + a) % b == 0 ==> a / b < (i + a) / b);
        LemmaDivMultiplesVanish(c, b);
      }

      lemma LemmaMultiplyDivideLtAuto()
        ensures forall a: int, b: int, c: int {:trigger a / b, b * c} :: 0 < b && a < b * c ==> a / b < c
      {
        forall a: int, b: int, c: int | 0 < b && a < b * c
          ensures a / b < c
        {
          LemmaMultiplyDivideLt(a, b, c);
        }
      }

      lemma LemmaHoistOverDenominator(x: int, j: int, d: nat)
        requires 0 < d
        ensures x / d + j == (x + j * d) / d
        decreases x, j, d
      {
        LemmaDivAuto(d);
        LemmaMulInductionAuto(j, (u: int) => x / d + u == (x + u * d) / d);
      }

      lemma LemmaHoistOverDenominatorAuto()
        ensures forall x: int, j: int, d: nat {:trigger x / d + j} :: 0 < d ==> x / d + j == (x + j * d) / d
      {
        forall x: int, j: int, d: nat | 0 < d
          ensures x / d + j == (x + j * d) / d
        {
          LemmaHoistOverDenominator(x, j, d);
        }
      }

      lemma LemmaPartBound1(a: int, b: int, c: int)
        requires 0 <= a
        requires 0 < b
        requires 0 < c
        ensures 0 < b * c
        ensures b * a / b % (b * c) <= b * (c - 1)
        decreases a, b, c
      {
        LemmaMulStrictlyPositiveAuto();
        calc {
          b * a / b % (b * c);
          {
            LemmaFundamentalDivMod(b * a / b, b * c);
          }
          b * a / b - b * c * b * a / b / (b * c);
          {
            LemmaMulIsAssociativeAuto();
          }
          b * a / b - b * c * b * a / b / (b * c);
          {
            LemmaMulIsDistributiveAuto();
          }
          b * (a / b - c * b * a / b / (b * c));
        }
        calc ==> {
          true;
          {
            LemmaModPropertiesAuto();
          }
          b * a / b % (b * c) < b * c;
          b * (a / b - c * b * a / b / (b * c)) < b * c;
          {
            LemmaMulIsCommutativeAuto();
            LemmaMulStrictInequalityConverseAuto();
          }
          a / b - c * b * a / b / (b * c) < c;
          a / b - c * b * a / b / (b * c) <= c - 1;
          {
            LemmaMulIsCommutativeAuto();
            LemmaMulInequalityAuto();
          }
          b * (a / b - c * b * a / b / (b * c)) <= b * (c - 1);
          b * a / b % (b * c) <= b * (c - 1);
        }
      }

      lemma LemmaPartBound1Auto()
        ensures (forall a: int, b: int, c: int {:trigger b * a / b % (b * c)} :: 0 <= a && 0 < b && 0 < c ==> 0 < b * c) && forall a: int, b: int, c: int {:trigger b * a / b % (b * c)} :: 0 <= a && 0 < b && 0 < c ==> b * a / b % (b * c) <= b * (c - 1)
      {
        forall a: int, b: int, c: int {:trigger b * c, 0 <= a} | 0 <= a && 0 < b && 0 < c
          ensures 0 < b * c && b * a / b % (b * c) <= b * (c - 1)
        {
          LemmaPartBound1(a, b, c);
        }
      }

      lemma /*{:_induction x, m}*/ LemmaModIsModRecursive(x: int, m: int)
        requires m > 0
        ensures ModRecursive(x, m) == x % m
        decreases if x < 0 then -x + m else x
      {
        reveal ModRecursive();
        if x < 0 {
          calc {
            ModRecursive(x, m);
            ModRecursive(x + m, m);
            {
              LemmaModIsModRecursive(x + m, m);
            }
            (x + m) % m;
            {
              LemmaAddModNoop(x, m, m);
            }
            (x % m + m % m) % m;
            {
              LemmaModBasicsAuto();
            }
            x % m % m;
            {
              LemmaModBasicsAuto();
            }
            x % m;
          }
        } else if x < m {
          LemmaSmallMod(x, m);
        } else {
          calc {
            ModRecursive(x, m);
            ModRecursive(x - m, m);
            {
              LemmaModIsModRecursive(x - m, m);
            }
            (x - m) % m;
            {
              LemmaSubModNoop(x, m, m);
            }
            (x % m - m % m) % m;
            {
              LemmaModBasicsAuto();
            }
            x % m % m;
            {
              LemmaModBasicsAuto();
            }
            x % m;
          }
        }
      }

      lemma LemmaModIsModRecursiveAuto()
        ensures forall x: int, d: int {:trigger x % d} :: d > 0 ==> ModRecursive(x, d) == x % d
      {
        reveal ModRecursive();
        forall x: int, d: int | d > 0
          ensures ModRecursive(x, d) == x % d
        {
          LemmaModIsModRecursive(x, d);
        }
      }

      lemma LemmaModBasicsAuto()
        ensures forall m: int {:trigger m % m} :: m > 0 ==> m % m == 0
        ensures forall x: int, m: int {:trigger x % m % m} :: m > 0 ==> x % m % m == x % m
      {
        forall m: int | m > 0
          ensures m % m == 0
        {
          LemmaModAuto(m);
        }
        forall x: int, m: int | m > 0
          ensures x % m % m == x % m
        {
          LemmaModAuto(m);
        }
      }

      lemma LemmaModPropertiesAuto()
        ensures forall m: int {:trigger m % m} :: m > 0 ==> m % m == 0
        ensures forall x: int, m: int {:trigger x % m % m} :: m > 0 ==> x % m % m == x % m
        ensures forall x: int, m: int {:trigger x % m} :: (m > 0 ==> 0 <= x % m) && (m > 0 ==> x % m < m)
      {
        LemmaModBasicsAuto();
        forall x: int, m: int | m > 0
          ensures 0 <= x % m < m
        {
          LemmaModAuto(m);
        }
      }

      lemma LemmaModDecreases(x: nat, m: nat)
        requires 0 < m
        ensures x % m <= x
        decreases x, m
      {
        LemmaModAuto(m);
      }

      lemma LemmaModDecreasesAuto()
        ensures forall x: nat, m: nat {:trigger x % m} :: 0 < m ==> x % m <= x
      {
        forall x: nat, m: nat | 0 < m
          ensures x % m <= x
        {
          LemmaModDecreases(x, m);
        }
      }

      lemma LemmaModIsZero(x: nat, m: nat)
        requires x > 0 && m > 0
        requires x % m == 0
        ensures x >= m
        decreases x, m
      {
        if x < m {
          assert x % m == x by {
            LemmaSmallMod(x, m);
          }
          assert false;
        }
      }

      lemma LemmaModIsZeroAuto()
        ensures forall m: nat, x: nat {:trigger x % m} :: x > 0 && m > 0 && x % m == 0 ==> x >= m
      {
        forall x: nat, m: nat | x > 0 && m > 0 && x % m == 0
          ensures x >= m
        {
          LemmaModIsZero(x, m);
        }
      }

      lemma LemmaModMultiplesBasic(x: int, m: int)
        requires m > 0
        ensures x * m % m == 0
        decreases x, m
      {
        LemmaModAuto(m);
        LemmaMulInductionAuto(x, (u: int) => u * m % m == 0);
      }

      lemma LemmaModMultiplesBasicAuto()
        ensures forall x: int, m: int {:trigger x * m % m} :: m > 0 ==> x * m % m == 0
      {
        forall x: int, m: int | m > 0
          ensures x * m % m == 0
        {
          LemmaModMultiplesBasic(x, m);
        }
      }

      lemma LemmaModAddMultiplesVanish(b: int, m: int)
        requires 0 < m
        ensures (m + b) % m == b % m
        decreases b, m
      {
        LemmaModAuto(m);
      }

      lemma LemmaModAddMultiplesVanishAuto()
        ensures forall b: int, m: int {:trigger b % m} :: 0 < m ==> (m + b) % m == b % m
      {
        forall b: int, m: int | 0 < m
          ensures (m + b) % m == b % m
        {
          LemmaModAddMultiplesVanish(b, m);
        }
      }

      lemma LemmaModSubMultiplesVanish(b: int, m: int)
        requires 0 < m
        ensures (-m + b) % m == b % m
        decreases b, m
      {
        LemmaModAuto(m);
      }

      lemma LemmaModSubMultiplesVanishAuto()
        ensures forall b: int, m: int {:trigger b % m} :: 0 < m ==> (-m + b) % m == b % m
      {
        forall b: int, m: int | 0 < m
          ensures (-m + b) % m == b % m
        {
          LemmaModSubMultiplesVanish(b, m);
        }
      }

      predicate MultiplesVanish(a: int, b: int, m: int)
        requires 0 < m
        decreases a, b, m
      {
        (m * a + b) % m == b % m
      }

      lemma LemmaModMultiplesVanish(a: int, b: int, m: int)
        requires 0 < m
        ensures MultiplesVanish(a, b, m)
        decreases if a > 0 then a else -a
      {
        LemmaModAuto(m);
        LemmaMulAuto();
        assert MultiplesVanish(0, b, m);
        LemmaMulInductionAuto(a, (u: int) => MultiplesVanish(u, b, m));
      }

      lemma LemmaModMultiplesVanishAuto()
        ensures forall a: int, b: int, m: int {:trigger (m * a + b) % m} :: 0 < m ==> MultiplesVanish(a, b, m)
      {
        forall a: int, b: int, m: int | 0 < m
          ensures MultiplesVanish(a, b, m)
        {
          LemmaModMultiplesVanish(a, b, m);
        }
      }

      lemma LemmaModSubtraction(x: nat, s: nat, d: nat)
        requires 0 < d
        requires 0 <= s <= x % d
        ensures x % d - s % d == (x - s) % d
        decreases x, s, d
      {
        LemmaModAuto(d);
      }

      lemma LemmaModSubtractionAuto()
        ensures forall x: nat, s: nat, d: nat {:trigger (x - s) % d} :: 0 < d && 0 <= s <= x % d ==> x % d - s % d == (x - s) % d
      {
        forall x: nat, s: nat, d: nat | 0 < d && 0 <= s <= x % d
          ensures x % d - s % d == (x - s) % d
        {
          LemmaModSubtraction(x, s, d);
        }
      }

      lemma LemmaAddModNoop(x: int, y: int, m: int)
        requires 0 < m
        ensures (x % m + y % m) % m == (x + y) % m
        decreases x, y, m
      {
        LemmaModAuto(m);
      }

      lemma LemmaAddModNoopAuto()
        ensures forall x: int, y: int, m: int {:trigger (x + y) % m} :: 0 < m ==> (x % m + y % m) % m == (x + y) % m
      {
        forall x: int, y: int, m: int | 0 < m
          ensures (x % m + y % m) % m == (x + y) % m
        {
          LemmaAddModNoop(x, y, m);
        }
      }

      lemma LemmaAddModNoopRight(x: int, y: int, m: int)
        requires 0 < m
        ensures (x + y % m) % m == (x + y) % m
        decreases x, y, m
      {
        LemmaModAuto(m);
      }

      lemma LemmaAddModNoopRightAuto()
        ensures forall x: int, y: int, m: int {:trigger (x + y) % m} :: 0 < m ==> (x + y % m) % m == (x + y) % m
      {
        forall x: int, y: int, m: int {:trigger x + y % m} | 0 < m
          ensures (x + y % m) % m == (x + y) % m
        {
          LemmaAddModNoopRight(x, y, m);
        }
      }

      lemma LemmaSubModNoop(x: int, y: int, m: int)
        requires 0 < m
        ensures (x % m - y % m) % m == (x - y) % m
        decreases x, y, m
      {
        LemmaModAuto(m);
      }

      lemma LemmaSubModNoopAuto()
        ensures forall x: int, y: int, m: int {:trigger (x - y) % m} :: 0 < m ==> (x % m - y % m) % m == (x - y) % m
      {
        forall x: int, y: int, m: int {:trigger x % m - y % m} | 0 < m
          ensures (x % m - y % m) % m == (x - y) % m
        {
          LemmaSubModNoop(x, y, m);
        }
      }

      lemma LemmaSubModNoopRight(x: int, y: int, m: int)
        requires 0 < m
        ensures (x - y % m) % m == (x - y) % m
        decreases x, y, m
      {
        LemmaModAuto(m);
      }

      lemma LemmaSubModNoopRightAuto()
        ensures forall x: int, y: int, m: int {:trigger (x - y) % m} :: 0 < m ==> (x - y % m) % m == (x - y) % m
      {
        forall x: int, y: int, m: int {:trigger x - y % m} | 0 < m
          ensures (x - y % m) % m == (x - y) % m
        {
          LemmaSubModNoopRight(x, y, m);
        }
      }

      lemma LemmaModAdds(a: int, b: int, d: int)
        requires 0 < d
        ensures a % d + b % d == (a + b) % d + d * (a % d + b % d) / d
        ensures a % d + b % d < d ==> a % d + b % d == (a + b) % d
        decreases a, b, d
      {
        LemmaMulAuto();
        LemmaDivAuto(d);
      }

      lemma LemmaModAddsAuto()
        ensures forall a: int, b: int, d: int {:trigger (a + b) % d} :: (0 < d ==> a % d + b % d == (a + b) % d + d * (a % d + b % d) / d) && (0 < d ==> a % d + b % d < d ==> a % d + b % d == (a + b) % d)
      {
        forall a: int, b: int, d: int | 0 < d
          ensures a % d + b % d == (a + b) % d + d * (a % d + b % d) / d && (a % d + b % d < d ==> a % d + b % d == (a + b) % d)
        {
          LemmaModAdds(a, b, d);
        }
      }

      lemma {:isolate_assertions} LemmaModNegNeg(x: int, d: int)
        requires 0 < d
        ensures x % d == x * (1 - d) % d
        decreases x, d
      {
        assert (x - x * d) % d == x % d by {
          LemmaModAuto(d);
          ghost var f := (i: int) => (x - i * d) % d == x % d;
          assert MulAuto() ==> f(0) && (forall i: int {:trigger IsLe(0, i)} :: IsLe(0, i) && f(i) ==> f(i + 1)) && forall i: int {:trigger IsLe(i, 0)} :: IsLe(i, 0) && f(i) ==> f(i - 1);
          LemmaMulInductionAuto(x, f);
        }
        LemmaMulAuto();
      }

      lemma {:timeLimitMultiplier 5} /*{:_timeLimit 50}*/ LemmaFundamentalDivModConverse(x: int, d: int, q: int, r: int)
        requires d != 0
        requires 0 <= r < d
        requires x == q * d + r
        ensures q == x / d
        ensures r == x % d
        decreases x, d, q, r
      {
        LemmaDivAuto(d);
        LemmaMulInductionAuto(q, (u: int) => u == (u * d + r) / d);
        LemmaMulInductionAuto(q, (u: int) => r == (u * d + r) % d);
      }

      lemma {:timeLimitMultiplier 5} /*{:_timeLimit 50}*/ LemmaFundamentalDivModConverseAuto()
        ensures forall x: int, d: int, q: int, r: int {:trigger q * d + r, x % d} :: (d != 0 && 0 <= r < d && x == q * d + r ==> q == x / d) && (d != 0 && 0 <= r < d && x == q * d + r ==> r == x % d)
      {
        forall x: int, d: int, q: int, r: int {:trigger x / d, q * d, r < d} {:trigger x / d, q * d, 0 <= r} | d != 0 && 0 <= r < d && x == q * d + r
          ensures q == x / d && r == x % d
        {
          LemmaFundamentalDivModConverse(x, d, q, r);
        }
      }

      lemma LemmaModPosBound(x: int, m: int)
        requires 0 <= x
        requires 0 < m
        ensures 0 <= x % m < m
        decreases x
      {
        LemmaModAuto(m);
      }

      lemma LemmaModPosBoundAuto()
        ensures (forall x: int, m: int {:trigger x % m} :: 0 <= x && 0 < m ==> 0 <= x % m) && forall x: int, m: int {:trigger x % m} :: 0 <= x && 0 < m ==> x % m < m
      {
        forall x: int, m: int | 0 <= x && 0 < m
          ensures 0 <= x % m < m
        {
          LemmaModPosBound(x, m);
        }
      }

      lemma LemmaMulModNoopLeft(x: int, y: int, m: int)
        requires 0 < m
        ensures x % m * y % m == x * y % m
        decreases x, y, m
      {
        LemmaModAuto(m);
        LemmaMulInductionAuto(y, (u: int) => x % m * u % m == x * u % m);
      }

      lemma LemmaMulModNoopLeftAuto()
        ensures forall x: int, y: int, m: int {:trigger x * y % m} :: 0 < m ==> x % m * y % m == x * y % m
      {
        forall x: int, y: int, m: int | 0 < m
          ensures x % m * y % m == x * y % m
        {
          LemmaMulModNoopLeft(x, y, m);
        }
      }

      lemma LemmaMulModNoopRight(x: int, y: int, m: int)
        requires 0 < m
        ensures x * y % m % m == x * y % m
        decreases x, y, m
      {
        LemmaModAuto(m);
        LemmaMulInductionAuto(x, (u: int) => u * y % m % m == u * y % m);
      }

      lemma LemmaMulModNoopRightAuto()
        ensures forall x: int, y: int, m: int {:trigger x * y % m} :: 0 < m ==> x * y % m % m == x * y % m
      {
        forall x: int, y: int, m: int | 0 < m
          ensures x * y % m % m == x * y % m
        {
          LemmaMulModNoopRight(x, y, m);
        }
      }

      lemma LemmaMulModNoopGeneral(x: int, y: int, m: int)
        requires 0 < m
        ensures x % m * y % m == x * y % m
        ensures x * y % m % m == x * y % m
        ensures x % m * y % m % m == x * y % m
        decreases x, y, m
      {
        LemmaModPropertiesAuto();
        LemmaMulModNoopLeft(x, y, m);
        LemmaMulModNoopRight(x, y, m);
        LemmaMulModNoopRight(x % m, y, m);
      }

      lemma LemmaMulModNoopGeneralAuto()
        ensures (forall x: int, y: int, m: int {:trigger x * y % m} :: 0 < m ==> x % m * y % m == x * y % m % m) && forall x: int, y: int, m: int {:trigger x * y % m} :: (0 < m ==> x * y % m % m == x % m * y % m % m) && (0 < m ==> x % m * y % m % m == x * y % m)
      {
        forall x: int, y: int, m: int | 0 < m
          ensures x % m * y % m == x * y % m % m == x % m * y % m % m == x * y % m
        {
          LemmaMulModNoopGeneral(x, y, m);
        }
      }

      lemma LemmaMulModNoop(x: int, y: int, m: int)
        requires 0 < m
        ensures x % m * y % m % m == x * y % m
        decreases x, y, m
      {
        LemmaMulModNoopGeneral(x, y, m);
      }

      lemma LemmaMulModNoopAuto()
        ensures forall x: int, y: int, m: int {:trigger x * y % m} :: 0 < m ==> x % m * y % m % m == x * y % m
      {
        forall x: int, y: int, m: int | 0 < m
          ensures x % m * y % m % m == x * y % m
        {
          LemmaMulModNoop(x, y, m);
        }
      }

      lemma LemmaModEquivalence(x: int, y: int, m: int)
        requires 0 < m
        ensures x % m == y % m <==> (x - y) % m == 0
        decreases x, y, m
      {
        LemmaModAuto(m);
      }

      lemma LemmaModEquivalenceAuto()
        ensures forall x: int, y: int, m: int {:trigger x % m, y % m} :: 0 < m && x % m == y % m <==> 0 < m && (x - y) % m == 0
      {
        forall x: int, y: int, m: int | 0 < m
          ensures x % m == y % m <==> 0 < m && (x - y) % m == 0
        {
          LemmaModEquivalence(x, y, m);
        }
      }

      ghost predicate IsModEquivalent(x: int, y: int, m: int)
        requires m > 0
        ensures x % m == y % m <==> (x - y) % m == 0
        decreases x, y, m
      {
        LemmaModEquivalence(x, y, m);
        (x - y) % m == 0
      }

      lemma LemmaModMulEquivalent(x: int, y: int, z: int, m: int)
        requires m > 0
        requires IsModEquivalent(x, y, m)
        ensures IsModEquivalent(x * z, y * z, m)
        decreases x, y, z, m
      {
        LemmaMulModNoopLeft(x, z, m);
        LemmaMulModNoopLeft(y, z, m);
      }

      lemma LemmaModMulEquivalentAuto()
        ensures forall x: int, y: int, z: int, m: int {:trigger IsModEquivalent(x * z, y * z, m)} :: m > 0 && IsModEquivalent(x, y, m) ==> IsModEquivalent(x * z, y * z, m)
      {
        forall x: int, y: int, z: int, m: int | m > 0 && IsModEquivalent(x, y, m)
          ensures IsModEquivalent(x * z, y * z, m)
        {
          LemmaModMulEquivalent(x, y, z, m);
        }
      }

      lemma LemmaModOrdering(x: int, k: int, d: int)
        requires 1 < d
        requires 0 < k
        ensures 0 < d * k
        ensures x % d <= x % (d * k)
        decreases x, k, d
      {
        LemmaMulStrictlyIncreases(d, k);
        calc {
          x % d + d * x / d;
          {
            LemmaFundamentalDivMod(x, d);
          }
          x;
          {
            LemmaFundamentalDivMod(x, d * k);
          }
          x % (d * k) + d * k * x / (d * k);
          {
            LemmaMulIsAssociativeAuto();
          }
          x % (d * k) + d * k * x / (d * k);
        }
        calc {
          x % d;
          {
            LemmaModPropertiesAuto();
          }
          x % d % d;
          {
            LemmaModMultiplesVanish(x / d - k * x / (d * k), x % d, d);
          }
          (x % d + d * (x / d - k * x / (d * k))) % d;
          {
            LemmaMulIsDistributiveSubAuto();
          }
          (x % d + d * x / d - d * k * x / (d * k)) % d;
          x % (d * k) % d;
        <=
          {
            LemmaModPropertiesAuto();
            LemmaModDecreases(x % (d * k), d);
          }
          x % (d * k);
        }
      }

      lemma LemmaModOrderingAuto()
        ensures forall k: int, d: int {:trigger d * k} :: 1 < d && 0 < k ==> 0 < d * k
        ensures forall x: int, k: int, d: int {:trigger x % (d * k)} :: 1 < d && 0 < k ==> x % d <= x % (d * k)
      {
        forall k: int, d: int {:trigger d * k} | 1 < d && 0 < k
          ensures 1 < d && 0 < k ==> 0 < d * k
        {
          LemmaMulStrictlyIncreases(d, k);
        }
        forall x: int, k: int, d: int {:trigger x % (d * k)} | 1 < d && 0 < k
          ensures 1 < d && 0 < k ==> x % d <= x % (d * k)
        {
          LemmaModOrdering(x, k, d);
        }
      }

      lemma LemmaModMod(x: int, a: int, b: int)
        requires 0 < a
        requires 0 < b
        ensures 0 < a * b
        ensures x % (a * b) % a == x % a
        decreases x, a, b
      {
        LemmaMulStrictlyPositiveAuto();
        calc {
          x;
          {
            LemmaFundamentalDivMod(x, a * b);
          }
          a * b * x / (a * b) + x % (a * b);
          {
            LemmaMulIsAssociativeAuto();
          }
          a * b * x / (a * b) + x % (a * b);
          {
            LemmaFundamentalDivMod(x % (a * b), a);
          }
          a * b * x / (a * b) + a * x % (a * b) / a + x % (a * b) % a;
          {
            LemmaMulIsDistributiveAuto();
          }
          a * (b * x / (a * b) + x % (a * b) / a) + x % (a * b) % a;
        }
        LemmaModPropertiesAuto();
        LemmaMulIsCommutativeAuto();
        LemmaFundamentalDivModConverse(x, a, b * x / (a * b) + x % (a * b) / a, x % (a * b) % a);
      }

      lemma LemmaModModAuto()
        ensures forall a: int, b: int {:trigger a * b} :: 0 < a && 0 < b ==> 0 < a * b
        ensures forall x: int, a: int, b: int {:trigger x % (a * b) % a, x % a} :: 0 < a && 0 < b ==> x % (a * b) % a == x % a
      {
        forall a: int, b: int {:trigger a * b} | 0 < a && 0 < b
          ensures 0 < a * b
        {
          LemmaMulStrictlyPositiveAuto();
        }
        forall x: int, a: int, b: int | 0 < a && 0 < b
          ensures x % (a * b) % a == x % a
        {
          LemmaModMod(x, a, b);
        }
      }

      lemma LemmaPartBound2(x: int, y: int, z: int)
        requires 0 <= x
        requires 0 < y
        requires 0 < z
        ensures y * z > 0
        ensures x % y % (y * z) < y
        decreases x, y, z
      {
        LemmaMulStrictlyPositiveAuto();
        LemmaModPropertiesAuto();
        assert x % y < y;
        LemmaMulIncreasesAuto();
        LemmaMulIsCommutativeAuto();
        assert y <= y * z;
        assert 0 <= x % y < y * z;
        LemmaModPropertiesAuto();
        LemmaSmallMod(x % y, y * z);
        assert x % y % (y * z) == x % y;
      }

      lemma LemmaPartBound2Auto()
        ensures (forall x: int, y: int, z: int {:trigger y * z, x % y} :: 0 <= x && 0 < y && 0 < z ==> y * z > 0) && forall x: int, y: int, z: int {:trigger y * z, x % y} :: 0 <= x && 0 < y && 0 < z ==> x % y % (y * z) < y
      {
        forall x: int, y: int, z: int {:trigger y * z, 0 <= x} {:trigger 0 < z, 0 < y, 0 <= x} | 0 <= x && 0 < y && 0 < z
          ensures y * z > 0 && x % y % (y * z) < y
        {
          LemmaPartBound2(x, y, z);
        }
      }

      lemma LemmaModBreakdown(x: int, y: int, z: int)
        requires 0 <= x
        requires 0 < y
        requires 0 < z
        ensures y * z > 0
        ensures x % (y * z) == y * x / y % z + x % y
        decreases x, y, z
      {
        LemmaMulStrictlyPositiveAuto();
        LemmaDivPosIsPos(x, y);
        assert 0 <= x / y;
        calc {
          y * x / y % (y * z) + x % y % (y * z);
        <=
          {
            LemmaPartBound1(x, y, z);
          }
          y * (z - 1) + x % y % (y * z);
        <
          {
            LemmaPartBound2(x, y, z);
          }
          y * (z - 1) + y;
          {
            LemmaMulBasicsAuto();
          }
          y * (z - 1) + y * 1;
          {
            LemmaMulIsDistributiveAuto();
          }
          y * (z - 1 + 1);
          y * z;
        }
        calc {
          x % (y * z);
          {
            LemmaFundamentalDivMod(x, y);
          }
          (y * x / y + x % y) % (y * z);
          {
            LemmaModPropertiesAuto();
            assert 0 <= x % y;
            LemmaMulNonnegative(y, x / y);
            assert y * x / y % (y * z) + x % y % (y * z) < y * z;
            LemmaModAdds(y * x / y, x % y, y * z);
          }
          y * x / y % (y * z) + x % y % (y * z);
          {
            LemmaModPropertiesAuto();
            LemmaMulIncreases(z, y);
            LemmaMulIsCommutativeAuto();
            assert x % y < y <= y * z;
            LemmaSmallMod(x % y, y * z);
            assert x % y % (y * z) == x % y;
          }
          y * x / y % (y * z) + x % y;
          {
            LemmaTruncateMiddle(x / y, y, z);
          }
          y * x / y % z + x % y;
        }
      }

      lemma LemmaModBreakdownAuto()
        ensures (forall x: int, y: int, z: int {:trigger x % (y * z)} :: 0 <= x && 0 < y && 0 < z ==> y * z > 0) && forall x: int, y: int, z: int {:trigger x % (y * z)} :: 0 <= x && 0 < y && 0 < z ==> x % (y * z) == y * x / y % z + x % y
      {
        forall x: int, y: int, z: int | 0 <= x && 0 < y && 0 < z
          ensures y * z > 0 && x % (y * z) == y * x / y % z + x % y
        {
          LemmaModBreakdown(x, y, z);
        }
      }

      import opened DivInternals

      import DivINL = DivInternalsNonlinear

      import opened ModInternals

      import ModINL = ModInternalsNonlinear

      import opened MulInternals

      import opened Mul

      import opened GeneralInternals
    }

    module {:disableNonlinearArithmetic} DivInternals {
      function {:opaque} DivPos(x: int, d: int): int
        requires d > 0
        decreases if x < 0 then d - x else x
      {
        if x < 0 then
          -1 + DivPos(x + d, d)
        else if x < d then
          0
        else
          1 + DivPos(x - d, d)
      }

      function {:opaque} DivRecursive(x: int, d: int): int
        requires d != 0
        decreases x, d
      {
        reveal DivPos();
        if d > 0 then
          DivPos(x, d)
        else
          -1 * DivPos(x, -1 * d)
      }

      lemma LemmaDivBasics(n: int)
        requires n > 0
        ensures n / n == -(-n / n) == 1
        ensures forall x: int {:trigger x / n} :: 0 <= x < n <==> x / n == 0
        ensures forall x: int {:trigger (x + n) / n} :: (x + n) / n == x / n + 1
        ensures forall x: int {:trigger (x - n) / n} :: (x - n) / n == x / n - 1
        decreases n
      {
        LemmaModAuto(n);
        LemmaModBasics(n);
        LemmaSmallDiv();
        LemmaDivBySelf(n);
        forall x: int | x / n == 0
          ensures 0 <= x < n
        {
          LemmaFundamentalDivMod(x, n);
        }
      }

      ghost predicate DivAuto(n: int)
        requires n > 0
        decreases n
      {
        ModAuto(n) &&
        n / n == -(-n / n) == 1 &&
        (forall x: int {:trigger x / n} :: 
          0 <= x < n <==> x / n == 0) &&
        DivAutoMinus(n) &&
        DivAutoPlus(n)
      }

      ghost predicate DivAutoPlus(n: int)
        requires n > 0
        decreases n
      {
        forall x: int, y: int {:trigger (x + y) / n} :: 
          DivPlus(n, x, y)
      }

      ghost predicate DivPlus(n: int, x: int, y: int)
        requires n > 0
        decreases n, x, y
      {
        ghost var z: int := x % n + y % n;
        (0 <= z < n && (x + y) / n == x / n + y / n) || (n <= z < n + n && (x + y) / n == x / n + y / n + 1)
      }

      ghost predicate DivAutoMinus(n: int)
        requires n > 0
        decreases n
      {
        forall x: int, y: int {:trigger (x - y) / n} :: 
          DivMinus(n, x, y)
      }

      ghost predicate DivMinus(n: int, x: int, y: int)
        requires n > 0
        decreases n, x, y
      {
        ghost var z: int := x % n - y % n;
        (0 <= z < n && (x - y) / n == x / n - y / n) || (-n <= z < 0 && (x - y) / n == x / n - y / n - 1)
      }

      lemma {:isolate_assertions} LemmaDivAutoAuxPlus(n: int)
        requires n > 0 && ModAuto(n)
        ensures DivAutoPlus(n)
        decreases n
      {
        LemmaModAuto(n);
        LemmaDivBasics(n);
        ghost var f := (x: int, y: int) => DivPlus(n, x, y);
        forall i: int, j: int | true
          ensures j >= 0 && f(i, j) ==> f(i, j + n)
          ensures i < n && f(i, j) ==> f(i - n, j)
          ensures j < n && f(i, j) ==> f(i, j - n)
          ensures i >= 0 && f(i, j) ==> f(i + n, j)
          ensures 0 <= i < n && 0 <= j < n ==> f(i, j)
        {
          assert (i + n + j) / n == (i + j + n) / n;
          assert (i + j + n) / n == (i + j + n) / n;
          assert i - n + j == i + j - n;
          assert (i - n + j) / n == (i + j - n) / n;
          assert (i + j - n) / n == (i + j - n) / n;
        }
        forall x: int, y: int | true
          ensures DivPlus(n, x, y)
        {
          LemmaModInductionForall2(n, f);
          assert f(x, y);
        }
      }

      lemma {:isolate_assertions} LemmaDivAutoAuxMinusHelper(n: int)
        requires n > 0 && ModAuto(n)
        ensures (forall i: int, j: int {:trigger DivMinus(n, i, j + n)} :: j >= 0 && DivMinus(n, i, j) ==> DivMinus(n, i, j + n)) && (forall i: int, j: int {:trigger DivMinus(n, i - n, j)} :: i < n && DivMinus(n, i, j) ==> DivMinus(n, i - n, j)) && (forall i: int, j: int {:trigger DivMinus(n, i, j - n)} :: j < n && DivMinus(n, i, j) ==> DivMinus(n, i, j - n)) && (forall i: int, j: int {:trigger DivMinus(n, i + n, j)} :: i >= 0 && DivMinus(n, i, j) ==> DivMinus(n, i + n, j)) && forall i: int, j: int {:trigger DivMinus(n, i, j)} {:trigger j < n, i < n} {:trigger j < n, 0 <= i} {:trigger 0 <= j, i < n} {:trigger 0 <= j, 0 <= i} :: 0 <= i < n && 0 <= j < n ==> DivMinus(n, i, j)
        decreases n
      {
        LemmaModAuto(n);
        LemmaDivBasics(n);
        forall i: int, j: int | true
          ensures j >= 0 && DivMinus(n, i, j) ==> DivMinus(n, i, j + n)
          ensures i < n && DivMinus(n, i, j) ==> DivMinus(n, i - n, j)
          ensures j < n && DivMinus(n, i, j) ==> DivMinus(n, i, j - n)
          ensures i >= 0 && DivMinus(n, i, j) ==> DivMinus(n, i + n, j)
          ensures 0 <= i < n && 0 <= j < n ==> DivMinus(n, i, j)
        {
          assert (i + n - j) / n == (i - j + n) / n;
          assert (i - (j - n)) / n == (i - j + n) / n;
          assert (i - n - j) / n == (i - j - n) / n;
          assert (i - (j + n)) / n == (i - j - n) / n;
        }
      }

      lemma LemmaDivAutoAuxMinus(n: int)
        requires n > 0 && ModAuto(n)
        ensures DivAutoMinus(n)
        decreases n
      {
        LemmaDivAutoAuxMinusHelper(n);
        ghost var f := (x: int, y: int) => DivMinus(n, x, y);
        LemmaModInductionForall2(n, f);
        forall x: int, y: int | true
          ensures DivMinus(n, x, y)
        {
          assert f(x, y);
        }
      }

      lemma LemmaDivAutoAux(n: int)
        requires n > 0 && ModAuto(n)
        ensures DivAuto(n)
        decreases n
      {
        LemmaDivBasics(n);
        assert (0 + n) / n == 1;
        assert (0 - n) / n == -1;
        LemmaDivAutoAuxPlus(n);
        LemmaDivAutoAuxMinus(n);
      }

      lemma LemmaDivAuto(n: int)
        requires n > 0
        ensures DivAuto(n)
        decreases n
      {
        LemmaModAuto(n);
        LemmaDivAutoAux(n);
      }

      lemma LemmaDivInductionAuto(n: int, x: int, f: int -> bool)
        requires n > 0
        requires DivAuto(n) ==> (forall i: int {:trigger IsLe(0, i)} :: IsLe(0, i) && i < n ==> f(i)) && (forall i: int {:trigger IsLe(0, i)} :: IsLe(0, i) && f(i) ==> f(i + n)) && forall i: int {:trigger IsLe(i + 1, n)} :: IsLe(i + 1, n) && f(i) ==> f(i - n)
        ensures DivAuto(n)
        ensures f(x)
        decreases n, x
      {
        LemmaDivAuto(n);
        assert forall i: int {:trigger f(i)} {:trigger IsLe(0, i)} :: IsLe(0, i) && i < n ==> f(i);
        assert forall i: int {:trigger f(i), f(i + n)} :: IsLe(0, i) && f(i) ==> f(i + n);
        assert forall i: int {:trigger f(i), f(i - n)} :: IsLe(i + 1, n) && f(i) ==> f(i - n);
        LemmaModInductionForall(n, f);
        assert f(x);
      }

      lemma LemmaDivInductionAutoForall(n: int, f: int -> bool)
        requires n > 0
        requires DivAuto(n) ==> (forall i: int {:trigger IsLe(0, i)} :: IsLe(0, i) && i < n ==> f(i)) && (forall i: int {:trigger IsLe(0, i)} :: IsLe(0, i) && f(i) ==> f(i + n)) && forall i: int {:trigger IsLe(i + 1, n)} :: IsLe(i + 1, n) && f(i) ==> f(i - n)
        ensures DivAuto(n)
        ensures forall i: int {:trigger f(i)} :: f(i)
        decreases n
      {
        LemmaDivAuto(n);
        assert forall i: int {:trigger f(i)} {:trigger IsLe(0, i)} :: IsLe(0, i) && i < n ==> f(i);
        assert forall i: int {:trigger f(i), f(i + n)} :: IsLe(0, i) && f(i) ==> f(i + n);
        assert forall i: int {:trigger f(i), f(i - n)} :: IsLe(i + 1, n) && f(i) ==> f(i - n);
        LemmaModInductionForall(n, f);
      }

      import opened GeneralInternals

      import opened ModInternals

      import opened ModInternalsNonlinear

      import opened DivInternalsNonlinear

      import opened MulInternals
    }

    module {:z3ArithmeticSolver 6} DivInternalsNonlinear {
      lemma LemmaDivOf0(d: int)
        requires d != 0
        ensures 0 / d == 0
        decreases d
      {
      }

      lemma LemmaDivBySelf(d: int)
        requires d != 0
        ensures d / d == 1
        decreases d
      {
      }

      lemma LemmaSmallDiv()
        ensures forall d: int, x: int {:trigger x / d} :: 0 <= x < d && d > 0 ==> x / d == 0
      {
      }

      lemma LemmaRealDivGt(x: real, y: real)
        requires x > y
        requires y > 0.0
        ensures x / y > 1 as real
        decreases x, y
      {
      }
    }

    module {:disableNonlinearArithmetic} GeneralInternals {
      ghost predicate IsLe(x: int, y: int)
        decreases x, y
      {
        x <= y
      }

      lemma LemmaInductionHelper(n: int, f: int -> bool, x: int)
        requires n > 0
        requires forall i: int {:trigger f(i)} :: 0 <= i < n ==> f(i)
        requires forall i: int {:trigger f(i), f(i + n)} :: i >= 0 && f(i) ==> f(i + n)
        requires forall i: int {:trigger f(i), f(i - n)} :: i < n && f(i) ==> f(i - n)
        ensures f(x)
        decreases if x >= n then x else -x
      {
        if x >= n {
          LemmaInductionHelper(n, f, x - n);
          assert f(x - n + n);
        } else if x < 0 {
          LemmaInductionHelper(n, f, x + n);
          assert f(x + n - n);
        }
      }
    }

    module {:disableNonlinearArithmetic} ModInternals {
      function {:opaque} ModRecursive(x: int, d: int): int
        requires d > 0
        decreases if x < 0 then d - x else x
      {
        if x < 0 then
          ModRecursive(d + x, d)
        else if x < d then
          x
        else
          ModRecursive(x - d, d)
      }

      lemma LemmaModInductionForall(n: int, f: int -> bool)
        requires n > 0
        requires forall i: int {:trigger f(i)} :: 0 <= i < n ==> f(i)
        requires forall i: int {:trigger f(i), f(i + n)} :: i >= 0 && f(i) ==> f(i + n)
        requires forall i: int {:trigger f(i), f(i - n)} :: i < n && f(i) ==> f(i - n)
        ensures forall i: int {:trigger f(i)} :: f(i)
        decreases n
      {
        forall i: int | true
          ensures f(i)
        {
          LemmaInductionHelper(n, f, i);
        }
      }

      lemma LemmaModInductionForall2(n: int, f: (int, int) -> bool)
        requires n > 0
        requires forall i: int, j: int {:trigger f(i, j)} :: 0 <= i < n && 0 <= j < n ==> f(i, j)
        requires forall i: int, j: int {:trigger f(i, j), f(i + n, j)} :: i >= 0 && f(i, j) ==> f(i + n, j)
        requires forall i: int, j: int {:trigger f(i, j), f(i, j + n)} :: j >= 0 && f(i, j) ==> f(i, j + n)
        requires forall i: int, j: int {:trigger f(i, j), f(i - n, j)} :: i < n && f(i, j) ==> f(i - n, j)
        requires forall i: int, j: int {:trigger f(i, j), f(i, j - n)} :: j < n && f(i, j) ==> f(i, j - n)
        ensures forall i: int, j: int {:trigger f(i, j)} :: f(i, j)
        decreases n
      {
        forall x: int, y: int | true
          ensures f(x, y)
        {
          forall i: int | 0 <= i < n
            ensures f(i, y)
          {
            ghost var fj := (j: int) => f(i, j);
            LemmaModInductionForall(n, fj);
            assert fj(y);
          }
          ghost var fi := (i: int) => f(i, y);
          LemmaModInductionForall(n, fi);
          assert fi(x);
        }
      }

      lemma {:isolate_assertions} LemmaDivAddDenominator(n: int, x: int)
        requires n > 0
        ensures (x + n) / n == x / n + 1
        decreases n, x
      {
        LemmaFundamentalDivMod(x, n);
        LemmaFundamentalDivMod(x + n, n);
        ghost var zp := (x + n) / n - x / n - 1;
        assert 0 == n * zp + (x + n) % n - x % n by {
          LemmaMulDistributes();
        }
        if zp > 0 {
          assert (x + n) / n == x / n + 1 by {
            LemmaMulInequality(1, zp, n);
          }
        }
        if zp < 0 {
          assert (x + n) / n == x / n + 1 by {
            LemmaMulInequality(zp, -1, n);
          }
        }
      }

      lemma {:isolate_assertions} LemmaDivSubDenominator(n: int, x: int)
        requires n > 0
        ensures (x - n) / n == x / n - 1
        decreases n, x
      {
        LemmaFundamentalDivMod(x, n);
        LemmaFundamentalDivMod(x - n, n);
        ghost var zm := (x - n) / n - x / n + 1;
        assert 0 == n * zm + (x - n) % n - x % n by {
          LemmaMulDistributes();
        }
        if zm > 0 {
          assert (x - n) / n == x / n - 1 by {
            LemmaMulInequality(1, zm, n);
          }
        }
        if zm < 0 {
          assert (x - n) / n == x / n - 1 by {
            LemmaMulInequality(zm, -1, n);
          }
        }
      }

      lemma {:isolate_assertions} LemmaModAddDenominator(n: int, x: int)
        requires n > 0
        ensures (x + n) % n == x % n
        decreases n, x
      {
        LemmaFundamentalDivMod(x, n);
        LemmaFundamentalDivMod(x + n, n);
        ghost var zp := (x + n) / n - x / n - 1;
        assert 0 == n * zp + (x + n) % n - x % n by {
          LemmaMulDistributes();
        }
        if zp > 0 {
          assert (x + n) % n == x % n by {
            LemmaMulInequality(1, zp, n);
          }
        }
        if zp < 0 {
          assert (x + n) % n == x % n by {
            LemmaMulInequality(zp, -1, n);
          }
        }
      }

      lemma {:isolate_assertions} LemmaModSubDenominator(n: int, x: int)
        requires n > 0
        ensures (x - n) % n == x % n
        decreases n, x
      {
        LemmaFundamentalDivMod(x, n);
        LemmaFundamentalDivMod(x - n, n);
        ghost var zm := (x - n) / n - x / n + 1;
        assert 0 == n * zm + (x - n) % n - x % n by {
          LemmaMulDistributes();
        }
        if zm > 0 {
          assert (x - n) % n == x % n by {
            LemmaMulInequality(1, zm, n);
          }
        }
        if zm < 0 {
          assert (x - n) % n == x % n by {
            LemmaMulInequality(zm, -1, n);
          }
        }
      }

      lemma LemmaModBelowDenominator(n: int, x: int)
        requires n > 0
        ensures 0 <= x < n <==> x % n == x
        decreases n, x
      {
        forall x: int | true
          ensures 0 <= x < n <==> x % n == x
        {
          if 0 <= x < n {
            LemmaSmallMod(x, n);
          }
          LemmaModRange(x, n);
        }
      }

      lemma LemmaModBasics(n: int)
        requires n > 0
        ensures forall x: int {:trigger (x + n) % n} :: (x + n) % n == x % n
        ensures forall x: int {:trigger (x - n) % n} :: (x - n) % n == x % n
        ensures forall x: int {:trigger (x + n) / n} :: (x + n) / n == x / n + 1
        ensures forall x: int {:trigger (x - n) / n} :: (x - n) / n == x / n - 1
        ensures forall x: int {:trigger x % n} :: 0 <= x < n <==> x % n == x
        decreases n
      {
        forall x: int | true
          ensures (x + n) % n == x % n
          ensures (x - n) % n == x % n
          ensures (x + n) / n == x / n + 1
          ensures (x - n) / n == x / n - 1
          ensures 0 <= x < n <==> x % n == x
        {
          LemmaModBelowDenominator(n, x);
          LemmaModAddDenominator(n, x);
          LemmaModSubDenominator(n, x);
          LemmaDivAddDenominator(n, x);
          LemmaDivSubDenominator(n, x);
        }
      }

      lemma {:isolate_assertions} LemmaQuotientAndRemainder(x: int, q: int, r: int, n: int)
        requires n > 0
        requires 0 <= r < n
        requires x == q * n + r
        ensures q == x / n
        ensures r == x % n
        decreases if q > 0 then q else -q
      {
        LemmaModBasics(n);
        if q > 0 {
          MulInternalsNonlinear.LemmaMulIsDistributiveAdd(n, q - 1, 1);
          LemmaMulIsCommutativeAuto();
          assert q * n + r == (q - 1) * n + n + r;
          LemmaQuotientAndRemainder(x - n, q - 1, r, n);
        } else if q < 0 {
          Mul.LemmaMulIsDistributiveSub(n, q + 1, 1);
          LemmaMulIsCommutativeAuto();
          assert q * n + r == (q + 1) * n - n + r;
          LemmaQuotientAndRemainder(x + n, q + 1, r, n);
        } else {
          LemmaSmallDiv();
          assert r / n == 0;
        }
      }

      ghost predicate ModAuto(n: int)
        requires n > 0
        decreases n
      {
        n % n == -n % n == 0 &&
        (forall x: int {:trigger x % n % n} :: 
          x % n % n == x % n) &&
        (forall x: int {:trigger x % n} :: 
          0 <= x < n <==> x % n == x) &&
        ModAutoPlus(n) &&
        ModAutoMinus(n)
      }

      ghost predicate ModAutoPlus(n: int)
        requires n > 0
        decreases n
      {
        forall x: int, y: int {:trigger (x + y) % n} :: 
          ghost var z: int := x % n + y % n; (0 <= z < n && (x + y) % n == z) || (n <= z < n + n && (x + y) % n == z - n)
      }

      ghost predicate ModAutoMinus(n: int)
        requires n > 0
        decreases n
      {
        forall x: int, y: int {:trigger (x - y) % n} :: 
          ghost var z: int := x % n - y % n; (0 <= z < n && (x - y) % n == z) || (-n <= z < 0 && (x - y) % n == z + n)
      }

      lemma LemmaModAuto(n: int)
        requires n > 0
        ensures ModAuto(n)
        decreases n
      {
        LemmaModBasics(n);
        LemmaModAutoPlus(n);
        LemmaModAutoMinus(n);
      }

      lemma {:resource_limit 2000000} LemmaModAutoMinus(n: int)
        requires n > 0
        ensures ModAutoMinus(n)
        decreases n
      {
        LemmaModBasics(n);
        LemmaMulIsCommutativeAuto();
        LemmaMulIsDistributiveSubAuto();
        forall x: int, y: int {:trigger (x - y) % n} | true
          ensures ghost var z: int := x % n - y % n; (0 <= z < n && (x - y) % n == z) || (-n <= z < 0 && (x - y) % n == z + n)
        {
          ghost var xq, xr := x / n, x % n;
          LemmaFundamentalDivMod(x, n);
          assert x == xq * n + xr;
          ghost var yq, yr := y / n, y % n;
          LemmaFundamentalDivMod(y, n);
          assert y == yq * n + yr;
          if xr - yr >= 0 {
            LemmaQuotientAndRemainder(x - y, xq - yq, xr - yr, n);
          } else {
            LemmaQuotientAndRemainder(x - y, xq - yq - 1, xr - yr + n, n);
          }
        }
      }

      lemma LemmaModAutoPlus(n: int)
        requires n > 0
        ensures ModAutoPlus(n)
        decreases n
      {
        LemmaMulIsCommutativeAuto();
        LemmaMulIsDistributiveAddAuto();
        forall x: int, y: int {:trigger (x + y) % n} | true
          ensures ghost var z: int := x % n + y % n; (0 <= z < n && (x + y) % n == z) || (n <= z < 2 * n && (x + y) % n == z - n)
        {
          ghost var xq, xr := x / n, x % n;
          LemmaFundamentalDivMod(x, n);
          assert x == xq * n + xr;
          ghost var yq, yr := y / n, y % n;
          LemmaFundamentalDivMod(y, n);
          assert y == yq * n + yr;
          if xr + yr < n {
            LemmaQuotientAndRemainder(x + y, xq + yq, xr + yr, n);
          } else {
            LemmaQuotientAndRemainder(x + y, xq + yq + 1, xr + yr - n, n);
          }
        }
      }

      lemma LemmaModInductionAuto(n: int, x: int, f: int -> bool)
        requires n > 0
        requires ModAuto(n) ==> (forall i: int {:trigger IsLe(0, i)} :: IsLe(0, i) && i < n ==> f(i)) && (forall i: int {:trigger IsLe(0, i)} :: IsLe(0, i) && f(i) ==> f(i + n)) && forall i: int {:trigger IsLe(i + 1, n)} :: IsLe(i + 1, n) && f(i) ==> f(i - n)
        ensures ModAuto(n)
        ensures f(x)
        decreases n, x
      {
        LemmaModAuto(n);
        assert forall i: int {:trigger f(i)} {:trigger IsLe(0, i)} :: IsLe(0, i) && i < n ==> f(i);
        assert forall i: int {:trigger f(i), f(i + n)} :: IsLe(0, i) && f(i) ==> f(i + n);
        assert forall i: int {:trigger f(i), f(i - n)} :: IsLe(i + 1, n) && f(i) ==> f(i - n);
        LemmaModInductionForall(n, f);
        assert f(x);
      }

      lemma LemmaModInductionAutoForall(n: int, f: int -> bool)
        requires n > 0
        requires ModAuto(n) ==> (forall i: int {:trigger IsLe(0, i)} :: IsLe(0, i) && i < n ==> f(i)) && (forall i: int {:trigger IsLe(0, i)} :: IsLe(0, i) && f(i) ==> f(i + n)) && forall i: int {:trigger IsLe(i + 1, n)} :: IsLe(i + 1, n) && f(i) ==> f(i - n)
        ensures ModAuto(n)
        ensures forall i: int {:trigger f(i)} :: f(i)
        decreases n
      {
        LemmaModAuto(n);
        assert forall i: int {:trigger f(i)} {:trigger IsLe(0, i)} :: IsLe(0, i) && i < n ==> f(i);
        assert forall i: int {:trigger f(i), f(i + n)} :: IsLe(0, i) && f(i) ==> f(i + n);
        assert forall i: int {:trigger f(i), f(i - n)} :: IsLe(i + 1, n) && f(i) ==> f(i - n);
        LemmaModInductionForall(n, f);
      }

      import opened GeneralInternals

      import opened Mul

      import opened MulInternalsNonlinear

      import opened MulInternals

      import opened ModInternalsNonlinear

      import opened DivInternalsNonlinear
    }

    module {:z3ArithmeticSolver 6} ModInternalsNonlinear {
      lemma LemmaModOfZeroIsZero(m: int)
        requires 0 < m
        ensures 0 % m == 0
        decreases m
      {
      }

      lemma LemmaFundamentalDivMod(x: int, d: int)
        requires d != 0
        ensures x == d * x / d + x % d
        decreases x, d
      {
      }

      lemma Lemma0ModAnything()
        ensures forall m: int {:trigger 0 % m} :: m > 0 ==> 0 % m == 0
      {
      }

      lemma LemmaSmallMod(x: nat, m: nat)
        requires x < m
        requires 0 < m
        ensures x % m == x
        decreases x, m
      {
      }

      lemma LemmaModRange(x: int, m: int)
        requires m > 0
        ensures 0 <= x % m < m
        decreases x, m
      {
      }
    }

    module {:disableNonlinearArithmetic} MulInternals {
      function {:opaque} MulPos(x: int, y: int): int
        requires x >= 0
        decreases x, y
      {
        if x == 0 then
          0
        else
          y + MulPos(x - 1, y)
      }

      function MulRecursive(x: int, y: int): int
        decreases x, y
      {
        if x >= 0 then
          MulPos(x, y)
        else
          -1 * MulPos(-1 * x, y)
      }

      lemma LemmaMulInduction(f: int -> bool)
        requires f(0)
        requires forall i: int {:trigger f(i), f(i + 1)} :: i >= 0 && f(i) ==> f(i + 1)
        requires forall i: int {:trigger f(i), f(i - 1)} :: i <= 0 && f(i) ==> f(i - 1)
        ensures forall i: int {:trigger f(i)} :: f(i)
      {
        forall i: int | true
          ensures f(i)
        {
          LemmaInductionHelper(1, f, i);
        }
      }

      lemma LemmaMulCommutes()
        ensures forall x: int, y: int {:trigger x * y} :: x * y == y * x
      {
        forall x: int, y: int | true
          ensures x * y == y * x
        {
          LemmaMulInduction((i: int) => x * i == i * x);
        }
      }

      lemma LemmaMulSuccessor()
        ensures forall x: int, y: int {:trigger (x + 1) * y} :: (x + 1) * y == x * y + y
        ensures forall x: int, y: int {:trigger (x - 1) * y} :: (x - 1) * y == x * y - y
      {
        LemmaMulCommutes();
        forall x: int, y: int | true
          ensures (x + 1) * y == x * y + y
          ensures (x - 1) * y == x * y - y
        {
          LemmaMulIsDistributiveAdd(y, x, 1);
          LemmaMulIsDistributiveAdd(y, x, -1);
        }
      }

      lemma LemmaMulDistributes()
        ensures forall x: int, y: int, z: int {:trigger (x + y) * z} :: (x + y) * z == x * z + y * z
        ensures forall x: int, y: int, z: int {:trigger (x - y) * z} :: (x - y) * z == x * z - y * z
      {
        LemmaMulSuccessor();
        forall x: int, y: int, z: int | true
          ensures (x + y) * z == x * z + y * z
          ensures (x - y) * z == x * z - y * z
        {
          ghost var f1 := (i: int) => (x + i) * z == x * z + i * z;
          ghost var f2 := (i: int) => (x - i) * z == x * z - i * z;
          assert forall i: int {:trigger (x + i + 1) * z} :: (x + i + 1) * z == (x + i + 1) * z && (x + i + 1) * z == (x + i) * z + z;
          assert forall i: int {:trigger (x + i - 1) * z} :: (x + i - 1) * z == (x + i - 1) * z && (x + i - 1) * z == (x + i) * z - z;
          assert forall i: int {:trigger (x - (i + 1)) * z} :: (x - (i + 1)) * z == (x - i - 1) * z && (x - i - 1) * z == (x - i) * z - z;
          assert forall i: int {:trigger (x - (i - 1)) * z} :: (x - (i - 1)) * z == (x - i + 1) * z && (x - i + 1) * z == (x - i) * z + z;
          LemmaMulInduction(f1);
          LemmaMulInduction(f2);
          assert f1(y);
          assert f2(y);
        }
      }

      ghost predicate MulAuto()
      {
        (forall x: int, y: int {:trigger x * y} :: 
          x * y == y * x) &&
        (forall x: int, y: int, z: int {:trigger (x + y) * z} :: 
          (x + y) * z == x * z + y * z) &&
        forall x: int, y: int, z: int {:trigger (x - y) * z} :: 
          (x - y) * z == x * z - y * z
      }

      lemma LemmaMulAuto()
        ensures MulAuto()
      {
        LemmaMulCommutes();
        LemmaMulDistributes();
      }

      lemma LemmaMulInductionAuto(x: int, f: int -> bool)
        requires MulAuto() ==> f(0) && (forall i: int {:trigger IsLe(0, i)} :: IsLe(0, i) && f(i) ==> f(i + 1)) && forall i: int {:trigger IsLe(i, 0)} :: IsLe(i, 0) && f(i) ==> f(i - 1)
        ensures MulAuto()
        ensures f(x)
        decreases x
      {
        LemmaMulCommutes();
        LemmaMulDistributes();
        assert forall i: int {:trigger f(i)} :: IsLe(0, i) && f(i) ==> f(i + 1);
        assert forall i: int {:trigger f(i)} :: IsLe(i, 0) && f(i) ==> f(i - 1);
        LemmaMulInduction(f);
        assert f(x);
      }

      lemma LemmaMulInductionAutoForall(f: int -> bool)
        requires MulAuto() ==> f(0) && (forall i: int {:trigger IsLe(0, i)} :: IsLe(0, i) && f(i) ==> f(i + 1)) && forall i: int {:trigger IsLe(i, 0)} :: IsLe(i, 0) && f(i) ==> f(i - 1)
        ensures MulAuto()
        ensures forall i: int {:trigger f(i)} :: f(i)
      {
        LemmaMulCommutes();
        LemmaMulDistributes();
        assert forall i: int {:trigger f(i)} :: IsLe(0, i) && f(i) ==> f(i + 1);
        assert forall i: int {:trigger f(i)} :: IsLe(i, 0) && f(i) ==> f(i - 1);
        LemmaMulInduction(f);
      }

      import opened GeneralInternals

      import opened MulInternalsNonlinear
    }

    module {:z3ArithmeticSolver 6} MulInternalsNonlinear {
      lemma LemmaMulStrictlyPositive(x: int, y: int)
        ensures 0 < x && 0 < y ==> 0 < x * y
        decreases x, y
      {
      }

      lemma LemmaMulNonzero(x: int, y: int)
        ensures x * y != 0 <==> x != 0 && y != 0
        decreases x, y
      {
      }

      lemma LemmaMulIsAssociative(x: int, y: int, z: int)
        ensures x * y * z == x * y * z
        decreases x, y, z
      {
      }

      lemma LemmaMulIsDistributiveAdd(x: int, y: int, z: int)
        ensures x * (y + z) == x * y + x * z
        decreases x, y, z
      {
      }

      lemma LemmaMulOrdering(x: int, y: int)
        requires x != 0
        requires y != 0
        requires 0 <= x * y
        ensures x * y >= x && x * y >= y
        decreases x, y
      {
      }

      lemma LemmaMulStrictInequality(x: int, y: int, z: int)
        requires x < y
        requires z > 0
        ensures x * z < y * z
        decreases x, y, z
      {
      }
    }

    abstract module {:disableNonlinearArithmetic} LittleEndianNat {
      function BASE(): nat
        ensures BASE() > 1

      function {:opaque} ToNatRight(xs: seq<digit>): nat
        decreases xs
      {
        if |xs| == 0 then
          0
        else
          LemmaMulNonnegativeAuto(); ToNatRight(DropFirst(xs)) * BASE() + First(xs)
      }

      function {:opaque} ToNatLeft(xs: seq<digit>): nat
        decreases xs
      {
        if |xs| == 0 then
          0
        else
          LemmaPowPositiveAuto(); LemmaMulNonnegativeAuto(); ToNatLeft(DropLast(xs)) + Last(xs) * Pow(BASE(), |xs| - 1)
      }

      lemma {:isolate_assertions} /*{:_induction xs}*/ LemmaToNatLeftEqToNatRight(xs: seq<digit>)
        ensures ToNatRight(xs) == ToNatLeft(xs)
        decreases xs
      {
        reveal ToNatRight();
        reveal ToNatLeft();
        if xs == [] {
        } else {
          if DropLast(xs) == [] {
            calc {
              ToNatLeft(xs);
              Last(xs) * Pow(BASE(), |xs| - 1);
              {
                reveal Pow();
              }
              Last(xs);
              First(xs);
              {
                assert ToNatRight(DropFirst(xs)) == 0;
              }
              ToNatRight(xs);
            }
          } else {
            calc {
              ToNatLeft(xs);
              ToNatLeft(DropLast(xs)) + Last(xs) * Pow(BASE(), |xs| - 1);
              {
                LemmaToNatLeftEqToNatRight(DropLast(xs));
              }
              ToNatRight(DropLast(xs)) + Last(xs) * Pow(BASE(), |xs| - 1);
              ToNatRight(DropFirst(DropLast(xs))) * BASE() + First(xs) + Last(xs) * Pow(BASE(), |xs| - 1);
              {
                LemmaToNatLeftEqToNatRight(DropFirst(DropLast(xs)));
              }
              ToNatLeft(DropFirst(DropLast(xs))) * BASE() + First(xs) + Last(xs) * Pow(BASE(), |xs| - 1);
              {
                assert DropFirst(DropLast(xs)) == DropLast(DropFirst(xs));
                reveal Pow();
                LemmaMulProperties();
              }
              ToNatLeft(DropLast(DropFirst(xs))) * BASE() + First(xs) + Last(xs) * Pow(BASE(), |xs| - 2) * BASE();
              {
                LemmaMulIsDistributiveAddOtherWayAuto();
              }
              ToNatLeft(DropFirst(xs)) * BASE() + First(xs);
              {
                LemmaToNatLeftEqToNatRight(DropFirst(xs));
              }
              ToNatRight(xs);
            }
          }
        }
      }

      lemma LemmaToNatLeftEqToNatRightAuto()
        ensures forall xs: seq<digit> {:trigger ToNatLeft(xs)} {:trigger ToNatRight(xs)} :: ToNatRight(xs) == ToNatLeft(xs)
      {
        reveal ToNatRight();
        reveal ToNatLeft();
        forall xs: seq<digit> | true
          ensures ToNatRight(xs) == ToNatLeft(xs)
        {
          LemmaToNatLeftEqToNatRight(xs);
        }
      }

      lemma /*{:_induction xs}*/ LemmaSeqLen1(xs: seq<digit>)
        requires |xs| == 1
        ensures ToNatRight(xs) == First(xs)
        decreases xs
      {
        reveal ToNatRight();
        assert ToNatRight(DropFirst(xs)) == 0;
      }

      lemma /*{:_induction xs}*/ LemmaSeqLen2(xs: seq<digit>)
        requires |xs| == 2
        ensures ToNatRight(xs) == First(xs) + xs[1] * BASE()
        decreases xs
      {
        reveal ToNatRight();
        LemmaSeqLen1(DropLast(xs));
      }

      lemma /*{:_induction xs}*/ LemmaSeqAppendZero(xs: seq<digit>)
        ensures ToNatRight(xs + [0]) == ToNatRight(xs)
        decreases xs
      {
        reveal ToNatLeft();
        LemmaToNatLeftEqToNatRightAuto();
        calc {
          ToNatRight(xs + [0]);
          ToNatLeft(xs + [0]);
          ToNatLeft(xs) + 0 * Pow(BASE(), |xs|);
          {
            LemmaMulBasicsAuto();
          }
          ToNatLeft(xs);
          ToNatRight(xs);
        }
      }

      lemma /*{:_induction xs}*/ LemmaSeqNatBound(xs: seq<digit>)
        ensures ToNatRight(xs) < Pow(BASE(), |xs|)
        decreases xs
      {
        reveal Pow();
        if |xs| == 0 {
          reveal ToNatRight();
        } else {
          ghost var len' := |xs| - 1;
          ghost var pow := Pow(BASE(), len');
          calc {
            ToNatRight(xs);
            {
              LemmaToNatLeftEqToNatRight(xs);
            }
            ToNatLeft(xs);
            {
              reveal ToNatLeft();
            }
            ToNatLeft(DropLast(xs)) + Last(xs) * pow;
          <
            {
              LemmaToNatLeftEqToNatRight(DropLast(xs));
              LemmaSeqNatBound(DropLast(xs));
            }
            pow + Last(xs) * pow;
          <=
            {
              LemmaPowPositiveAuto();
              LemmaMulInequalityAuto();
            }
            pow + (BASE() - 1) * pow;
            {
              LemmaMulIsDistributiveAuto();
            }
            Pow(BASE(), len' + 1);
          }
        }
      }

      lemma {:isolate_assertions} /*{:_induction xs, i}*/ LemmaSeqPrefix(xs: seq<digit>, i: nat)
        requires 0 <= i <= |xs|
        ensures ToNatRight(xs[..i]) + ToNatRight(xs[i..]) * Pow(BASE(), i) == ToNatRight(xs)
        decreases xs, i
      {
        reveal ToNatRight();
        reveal Pow();
        if i == 1 {
          assert ToNatRight(xs[..1]) == First(xs);
        } else if i > 1 {
          calc {
            ToNatRight(xs[..i]) + ToNatRight(xs[i..]) * Pow(BASE(), i);
            ToNatRight(DropFirst(xs[..i])) * BASE() + First(xs) + ToNatRight(xs[i..]) * Pow(BASE(), i);
            {
              assert DropFirst(xs[..i]) == DropFirst(xs)[..i - 1];
              LemmaMulProperties();
            }
            ToNatRight(DropFirst(xs)[..i - 1]) * BASE() + First(xs) + ToNatRight(xs[i..]) * Pow(BASE(), i - 1) * BASE();
            {
              LemmaMulIsDistributiveAddOtherWayAuto();
            }
            (ToNatRight(DropFirst(xs)[..i - 1]) + ToNatRight(DropFirst(xs)[i - 1..]) * Pow(BASE(), i - 1)) * BASE() + First(xs);
            {
              LemmaSeqPrefix(DropFirst(xs), i - 1);
            }
            ToNatRight(xs);
          }
        }
      }

      lemma /*{:_induction xs, ys}*/ LemmaSeqMswInequality(xs: seq<digit>, ys: seq<digit>)
        requires |xs| == |ys| > 0
        requires Last(xs) < Last(ys)
        ensures ToNatRight(xs) < ToNatRight(ys)
        decreases xs, ys
      {
        reveal ToNatLeft();
        LemmaToNatLeftEqToNatRightAuto();
        ghost var len' := |xs| - 1;
        calc {
          ToNatRight(xs);
          ToNatLeft(xs);
        <
          {
            LemmaSeqNatBound(DropLast(xs));
          }
          Pow(BASE(), len') + Last(xs) * Pow(BASE(), len');
        ==
          {
            LemmaMulIsDistributiveAuto();
          }
          (1 + Last(xs)) * Pow(BASE(), len');
        <=
          {
            LemmaPowPositiveAuto();
            LemmaMulInequalityAuto();
          }
          ToNatLeft(ys);
          ToNatRight(ys);
        }
      }

      lemma {:isolate_assertions} /*{:_induction xs, ys}*/ LemmaSeqPrefixNeq(xs: seq<digit>, ys: seq<digit>, i: nat)
        requires 0 <= i <= |xs| == |ys|
        requires ToNatRight(xs[..i]) != ToNatRight(ys[..i])
        ensures ToNatRight(xs) != ToNatRight(ys)
        decreases |xs| - i
      {
        if i == |xs| {
          assert xs[..i] == xs;
          assert ys[..i] == ys;
        } else {
          if xs[i] == ys[i] {
            reveal ToNatLeft();
            assert DropLast(xs[..i + 1]) == xs[..i];
            assert DropLast(ys[..i + 1]) == ys[..i];
            LemmaToNatLeftEqToNatRightAuto();
            assert ToNatRight(xs[..i + 1]) == ToNatLeft(xs[..i + 1]);
          } else if xs[i] < ys[i] {
            LemmaSeqMswInequality(xs[..i + 1], ys[..i + 1]);
          } else {
            LemmaSeqMswInequality(ys[..i + 1], xs[..i + 1]);
          }
          reveal ToNatRight();
          LemmaSeqPrefixNeq(xs, ys, i + 1);
        }
      }

      lemma /*{:_induction xs, ys}*/ LemmaSeqNeq(xs: seq<digit>, ys: seq<digit>)
        requires |xs| == |ys|
        requires xs != ys
        ensures ToNatRight(xs) != ToNatRight(ys)
        decreases xs, ys
      {
        ghost var i: nat, n: nat := 0, |xs|;
        while i < n
          invariant 0 <= i < n
          invariant xs[..i] == ys[..i]
          decreases n - i
        {
          if xs[i] != ys[i] {
            break;
          }
          i := i + 1;
        }
        assert ToNatLeft(xs[..i]) == ToNatLeft(ys[..i]);
        reveal ToNatLeft();
        assert xs[..i + 1][..i] == xs[..i];
        assert ys[..i + 1][..i] == ys[..i];
        LemmaPowPositiveAuto();
        LemmaMulStrictInequalityAuto();
        assert ToNatLeft(xs[..i + 1]) != ToNatLeft(ys[..i + 1]);
        LemmaToNatLeftEqToNatRightAuto();
        LemmaSeqPrefixNeq(xs, ys, i + 1);
      }

      lemma /*{:_induction xs, ys}*/ LemmaSeqEq(xs: seq<digit>, ys: seq<digit>)
        requires |xs| == |ys|
        requires ToNatRight(xs) == ToNatRight(ys)
        ensures xs == ys
        decreases xs, ys
      {
        calc ==> {
          xs != ys;
          {
            LemmaSeqNeq(xs, ys);
          }
          ToNatRight(xs) != ToNatRight(ys);
          false;
        }
      }

      lemma {:isolate_assertions} /*{:_induction xs}*/ LemmaSeqLswModEquivalence(xs: seq<digit>)
        requires |xs| >= 1
        ensures IsModEquivalent(ToNatRight(xs), First(xs), BASE())
        decreases xs
      {
        if |xs| == 1 {
          LemmaSeqLen1(xs);
          LemmaModEquivalenceAuto();
        } else {
          assert IsModEquivalent(ToNatRight(xs), First(xs), BASE()) by {
            reveal ToNatRight();
            calc ==> {
              true;
              {
                LemmaModEquivalence(ToNatRight(xs), ToNatRight(DropFirst(xs)) * BASE() + First(xs), BASE());
              }
              IsModEquivalent(ToNatRight(xs), ToNatRight(DropFirst(xs)) * BASE() + First(xs), BASE());
              {
                LemmaModMultiplesBasicAuto();
              }
              IsModEquivalent(ToNatRight(xs), First(xs), BASE());
            }
          }
        }
      }

      function {:opaque} FromNat(n: nat): (xs: seq<digit>)
        decreases n
      {
        if n == 0 then
          []
        else
          LemmaDivBasicsAuto(); LemmaDivDecreasesAuto(); [n % BASE()] + FromNat(n / BASE())
      }

      lemma /*{:_induction n}*/ LemmaFromNatLen2(n: nat)
        ensures n == 0 ==> |FromNat(n)| == 0
        ensures n > 0 ==> |FromNat(n)| == Log(BASE(), n) + 1
        decreases n
      {
        reveal FromNat();
        ghost var digits := FromNat(n);
        if n == 0 {
        } else {
          assert |digits| == Log(BASE(), n) + 1 by {
            LemmaDivBasicsAuto();
            ghost var digits' := FromNat(n / BASE());
            assert |digits| == |digits'| + 1;
            if n < BASE() {
              LemmaLog0(BASE(), n);
              assert n / BASE() == 0 by {
                LemmaBasicDiv(BASE());
              }
            } else {
              LemmaLogS(BASE(), n);
              assert n / BASE() > 0 by {
                LemmaDivNonZeroAuto();
              }
            }
          }
        }
      }

      lemma /*{:_induction n, len}*/ LemmaFromNatLen(n: nat, len: nat)
        requires Pow(BASE(), len) > n
        ensures |FromNat(n)| <= len
        decreases n, len
      {
        reveal FromNat();
        if n == 0 {
        } else {
          calc {
            |FromNat(n)|;
          ==
            {
              LemmaDivBasicsAuto();
            }
            1 + |FromNat(n / BASE())|;
          <=
            {
              LemmaMultiplyDivideLtAuto();
              LemmaDivDecreasesAuto();
              reveal Pow();
              LemmaFromNatLen(n / BASE(), len - 1);
            }
            len;
          }
        }
      }

      lemma /*{:_induction n}*/ LemmaNatSeqNat(n: nat)
        ensures ToNatRight(FromNat(n)) == n
        decreases n
      {
        reveal ToNatRight();
        reveal FromNat();
        if n == 0 {
        } else {
          calc {
            ToNatRight(FromNat(n));
            {
              LemmaDivBasicsAuto();
            }
            ToNatRight([n % BASE()] + FromNat(n / BASE()));
            n % BASE() + ToNatRight(FromNat(n / BASE())) * BASE();
            {
              LemmaDivDecreasesAuto();
              LemmaNatSeqNat(n / BASE());
            }
            n % BASE() + n / BASE() * BASE();
            {
              LemmaFundamentalDivMod(n, BASE());
            }
            n;
          }
        }
      }

      function {:opaque} SeqExtend(xs: seq<digit>, n: nat): (ys: seq<digit>)
        requires |xs| <= n
        ensures |ys| == n
        ensures ToNatRight(ys) == ToNatRight(xs)
        decreases n - |xs|
      {
        if |xs| >= n then
          xs
        else
          LemmaSeqAppendZero(xs); SeqExtend(xs + [0], n)
      }

      function {:opaque} SeqExtendMultiple(xs: seq<digit>, n: nat): (ys: seq<digit>)
        requires n > 0
        ensures |ys| % n == 0
        ensures ToNatRight(ys) == ToNatRight(xs)
        decreases xs, n
      {
        var newLen: int := |xs| + n - |xs| % n;
        LemmaSubModNoopRight(|xs| + n, |xs|, n);
        LemmaModBasicsAuto();
        assert newLen % n == 0;
        LemmaSeqNatBound(xs);
        LemmaPowIncreasesAuto();
        SeqExtend(xs, newLen)
      }

      function {:opaque} FromNatWithLen(n: nat, len: nat): (xs: seq<digit>)
        requires Pow(BASE(), len) > n
        ensures |xs| == len
        ensures ToNatRight(xs) == n
        decreases n, len
      {
        LemmaFromNatLen(n, len);
        LemmaNatSeqNat(n);
        SeqExtend(FromNat(n), len)
      }

      lemma {:resource_limit ""10e6""} /*{:_induction xs}*/ LemmaSeqZero(xs: seq<digit>)
        requires ToNatRight(xs) == 0
        ensures forall i: int {:trigger xs[i]} :: 0 <= i < |xs| ==> xs[i] == 0
        decreases xs
      {
        reveal ToNatRight();
        if |xs| == 0 {
        } else {
          LemmaMulNonnegativeAuto();
          assert First(xs) == 0;
          LemmaMulNonzeroAuto();
          LemmaSeqZero(DropFirst(xs));
        }
      }

      function {:opaque} SeqZero(len: nat): (xs: seq<digit>)
        ensures |xs| == len
        ensures forall i: int {:trigger xs[i]} :: 0 <= i < |xs| ==> xs[i] == 0
        ensures ToNatRight(xs) == 0
        decreases len
      {
        LemmaPowPositive(BASE(), len);
        var xs: seq<digit> := FromNatWithLen(0, len);
        LemmaSeqZero(xs);
        xs
      }

      lemma /*{:_induction xs}*/ LemmaSeqNatSeq(xs: seq<digit>)
        ensures Pow(BASE(), |xs|) > ToNatRight(xs)
        ensures FromNatWithLen(ToNatRight(xs), |xs|) == xs
        decreases xs
      {
        reveal FromNat();
        reveal ToNatRight();
        LemmaSeqNatBound(xs);
        if |xs| > 0 {
          calc {
            FromNatWithLen(ToNatRight(xs), |xs|) != xs;
            {
              LemmaSeqNeq(FromNatWithLen(ToNatRight(xs), |xs|), xs);
            }
            ToNatRight(FromNatWithLen(ToNatRight(xs), |xs|)) != ToNatRight(xs);
            ToNatRight(xs) != ToNatRight(xs);
            false;
          }
        }
      }

      function {:opaque} SeqAdd(xs: seq<digit>, ys: seq<digit>): (seq<digit>, nat)
        requires |xs| == |ys|
        ensures var (zs: seq<digit>, cout: nat) := SeqAdd(xs, ys); |zs| == |xs| && 0 <= cout <= 1
        decreases xs
      {
        if |xs| == 0 then
          ([], 0)
        else
          var (zs': seq<digit>, cin: nat) := SeqAdd(DropLast(xs), DropLast(ys)); var sum: int := Last(xs) + Last(ys) + cin; var (sum_out: int, cout: int) := if sum < BASE() then (sum, 0) else (sum - BASE(), 1); (zs' + [sum_out], cout)
      }

      lemma {:isolate_assertions} /*{:_induction xs, ys, zs}*/ LemmaSeqAdd(xs: seq<digit>, ys: seq<digit>, zs: seq<digit>, cout: nat)
        requires |xs| == |ys|
        requires SeqAdd(xs, ys) == (zs, cout)
        ensures ToNatRight(xs) + ToNatRight(ys) == ToNatRight(zs) + cout * Pow(BASE(), |xs|)
        decreases xs, ys, zs, cout
      {
        reveal SeqAdd();
        if |xs| == 0 {
          reveal ToNatRight();
        } else {
          ghost var pow := Pow(BASE(), |xs| - 1);
          var (zs', cin) := SeqAdd(DropLast(xs), DropLast(ys));
          ghost var sum: int := Last(xs) + Last(ys) + cin;
          ghost var z := if sum < BASE() then sum else sum - BASE();
          assert sum == z + cout * BASE();
          reveal ToNatLeft();
          LemmaToNatLeftEqToNatRightAuto();
          calc {
            ToNatRight(zs);
            ToNatLeft(zs);
            ToNatLeft(zs') + z * pow;
            {
              LemmaSeqAdd(DropLast(xs), DropLast(ys), zs', cin);
            }
            ToNatLeft(DropLast(xs)) + ToNatLeft(DropLast(ys)) - cin * pow + z * pow;
            {
              LemmaMulEquality(sum, z + cout * BASE(), pow);
              assert sum * pow == (z + cout * BASE()) * pow;
              LemmaMulIsDistributiveAuto();
            }
            ToNatLeft(xs) + ToNatLeft(ys) - cout * BASE() * pow;
            {
              LemmaMulIsAssociative(cout, BASE(), pow);
              reveal Pow();
            }
            ToNatLeft(xs) + ToNatLeft(ys) - cout * Pow(BASE(), |xs|);
            ToNatRight(xs) + ToNatRight(ys) - cout * Pow(BASE(), |xs|);
          }
        }
      }

      function {:opaque} SeqSub(xs: seq<digit>, ys: seq<digit>): (seq<digit>, nat)
        requires |xs| == |ys|
        ensures var (zs: seq<digit>, cout: nat) := SeqSub(xs, ys); |zs| == |xs| && 0 <= cout <= 1
        decreases xs
      {
        if |xs| == 0 then
          ([], 0)
        else
          var (zs: seq<digit>, cin: nat) := SeqSub(DropLast(xs), DropLast(ys)); var (diff_out: int, cout: int) := if Last(xs) >= Last(ys) + cin then (Last(xs) - Last(ys) - cin, 0) else (BASE() + Last(xs) - Last(ys) - cin, 1); (zs + [diff_out], cout)
      }

      lemma {:isolate_assertions} /*{:_induction xs, ys, zs}*/ LemmaSeqSub(xs: seq<digit>, ys: seq<digit>, zs: seq<digit>, cout: nat)
        requires |xs| == |ys|
        requires SeqSub(xs, ys) == (zs, cout)
        ensures ToNatRight(xs) - ToNatRight(ys) + cout * Pow(BASE(), |xs|) == ToNatRight(zs)
        decreases xs, ys, zs, cout
      {
        reveal SeqSub();
        if |xs| == 0 {
          reveal ToNatRight();
        } else {
          ghost var pow := Pow(BASE(), |xs| - 1);
          var (zs', cin) := SeqSub(DropLast(xs), DropLast(ys));
          ghost var z := if Last(xs) >= Last(ys) + cin then Last(xs) - Last(ys) - cin else BASE() + Last(xs) - Last(ys) - cin;
          assert cout * BASE() + Last(xs) - cin - Last(ys) == z;
          reveal ToNatLeft();
          LemmaToNatLeftEqToNatRightAuto();
          calc {
            ToNatRight(zs);
            ToNatLeft(zs);
            ToNatLeft(zs') + z * pow;
            {
              LemmaSeqSub(DropLast(xs), DropLast(ys), zs', cin);
            }
            ToNatLeft(DropLast(xs)) - ToNatLeft(DropLast(ys)) + cin * pow + z * pow;
            {
              LemmaMulEquality(cout * BASE() + Last(xs) - cin - Last(ys), z, pow);
              assert pow * (cout * BASE() + Last(xs) - cin - Last(ys)) == pow * z;
              LemmaMulIsDistributiveAuto();
            }
            ToNatLeft(xs) - ToNatLeft(ys) + cout * BASE() * pow;
            {
              LemmaMulIsAssociative(cout, BASE(), pow);
              reveal Pow();
            }
            ToNatLeft(xs) - ToNatLeft(ys) + cout * Pow(BASE(), |xs|);
            ToNatRight(xs) - ToNatRight(ys) + cout * Pow(BASE(), |xs|);
          }
        }
      }

      import opened DivMod

      import opened Mul

      import opened Power

      import opened Seq = Collections.Seq

      import opened Logarithm

      type digit = i: nat
        | 0 <= i < BASE()
    }

    module {:disableNonlinearArithmetic} Logarithm {
      function {:opaque} Log(base: nat, pow: nat): nat
        requires base > 1
        decreases pow
      {
        if pow < base then
          0
        else
          LemmaDivPosIsPosAuto(); LemmaDivDecreasesAuto(); 1 + Log(base, pow / base)
      }

      lemma {:induction false} LemmaLog0(base: nat, pow: nat)
        requires base > 1
        requires pow < base
        ensures Log(base, pow) == 0
        decreases base, pow
      {
        reveal Log();
      }

      lemma {:induction false} LemmaLogS(base: nat, pow: nat)
        requires base > 1
        requires pow >= base
        ensures pow / base >= 0
        ensures Log(base, pow) == 1 + Log(base, pow / base)
        decreases base, pow
      {
        LemmaDivPosIsPosAuto();
        reveal Log();
      }

      lemma {:induction false} LemmaLogSAuto()
        ensures forall pow: nat, base: nat {:trigger Log(base, pow / base)} | base > 1 && pow >= base :: pow / base >= 0 && Log(base, pow) == 1 + Log(base, pow / base)
      {
        forall base: nat, pow: nat | base > 1 && pow >= base
          ensures pow / base >= 0 && Log(base, pow) == 1 + Log(base, pow / base)
        {
          LemmaLogS(base, pow);
        }
      }

      lemma {:induction false} LemmaLogIsOrdered(base: nat, pow: nat, pow': nat)
        requires base > 1
        requires pow <= pow'
        ensures Log(base, pow) <= Log(base, pow')
        decreases pow
      {
        reveal Log();
        if pow' < base {
          assert Log(base, pow) == 0 == Log(base, pow');
        } else if pow < base {
          assert Log(base, pow) == 0;
        } else {
          LemmaDivPosIsPosAuto();
          LemmaDivDecreasesAuto();
          LemmaDivIsOrderedAuto();
          LemmaLogIsOrdered(base, pow / base, pow' / base);
        }
      }

      lemma {:induction false} LemmaLogPow(base: nat, n: nat)
        requires base > 1
        ensures (LemmaPowPositive(base, n); Log(base, Pow(base, n)) == n)
        decreases base, n
      {
        if n == 0 {
          reveal Pow();
          reveal Log();
        } else {
          LemmaPowPositive(base, n);
          calc {
            Log(base, Pow(base, n));
            {
              reveal Pow();
            }
            Log(base, base * Pow(base, n - 1));
            {
              LemmaPowPositive(base, n - 1);
              LemmaMulIncreases(Pow(base, n - 1), base);
              LemmaMulIsCommutative(Pow(base, n - 1), base);
              LemmaLogS(base, base * Pow(base, n - 1));
            }
            1 + Log(base, base * Pow(base, n - 1) / base);
            {
              LemmaDivMultiplesVanish(Pow(base, n - 1), base);
            }
            1 + Log(base, Pow(base, n - 1));
            {
              LemmaLogPow(base, n - 1);
            }
            1 + n - 1;
          }
        }
      }

      import opened Mul

      import opened DivMod

      import opened Power
    }

    module {:disableNonlinearArithmetic} Mul {
      lemma LemmaMulIsMulRecursive(x: int, y: int)
        ensures x * y == MulRecursive(x, y)
        decreases x, y
      {
        if x >= 0 {
          LemmaMulIsMulPos(x, y);
        }
        if x <= 0 {
          LemmaMulIsMulPos(-x, y);
        }
        LemmaMulAuto();
      }

      lemma LemmaMulIsMulRecursiveAuto()
        ensures forall x: int, y: int {:trigger MulRecursive(x, y)} :: x * y == MulRecursive(x, y)
      {
        forall x: int, y: int | true
          ensures x * y == MulRecursive(x, y)
        {
          LemmaMulIsMulRecursive(x, y);
        }
      }

      lemma /*{:_induction x, y}*/ LemmaMulIsMulPos(x: int, y: int)
        requires x >= 0
        ensures x * y == MulPos(x, y)
        decreases x, y
      {
        reveal MulPos();
        LemmaMulInductionAuto(x, (u: int) => u >= 0 ==> u * y == MulPos(u, y));
      }

      lemma LemmaMulBasics(x: int)
        ensures 0 * x == 0
        ensures x * 0 == 0
        ensures 1 * x == x
        ensures x * 1 == x
        decreases x
      {
      }

      lemma LemmaMulBasicsAuto()
        ensures forall x: int {:trigger 0 * x} :: 0 * x == 0
        ensures forall x: int {:trigger x * 0} :: x * 0 == 0
        ensures forall x: int {:trigger 1 * x} :: 1 * x == x
        ensures forall x: int {:trigger x * 1} :: x * 1 == x
      {
      }

      lemma LemmaMulNonzero(x: int, y: int)
        ensures x * y != 0 <==> x != 0 && y != 0
        decreases x, y
      {
        MulINL.LemmaMulNonzero(x, y);
      }

      lemma LemmaMulNonzeroAuto()
        ensures forall x: int, y: int {:trigger x * y} :: x * y != 0 <==> x != 0 && y != 0
      {
        forall x: int, y: int | true
          ensures x * y != 0 <==> x != 0 && y != 0
        {
          LemmaMulNonzero(x, y);
        }
      }

      lemma LemmaMulByZeroIsZeroAuto()
        ensures forall x: int {:trigger 0 * x} {:trigger x * 0} :: x * 0 == 0 * x && 0 * x == 0
      {
        forall x: int {:trigger 0 * x} {:trigger x * 0} | true
          ensures x * 0 == 0 * x == 0
        {
          LemmaMulBasics(x);
        }
      }

      lemma LemmaMulIsAssociative(x: int, y: int, z: int)
        ensures x * y * z == x * y * z
        decreases x, y, z
      {
        MulINL.LemmaMulIsAssociative(x, y, z);
      }

      lemma LemmaMulIsAssociativeAuto()
        ensures forall x: int, y: int, z: int {:trigger x * y * z} {:trigger x * y * z} :: x * y * z == x * y * z
      {
        forall x: int, y: int, z: int | true
          ensures x * y * z == x * y * z
        {
          LemmaMulIsAssociative(x, y, z);
        }
      }

      lemma LemmaMulIsCommutative(x: int, y: int)
        ensures x * y == y * x
        decreases x, y
      {
      }

      lemma LemmaMulIsCommutativeAuto()
        ensures forall x: int, y: int {:trigger x * y} :: x * y == y * x
      {
      }

      lemma LemmaMulOrdering(x: int, y: int)
        requires x != 0
        requires y != 0
        requires 0 <= x * y
        ensures x * y >= x && x * y >= y
        decreases x, y
      {
        MulINL.LemmaMulOrdering(x, y);
      }

      lemma LemmaMulOrderingAuto()
        ensures forall x: int, y: int {:trigger x * y} :: (0 != x && 0 != y && x * y >= 0 ==> x * y >= x) && (0 != x && 0 != y && x * y >= 0 ==> x * y >= y)
      {
        forall x: int, y: int | 0 != x && 0 != y && x * y >= 0
          ensures x * y >= x && x * y >= y
        {
          LemmaMulOrdering(x, y);
        }
      }

      lemma LemmaMulEquality(x: int, y: int, z: int)
        requires x == y
        ensures x * z == y * z
        decreases x, y, z
      {
      }

      lemma LemmaMulEqualityAuto()
        ensures forall x: int, y: int, z: int {:trigger x * z, y * z} :: x == y ==> x * z == y * z
      {
        forall x: int, y: int, z: int | x == y
          ensures x * z == y * z
        {
          LemmaMulEquality(x, y, z);
        }
      }

      lemma LemmaMulInequality(x: int, y: int, z: int)
        requires x <= y
        requires z >= 0
        ensures x * z <= y * z
        decreases x, y, z
      {
        LemmaMulInductionAuto(z, (u: int) => u >= 0 ==> x * u <= y * u);
      }

      lemma LemmaMulInequalityAuto()
        ensures forall x: int, y: int, z: int {:trigger x * z, y * z} :: x <= y && z >= 0 ==> x * z <= y * z
      {
        forall x: int, y: int, z: int | x <= y && z >= 0
          ensures x * z <= y * z
        {
          LemmaMulInequality(x, y, z);
        }
      }

      lemma LemmaMulStrictInequality(x: int, y: int, z: int)
        requires x < y
        requires z > 0
        ensures x * z < y * z
        decreases x, y, z
      {
        MulINL.LemmaMulStrictInequality(x, y, z);
      }

      lemma LemmaMulStrictInequalityAuto()
        ensures forall x: int, y: int, z: int {:trigger x * z, y * z} :: x < y && z > 0 ==> x * z < y * z
      {
        forall x: int, y: int, z: int | x < y && z > 0
          ensures x * z < y * z
        {
          LemmaMulStrictInequality(x, y, z);
        }
      }

      lemma LemmaMulUpperBound(x: int, XBound: int, y: int, YBound: int)
        requires x <= XBound
        requires y <= YBound
        requires 0 <= x
        requires 0 <= y
        ensures x * y <= XBound * YBound
        decreases x, XBound, y, YBound
      {
        LemmaMulInequality(x, XBound, y);
        LemmaMulInequality(y, YBound, XBound);
      }

      lemma LemmaMulUpperBoundAuto()
        ensures forall YBound: int, y: int, XBound: int, x: int {:trigger x * y, XBound * YBound} :: x <= XBound && y <= YBound && 0 <= x && 0 <= y ==> x * y <= XBound * YBound
      {
        forall x: int, XBound: int, y: int, YBound: int | x <= XBound && y <= YBound && 0 <= x && 0 <= y
          ensures x * y <= XBound * YBound
        {
          LemmaMulUpperBound(x, XBound, y, YBound);
        }
      }

      lemma LemmaMulStrictUpperBound(x: int, XBound: int, y: int, YBound: int)
        requires x < XBound
        requires y < YBound
        requires 0 < x
        requires 0 < y
        ensures x * y <= (XBound - 1) * (YBound - 1)
        decreases x, XBound, y, YBound
      {
        LemmaMulInequality(x, XBound - 1, y);
        LemmaMulInequality(y, YBound - 1, XBound - 1);
      }

      lemma LemmaMulStrictUpperBoundAuto()
        ensures forall YBound: int, y: int, XBound: int, x: int {:trigger x * y, (XBound - 1) * (YBound - 1)} :: x < XBound && y < YBound && 0 < x && 0 < y ==> x * y <= (XBound - 1) * (YBound - 1)
      {
        forall x: int, XBound: int, y: int, YBound: int {:trigger (XBound - 1) * (YBound - 1), x * y} {:trigger YBound - 1, XBound - 1, 0 < y, 0 < x} {:trigger YBound - 1, 0 < y, x < XBound} {:trigger XBound - 1, 0 < x, y < YBound} {:trigger y < YBound, x < XBound} | x < XBound && y < YBound && 0 < x && 0 < y
          ensures x * y <= (XBound - 1) * (YBound - 1)
        {
          LemmaMulStrictUpperBound(x, XBound, y, YBound);
        }
      }

      lemma LemmaMulLeftInequality(x: int, y: int, z: int)
        requires 0 < x
        ensures y <= z ==> x * y <= x * z
        ensures y < z ==> x * y < x * z
        decreases x, y, z
      {
        LemmaMulInductionAuto(x, (u: int) => u > 0 ==> y <= z ==> u * y <= u * z);
        LemmaMulInductionAuto(x, (u: int) => u > 0 ==> y < z ==> u * y < u * z);
      }

      lemma LemmaMulLeftInequalityAuto()
        ensures (forall x: int, y: int, z: int {:trigger x * y, x * z} :: x > 0 ==> y <= z ==> x * y <= x * z) && forall x: int, y: int, z: int {:trigger x * y, x * z} :: x > 0 ==> y < z ==> x * y < x * z
      {
        forall x: int, y: int, z: int | (y <= z || y < z) && 0 < x
          ensures (y <= z ==> x * y <= x * z) && (y < z ==> x * y < x * z)
        {
          LemmaMulLeftInequality(x, y, z);
        }
      }

      lemma LemmaMulEqualityConverse(m: int, x: int, y: int)
        requires m != 0
        requires m * x == m * y
        ensures x == y
        decreases m, x, y
      {
        LemmaMulInductionAuto(m, (u: int) => x > y && 0 < u ==> x * u > y * u);
        LemmaMulInductionAuto(m, (u: int) => x > y && 0 > u ==> x * u < y * u);
        LemmaMulInductionAuto(m, (u: int) => x < y && 0 < u ==> x * u < y * u);
        LemmaMulInductionAuto(m, (u: int) => x < y && 0 > u ==> x * u > y * u);
      }

      lemma LemmaMulEqualityConverseAuto()
        ensures forall m: int, x: int, y: int {:trigger m * x, m * y} :: m != 0 && m * x == m * y ==> x == y
      {
        forall m: int, x: int, y: int | m != 0 && m * x == m * y
          ensures x == y
        {
          LemmaMulEqualityConverse(m, x, y);
        }
      }

      lemma LemmaMulInequalityConverse(x: int, y: int, z: int)
        requires x * z <= y * z
        requires z > 0
        ensures x <= y
        decreases x, y, z
      {
        LemmaMulInductionAuto(z, (u: int) => x * u <= y * u && u > 0 ==> x <= y);
      }

      lemma LemmaMulInequalityConverseAuto()
        ensures forall x: int, y: int, z: int {:trigger x * z, y * z} :: x * z <= y * z && z > 0 ==> x <= y
      {
        forall x: int, y: int, z: int | x * z <= y * z && z > 0
          ensures x <= y
        {
          LemmaMulInequalityConverse(x, y, z);
        }
      }

      lemma LemmaMulStrictInequalityConverse(x: int, y: int, z: int)
        requires x * z < y * z
        requires z >= 0
        ensures x < y
        decreases x, y, z
      {
        LemmaMulInductionAuto(z, (u: int) => x * u < y * u && u >= 0 ==> x < y);
      }

      lemma LemmaMulStrictInequalityConverseAuto()
        ensures forall x: int, y: int, z: int {:trigger x * z, y * z} :: x * z < y * z && z >= 0 ==> x < y
      {
        forall x: int, y: int, z: int | x * z < y * z && z >= 0
          ensures x < y
        {
          LemmaMulStrictInequalityConverse(x, y, z);
        }
      }

      lemma LemmaMulIsDistributiveAdd(x: int, y: int, z: int)
        ensures x * (y + z) == x * y + x * z
        decreases x, y, z
      {
        MulINL.LemmaMulIsDistributiveAdd(x, y, z);
      }

      lemma LemmaMulIsDistributiveAddAuto()
        ensures forall x: int, y: int, z: int {:trigger x * (y + z)} :: x * (y + z) == x * y + x * z
      {
        forall x: int, y: int, z: int | true
          ensures x * (y + z) == x * y + x * z
        {
          LemmaMulIsDistributiveAdd(x, y, z);
        }
      }

      lemma LemmaMulIsDistributiveAddOtherWay(x: int, y: int, z: int)
        ensures (y + z) * x == y * x + z * x
        decreases x, y, z
      {
        LemmaMulAuto();
      }

      lemma LemmaMulIsDistributiveAddOtherWayAuto()
        ensures forall x: int, y: int, z: int {:trigger (y + z) * x} :: (y + z) * x == y * x + z * x
      {
        forall x: int, y: int, z: int | true
          ensures (y + z) * x == y * x + z * x
        {
          LemmaMulIsDistributiveAddOtherWay(x, y, z);
        }
      }

      lemma LemmaMulIsDistributiveSub(x: int, y: int, z: int)
        ensures x * (y - z) == x * y - x * z
        decreases x, y, z
      {
        LemmaMulAuto();
      }

      lemma LemmaMulIsDistributiveSubAuto()
        ensures forall x: int, y: int, z: int {:trigger x * (y - z)} :: x * (y - z) == x * y - x * z
      {
        forall x: int, y: int, z: int | true
          ensures x * (y - z) == x * y - x * z
        {
          LemmaMulIsDistributiveSub(x, y, z);
        }
      }

      lemma LemmaMulIsDistributive(x: int, y: int, z: int)
        ensures x * (y + z) == x * y + x * z
        ensures x * (y - z) == x * y - x * z
        ensures (y + z) * x == y * x + z * x
        ensures (y - z) * x == y * x - z * x
        ensures x * (y + z) == (y + z) * x
        ensures x * (y - z) == (y - z) * x
        ensures x * y == y * x
        ensures x * z == z * x
        decreases x, y, z
      {
        LemmaMulAuto();
      }

      lemma LemmaMulIsDistributiveAuto()
        ensures forall x: int, y: int, z: int {:trigger x * (y + z)} :: x * (y + z) == x * y + x * z
        ensures forall x: int, y: int, z: int {:trigger x * (y - z)} :: x * (y - z) == x * y - x * z
        ensures forall x: int, y: int, z: int {:trigger (y + z) * x} :: (y + z) * x == y * x + z * x
        ensures forall x: int, y: int, z: int {:trigger (y - z) * x} :: (y - z) * x == y * x - z * x
      {
        LemmaMulIsDistributiveAddAuto();
        LemmaMulIsDistributiveSubAuto();
        LemmaMulIsCommutativeAuto();
      }

      lemma LemmaMulStrictlyPositive(x: int, y: int)
        ensures 0 < x && 0 < y ==> 0 < x * y
        decreases x, y
      {
        MulINL.LemmaMulStrictlyPositive(x, y);
      }

      lemma LemmaMulStrictlyPositiveAuto()
        ensures forall x: int, y: int {:trigger x * y} :: 0 < x && 0 < y ==> 0 < x * y
      {
        forall x: int, y: int | 0 < x && 0 < y
          ensures 0 < x * y
        {
          LemmaMulStrictlyPositive(x, y);
        }
      }

      lemma LemmaMulStrictlyIncreases(x: int, y: int)
        requires 1 < x
        requires 0 < y
        ensures y < x * y
        decreases x, y
      {
        LemmaMulInductionAuto(x, (u: int) => 1 < u ==> y < u * y);
      }

      lemma LemmaMulStrictlyIncreasesAuto()
        ensures forall x: int, y: int {:trigger x * y} :: 1 < x && 0 < y ==> y < x * y
      {
        forall x: int, y: int | 1 < x && 0 < y
          ensures y < x * y
        {
          LemmaMulStrictlyIncreases(x, y);
        }
      }

      lemma LemmaMulIncreases(x: int, y: int)
        requires 0 < x
        requires 0 < y
        ensures y <= x * y
        decreases x, y
      {
        LemmaMulInductionAuto(x, (u: int) => 0 < u ==> y <= u * y);
      }

      lemma LemmaMulIncreasesAuto()
        ensures forall x: int, y: int {:trigger x * y} :: 0 < x && 0 < y ==> y <= x * y
      {
        forall x: int, y: int | 0 < x && 0 < y
          ensures y <= x * y
        {
          LemmaMulIncreases(x, y);
        }
      }

      lemma LemmaMulNonnegative(x: int, y: int)
        requires 0 <= x
        requires 0 <= y
        ensures 0 <= x * y
        decreases x, y
      {
        LemmaMulInductionAuto(x, (u: int) => 0 <= u ==> 0 <= u * y);
      }

      lemma LemmaMulNonnegativeAuto()
        ensures forall x: int, y: int {:trigger x * y} :: 0 <= x && 0 <= y ==> 0 <= x * y
      {
        forall x: int, y: int | 0 <= x && 0 <= y
          ensures 0 <= x * y
        {
          LemmaMulNonnegative(x, y);
        }
      }

      lemma LemmaMulUnaryNegation(x: int, y: int)
        ensures -x * y == -(x * y) == x * -y
        decreases x, y
      {
        LemmaMulInductionAuto(x, (u: int) => -u * y == -(u * y) == u * -y);
      }

      lemma LemmaMulUnaryNegationAuto()
        ensures forall x: int, y: int {:trigger -x * y} {:trigger x * -y} :: -x * y == -(x * y) && -(x * y) == x * -y
      {
        forall x: int, y: int | true
          ensures -x * y == -(x * y) == x * -y
        {
          LemmaMulUnaryNegation(x, y);
        }
      }

      lemma LemmaMulCancelsNegatives(x: int, y: int)
        ensures x * y == -x * -y
        decreases x, y
      {
        LemmaMulUnaryNegationAuto();
      }

      lemma LemmaMulCancelsNegativesAuto()
        ensures forall x: int, y: int {:trigger x * y} :: x * y == -x * -y
      {
        forall x: int, y: int | true
          ensures x * y == -x * -y
        {
          LemmaMulCancelsNegatives(x, y);
        }
      }

      lemma LemmaMulProperties()
        ensures forall x: int, y: int {:trigger x * y} :: x * y == y * x
        ensures forall x: int {:trigger x * 1} {:trigger 1 * x} :: x * 1 == 1 * x && 1 * x == x
        ensures forall x: int, y: int, z: int {:trigger x * z, y * z} :: x < y && z > 0 ==> x * z < y * z
        ensures forall x: int, y: int, z: int {:trigger x * z, y * z} :: x <= y && z >= 0 ==> x * z <= y * z
        ensures forall x: int, y: int, z: int {:trigger x * (y + z)} :: x * (y + z) == x * y + x * z
        ensures forall x: int, y: int, z: int {:trigger x * (y - z)} :: x * (y - z) == x * y - x * z
        ensures forall x: int, y: int, z: int {:trigger (y + z) * x} :: (y + z) * x == y * x + z * x
        ensures forall x: int, y: int, z: int {:trigger (y - z) * x} :: (y - z) * x == y * x - z * x
        ensures forall x: int, y: int, z: int {:trigger x * y * z} {:trigger x * y * z} :: x * y * z == x * y * z
        ensures forall x: int, y: int {:trigger x * y} :: x * y != 0 <==> x != 0 && y != 0
        ensures forall x: int, y: int {:trigger x * y} :: 0 <= x && 0 <= y ==> 0 <= x * y
        ensures forall x: int, y: int {:trigger x * y} :: (0 < x && 0 < y && 0 <= x * y ==> x <= x * y) && (0 < x && 0 < y && 0 <= x * y ==> y <= x * y)
        ensures forall x: int, y: int {:trigger x * y} :: 1 < x && 0 < y ==> y < x * y
        ensures forall x: int, y: int {:trigger x * y} :: 0 < x && 0 < y ==> y <= x * y
        ensures forall x: int, y: int {:trigger x * y} :: 0 < x && 0 < y ==> 0 < x * y
      {
        LemmaMulStrictInequalityAuto();
        LemmaMulInequalityAuto();
        LemmaMulIsDistributiveAuto();
        LemmaMulIsAssociativeAuto();
        LemmaMulOrderingAuto();
        LemmaMulNonzeroAuto();
        LemmaMulNonnegativeAuto();
        LemmaMulStrictlyIncreasesAuto();
        LemmaMulIncreasesAuto();
      }

      import MulINL = MulInternalsNonlinear

      import opened MulInternals
    }

    module {:disableNonlinearArithmetic} Power {
      function {:opaque} Pow(b: int, e: nat): int
        decreases e
      {
        if e == 0 then
          1
        else
          b * Pow(b, e - 1)
      }

      lemma /*{:_induction b}*/ LemmaPow0(b: int)
        ensures Pow(b, 0) == 1
        decreases b
      {
        reveal Pow();
      }

      lemma LemmaPow0Auto()
        ensures forall b: nat {:trigger Pow(b, 0)} :: Pow(b, 0) == 1
      {
        reveal Pow();
        forall b: nat {:trigger Pow(b, 0)} | true
          ensures Pow(b, 0) == 1
        {
          LemmaPow0(b);
        }
      }

      lemma /*{:_induction b}*/ LemmaPow1(b: int)
        ensures Pow(b, 1) == b
        decreases b
      {
        calc {
          Pow(b, 1);
          {
            reveal Pow();
          }
          b * Pow(b, 0);
          {
            LemmaPow0(b);
          }
          b * 1;
          {
            LemmaMulBasicsAuto();
          }
          b;
        }
      }

      lemma LemmaPow1Auto()
        ensures forall b: nat {:trigger Pow(b, 1)} :: Pow(b, 1) == b
      {
        reveal Pow();
        forall b: nat {:trigger Pow(b, 1)} | true
          ensures Pow(b, 1) == b
        {
          LemmaPow1(b);
        }
      }

      lemma /*{:_induction e}*/ Lemma0Pow(e: nat)
        requires e > 0
        ensures Pow(0, e) == 0
        decreases e
      {
        reveal Pow();
        LemmaMulBasicsAuto();
        if e != 1 {
          Lemma0Pow(e - 1);
        }
      }

      lemma Lemma0PowAuto()
        ensures forall e: nat {:trigger Pow(0, e)} :: e > 0 ==> Pow(0, e) == 0
      {
        reveal Pow();
        forall e: nat {:trigger Pow(0, e)} | e > 0
          ensures Pow(0, e) == 0
        {
          Lemma0Pow(e);
        }
      }

      lemma /*{:_induction e}*/ Lemma1Pow(e: nat)
        ensures Pow(1, e) == 1
        decreases e
      {
        reveal Pow();
        LemmaMulBasicsAuto();
        if e != 0 {
          Lemma1Pow(e - 1);
        }
      }

      lemma Lemma1PowAuto()
        ensures forall e: nat {:trigger Pow(1, e)} :: Pow(1, e) == 1
      {
        reveal Pow();
        forall e: nat {:trigger Pow(1, e)} | true
          ensures Pow(1, e) == 1
        {
          Lemma1Pow(e);
        }
      }

      lemma /*{:_induction x}*/ LemmaSquareIsPow2(x: nat)
        ensures Pow(x, 2) == x * x
        decreases x
      {
        reveal Pow();
      }

      lemma LemmaSquareIsPow2Auto()
        ensures forall x: nat {:trigger Pow(x, 2)} :: Pow(x, 2) == x * x
      {
        reveal Pow();
        forall x: nat {:trigger Pow(x, 2)} | true
          ensures Pow(x, 2) == x * x
        {
        }
      }

      lemma /*{:_induction b, e}*/ LemmaPowPositive(b: int, e: nat)
        requires b > 0
        ensures 0 < Pow(b, e)
        decreases b, e
      {
        LemmaMulIncreasesAuto();
        LemmaPow0Auto();
        reveal Pow();
        LemmaMulInductionAuto(e, (u: int) => 0 <= u ==> 0 < Pow(b, u));
      }

      lemma LemmaPowPositiveAuto()
        ensures forall b: int, e: nat {:trigger Pow(b, e)} :: b > 0 ==> 0 < Pow(b, e)
      {
        reveal Pow();
        forall b: int, e: nat {:trigger Pow(b, e)} | b > 0
          ensures 0 < Pow(b, e)
        {
          LemmaPowPositive(b, e);
        }
      }

      lemma /*{:_induction b, e1, e2}*/ LemmaPowAdds(b: int, e1: nat, e2: nat)
        ensures Pow(b, e1 + e2) == Pow(b, e1) * Pow(b, e2)
        decreases e1
      {
        if e1 == 0 {
          calc {
            Pow(b, e1) * Pow(b, e2);
            {
              LemmaPow0(b);
            }
            1 * Pow(b, e2);
            {
              LemmaMulBasicsAuto();
            }
            Pow(b, 0 + e2);
          }
        } else {
          calc {
            Pow(b, e1) * Pow(b, e2);
            {
              reveal Pow();
            }
            b * Pow(b, e1 - 1) * Pow(b, e2);
            {
              LemmaMulIsAssociativeAuto();
            }
            b * Pow(b, e1 - 1) * Pow(b, e2);
            {
              LemmaPowAdds(b, e1 - 1, e2);
            }
            b * Pow(b, e1 - 1 + e2);
            {
              reveal Pow();
            }
            Pow(b, e1 + e2);
          }
        }
      }

      lemma LemmaPowAddsAuto()
        ensures forall b: int, e1: nat, e2: nat {:trigger Pow(b, e1 + e2)} :: Pow(b, e1 + e2) == Pow(b, e1) * Pow(b, e2)
      {
        reveal Pow();
        forall b: int, e1: nat, e2: nat {:trigger Pow(b, e1 + e2)} | true
          ensures Pow(b, e1 + e2) == Pow(b, e1) * Pow(b, e2)
        {
          LemmaPowAdds(b, e1, e2);
        }
      }

      lemma /*{:_induction b, e1, e2}*/ LemmaPowSubAddCancel(b: int, e1: nat, e2: nat)
        requires e1 >= e2
        ensures Pow(b, e1 - e2) * Pow(b, e2) == Pow(b, e1)
        decreases e1
      {
        LemmaPowAdds(b, e1 - e2, e2);
      }

      lemma LemmaPowSubAddCancelAuto()
        ensures forall b: int, e1: nat, e2: nat {:trigger Pow(b, e1 - e2)} | e1 >= e2 :: Pow(b, e1 - e2) * Pow(b, e2) == Pow(b, e1)
      {
        reveal Pow();
        forall b: int, e1: nat, e2: nat | e1 >= e2 {
          LemmaPowSubAddCancel(b, e1, e2);
        }
      }

      lemma /*{:_induction b, e1, e2}*/ LemmaPowSubtracts(b: nat, e1: nat, e2: nat)
        requires b > 0
        requires e1 <= e2
        ensures Pow(b, e1) > 0
        ensures Pow(b, e2 - e1) == Pow(b, e2) / Pow(b, e1) > 0
        decreases b, e1, e2
      {
        LemmaPowPositiveAuto();
        calc {
          Pow(b, e2) / Pow(b, e1);
          {
            LemmaPowSubAddCancel(b, e2, e1);
          }
          Pow(b, e2 - e1) * Pow(b, e1) / Pow(b, e1);
          {
            LemmaDivByMultiple(Pow(b, e2 - e1), Pow(b, e1));
          }
          Pow(b, e2 - e1);
        }
      }

      lemma LemmaPowSubtractsAuto()
        ensures forall b: nat, e1: nat {:trigger Pow(b, e1)} :: b > 0 ==> Pow(b, e1) > 0
        ensures forall e2: nat, e1: nat, b: nat {:trigger Pow(b, e2 - e1)} :: (b > 0 && e1 <= e2 ==> Pow(b, e2 - e1) == Pow(b, e2) / Pow(b, e1)) && (b > 0 && e1 <= e2 ==> Pow(b, e2) / Pow(b, e1) > 0)
      {
        reveal Pow();
        LemmaPowPositiveAuto();
        forall b: nat, e1: nat, e2: nat {:trigger Pow(b, e2 - e1)} | b > 0 && e1 <= e2
          ensures Pow(b, e2 - e1) == Pow(b, e2) / Pow(b, e1) > 0
        {
          LemmaPowSubtracts(b, e1, e2);
        }
      }

      lemma /*{:_induction a, b, c}*/ LemmaPowMultiplies(a: int, b: nat, c: nat)
        ensures 0 <= b * c
        ensures Pow(Pow(a, b), c) == Pow(a, b * c)
        decreases c
      {
        LemmaMulNonnegative(b, c);
        if c == 0 {
          LemmaMulBasicsAuto();
          calc {
            Pow(a, b * c);
            {
              LemmaPow0(a);
            }
            1;
            {
              LemmaPow0(Pow(a, b));
            }
            Pow(Pow(a, b), c);
          }
        } else {
          calc {
            b * c - b;
            {
              LemmaMulBasicsAuto();
            }
            b * c - b * 1;
            {
              LemmaMulIsDistributiveAuto();
            }
            b * (c - 1);
          }
          LemmaMulNonnegative(b, c - 1);
          assert 0 <= b * c - b;
          calc {
            Pow(a, b * c);
            Pow(a, b + b * c - b);
            {
              LemmaPowAdds(a, b, b * c - b);
            }
            Pow(a, b) * Pow(a, b * c - b);
            Pow(a, b) * Pow(a, b * (c - 1));
            {
              LemmaPowMultiplies(a, b, c - 1);
            }
            Pow(a, b) * Pow(Pow(a, b), c - 1);
            {
              reveal Pow();
            }
            Pow(Pow(a, b), c);
          }
        }
      }

      lemma LemmaPowMultipliesAuto()
        ensures forall b: nat, c: nat {:trigger b * c} :: 0 <= b * c
        ensures forall a: int, b: nat, c: nat {:trigger Pow(a, b * c)} :: Pow(Pow(a, b), c) == Pow(a, b * c)
      {
        reveal Pow();
        LemmaMulNonnegativeAuto();
        forall a: int, b: nat, c: nat {:trigger Pow(a, b * c)} | true
          ensures Pow(Pow(a, b), c) == Pow(a, b * c)
        {
          LemmaPowMultiplies(a, b, c);
        }
      }

      lemma /*{:_induction a, b, e}*/ LemmaPowDistributes(a: int, b: int, e: nat)
        ensures Pow(a * b, e) == Pow(a, e) * Pow(b, e)
        decreases e
      {
        reveal Pow();
        LemmaMulBasicsAuto();
        if e > 0 {
          calc {
            Pow(a * b, e);
            a * b * Pow(a * b, e - 1);
            {
              LemmaPowDistributes(a, b, e - 1);
            }
            a * b * Pow(a, e - 1) * Pow(b, e - 1);
            {
              LemmaMulIsAssociativeAuto();
              LemmaMulIsCommutativeAuto();
            }
            a * Pow(a, e - 1) * b * Pow(b, e - 1);
            Pow(a, e) * Pow(b, e);
          }
        }
      }

      lemma LemmaPowDistributesAuto()
        ensures forall a: int, b: int, e: nat {:trigger Pow(a * b, e)} :: Pow(a * b, e) == Pow(a, e) * Pow(b, e)
      {
        reveal Pow();
        forall a: int, b: int, e: nat {:trigger Pow(a * b, e)} | true
          ensures Pow(a * b, e) == Pow(a, e) * Pow(b, e)
        {
          LemmaPowDistributes(a, b, e);
        }
      }

      lemma LemmaPowAuto()
        ensures forall x: int {:trigger Pow(x, 0)} :: Pow(x, 0) == 1
        ensures forall x: int {:trigger Pow(x, 1)} :: Pow(x, 1) == x
        ensures forall x: int, y: int {:trigger Pow(x, y)} :: y == 0 ==> Pow(x, y) == 1
        ensures forall x: int, y: int {:trigger Pow(x, y)} :: y == 1 ==> Pow(x, y) == x
        ensures forall x: int, y: int {:trigger x * y} :: 0 < x && 0 < y ==> x <= x * y
        ensures forall x: int, y: int {:trigger x * y} :: 0 < x && 1 < y ==> x < x * y
        ensures forall x: int, y: nat, z: nat {:trigger Pow(x, y + z)} :: Pow(x, y + z) == Pow(x, y) * Pow(x, z)
        ensures forall x: int, y: nat, z: nat {:trigger Pow(x, y - z)} :: y >= z ==> Pow(x, y - z) * Pow(x, z) == Pow(x, y)
        ensures forall x: int, y: int, z: nat {:trigger Pow(x * y, z)} :: Pow(x * y, z) == Pow(x, z) * Pow(y, z)
      {
        reveal Pow();
        LemmaPow0Auto();
        LemmaPow1Auto();
        LemmaPowDistributesAuto();
        LemmaPowAddsAuto();
        LemmaPowSubAddCancelAuto();
        LemmaMulAuto();
        LemmaMulIncreasesAuto();
        LemmaMulStrictlyIncreasesAuto();
      }

      lemma /*{:_induction b, e1, e2}*/ LemmaPowStrictlyIncreases(b: nat, e1: nat, e2: nat)
        requires 1 < b
        requires e1 < e2
        ensures Pow(b, e1) < Pow(b, e2)
        decreases b, e1, e2
      {
        reveal Pow();
        LemmaPowAuto();
        ghost var f := (e: int) => 0 < e ==> Pow(b, e1) < Pow(b, e1 + e);
        forall i: int {:trigger IsLe(0, i)} | IsLe(0, i) && f(i)
          ensures f(i + 1)
        {
          assert 0 < i ==> Pow(b, e1) < Pow(b, e1 + i);
          calc {
            Pow(b, e1 + i);
          <=
            {
              LemmaPowPositive(b, e1 + i);
              LemmaMulLeftInequality(Pow(b, e1 + i), 1, b);
            }
            Pow(b, e1 + i) * b;
          ==
            {
              LemmaPow1(b);
            }
            Pow(b, e1 + i) * Pow(b, 1);
          ==
            {
              LemmaPowAdds(b, e1 + i, 1);
            }
            Pow(b, e1 + i + 1);
          ==
            calc {
              e1 + i + 1;
              e1 + i + 1;
            }
            Pow(b, e1 + i + 1);
          }
          assert f(i + 1);
        }
        LemmaMulInductionAuto(e2 - e1, f);
        assert Pow(b, e1) < Pow(b, e1 + e2 - e1) == Pow(b, e2) by {
          assert 0 < e2 - e1;
        }
      }

      lemma LemmaPowStrictlyIncreasesAuto()
        ensures forall e2: nat, e1: nat, b: nat {:trigger Pow(b, e1), Pow(b, e2)} :: 1 < b && e1 < e2 ==> Pow(b, e1) < Pow(b, e2)
      {
        reveal Pow();
        forall b: nat, e1: nat, e2: nat {:trigger Pow(b, e1), Pow(b, e2)} | 1 < b && e1 < e2
          ensures Pow(b, e1) < Pow(b, e2)
        {
          LemmaPowStrictlyIncreases(b, e1, e2);
        }
      }

      lemma /*{:_induction b, e1, e2}*/ LemmaPowIncreases(b: nat, e1: nat, e2: nat)
        requires b > 0
        requires e1 <= e2
        ensures Pow(b, e1) <= Pow(b, e2)
        decreases b, e1, e2
      {
        reveal Pow();
        LemmaPowAuto();
        ghost var f := (e: int) => 0 <= e ==> Pow(b, e1) <= Pow(b, e1 + e);
        forall i: int {:trigger IsLe(0, i)} | IsLe(0, i) && f(i)
          ensures f(i + 1)
        {
          calc {
            Pow(b, e1 + i);
          <=
            {
              LemmaPowPositive(b, e1 + i);
              LemmaMulLeftInequality(Pow(b, e1 + i), 1, b);
            }
            Pow(b, e1 + i) * b;
          ==
            {
              LemmaPow1(b);
            }
            Pow(b, e1 + i) * Pow(b, 1);
          ==
            {
              LemmaPowAdds(b, e1 + i, 1);
            }
            Pow(b, e1 + i + 1);
          }
        }
        LemmaMulInductionAuto(e2 - e1, f);
        assert Pow(b, e1) <= Pow(b, e1 + e2 - e1) by {
          assert 0 <= e2 - e1;
        }
      }

      lemma LemmaPowIncreasesAuto()
        ensures forall e2: nat, e1: nat, b: nat {:trigger Pow(b, e1), Pow(b, e2)} :: 1 < b && e1 <= e2 ==> Pow(b, e1) <= Pow(b, e2)
      {
        reveal Pow();
        forall b: nat, e1: nat, e2: nat {:trigger Pow(b, e1), Pow(b, e2)} | 1 < b && e1 <= e2
          ensures Pow(b, e1) <= Pow(b, e2)
        {
          LemmaPowIncreases(b, e1, e2);
        }
      }

      lemma /*{:_induction b, e1, e2}*/ LemmaPowStrictlyIncreasesConverse(b: nat, e1: nat, e2: nat)
        requires b > 0
        requires Pow(b, e1) < Pow(b, e2)
        ensures e1 < e2
        decreases b, e1, e2
      {
        if e1 >= e2 {
          LemmaPowIncreases(b, e2, e1);
          assert false;
        }
      }

      lemma LemmaPowStrictlyIncreasesConverseAuto()
        ensures forall b: nat, e1: nat, e2: nat {:trigger Pow(b, e1), Pow(b, e2)} :: b > 0 && Pow(b, e1) < Pow(b, e2) ==> e1 < e2
      {
        reveal Pow();
        forall b: nat, e1: nat, e2: nat {:trigger Pow(b, e1), Pow(b, e2)} | b > 0 && Pow(b, e1) < Pow(b, e2)
          ensures e1 < e2
        {
          LemmaPowStrictlyIncreasesConverse(b, e1, e2);
        }
      }

      lemma /*{:_induction b, e1, e2}*/ LemmaPowIncreasesConverse(b: nat, e1: nat, e2: nat)
        requires 1 < b
        requires Pow(b, e1) <= Pow(b, e2)
        ensures e1 <= e2
        decreases b, e1, e2
      {
        if e1 > e2 {
          LemmaPowStrictlyIncreases(b, e2, e1);
          assert false;
        }
      }

      lemma LemmaPowIncreasesConverseAuto()
        ensures forall b: nat, e1: nat, e2: nat {:trigger Pow(b, e1), Pow(b, e2)} :: 1 < b && Pow(b, e1) <= Pow(b, e2) ==> e1 <= e2
      {
        reveal Pow();
        forall b: nat, e1: nat, e2: nat {:trigger Pow(b, e1), Pow(b, e2)} | 1 < b && Pow(b, e1) <= Pow(b, e2)
          ensures e1 <= e2
        {
          LemmaPowIncreasesConverse(b, e1, e2);
        }
      }

      lemma /*{:_induction b, x, y, z}*/ LemmaPullOutPows(b: nat, x: nat, y: nat, z: nat)
        requires b > 0
        ensures 0 <= x * y
        ensures 0 <= y * z
        ensures Pow(Pow(b, x * y), z) == Pow(Pow(b, x), y * z)
        decreases b, x, y, z
      {
        LemmaMulNonnegative(x, y);
        LemmaMulNonnegative(y, z);
        LemmaPowPositive(b, x);
        calc {
          Pow(Pow(b, x * y), z);
          {
            LemmaPowMultiplies(b, x, y);
          }
          Pow(Pow(Pow(b, x), y), z);
          {
            LemmaPowMultiplies(Pow(b, x), y, z);
          }
          Pow(Pow(b, x), y * z);
        }
      }

      lemma LemmaPullOutPowsAuto()
        ensures forall y: nat, z: nat {:trigger z * y} :: 0 <= z * y && 0 <= y * z
        ensures forall b: nat, x: nat, y: nat, z: nat {:trigger Pow(Pow(b, x * y), z)} :: b > 0 ==> Pow(Pow(b, x * y), z) == Pow(Pow(b, x), y * z)
      {
        reveal Pow();
        LemmaMulNonnegativeAuto();
        forall b: nat, x: nat, y: nat, z: nat {:trigger Pow(Pow(b, x * y), z)} | b > 0
          ensures Pow(Pow(b, x * y), z) == Pow(Pow(b, x), y * z)
        {
          LemmaPullOutPows(b, x, y, z);
        }
      }

      lemma /*{:_induction b, e1, e2}*/ LemmaPowDivisionInequality(x: nat, b: nat, e1: nat, e2: nat)
        requires b > 0
        requires e2 <= e1
        requires x < Pow(b, e1)
        ensures Pow(b, e2) > 0
        ensures x / Pow(b, e2) < Pow(b, e1 - e2)
        decreases x, b, e1, e2
      {
        LemmaPowPositiveAuto();
        if x / Pow(b, e2) >= Pow(b, e1 - e2) {
          assert x / Pow(b, e2) >= Pow(b, e1 - e2);
          assert x / Pow(b, e2) * Pow(b, e2) >= Pow(b, e1 - e2) * Pow(b, e2) by {
            LemmaMulInequality(Pow(b, e1 - e2), x / Pow(b, e2), Pow(b, e2));
          }
          assert x - x % Pow(b, e2) >= Pow(b, e1 - e2) * Pow(b, e2) by {
            LemmaFundamentalDivMod(x, Pow(b, e2));
            LemmaMulIsCommutativeAuto();
          }
          assert x - x % Pow(b, e2) >= Pow(b, e1) by {
            LemmaPowAdds(b, e1 - e2, e2);
          }
          assert x >= Pow(b, e1) by {
            LemmaModPropertiesAuto();
          }
        }
      }

      lemma LemmaPowDivisionInequalityAuto()
        ensures forall b: nat, e2: nat {:trigger Pow(b, e2)} :: b > 0 ==> Pow(b, e2) > 0
        ensures forall x: nat, b: nat, e1: nat, e2: nat {:trigger x / Pow(b, e2), Pow(b, e1 - e2)} :: b > 0 && e2 <= e1 && x < Pow(b, e1) ==> x / Pow(b, e2) < Pow(b, e1 - e2)
      {
        reveal Pow();
        LemmaPowPositiveAuto();
        forall x: nat, b: nat, e1: nat, e2: nat {:trigger x / Pow(b, e2), Pow(b, e1 - e2)} | b > 0 && e2 <= e1 && x < Pow(b, e1)
          ensures x / Pow(b, e2) < Pow(b, e1 - e2)
        {
          LemmaPowDivisionInequality(x, b, e1, e2);
        }
      }

      lemma /*{:_induction b, e}*/ LemmaPowMod(b: nat, e: nat)
        requires b > 0 && e > 0
        ensures Pow(b, e) % b == 0
        decreases b, e
      {
        reveal Pow();
        calc {
          Pow(b, e) % b;
          b * Pow(b, e - 1) % b;
          {
            LemmaMulIsAssociativeAuto();
          }
          Pow(b, e - 1) * b % b;
          {
            LemmaPowPositiveAuto();
            LemmaModMultiplesBasic(Pow(b, e - 1), b);
          }
          0;
        }
      }

      lemma LemmaPowModAuto()
        ensures forall b: nat, e: nat {:trigger Pow(b, e)} :: b > 0 && e > 0 ==> Pow(b, e) % b == 0
      {
        reveal Pow();
        forall b: nat, e: nat {:trigger Pow(b, e)} | b > 0 && e > 0
          ensures Pow(b, e) % b == 0
        {
          LemmaPowMod(b, e);
        }
      }

      lemma /*{:_induction b, e, m}*/ LemmaPowModNoop(b: int, e: nat, m: int)
        requires m > 0
        ensures Pow(b % m, e) % m == Pow(b, e) % m
        decreases e
      {
        reveal Pow();
        LemmaModPropertiesAuto();
        if e > 0 {
          calc {
            Pow(b % m, e) % m;
            b % m * Pow(b % m, e - 1) % m;
            {
              LemmaMulModNoopGeneral(b, Pow(b % m, e - 1), m);
            }
            b % m * Pow(b % m, e - 1) % m % m % m;
            {
              LemmaPowModNoop(b, e - 1, m);
            }
            b % m * Pow(b, e - 1) % m % m % m;
            {
              LemmaMulModNoopGeneral(b, Pow(b, e - 1), m);
            }
            b * Pow(b, e - 1) % m % m;
            b * Pow(b, e - 1) % m;
            Pow(b, e) % m;
          }
        }
      }

      lemma LemmaPowModNoopAuto()
        ensures forall b: nat, e: nat, m: nat {:trigger Pow(b % m, e)} :: m > 0 ==> Pow(b % m, e) % m == Pow(b, e) % m
      {
        reveal Pow();
        forall b: nat, e: nat, m: nat {:trigger Pow(b % m, e)} | m > 0
          ensures Pow(b % m, e) % m == Pow(b, e) % m
        {
          LemmaPowModNoop(b, e, m);
        }
      }

      import opened DivMod

      import opened GeneralInternals

      import opened Mul

      import opened MulInternals
    }

    module {:disableNonlinearArithmetic} Power2 {
      function {:opaque} Pow2(e: nat): nat
        ensures Pow2(e) > 0
        decreases e
      {
        reveal Pow();
        LemmaPowPositive(2, e);
        Pow(2, e)
      }

      lemma /*{:_induction e}*/ LemmaPow2(e: nat)
        ensures Pow2(e) == Pow(2, e)
        decreases e
      {
        reveal Pow();
        reveal Pow2();
        if e != 0 {
          LemmaPow2(e - 1);
        }
      }

      lemma LemmaPow2Auto()
        ensures forall e: nat {:trigger Pow2(e)} :: Pow2(e) == Pow(2, e)
      {
        reveal Pow();
        reveal Pow2();
        forall e: nat {:trigger Pow2(e)} | true
          ensures Pow2(e) == Pow(2, e)
        {
          LemmaPow2(e);
        }
      }

      lemma LemmaPow2MaskDiv2(e: nat)
        requires 0 < e
        ensures (Pow2(e) - 1) / 2 == Pow2(e - 1) - 1
        decreases e
      {
        LemmaPow2Auto();
        LemmaPowAuto();
        ghost var f := (e: int) => 0 < e ==> (Pow2(e) - 1) / 2 == Pow2(e - 1) - 1;
        assert forall i: int {:trigger IsLe(0, i)} :: IsLe(0, i) && f(i) ==> f(i + 1);
        assert forall i: int {:trigger IsLe(i, 0)} :: IsLe(i, 0) && f(i) ==> f(i - 1);
        LemmaMulInductionAuto(e, f);
      }

      lemma LemmaPow2MaskDiv2Auto()
        ensures forall e: nat {:trigger Pow2(e)} :: 0 < e ==> (Pow2(e) - 1) / 2 == Pow2(e - 1) - 1
      {
        reveal Pow2();
        forall e: nat {:trigger Pow2(e)} | 0 < e
          ensures (Pow2(e) - 1) / 2 == Pow2(e - 1) - 1
        {
          LemmaPow2MaskDiv2(e);
        }
      }

      lemma Lemma2To64()
        ensures Pow2(0) == 1
        ensures Pow2(1) == 2
        ensures Pow2(2) == 4
        ensures Pow2(3) == 8
        ensures Pow2(4) == 16
        ensures Pow2(5) == 32
        ensures Pow2(6) == 64
        ensures Pow2(7) == 128
        ensures Pow2(8) == 256
        ensures Pow2(9) == 512
        ensures Pow2(10) == 1024
        ensures Pow2(11) == 2048
        ensures Pow2(12) == 4096
        ensures Pow2(13) == 8192
        ensures Pow2(14) == 16384
        ensures Pow2(15) == 32768
        ensures Pow2(16) == 65536
        ensures Pow2(17) == 131072
        ensures Pow2(18) == 262144
        ensures Pow2(19) == 524288
        ensures Pow2(20) == 1048576
        ensures Pow2(21) == 2097152
        ensures Pow2(22) == 4194304
        ensures Pow2(23) == 8388608
        ensures Pow2(24) == 16777216
        ensures Pow2(25) == 33554432
        ensures Pow2(26) == 67108864
        ensures Pow2(27) == 134217728
        ensures Pow2(28) == 268435456
        ensures Pow2(29) == 536870912
        ensures Pow2(30) == 1073741824
        ensures Pow2(31) == 2147483648
        ensures Pow2(32) == 4294967296
        ensures Pow2(64) == 18446744073709551616
      {
        reveal Pow2();
        reveal Pow();
      }

      import opened GeneralInternals

      import opened MulInternals

      import opened Power
    }
  }

  module JSON {

    module API {
      opaque function Serialize(js: Values.JSON): (bs: SerializationResult<seq<byte>>)
        decreases js
      {
        var js: Grammar.JSON :- Serializer.JSON(js); ZeroCopy.Serialize(js)
      }

      method SerializeAlloc(js: Values.JSON) returns (bs: SerializationResult<array<byte>>)
        decreases js
      {
        var js :- Serializer.JSON(js);
        bs := ZeroCopy.SerializeAlloc(js);
      }

      method SerializeInto(js: Values.JSON, bs: array<byte>) returns (len: SerializationResult<uint32>)
        modifies bs
        decreases js, bs
      {
        var js :- Serializer.JSON(js);
        len := ZeroCopy.SerializeInto(js, bs);
      }

      opaque function Deserialize(bs: seq<byte>): (js: DeserializationResult<Values.JSON>)
        decreases bs
      {
        var js: Grammar.JSON :- ZeroCopy.Deserialize(bs); Deserializer.JSON(js)
      }

      import Values

      import Serializer

      import Deserializer

      import ZeroCopy = ZeroCopy.API

      import opened BoundedInts

      import opened Errors
    }

    module {:disableNonlinearArithmetic} ByteStrConversion refines Strings.ParametricConversion {
      const chars: CharSeq := ['0' as byte, '1' as byte, '2' as byte, '3' as byte, '4' as byte, '5' as byte, '6' as byte, '7' as byte, '8' as byte, '9' as byte]
      const charToDigit: map<Char, digit> := map['0' as byte := 0, '1' as byte := 1, '2' as byte := 2, '3' as byte := 3, '4' as byte := 4, '5' as byte := 5, '6' as byte := 6, '7' as byte := 7, '8' as byte := 8, '9' as byte := 9]

      lemma CharsConsistent()
        ensures forall c: uint8 {:trigger charToDigit[c]} {:trigger c in charToDigit} {:trigger c in chars} | c in chars :: c in charToDigit && chars[charToDigit[c]] == c
        ensures forall c: uint8 {:trigger charToDigit[c]} {:trigger c in charToDigit} {:trigger c in chars} | c in chars :: c in charToDigit && chars[charToDigit[c]] == c
      {
      }

      const base := |chars|

      function BASE(): nat
        ensures BASE() > 1
      {
        base
      }

      predicate IsDigitChar(c: Char)
        decreases c
      {
        c in charToDigit
      }

      function OfDigits(digits: seq<digit>): (str: String)
        ensures forall c: uint8 {:trigger c in chars} {:trigger c in str} | c in str :: c in chars
        ensures |str| == |digits|
        decreases digits
      {
        if digits == [] then
          []
        else
          assert digits[0] in digits; assert forall d: int {:trigger d in digits} {:trigger d in digits[1..]} | d in digits[1..] :: d in digits; OfDigits(digits[1..]) + [chars[digits[0]]]
      }

      function OfNat(n: nat): (str: String)
        ensures |str| == Log(base, n) + 1
        ensures forall c: uint8 {:trigger c in chars} {:trigger c in str} | c in str :: c in chars
        decreases n
      {
        if n == 0 then
          reveal Log();
          [chars[0]]
        else
          LemmaFromNatLen2(n); OfDigits(FromNat(n))
      }

      predicate IsNumberStr(str: String, minus: Char)
        decreases str
      {
        str != [] ==>
          (str[0] == minus || str[0] in charToDigit) &&
          forall c: uint8 {:trigger IsDigitChar(c)} {:trigger c in str[1..]} | c in str[1..] :: 
            IsDigitChar(c)
      }

      function OfInt(n: int, minus: Char): (str: String)
        ensures IsNumberStr(str, minus)
        decreases n
      {
        CharsConsistent();
        if n >= 0 then
          OfNat(n)
        else
          [minus] + OfNat(-n)
      }

      function {:isolate_assertions} ToNat(str: String): (n: nat)
        requires forall c: uint8 {:trigger IsDigitChar(c)} {:trigger c in str} | c in str :: IsDigitChar(c)
        decreases str
      {
        if str == [] then
          0
        else
          LemmaMulNonnegativeAuto(); var c: uint8 := str[|str| - 1]; assert IsDigitChar(c); ToNat(str[..|str| - 1]) * base + charToDigit[c]
      }

      lemma {:induction false} ToNatBound(str: String)
        requires base > 0
        requires forall c: uint8 {:trigger IsDigitChar(c)} {:trigger c in str} | c in str :: IsDigitChar(c)
        ensures ToNat(str) < Pow(base, |str|)
        decreases str
      {
        if str == [] {
          reveal Pow();
        } else {
          calc <= {
            ToNat(str);
            {
              assert IsDigitChar(str[|str| - 1]);
            }
            ToNat(str[..|str| - 1]) * base + charToDigit[str[|str| - 1]];
            ToNat(str[..|str| - 1]) * base + base - 1;
            {
              ToNatBound(str[..|str| - 1]);
              LemmaMulInequalityAuto();
            }
            (Pow(base, |str| - 1) - 1) * base + base - 1;
            {
              LemmaMulIsDistributiveAuto();
            }
            Pow(base, |str| - 1) * base - 1;
            {
              reveal Pow();
              LemmaMulIsCommutativeAuto();
            }
            Pow(base, |str|) - 1;
          }
        }
      }

      function ToInt(str: String, minus: Char): (s: int)
        requires str != [minus]
        requires IsNumberStr(str, minus)
        decreases str
      {
        if [minus] <= str then
          -(ToNat(str[1..]) as int)
        else
          assert str == [] || str == [str[0]] + str[1..]; ToNat(str)
      }

      function {:opaque} ToNatRight(xs: seq<digit>): nat
        decreases xs
      {
        if |xs| == 0 then
          0
        else
          LemmaMulNonnegativeAuto(); ToNatRight(DropFirst(xs)) * BASE() + First(xs)
      }

      function {:opaque} ToNatLeft(xs: seq<digit>): nat
        decreases xs
      {
        if |xs| == 0 then
          0
        else
          LemmaPowPositiveAuto(); LemmaMulNonnegativeAuto(); ToNatLeft(DropLast(xs)) + Last(xs) * Pow(BASE(), |xs| - 1)
      }

      lemma {:isolate_assertions} /*{:_induction xs}*/ LemmaToNatLeftEqToNatRight(xs: seq<digit>)
        ensures ToNatRight(xs) == ToNatLeft(xs)
        decreases xs
      {
        reveal ToNatRight();
        reveal ToNatLeft();
        if xs == [] {
        } else {
          if DropLast(xs) == [] {
            calc {
              ToNatLeft(xs);
              Last(xs) * Pow(BASE(), |xs| - 1);
              {
                reveal Pow();
              }
              Last(xs);
              First(xs);
              {
                assert ToNatRight(DropFirst(xs)) == 0;
              }
              ToNatRight(xs);
            }
          } else {
            calc {
              ToNatLeft(xs);
              ToNatLeft(DropLast(xs)) + Last(xs) * Pow(BASE(), |xs| - 1);
              {
                LemmaToNatLeftEqToNatRight(DropLast(xs));
              }
              ToNatRight(DropLast(xs)) + Last(xs) * Pow(BASE(), |xs| - 1);
              ToNatRight(DropFirst(DropLast(xs))) * BASE() + First(xs) + Last(xs) * Pow(BASE(), |xs| - 1);
              {
                LemmaToNatLeftEqToNatRight(DropFirst(DropLast(xs)));
              }
              ToNatLeft(DropFirst(DropLast(xs))) * BASE() + First(xs) + Last(xs) * Pow(BASE(), |xs| - 1);
              {
                assert DropFirst(DropLast(xs)) == DropLast(DropFirst(xs));
                reveal Pow();
                LemmaMulProperties();
              }
              ToNatLeft(DropLast(DropFirst(xs))) * BASE() + First(xs) + Last(xs) * Pow(BASE(), |xs| - 2) * BASE();
              {
                LemmaMulIsDistributiveAddOtherWayAuto();
              }
              ToNatLeft(DropFirst(xs)) * BASE() + First(xs);
              {
                LemmaToNatLeftEqToNatRight(DropFirst(xs));
              }
              ToNatRight(xs);
            }
          }
        }
      }

      lemma LemmaToNatLeftEqToNatRightAuto()
        ensures forall xs: seq<digit> {:trigger ToNatLeft(xs)} {:trigger ToNatRight(xs)} :: ToNatRight(xs) == ToNatLeft(xs)
      {
        reveal ToNatRight();
        reveal ToNatLeft();
        forall xs: seq<digit> | true
          ensures ToNatRight(xs) == ToNatLeft(xs)
        {
          LemmaToNatLeftEqToNatRight(xs);
        }
      }

      lemma /*{:_induction xs}*/ LemmaSeqLen1(xs: seq<digit>)
        requires |xs| == 1
        ensures ToNatRight(xs) == First(xs)
        decreases xs
      {
        reveal ToNatRight();
        assert ToNatRight(DropFirst(xs)) == 0;
      }

      lemma /*{:_induction xs}*/ LemmaSeqLen2(xs: seq<digit>)
        requires |xs| == 2
        ensures ToNatRight(xs) == First(xs) + xs[1] * BASE()
        decreases xs
      {
        reveal ToNatRight();
        LemmaSeqLen1(DropLast(xs));
      }

      lemma /*{:_induction xs}*/ LemmaSeqAppendZero(xs: seq<digit>)
        ensures ToNatRight(xs + [0]) == ToNatRight(xs)
        decreases xs
      {
        reveal ToNatLeft();
        LemmaToNatLeftEqToNatRightAuto();
        calc {
          ToNatRight(xs + [0]);
          ToNatLeft(xs + [0]);
          ToNatLeft(xs) + 0 * Pow(BASE(), |xs|);
          {
            LemmaMulBasicsAuto();
          }
          ToNatLeft(xs);
          ToNatRight(xs);
        }
      }

      lemma /*{:_induction xs}*/ LemmaSeqNatBound(xs: seq<digit>)
        ensures ToNatRight(xs) < Pow(BASE(), |xs|)
        decreases xs
      {
        reveal Pow();
        if |xs| == 0 {
          reveal ToNatRight();
        } else {
          ghost var len' := |xs| - 1;
          ghost var pow := Pow(BASE(), len');
          calc {
            ToNatRight(xs);
            {
              LemmaToNatLeftEqToNatRight(xs);
            }
            ToNatLeft(xs);
            {
              reveal ToNatLeft();
            }
            ToNatLeft(DropLast(xs)) + Last(xs) * pow;
          <
            {
              LemmaToNatLeftEqToNatRight(DropLast(xs));
              LemmaSeqNatBound(DropLast(xs));
            }
            pow + Last(xs) * pow;
          <=
            {
              LemmaPowPositiveAuto();
              LemmaMulInequalityAuto();
            }
            pow + (BASE() - 1) * pow;
            {
              LemmaMulIsDistributiveAuto();
            }
            Pow(BASE(), len' + 1);
          }
        }
      }

      lemma {:isolate_assertions} /*{:_induction xs, i}*/ LemmaSeqPrefix(xs: seq<digit>, i: nat)
        requires 0 <= i <= |xs|
        ensures ToNatRight(xs[..i]) + ToNatRight(xs[i..]) * Pow(BASE(), i) == ToNatRight(xs)
        decreases xs, i
      {
        reveal ToNatRight();
        reveal Pow();
        if i == 1 {
          assert ToNatRight(xs[..1]) == First(xs);
        } else if i > 1 {
          calc {
            ToNatRight(xs[..i]) + ToNatRight(xs[i..]) * Pow(BASE(), i);
            ToNatRight(DropFirst(xs[..i])) * BASE() + First(xs) + ToNatRight(xs[i..]) * Pow(BASE(), i);
            {
              assert DropFirst(xs[..i]) == DropFirst(xs)[..i - 1];
              LemmaMulProperties();
            }
            ToNatRight(DropFirst(xs)[..i - 1]) * BASE() + First(xs) + ToNatRight(xs[i..]) * Pow(BASE(), i - 1) * BASE();
            {
              LemmaMulIsDistributiveAddOtherWayAuto();
            }
            (ToNatRight(DropFirst(xs)[..i - 1]) + ToNatRight(DropFirst(xs)[i - 1..]) * Pow(BASE(), i - 1)) * BASE() + First(xs);
            {
              LemmaSeqPrefix(DropFirst(xs), i - 1);
            }
            ToNatRight(xs);
          }
        }
      }

      lemma /*{:_induction xs, ys}*/ LemmaSeqMswInequality(xs: seq<digit>, ys: seq<digit>)
        requires |xs| == |ys| > 0
        requires Last(xs) < Last(ys)
        ensures ToNatRight(xs) < ToNatRight(ys)
        decreases xs, ys
      {
        reveal ToNatLeft();
        LemmaToNatLeftEqToNatRightAuto();
        ghost var len' := |xs| - 1;
        calc {
          ToNatRight(xs);
          ToNatLeft(xs);
        <
          {
            LemmaSeqNatBound(DropLast(xs));
          }
          Pow(BASE(), len') + Last(xs) * Pow(BASE(), len');
        ==
          {
            LemmaMulIsDistributiveAuto();
          }
          (1 + Last(xs)) * Pow(BASE(), len');
        <=
          {
            LemmaPowPositiveAuto();
            LemmaMulInequalityAuto();
          }
          ToNatLeft(ys);
          ToNatRight(ys);
        }
      }

      lemma {:isolate_assertions} /*{:_induction xs, ys}*/ LemmaSeqPrefixNeq(xs: seq<digit>, ys: seq<digit>, i: nat)
        requires 0 <= i <= |xs| == |ys|
        requires ToNatRight(xs[..i]) != ToNatRight(ys[..i])
        ensures ToNatRight(xs) != ToNatRight(ys)
        decreases |xs| - i
      {
        if i == |xs| {
          assert xs[..i] == xs;
          assert ys[..i] == ys;
        } else {
          if xs[i] == ys[i] {
            reveal ToNatLeft();
            assert DropLast(xs[..i + 1]) == xs[..i];
            assert DropLast(ys[..i + 1]) == ys[..i];
            LemmaToNatLeftEqToNatRightAuto();
            assert ToNatRight(xs[..i + 1]) == ToNatLeft(xs[..i + 1]);
          } else if xs[i] < ys[i] {
            LemmaSeqMswInequality(xs[..i + 1], ys[..i + 1]);
          } else {
            LemmaSeqMswInequality(ys[..i + 1], xs[..i + 1]);
          }
          reveal ToNatRight();
          LemmaSeqPrefixNeq(xs, ys, i + 1);
        }
      }

      lemma /*{:_induction xs, ys}*/ LemmaSeqNeq(xs: seq<digit>, ys: seq<digit>)
        requires |xs| == |ys|
        requires xs != ys
        ensures ToNatRight(xs) != ToNatRight(ys)
        decreases xs, ys
      {
        ghost var i: nat, n: nat := 0, |xs|;
        while i < n
          invariant 0 <= i < n
          invariant xs[..i] == ys[..i]
          decreases n - i
        {
          if xs[i] != ys[i] {
            break;
          }
          i := i + 1;
        }
        assert ToNatLeft(xs[..i]) == ToNatLeft(ys[..i]);
        reveal ToNatLeft();
        assert xs[..i + 1][..i] == xs[..i];
        assert ys[..i + 1][..i] == ys[..i];
        LemmaPowPositiveAuto();
        LemmaMulStrictInequalityAuto();
        assert ToNatLeft(xs[..i + 1]) != ToNatLeft(ys[..i + 1]);
        LemmaToNatLeftEqToNatRightAuto();
        LemmaSeqPrefixNeq(xs, ys, i + 1);
      }

      lemma /*{:_induction xs, ys}*/ LemmaSeqEq(xs: seq<digit>, ys: seq<digit>)
        requires |xs| == |ys|
        requires ToNatRight(xs) == ToNatRight(ys)
        ensures xs == ys
        decreases xs, ys
      {
        calc ==> {
          xs != ys;
          {
            LemmaSeqNeq(xs, ys);
          }
          ToNatRight(xs) != ToNatRight(ys);
          false;
        }
      }

      lemma {:isolate_assertions} /*{:_induction xs}*/ LemmaSeqLswModEquivalence(xs: seq<digit>)
        requires |xs| >= 1
        ensures IsModEquivalent(ToNatRight(xs), First(xs), BASE())
        decreases xs
      {
        if |xs| == 1 {
          LemmaSeqLen1(xs);
          LemmaModEquivalenceAuto();
        } else {
          assert IsModEquivalent(ToNatRight(xs), First(xs), BASE()) by {
            reveal ToNatRight();
            calc ==> {
              true;
              {
                LemmaModEquivalence(ToNatRight(xs), ToNatRight(DropFirst(xs)) * BASE() + First(xs), BASE());
              }
              IsModEquivalent(ToNatRight(xs), ToNatRight(DropFirst(xs)) * BASE() + First(xs), BASE());
              {
                LemmaModMultiplesBasicAuto();
              }
              IsModEquivalent(ToNatRight(xs), First(xs), BASE());
            }
          }
        }
      }

      function {:opaque} FromNat(n: nat): (xs: seq<digit>)
        decreases n
      {
        if n == 0 then
          []
        else
          LemmaDivBasicsAuto(); LemmaDivDecreasesAuto(); [n % BASE()] + FromNat(n / BASE())
      }

      lemma /*{:_induction n}*/ LemmaFromNatLen2(n: nat)
        ensures n == 0 ==> |FromNat(n)| == 0
        ensures n > 0 ==> |FromNat(n)| == Log(BASE(), n) + 1
        decreases n
      {
        reveal FromNat();
        ghost var digits := FromNat(n);
        if n == 0 {
        } else {
          assert |digits| == Log(BASE(), n) + 1 by {
            LemmaDivBasicsAuto();
            ghost var digits' := FromNat(n / BASE());
            assert |digits| == |digits'| + 1;
            if n < BASE() {
              LemmaLog0(BASE(), n);
              assert n / BASE() == 0 by {
                LemmaBasicDiv(BASE());
              }
            } else {
              LemmaLogS(BASE(), n);
              assert n / BASE() > 0 by {
                LemmaDivNonZeroAuto();
              }
            }
          }
        }
      }

      lemma /*{:_induction n, len}*/ LemmaFromNatLen(n: nat, len: nat)
        requires Pow(BASE(), len) > n
        ensures |FromNat(n)| <= len
        decreases n, len
      {
        reveal FromNat();
        if n == 0 {
        } else {
          calc {
            |FromNat(n)|;
          ==
            {
              LemmaDivBasicsAuto();
            }
            1 + |FromNat(n / BASE())|;
          <=
            {
              LemmaMultiplyDivideLtAuto();
              LemmaDivDecreasesAuto();
              reveal Pow();
              LemmaFromNatLen(n / BASE(), len - 1);
            }
            len;
          }
        }
      }

      lemma /*{:_induction n}*/ LemmaNatSeqNat(n: nat)
        ensures ToNatRight(FromNat(n)) == n
        decreases n
      {
        reveal ToNatRight();
        reveal FromNat();
        if n == 0 {
        } else {
          calc {
            ToNatRight(FromNat(n));
            {
              LemmaDivBasicsAuto();
            }
            ToNatRight([n % BASE()] + FromNat(n / BASE()));
            n % BASE() + ToNatRight(FromNat(n / BASE())) * BASE();
            {
              LemmaDivDecreasesAuto();
              LemmaNatSeqNat(n / BASE());
            }
            n % BASE() + n / BASE() * BASE();
            {
              LemmaFundamentalDivMod(n, BASE());
            }
            n;
          }
        }
      }

      function {:opaque} SeqExtend(xs: seq<digit>, n: nat): (ys: seq<digit>)
        requires |xs| <= n
        ensures |ys| == n
        ensures ToNatRight(ys) == ToNatRight(xs)
        decreases n - |xs|
      {
        if |xs| >= n then
          xs
        else
          LemmaSeqAppendZero(xs); SeqExtend(xs + [0], n)
      }

      function {:opaque} SeqExtendMultiple(xs: seq<digit>, n: nat): (ys: seq<digit>)
        requires n > 0
        ensures |ys| % n == 0
        ensures ToNatRight(ys) == ToNatRight(xs)
        decreases xs, n
      {
        var newLen: int := |xs| + n - |xs| % n;
        LemmaSubModNoopRight(|xs| + n, |xs|, n);
        LemmaModBasicsAuto();
        assert newLen % n == 0;
        LemmaSeqNatBound(xs);
        LemmaPowIncreasesAuto();
        SeqExtend(xs, newLen)
      }

      function {:opaque} FromNatWithLen(n: nat, len: nat): (xs: seq<digit>)
        requires Pow(BASE(), len) > n
        ensures |xs| == len
        ensures ToNatRight(xs) == n
        decreases n, len
      {
        LemmaFromNatLen(n, len);
        LemmaNatSeqNat(n);
        SeqExtend(FromNat(n), len)
      }

      lemma {:resource_limit ""10e6""} /*{:_induction xs}*/ LemmaSeqZero(xs: seq<digit>)
        requires ToNatRight(xs) == 0
        ensures forall i: int {:trigger xs[i]} :: 0 <= i < |xs| ==> xs[i] == 0
        decreases xs
      {
        reveal ToNatRight();
        if |xs| == 0 {
        } else {
          LemmaMulNonnegativeAuto();
          assert First(xs) == 0;
          LemmaMulNonzeroAuto();
          LemmaSeqZero(DropFirst(xs));
        }
      }

      function {:opaque} SeqZero(len: nat): (xs: seq<digit>)
        ensures |xs| == len
        ensures forall i: int {:trigger xs[i]} :: 0 <= i < |xs| ==> xs[i] == 0
        ensures ToNatRight(xs) == 0
        decreases len
      {
        LemmaPowPositive(BASE(), len);
        var xs: seq<digit> := FromNatWithLen(0, len);
        LemmaSeqZero(xs);
        xs
      }

      lemma /*{:_induction xs}*/ LemmaSeqNatSeq(xs: seq<digit>)
        ensures Pow(BASE(), |xs|) > ToNatRight(xs)
        ensures FromNatWithLen(ToNatRight(xs), |xs|) == xs
        decreases xs
      {
        reveal FromNat();
        reveal ToNatRight();
        LemmaSeqNatBound(xs);
        if |xs| > 0 {
          calc {
            FromNatWithLen(ToNatRight(xs), |xs|) != xs;
            {
              LemmaSeqNeq(FromNatWithLen(ToNatRight(xs), |xs|), xs);
            }
            ToNatRight(FromNatWithLen(ToNatRight(xs), |xs|)) != ToNatRight(xs);
            ToNatRight(xs) != ToNatRight(xs);
            false;
          }
        }
      }

      function {:opaque} SeqAdd(xs: seq<digit>, ys: seq<digit>): (seq<digit>, nat)
        requires |xs| == |ys|
        ensures var (zs: seq<digit>, cout: nat) := SeqAdd(xs, ys); |zs| == |xs| && 0 <= cout <= 1
        decreases xs
      {
        if |xs| == 0 then
          ([], 0)
        else
          var (zs': seq<digit>, cin: nat) := SeqAdd(DropLast(xs), DropLast(ys)); var sum: int := Last(xs) + Last(ys) + cin; var (sum_out: int, cout: int) := if sum < BASE() then (sum, 0) else (sum - BASE(), 1); (zs' + [sum_out], cout)
      }

      lemma {:isolate_assertions} /*{:_induction xs, ys, zs}*/ LemmaSeqAdd(xs: seq<digit>, ys: seq<digit>, zs: seq<digit>, cout: nat)
        requires |xs| == |ys|
        requires SeqAdd(xs, ys) == (zs, cout)
        ensures ToNatRight(xs) + ToNatRight(ys) == ToNatRight(zs) + cout * Pow(BASE(), |xs|)
        decreases xs, ys, zs, cout
      {
        reveal SeqAdd();
        if |xs| == 0 {
          reveal ToNatRight();
        } else {
          ghost var pow := Pow(BASE(), |xs| - 1);
          var (zs', cin) := SeqAdd(DropLast(xs), DropLast(ys));
          ghost var sum: int := Last(xs) + Last(ys) + cin;
          ghost var z := if sum < BASE() then sum else sum - BASE();
          assert sum == z + cout * BASE();
          reveal ToNatLeft();
          LemmaToNatLeftEqToNatRightAuto();
          calc {
            ToNatRight(zs);
            ToNatLeft(zs);
            ToNatLeft(zs') + z * pow;
            {
              LemmaSeqAdd(DropLast(xs), DropLast(ys), zs', cin);
            }
            ToNatLeft(DropLast(xs)) + ToNatLeft(DropLast(ys)) - cin * pow + z * pow;
            {
              LemmaMulEquality(sum, z + cout * BASE(), pow);
              assert sum * pow == (z + cout * BASE()) * pow;
              LemmaMulIsDistributiveAuto();
            }
            ToNatLeft(xs) + ToNatLeft(ys) - cout * BASE() * pow;
            {
              LemmaMulIsAssociative(cout, BASE(), pow);
              reveal Pow();
            }
            ToNatLeft(xs) + ToNatLeft(ys) - cout * Pow(BASE(), |xs|);
            ToNatRight(xs) + ToNatRight(ys) - cout * Pow(BASE(), |xs|);
          }
        }
      }

      function {:opaque} SeqSub(xs: seq<digit>, ys: seq<digit>): (seq<digit>, nat)
        requires |xs| == |ys|
        ensures var (zs: seq<digit>, cout: nat) := SeqSub(xs, ys); |zs| == |xs| && 0 <= cout <= 1
        decreases xs
      {
        if |xs| == 0 then
          ([], 0)
        else
          var (zs: seq<digit>, cin: nat) := SeqSub(DropLast(xs), DropLast(ys)); var (diff_out: int, cout: int) := if Last(xs) >= Last(ys) + cin then (Last(xs) - Last(ys) - cin, 0) else (BASE() + Last(xs) - Last(ys) - cin, 1); (zs + [diff_out], cout)
      }

      lemma {:isolate_assertions} /*{:_induction xs, ys, zs}*/ LemmaSeqSub(xs: seq<digit>, ys: seq<digit>, zs: seq<digit>, cout: nat)
        requires |xs| == |ys|
        requires SeqSub(xs, ys) == (zs, cout)
        ensures ToNatRight(xs) - ToNatRight(ys) + cout * Pow(BASE(), |xs|) == ToNatRight(zs)
        decreases xs, ys, zs, cout
      {
        reveal SeqSub();
        if |xs| == 0 {
          reveal ToNatRight();
        } else {
          ghost var pow := Pow(BASE(), |xs| - 1);
          var (zs', cin) := SeqSub(DropLast(xs), DropLast(ys));
          ghost var z := if Last(xs) >= Last(ys) + cin then Last(xs) - Last(ys) - cin else BASE() + Last(xs) - Last(ys) - cin;
          assert cout * BASE() + Last(xs) - cin - Last(ys) == z;
          reveal ToNatLeft();
          LemmaToNatLeftEqToNatRightAuto();
          calc {
            ToNatRight(zs);
            ToNatLeft(zs);
            ToNatLeft(zs') + z * pow;
            {
              LemmaSeqSub(DropLast(xs), DropLast(ys), zs', cin);
            }
            ToNatLeft(DropLast(xs)) - ToNatLeft(DropLast(ys)) + cin * pow + z * pow;
            {
              LemmaMulEquality(cout * BASE() + Last(xs) - cin - Last(ys), z, pow);
              assert pow * (cout * BASE() + Last(xs) - cin - Last(ys)) == pow * z;
              LemmaMulIsDistributiveAuto();
            }
            ToNatLeft(xs) - ToNatLeft(ys) + cout * BASE() * pow;
            {
              LemmaMulIsAssociative(cout, BASE(), pow);
              reveal Pow();
            }
            ToNatLeft(xs) - ToNatLeft(ys) + cout * Pow(BASE(), |xs|);
            ToNatRight(xs) - ToNatRight(ys) + cout * Pow(BASE(), |xs|);
          }
        }
      }

      import opened BoundedInts

      type Char = byte

      import opened Wrappers

      type String = seq<Char>

      type CharSeq = chars: seq<Char>
        | |chars| > 1
        witness *

      import opened DivMod

      import opened Mul

      import opened Power

      import opened Seq = Collections.Seq

      import opened Logarithm

      type digit = i: nat
        | 0 <= i < BASE()
    }

    module Deserializer {
      function Bool(js: Grammar.jbool): bool
        decreases js
      {
        assert js.Bytes() in {Grammar.TRUE, Grammar.FALSE};
        js.At(0) == 't' as byte
      }

      function UnsupportedEscape16(code: seq<uint16>): DeserializationError
        decreases code
      {
        UnsupportedEscape(FromUTF16Checked(code).GetOr(""Couldn't decode UTF-16""))
      }

      const HEX_TABLE_16 := Uint16StrConversion.charToDigit

      function ToNat16(str: Uint16StrConversion.String): uint16
        requires |str| <= 4
        requires forall c: uint16 {:trigger c in HEX_TABLE_16} {:trigger c in str} | c in str :: c in HEX_TABLE_16
        decreases str
      {
        assume {:axiom} false;
        Uint16StrConversion.ToNatBound(str);
        var hd: nat := Uint16StrConversion.ToNat(str);
        assert hd < 65536 by {
          reveal Pow();
        }
        hd as uint16
      }

      function {:tailrecursion} {:isolate_assertions} Unescape(str: seq<uint16>, start: nat := 0, prefix: seq<uint16> := []): DeserializationResult<seq<uint16>>
        decreases |str| - start
      {
        if start >= |str| then
          Success(prefix)
        else if str[start] == '\\' as uint16 then
          if |str| == start + 1 then
            Failure(EscapeAtEOS)
          else
            var c: uint16 := str[start + 1]; if c == 'u' as uint16 then if |str| <= start + 6 then Failure(EscapeAtEOS) else var code: seq<uint16> := str[start + 2 .. start + 6]; if exists c: uint16 {:trigger c in HEX_TABLE_16} {:trigger c in code} | c in code :: c !in HEX_TABLE_16 then Failure(UnsupportedEscape16(code)) else var hd: uint16 := ToNat16(code); Unescape(str, start + 6, prefix + [hd]) else var unescaped: uint16 := match c case 34 => 34 as uint16 case 92 => 92 as uint16 case 98 => 8 as uint16 case 102 => 12 as uint16 case 110 => 10 as uint16 case 114 => 13 as uint16 case 116 => 9 as uint16 case _ /* _v4 */ => 0 as uint16; if unescaped as int == 0 then Failure(UnsupportedEscape16(str[start .. start + 2])) else Unescape(str, start + 2, prefix + [unescaped])
        else
          Unescape(str, start + 1, prefix + [str[start]])
      }

      function String(js: Grammar.jstring): DeserializationResult<string>
        decreases js
      {
        var asUtf32: string :- FromUTF8Checked(js.contents.Bytes()).ToResult(DeserializationError.InvalidUnicode); var asUint16: seq<uint16> :- ToUTF16Checked(asUtf32).ToResult(DeserializationError.InvalidUnicode); var unescaped: seq<uint16> :- Unescape(asUint16); FromUTF16Checked(unescaped).ToResult(DeserializationError.InvalidUnicode)
      }

      const DIGITS := ByteStrConversion.charToDigit
      const MINUS := '-' as uint8

      function ToInt(sign: jsign, n: jnum): DeserializationResult<int>
        decreases sign, n
      {
        var n: int := ByteStrConversion.ToNat(n.Bytes());
        Success(if sign.Char?('-') then -n else n)
      }

      function Number(js: Grammar.jnumber): DeserializationResult<Values.Decimal>
        decreases js
      {
        var JNumber(minus: jminus, num: jnum, frac: Maybe<jfrac>, exp: Maybe<jexp>) := js;
        var n: int :- ToInt(minus, num); var e10: int :- match exp case Empty() => Success(0) case NonEmpty(JExp(_ /* _v5 */, sign, num)) => ToInt(sign, num); match frac case Empty() => Success(Values.Decimal(n, e10)) case NonEmpty(JFrac(_ /* _v6 */, num)) => var pow10: int := num.Length() as int; var frac: int :- ToInt(minus, num); Success(Values.Decimal(n * Pow(10, pow10) + frac, e10 - pow10))
      }

      function KeyValue(js: Grammar.jKeyValue): DeserializationResult<(string, Values.JSON)>
        decreases js
      {
        var k: string :- String(js.k); var v: Values.JSON :- Value(js.v); Success((k, v))
      }

      function Object(js: Grammar.jobject): DeserializationResult<seq<(string, Values.JSON)>>
        decreases js
      {
        Seq.MapWithResult((d: Suffixed<jKeyValue, jcomma>) requires d in js.data => KeyValue(d.t), js.data)
      }

      function Array(js: Grammar.jarray): DeserializationResult<seq<Values.JSON>>
        decreases js
      {
        Seq.MapWithResult((d: Suffixed<Value, jcomma>) requires d in js.data => Value(d.t), js.data)
      }

      function Value(js: Grammar.Value): DeserializationResult<Values.JSON>
        decreases js
      {
        match js
        case Null(_ /* _v7 */) =>
          Success(Values.Null())
        case Bool(b) =>
          Success(Values.Bool(Bool(b)))
        case String(str) =>
          var s: string :- String(str); Success(Values.String(s))
        case Number(dec) =>
          var n: Values.Decimal :- Number(dec); Success(Values.Number(n))
        case Object(obj) =>
          var o: seq<(string, Values.JSON)> :- Object(obj); Success(Values.Object(o))
        case Array(arr) =>
          var a: seq<Values.JSON> :- Array(arr); Success(Values.Array(a))
      }

      function JSON(js: Grammar.JSON): DeserializationResult<Values.JSON>
        decreases js
      {
        Value(js.t)
      }

      import Values

      import Spec

      import ByteStrConversion

      import opened Seq = Collections.Seq

      import opened Wrappers

      import opened BoundedInts

      import opened Logarithm = Arithmetic.Logarithm

      import opened Power = Arithmetic.Power

      import opened Strings

      import opened UnicodeStringsWithUnicodeChar = Unicode.UnicodeStringsWithUnicodeChar

      import opened Errors

      import opened DynamicArray

      import opened Grammar

      import opened Core = Utils.Views.Core

      module {:disableNonlinearArithmetic} Uint16StrConversion refines Strings.ParametricConversion {
        const chars: CharSeq := ['0' as uint16, '1' as uint16, '2' as uint16, '3' as uint16, '4' as uint16, '5' as uint16, '6' as uint16, '7' as uint16, '8' as uint16, '9' as uint16, 'a' as uint16, 'b' as uint16, 'c' as uint16, 'd' as uint16, 'e' as uint16, 'f' as uint16, 'A' as uint16, 'B' as uint16, 'C' as uint16, 'D' as uint16, 'E' as uint16, 'F' as uint16]
        const charToDigit: map<Char, digit> := map['0' as uint16 := 0, '1' as uint16 := 1, '2' as uint16 := 2, '3' as uint16 := 3, '4' as uint16 := 4, '5' as uint16 := 5, '6' as uint16 := 6, '7' as uint16 := 7, '8' as uint16 := 8, '9' as uint16 := 9, 'a' as uint16 := 10, 'b' as uint16 := 11, 'c' as uint16 := 12, 'd' as uint16 := 13, 'e' as uint16 := 14, 'f' as uint16 := 15, 'A' as uint16 := 10, 'B' as uint16 := 11, 'C' as uint16 := 12, 'D' as uint16 := 13, 'E' as uint16 := 14, 'F' as uint16 := 15]

        lemma {:axiom} CharsConsistent()
          ensures forall c: uint16 {:trigger charToDigit[c]} {:trigger c in charToDigit} {:trigger c in chars} | c in chars :: c in charToDigit && chars[charToDigit[c]] == c
          ensures forall c: uint16 {:trigger charToDigit[c]} {:trigger c in charToDigit} {:trigger c in chars} | c in chars :: c in charToDigit && chars[charToDigit[c]] == c

        const base := |chars|

        function BASE(): nat
          ensures BASE() > 1
        {
          base
        }

        predicate IsDigitChar(c: Char)
          decreases c
        {
          c in charToDigit
        }

        function OfDigits(digits: seq<digit>): (str: String)
          ensures forall c: uint16 {:trigger c in chars} {:trigger c in str} | c in str :: c in chars
          ensures |str| == |digits|
          decreases digits
        {
          if digits == [] then
            []
          else
            assert digits[0] in digits; assert forall d: int {:trigger d in digits} {:trigger d in digits[1..]} | d in digits[1..] :: d in digits; OfDigits(digits[1..]) + [chars[digits[0]]]
        }

        function OfNat(n: nat): (str: String)
          ensures |str| == Log(base, n) + 1
          ensures forall c: uint16 {:trigger c in chars} {:trigger c in str} | c in str :: c in chars
          decreases n
        {
          if n == 0 then
            reveal Log();
            [chars[0]]
          else
            LemmaFromNatLen2(n); OfDigits(FromNat(n))
        }

        predicate IsNumberStr(str: String, minus: Char)
          decreases str
        {
          str != [] ==>
            (str[0] == minus || str[0] in charToDigit) &&
            forall c: uint16 {:trigger IsDigitChar(c)} {:trigger c in str[1..]} | c in str[1..] :: 
              IsDigitChar(c)
        }

        function OfInt(n: int, minus: Char): (str: String)
          ensures IsNumberStr(str, minus)
          decreases n
        {
          CharsConsistent();
          if n >= 0 then
            OfNat(n)
          else
            [minus] + OfNat(-n)
        }

        function {:isolate_assertions} ToNat(str: String): (n: nat)
          requires forall c: uint16 {:trigger IsDigitChar(c)} {:trigger c in str} | c in str :: IsDigitChar(c)
          decreases str
        {
          if str == [] then
            0
          else
            LemmaMulNonnegativeAuto(); var c: uint16 := str[|str| - 1]; assert IsDigitChar(c); ToNat(str[..|str| - 1]) * base + charToDigit[c]
        }

        lemma {:induction false} ToNatBound(str: String)
          requires base > 0
          requires forall c: uint16 {:trigger IsDigitChar(c)} {:trigger c in str} | c in str :: IsDigitChar(c)
          ensures ToNat(str) < Pow(base, |str|)
          decreases str
        {
          if str == [] {
            reveal Pow();
          } else {
            calc <= {
              ToNat(str);
              {
                assert IsDigitChar(str[|str| - 1]);
              }
              ToNat(str[..|str| - 1]) * base + charToDigit[str[|str| - 1]];
              ToNat(str[..|str| - 1]) * base + base - 1;
              {
                ToNatBound(str[..|str| - 1]);
                LemmaMulInequalityAuto();
              }
              (Pow(base, |str| - 1) - 1) * base + base - 1;
              {
                LemmaMulIsDistributiveAuto();
              }
              Pow(base, |str| - 1) * base - 1;
              {
                reveal Pow();
                LemmaMulIsCommutativeAuto();
              }
              Pow(base, |str|) - 1;
            }
          }
        }

        function ToInt(str: String, minus: Char): (s: int)
          requires str != [minus]
          requires IsNumberStr(str, minus)
          decreases str
        {
          if [minus] <= str then
            -(ToNat(str[1..]) as int)
          else
            assert str == [] || str == [str[0]] + str[1..]; ToNat(str)
        }

        function {:opaque} ToNatRight(xs: seq<digit>): nat
          decreases xs
        {
          if |xs| == 0 then
            0
          else
            LemmaMulNonnegativeAuto(); ToNatRight(DropFirst(xs)) * BASE() + First(xs)
        }

        function {:opaque} ToNatLeft(xs: seq<digit>): nat
          decreases xs
        {
          if |xs| == 0 then
            0
          else
            LemmaPowPositiveAuto(); LemmaMulNonnegativeAuto(); ToNatLeft(DropLast(xs)) + Last(xs) * Pow(BASE(), |xs| - 1)
        }

        lemma {:isolate_assertions} /*{:_induction xs}*/ LemmaToNatLeftEqToNatRight(xs: seq<digit>)
          ensures ToNatRight(xs) == ToNatLeft(xs)
          decreases xs
        {
          reveal ToNatRight();
          reveal ToNatLeft();
          if xs == [] {
          } else {
            if DropLast(xs) == [] {
              calc {
                ToNatLeft(xs);
                Last(xs) * Pow(BASE(), |xs| - 1);
                {
                  reveal Pow();
                }
                Last(xs);
                First(xs);
                {
                  assert ToNatRight(DropFirst(xs)) == 0;
                }
                ToNatRight(xs);
              }
            } else {
              calc {
                ToNatLeft(xs);
                ToNatLeft(DropLast(xs)) + Last(xs) * Pow(BASE(), |xs| - 1);
                {
                  LemmaToNatLeftEqToNatRight(DropLast(xs));
                }
                ToNatRight(DropLast(xs)) + Last(xs) * Pow(BASE(), |xs| - 1);
                ToNatRight(DropFirst(DropLast(xs))) * BASE() + First(xs) + Last(xs) * Pow(BASE(), |xs| - 1);
                {
                  LemmaToNatLeftEqToNatRight(DropFirst(DropLast(xs)));
                }
                ToNatLeft(DropFirst(DropLast(xs))) * BASE() + First(xs) + Last(xs) * Pow(BASE(), |xs| - 1);
                {
                  assert DropFirst(DropLast(xs)) == DropLast(DropFirst(xs));
                  reveal Pow();
                  LemmaMulProperties();
                }
                ToNatLeft(DropLast(DropFirst(xs))) * BASE() + First(xs) + Last(xs) * Pow(BASE(), |xs| - 2) * BASE();
                {
                  LemmaMulIsDistributiveAddOtherWayAuto();
                }
                ToNatLeft(DropFirst(xs)) * BASE() + First(xs);
                {
                  LemmaToNatLeftEqToNatRight(DropFirst(xs));
                }
                ToNatRight(xs);
              }
            }
          }
        }

        lemma LemmaToNatLeftEqToNatRightAuto()
          ensures forall xs: seq<digit> {:trigger ToNatLeft(xs)} {:trigger ToNatRight(xs)} :: ToNatRight(xs) == ToNatLeft(xs)
        {
          reveal ToNatRight();
          reveal ToNatLeft();
          forall xs: seq<digit> | true
            ensures ToNatRight(xs) == ToNatLeft(xs)
          {
            LemmaToNatLeftEqToNatRight(xs);
          }
        }

        lemma /*{:_induction xs}*/ LemmaSeqLen1(xs: seq<digit>)
          requires |xs| == 1
          ensures ToNatRight(xs) == First(xs)
          decreases xs
        {
          reveal ToNatRight();
          assert ToNatRight(DropFirst(xs)) == 0;
        }

        lemma /*{:_induction xs}*/ LemmaSeqLen2(xs: seq<digit>)
          requires |xs| == 2
          ensures ToNatRight(xs) == First(xs) + xs[1] * BASE()
          decreases xs
        {
          reveal ToNatRight();
          LemmaSeqLen1(DropLast(xs));
        }

        lemma /*{:_induction xs}*/ LemmaSeqAppendZero(xs: seq<digit>)
          ensures ToNatRight(xs + [0]) == ToNatRight(xs)
          decreases xs
        {
          reveal ToNatLeft();
          LemmaToNatLeftEqToNatRightAuto();
          calc {
            ToNatRight(xs + [0]);
            ToNatLeft(xs + [0]);
            ToNatLeft(xs) + 0 * Pow(BASE(), |xs|);
            {
              LemmaMulBasicsAuto();
            }
            ToNatLeft(xs);
            ToNatRight(xs);
          }
        }

        lemma /*{:_induction xs}*/ LemmaSeqNatBound(xs: seq<digit>)
          ensures ToNatRight(xs) < Pow(BASE(), |xs|)
          decreases xs
        {
          reveal Pow();
          if |xs| == 0 {
            reveal ToNatRight();
          } else {
            ghost var len' := |xs| - 1;
            ghost var pow := Pow(BASE(), len');
            calc {
              ToNatRight(xs);
              {
                LemmaToNatLeftEqToNatRight(xs);
              }
              ToNatLeft(xs);
              {
                reveal ToNatLeft();
              }
              ToNatLeft(DropLast(xs)) + Last(xs) * pow;
            <
              {
                LemmaToNatLeftEqToNatRight(DropLast(xs));
                LemmaSeqNatBound(DropLast(xs));
              }
              pow + Last(xs) * pow;
            <=
              {
                LemmaPowPositiveAuto();
                LemmaMulInequalityAuto();
              }
              pow + (BASE() - 1) * pow;
              {
                LemmaMulIsDistributiveAuto();
              }
              Pow(BASE(), len' + 1);
            }
          }
        }

        lemma {:isolate_assertions} /*{:_induction xs, i}*/ LemmaSeqPrefix(xs: seq<digit>, i: nat)
          requires 0 <= i <= |xs|
          ensures ToNatRight(xs[..i]) + ToNatRight(xs[i..]) * Pow(BASE(), i) == ToNatRight(xs)
          decreases xs, i
        {
          reveal ToNatRight();
          reveal Pow();
          if i == 1 {
            assert ToNatRight(xs[..1]) == First(xs);
          } else if i > 1 {
            calc {
              ToNatRight(xs[..i]) + ToNatRight(xs[i..]) * Pow(BASE(), i);
              ToNatRight(DropFirst(xs[..i])) * BASE() + First(xs) + ToNatRight(xs[i..]) * Pow(BASE(), i);
              {
                assert DropFirst(xs[..i]) == DropFirst(xs)[..i - 1];
                LemmaMulProperties();
              }
              ToNatRight(DropFirst(xs)[..i - 1]) * BASE() + First(xs) + ToNatRight(xs[i..]) * Pow(BASE(), i - 1) * BASE();
              {
                LemmaMulIsDistributiveAddOtherWayAuto();
              }
              (ToNatRight(DropFirst(xs)[..i - 1]) + ToNatRight(DropFirst(xs)[i - 1..]) * Pow(BASE(), i - 1)) * BASE() + First(xs);
              {
                LemmaSeqPrefix(DropFirst(xs), i - 1);
              }
              ToNatRight(xs);
            }
          }
        }

        lemma /*{:_induction xs, ys}*/ LemmaSeqMswInequality(xs: seq<digit>, ys: seq<digit>)
          requires |xs| == |ys| > 0
          requires Last(xs) < Last(ys)
          ensures ToNatRight(xs) < ToNatRight(ys)
          decreases xs, ys
        {
          reveal ToNatLeft();
          LemmaToNatLeftEqToNatRightAuto();
          ghost var len' := |xs| - 1;
          calc {
            ToNatRight(xs);
            ToNatLeft(xs);
          <
            {
              LemmaSeqNatBound(DropLast(xs));
            }
            Pow(BASE(), len') + Last(xs) * Pow(BASE(), len');
          ==
            {
              LemmaMulIsDistributiveAuto();
            }
            (1 + Last(xs)) * Pow(BASE(), len');
          <=
            {
              LemmaPowPositiveAuto();
              LemmaMulInequalityAuto();
            }
            ToNatLeft(ys);
            ToNatRight(ys);
          }
        }

        lemma {:isolate_assertions} /*{:_induction xs, ys}*/ LemmaSeqPrefixNeq(xs: seq<digit>, ys: seq<digit>, i: nat)
          requires 0 <= i <= |xs| == |ys|
          requires ToNatRight(xs[..i]) != ToNatRight(ys[..i])
          ensures ToNatRight(xs) != ToNatRight(ys)
          decreases |xs| - i
        {
          if i == |xs| {
            assert xs[..i] == xs;
            assert ys[..i] == ys;
          } else {
            if xs[i] == ys[i] {
              reveal ToNatLeft();
              assert DropLast(xs[..i + 1]) == xs[..i];
              assert DropLast(ys[..i + 1]) == ys[..i];
              LemmaToNatLeftEqToNatRightAuto();
              assert ToNatRight(xs[..i + 1]) == ToNatLeft(xs[..i + 1]);
            } else if xs[i] < ys[i] {
              LemmaSeqMswInequality(xs[..i + 1], ys[..i + 1]);
            } else {
              LemmaSeqMswInequality(ys[..i + 1], xs[..i + 1]);
            }
            reveal ToNatRight();
            LemmaSeqPrefixNeq(xs, ys, i + 1);
          }
        }

        lemma /*{:_induction xs, ys}*/ LemmaSeqNeq(xs: seq<digit>, ys: seq<digit>)
          requires |xs| == |ys|
          requires xs != ys
          ensures ToNatRight(xs) != ToNatRight(ys)
          decreases xs, ys
        {
          ghost var i: nat, n: nat := 0, |xs|;
          while i < n
            invariant 0 <= i < n
            invariant xs[..i] == ys[..i]
            decreases n - i
          {
            if xs[i] != ys[i] {
              break;
            }
            i := i + 1;
          }
          assert ToNatLeft(xs[..i]) == ToNatLeft(ys[..i]);
          reveal ToNatLeft();
          assert xs[..i + 1][..i] == xs[..i];
          assert ys[..i + 1][..i] == ys[..i];
          LemmaPowPositiveAuto();
          LemmaMulStrictInequalityAuto();
          assert ToNatLeft(xs[..i + 1]) != ToNatLeft(ys[..i + 1]);
          LemmaToNatLeftEqToNatRightAuto();
          LemmaSeqPrefixNeq(xs, ys, i + 1);
        }

        lemma /*{:_induction xs, ys}*/ LemmaSeqEq(xs: seq<digit>, ys: seq<digit>)
          requires |xs| == |ys|
          requires ToNatRight(xs) == ToNatRight(ys)
          ensures xs == ys
          decreases xs, ys
        {
          calc ==> {
            xs != ys;
            {
              LemmaSeqNeq(xs, ys);
            }
            ToNatRight(xs) != ToNatRight(ys);
            false;
          }
        }

        lemma {:isolate_assertions} /*{:_induction xs}*/ LemmaSeqLswModEquivalence(xs: seq<digit>)
          requires |xs| >= 1
          ensures IsModEquivalent(ToNatRight(xs), First(xs), BASE())
          decreases xs
        {
          if |xs| == 1 {
            LemmaSeqLen1(xs);
            LemmaModEquivalenceAuto();
          } else {
            assert IsModEquivalent(ToNatRight(xs), First(xs), BASE()) by {
              reveal ToNatRight();
              calc ==> {
                true;
                {
                  LemmaModEquivalence(ToNatRight(xs), ToNatRight(DropFirst(xs)) * BASE() + First(xs), BASE());
                }
                IsModEquivalent(ToNatRight(xs), ToNatRight(DropFirst(xs)) * BASE() + First(xs), BASE());
                {
                  LemmaModMultiplesBasicAuto();
                }
                IsModEquivalent(ToNatRight(xs), First(xs), BASE());
              }
            }
          }
        }

        function {:opaque} FromNat(n: nat): (xs: seq<digit>)
          decreases n
        {
          if n == 0 then
            []
          else
            LemmaDivBasicsAuto(); LemmaDivDecreasesAuto(); [n % BASE()] + FromNat(n / BASE())
        }

        lemma /*{:_induction n}*/ LemmaFromNatLen2(n: nat)
          ensures n == 0 ==> |FromNat(n)| == 0
          ensures n > 0 ==> |FromNat(n)| == Log(BASE(), n) + 1
          decreases n
        {
          reveal FromNat();
          ghost var digits := FromNat(n);
          if n == 0 {
          } else {
            assert |digits| == Log(BASE(), n) + 1 by {
              LemmaDivBasicsAuto();
              ghost var digits' := FromNat(n / BASE());
              assert |digits| == |digits'| + 1;
              if n < BASE() {
                LemmaLog0(BASE(), n);
                assert n / BASE() == 0 by {
                  LemmaBasicDiv(BASE());
                }
              } else {
                LemmaLogS(BASE(), n);
                assert n / BASE() > 0 by {
                  LemmaDivNonZeroAuto();
                }
              }
            }
          }
        }

        lemma /*{:_induction n, len}*/ LemmaFromNatLen(n: nat, len: nat)
          requires Pow(BASE(), len) > n
          ensures |FromNat(n)| <= len
          decreases n, len
        {
          reveal FromNat();
          if n == 0 {
          } else {
            calc {
              |FromNat(n)|;
            ==
              {
                LemmaDivBasicsAuto();
              }
              1 + |FromNat(n / BASE())|;
            <=
              {
                LemmaMultiplyDivideLtAuto();
                LemmaDivDecreasesAuto();
                reveal Pow();
                LemmaFromNatLen(n / BASE(), len - 1);
              }
              len;
            }
          }
        }

        lemma /*{:_induction n}*/ LemmaNatSeqNat(n: nat)
          ensures ToNatRight(FromNat(n)) == n
          decreases n
        {
          reveal ToNatRight();
          reveal FromNat();
          if n == 0 {
          } else {
            calc {
              ToNatRight(FromNat(n));
              {
                LemmaDivBasicsAuto();
              }
              ToNatRight([n % BASE()] + FromNat(n / BASE()));
              n % BASE() + ToNatRight(FromNat(n / BASE())) * BASE();
              {
                LemmaDivDecreasesAuto();
                LemmaNatSeqNat(n / BASE());
              }
              n % BASE() + n / BASE() * BASE();
              {
                LemmaFundamentalDivMod(n, BASE());
              }
              n;
            }
          }
        }

        function {:opaque} SeqExtend(xs: seq<digit>, n: nat): (ys: seq<digit>)
          requires |xs| <= n
          ensures |ys| == n
          ensures ToNatRight(ys) == ToNatRight(xs)
          decreases n - |xs|
        {
          if |xs| >= n then
            xs
          else
            LemmaSeqAppendZero(xs); SeqExtend(xs + [0], n)
        }

        function {:opaque} SeqExtendMultiple(xs: seq<digit>, n: nat): (ys: seq<digit>)
          requires n > 0
          ensures |ys| % n == 0
          ensures ToNatRight(ys) == ToNatRight(xs)
          decreases xs, n
        {
          var newLen: int := |xs| + n - |xs| % n;
          LemmaSubModNoopRight(|xs| + n, |xs|, n);
          LemmaModBasicsAuto();
          assert newLen % n == 0;
          LemmaSeqNatBound(xs);
          LemmaPowIncreasesAuto();
          SeqExtend(xs, newLen)
        }

        function {:opaque} FromNatWithLen(n: nat, len: nat): (xs: seq<digit>)
          requires Pow(BASE(), len) > n
          ensures |xs| == len
          ensures ToNatRight(xs) == n
          decreases n, len
        {
          LemmaFromNatLen(n, len);
          LemmaNatSeqNat(n);
          SeqExtend(FromNat(n), len)
        }

        lemma {:resource_limit ""10e6""} /*{:_induction xs}*/ LemmaSeqZero(xs: seq<digit>)
          requires ToNatRight(xs) == 0
          ensures forall i: int {:trigger xs[i]} :: 0 <= i < |xs| ==> xs[i] == 0
          decreases xs
        {
          reveal ToNatRight();
          if |xs| == 0 {
          } else {
            LemmaMulNonnegativeAuto();
            assert First(xs) == 0;
            LemmaMulNonzeroAuto();
            LemmaSeqZero(DropFirst(xs));
          }
        }

        function {:opaque} SeqZero(len: nat): (xs: seq<digit>)
          ensures |xs| == len
          ensures forall i: int {:trigger xs[i]} :: 0 <= i < |xs| ==> xs[i] == 0
          ensures ToNatRight(xs) == 0
          decreases len
        {
          LemmaPowPositive(BASE(), len);
          var xs: seq<digit> := FromNatWithLen(0, len);
          LemmaSeqZero(xs);
          xs
        }

        lemma /*{:_induction xs}*/ LemmaSeqNatSeq(xs: seq<digit>)
          ensures Pow(BASE(), |xs|) > ToNatRight(xs)
          ensures FromNatWithLen(ToNatRight(xs), |xs|) == xs
          decreases xs
        {
          reveal FromNat();
          reveal ToNatRight();
          LemmaSeqNatBound(xs);
          if |xs| > 0 {
            calc {
              FromNatWithLen(ToNatRight(xs), |xs|) != xs;
              {
                LemmaSeqNeq(FromNatWithLen(ToNatRight(xs), |xs|), xs);
              }
              ToNatRight(FromNatWithLen(ToNatRight(xs), |xs|)) != ToNatRight(xs);
              ToNatRight(xs) != ToNatRight(xs);
              false;
            }
          }
        }

        function {:opaque} SeqAdd(xs: seq<digit>, ys: seq<digit>): (seq<digit>, nat)
          requires |xs| == |ys|
          ensures var (zs: seq<digit>, cout: nat) := SeqAdd(xs, ys); |zs| == |xs| && 0 <= cout <= 1
          decreases xs
        {
          if |xs| == 0 then
            ([], 0)
          else
            var (zs': seq<digit>, cin: nat) := SeqAdd(DropLast(xs), DropLast(ys)); var sum: int := Last(xs) + Last(ys) + cin; var (sum_out: int, cout: int) := if sum < BASE() then (sum, 0) else (sum - BASE(), 1); (zs' + [sum_out], cout)
        }

        lemma {:isolate_assertions} /*{:_induction xs, ys, zs}*/ LemmaSeqAdd(xs: seq<digit>, ys: seq<digit>, zs: seq<digit>, cout: nat)
          requires |xs| == |ys|
          requires SeqAdd(xs, ys) == (zs, cout)
          ensures ToNatRight(xs) + ToNatRight(ys) == ToNatRight(zs) + cout * Pow(BASE(), |xs|)
          decreases xs, ys, zs, cout
        {
          reveal SeqAdd();
          if |xs| == 0 {
            reveal ToNatRight();
          } else {
            ghost var pow := Pow(BASE(), |xs| - 1);
            var (zs', cin) := SeqAdd(DropLast(xs), DropLast(ys));
            ghost var sum: int := Last(xs) + Last(ys) + cin;
            ghost var z := if sum < BASE() then sum else sum - BASE();
            assert sum == z + cout * BASE();
            reveal ToNatLeft();
            LemmaToNatLeftEqToNatRightAuto();
            calc {
              ToNatRight(zs);
              ToNatLeft(zs);
              ToNatLeft(zs') + z * pow;
              {
                LemmaSeqAdd(DropLast(xs), DropLast(ys), zs', cin);
              }
              ToNatLeft(DropLast(xs)) + ToNatLeft(DropLast(ys)) - cin * pow + z * pow;
              {
                LemmaMulEquality(sum, z + cout * BASE(), pow);
                assert sum * pow == (z + cout * BASE()) * pow;
                LemmaMulIsDistributiveAuto();
              }
              ToNatLeft(xs) + ToNatLeft(ys) - cout * BASE() * pow;
              {
                LemmaMulIsAssociative(cout, BASE(), pow);
                reveal Pow();
              }
              ToNatLeft(xs) + ToNatLeft(ys) - cout * Pow(BASE(), |xs|);
              ToNatRight(xs) + ToNatRight(ys) - cout * Pow(BASE(), |xs|);
            }
          }
        }

        function {:opaque} SeqSub(xs: seq<digit>, ys: seq<digit>): (seq<digit>, nat)
          requires |xs| == |ys|
          ensures var (zs: seq<digit>, cout: nat) := SeqSub(xs, ys); |zs| == |xs| && 0 <= cout <= 1
          decreases xs
        {
          if |xs| == 0 then
            ([], 0)
          else
            var (zs: seq<digit>, cin: nat) := SeqSub(DropLast(xs), DropLast(ys)); var (diff_out: int, cout: int) := if Last(xs) >= Last(ys) + cin then (Last(xs) - Last(ys) - cin, 0) else (BASE() + Last(xs) - Last(ys) - cin, 1); (zs + [diff_out], cout)
        }

        lemma {:isolate_assertions} /*{:_induction xs, ys, zs}*/ LemmaSeqSub(xs: seq<digit>, ys: seq<digit>, zs: seq<digit>, cout: nat)
          requires |xs| == |ys|
          requires SeqSub(xs, ys) == (zs, cout)
          ensures ToNatRight(xs) - ToNatRight(ys) + cout * Pow(BASE(), |xs|) == ToNatRight(zs)
          decreases xs, ys, zs, cout
        {
          reveal SeqSub();
          if |xs| == 0 {
            reveal ToNatRight();
          } else {
            ghost var pow := Pow(BASE(), |xs| - 1);
            var (zs', cin) := SeqSub(DropLast(xs), DropLast(ys));
            ghost var z := if Last(xs) >= Last(ys) + cin then Last(xs) - Last(ys) - cin else BASE() + Last(xs) - Last(ys) - cin;
            assert cout * BASE() + Last(xs) - cin - Last(ys) == z;
            reveal ToNatLeft();
            LemmaToNatLeftEqToNatRightAuto();
            calc {
              ToNatRight(zs);
              ToNatLeft(zs);
              ToNatLeft(zs') + z * pow;
              {
                LemmaSeqSub(DropLast(xs), DropLast(ys), zs', cin);
              }
              ToNatLeft(DropLast(xs)) - ToNatLeft(DropLast(ys)) + cin * pow + z * pow;
              {
                LemmaMulEquality(cout * BASE() + Last(xs) - cin - Last(ys), z, pow);
                assert pow * (cout * BASE() + Last(xs) - cin - Last(ys)) == pow * z;
                LemmaMulIsDistributiveAuto();
              }
              ToNatLeft(xs) - ToNatLeft(ys) + cout * BASE() * pow;
              {
                LemmaMulIsAssociative(cout, BASE(), pow);
                reveal Pow();
              }
              ToNatLeft(xs) - ToNatLeft(ys) + cout * Pow(BASE(), |xs|);
              ToNatRight(xs) - ToNatRight(ys) + cout * Pow(BASE(), |xs|);
            }
          }
        }

        import opened BoundedInts

        type Char = uint16

        import opened Wrappers

        type String = seq<Char>

        type CharSeq = chars: seq<Char>
          | |chars| > 1
          witness *

        import opened DivMod

        import opened Mul

        import opened Power

        import opened Seq = Collections.Seq

        import opened Logarithm

        type digit = i: nat
          | 0 <= i < BASE()
      }
    }

    module Errors {

      import Wrappers

      import Strings

      import opened BoundedInts
      datatype DeserializationError = UnterminatedSequence | UnsupportedEscape(str: string) | EscapeAtEOS | EmptyNumber | ExpectingEOF | IntOverflow | ReachedEOF | ExpectingByte(expected: byte, b: opt_byte) | ExpectingAnyByte(expected_sq: seq<byte>, b: opt_byte) | InvalidUnicode {
        function ToString(): string
          decreases this
        {
          match this
          case UnterminatedSequence() =>
            ""Unterminated sequence""
          case UnsupportedEscape(str) =>
            ""Unsupported escape sequence: "" + str
          case EscapeAtEOS() =>
            ""Escape character at end of string""
          case EmptyNumber() =>
            ""Number must contain at least one digit""
          case ExpectingEOF() =>
            ""Expecting EOF""
          case IntOverflow() =>
            ""Input length does not fit in a 32-bit counter""
          case ReachedEOF() =>
            ""Reached EOF""
          case ExpectingByte(b0, b) =>
            var c: seq<char> := if b > 0 then ""'"" + [b as char] + ""'"" else ""EOF"";
            ""Expecting '"" + [b0 as char] + ""', read "" + c
          case ExpectingAnyByte(bs0, b) =>
            var c: seq<char> := if b > 0 then ""'"" + [b as char] + ""'"" else ""EOF"";
            var c0s: seq<char> := seq(|bs0|, (idx: int) requires 0 <= idx < |bs0| => bs0[idx] as char);
            ""Expecting one of '"" + c0s + ""', read "" + c
          case InvalidUnicode() =>
            ""Invalid Unicode sequence""
        }
      }

      datatype SerializationError = OutOfMemory | IntTooLarge(i: int) | StringTooLong(s: string) | InvalidUnicode {
        function ToString(): string
          decreases this
        {
          match this
          case OutOfMemory() =>
            ""Out of memory""
          case IntTooLarge(i: int) =>
            ""Integer too large: "" + Strings.OfInt(i)
          case StringTooLong(s: string) =>
            ""String too long: "" + s
          case InvalidUnicode() =>
            ""Invalid Unicode sequence""
        }
      }

      type SerializationResult<+T> = Wrappers.Result<T, SerializationError>

      type DeserializationResult<+T> = Wrappers.Result<T, DeserializationError>
    }

    module Grammar {
      const EMPTY := View.OfBytes([])
      const DOUBLEQUOTE := View.OfBytes(['\""' as byte])
      const PERIOD := View.OfBytes(['.' as byte])
      const E := View.OfBytes(['e' as byte])
      const COLON := View.OfBytes([':' as byte])
      const COMMA := View.OfBytes([',' as byte])
      const LBRACE := View.OfBytes(['{' as byte])
      const RBRACE := View.OfBytes(['}' as byte])
      const LBRACKET := View.OfBytes(['[' as byte])
      const RBRACKET := View.OfBytes([']' as byte])
      const MINUS := View.OfBytes(['-' as byte])

      predicate Blank?(b: byte)
        decreases b
      {
        b == 32 || b == 9 || b == 10 || b == 13
      }

      ghost predicate Blanks?(v: View)
        decreases v
      {
        forall b: uint8 {:trigger Blank?(b)} {:trigger b in v.Bytes()} | b in v.Bytes() :: 
          Blank?(b)
      }

      ghost predicate NoTrailingSuffix<S, D>(s: seq<Suffixed<D, S>>)
        decreases s
      {
        forall idx: int {:trigger s[idx]} | 0 <= idx < |s| :: 
          s[idx].suffix.Empty? <==> idx == |s| - 1
      }

      const NULL: bytes := ['n' as byte, 'u' as byte, 'l' as byte, 'l' as byte]
      const TRUE: bytes := ['t' as byte, 'r' as byte, 'u' as byte, 'e' as byte]
      const FALSE: bytes := ['f' as byte, 'a' as byte, 'l' as byte, 's' as byte, 'e' as byte]

      ghost predicate Null?(v: View)
        decreases v
      {
        v.Bytes() == NULL
      }

      ghost predicate Bool?(v: View)
        decreases v
      {
        v.Bytes() in {TRUE, FALSE}
      }

      predicate Digit?(b: byte)
        decreases b
      {
        '0' as byte <= b <= '9' as byte
      }

      ghost predicate Digits?(v: View)
        decreases v
      {
        forall b: uint8 {:trigger Digit?(b)} {:trigger b in v.Bytes()} | b in v.Bytes() :: 
          Digit?(b)
      }

      ghost predicate Num?(v: View)
        decreases v
      {
        Digits?(v) &&
        !v.Empty?
      }

      ghost predicate Int?(v: View)
        decreases v
      {
        v.Char?('0') || (Num?(v) && v.At(0) != '0' as byte)
      }

      import opened BoundedInts

      import opened Core = Utils.Views.Core

      type jchar = v: View
        | v.Length() == 1
        witness View.OfBytes(['b' as byte])

      type jquote = v: View
        | v.Char?('\""')
        witness DOUBLEQUOTE

      type jperiod = v: View
        | v.Char?('.')
        witness PERIOD

      type je = v: View
        | v.Char?('e') || v.Char?('E')
        witness E

      type jcolon = v: View
        | v.Char?(':')
        witness COLON

      type jcomma = v: View
        | v.Char?(',')
        witness COMMA

      type jlbrace = v: View
        | v.Char?('{')
        witness LBRACE

      type jrbrace = v: View
        | v.Char?('}')
        witness RBRACE

      type jlbracket = v: View
        | v.Char?('[')
        witness LBRACKET

      type jrbracket = v: View
        | v.Char?(']')
        witness RBRACKET

      type jminus = v: View
        | v.Char?('-') || v.Empty?
        witness MINUS

      type jsign = v: View
        | v.Char?('-') || v.Char?('+') || v.Empty?
        witness EMPTY

      type jblanks = v: View
        | Blanks?(v)
        witness View.OfBytes([])

      datatype Structural<+T> = Structural(before: jblanks, t: T, after: jblanks)

      datatype Maybe<+T> = Empty | NonEmpty(t: T)

      datatype Suffixed<+T, +S> = Suffixed(t: T, suffix: Maybe<Structural<S>>)

      type SuffixedSequence<+D, +S> = s: seq<Suffixed<D, S>>
        | NoTrailingSuffix(s)

      datatype Bracketed<+L, +D, +S, +R> = Bracketed(l: Structural<L>, data: SuffixedSequence<D, S>, r: Structural<R>)

      type jnull = v: View
        | Null?(v)
        witness View.OfBytes(NULL)

      type jbool = v: View
        | Bool?(v)
        witness View.OfBytes(TRUE)

      type jdigits = v: View
        | Digits?(v)
        witness View.OfBytes([])

      type jnum = v: View
        | Num?(v)
        witness View.OfBytes(['0' as byte])

      type jint = v: View
        | Int?(v)
        witness View.OfBytes(['0' as byte])

      type jstr = v: View
        | true
        witness View.OfBytes([])

      datatype jstring = JString(lq: jquote, contents: jstr, rq: jquote)

      datatype jKeyValue = KeyValue(k: jstring, colon: Structural<jcolon>, v: Value)

      type jobject = Bracketed<jlbrace, jKeyValue, jcomma, jrbrace>

      type jarray = Bracketed<jlbracket, Value, jcomma, jrbracket>

      type jmembers = SuffixedSequence<jKeyValue, jcomma>

      type jmember = Suffixed<jKeyValue, jcomma>

      type jitems = SuffixedSequence<Value, jcomma>

      type jitem = Suffixed<Value, jcomma>

      datatype jfrac = JFrac(period: jperiod, num: jnum)

      datatype jexp = JExp(e: je, sign: jsign, num: jnum)

      datatype jnumber = JNumber(minus: jminus, num: jnum, frac: Maybe<jfrac>, exp: Maybe<jexp>)

      datatype Value = Null(n: jnull) | Bool(b: jbool) | String(str: jstring) | Number(num: jnumber) | Object(obj: jobject) | Array(arr: jarray)

      type JSON = Structural<Value>
    }

    module Serializer {
      function Bool(b: bool): jbool
        decreases b
      {
        View.OfBytes(if b then TRUE else FALSE)
      }

      function CheckLength<T>(s: seq<T>, err: SerializationError): Outcome<SerializationError>
        decreases s, err
      {
        Outcome.Need(|s| < TWO_TO_THE_32, err)
      }

      function String(str: string): Result<jstring>
        decreases str
      {
        var bs: bytes :- Spec.EscapeToUTF8(str); var o: Outcome<SerializationError> := CheckLength(bs, StringTooLong(str)); if o.Pass? then Success(Grammar.JString(Grammar.DOUBLEQUOTE, View.OfBytes(bs), Grammar.DOUBLEQUOTE)) else Failure(o.error)
      }

      function Sign(n: int): jminus
        decreases n
      {
        View.OfBytes(if n < 0 then ['-' as byte] else [])
      }

      const DIGITS := ByteStrConversion.chars
      const MINUS := '-' as byte

      function Int'(n: int): (str: bytes)
        ensures forall c: uint8 {:trigger c in DIGITS} {:trigger c in str} | c in str :: c in DIGITS || c == MINUS
        decreases n
      {
        ByteStrConversion.OfInt(n, MINUS)
      }

      function Int(n: int): Result<View>
        decreases n
      {
        var bs: bytes := Int'(n);
        var o: Outcome<SerializationError> := CheckLength(bs, IntTooLarge(n));
        if o.Pass? then
          Success(View.OfBytes(bs))
        else
          Failure(o.error)
      }

      function {:isolate_assertions} {:resource_limit 1000000} Number(dec: Values.Decimal): Result<jnumber>
        decreases dec
      {
        var minus: jminus := Sign(dec.n);
        var num: jnum :- Int(Math.Abs(dec.n)); var frac: Maybe<jfrac> := Empty(); var exp: Maybe<jexp> :- if dec.e10 == 0 then Success(Empty()) else var e: je := View.OfBytes(['e' as byte]); var sign: jsign := Sign(dec.e10); var num: jnum :- Int(Math.Abs(dec.e10)); Success(NonEmpty(JExp(e, sign, num))); Success(JNumber(minus, num, Empty, exp))
      }

      function MkStructural<T>(v: T): Structural<T>
      {
        Structural(EMPTY, v, EMPTY)
      }

      const COLON: Structural<jcolon> := MkStructural(Grammar.COLON)

      function KeyValue(kv: (string, Values.JSON)): Result<jKeyValue>
        decreases kv
      {
        var k: jstring :- String(kv.0); var v: Grammar.Value :- Value(kv.1); Success(Grammar.KeyValue(k, COLON, v))
      }

      function MkSuffixedSequence<D, S>(ds: seq<D>, suffix: Structural<S>, start: nat := 0): SuffixedSequence<D, S>
        decreases |ds| - start
      {
        if start >= |ds| then
          []
        else if start == |ds| - 1 then
          [Suffixed(ds[start], Empty)]
        else
          [Suffixed(ds[start], NonEmpty(suffix))] + MkSuffixedSequence(ds, suffix, start + 1)
      }

      const COMMA: Structural<jcomma> := MkStructural(Grammar.COMMA)

      function Object(obj: seq<(string, Values.JSON)>): Result<jobject>
        decreases obj
      {
        var items: seq<jKeyValue> :- Seq.MapWithResult((v: (string, Values.JSON)) requires v in obj => KeyValue(v), obj); Success(Bracketed(MkStructural(LBRACE), MkSuffixedSequence(items, COMMA), MkStructural(RBRACE)))
      }

      function Array(arr: seq<Values.JSON>): Result<jarray>
        decreases arr
      {
        var items: seq<Grammar.Value> :- Seq.MapWithResult((v: Values.JSON) requires v in arr => Value(v), arr); Success(Bracketed(MkStructural(LBRACKET), MkSuffixedSequence(items, COMMA), MkStructural(RBRACKET)))
      }

      function Value(js: Values.JSON): Result<Grammar.Value>
        decreases js
      {
        match js
        case Null() =>
          Success(Grammar.Null(View.OfBytes(NULL)))
        case Bool(b) =>
          Success(Grammar.Bool(Bool(b)))
        case String(str) =>
          var s: jstring :- String(str); Success(Grammar.String(s))
        case Number(dec) =>
          var n: jnumber :- Number(dec); Success(Grammar.Number(n))
        case Object(obj) =>
          var o: jobject :- Object(obj); Success(Grammar.Object(o))
        case Array(arr) =>
          var a: jarray :- Array(arr); Success(Grammar.Array(a))
      }

      function JSON(js: Values.JSON): Result<Grammar.JSON>
        decreases js
      {
        var val: Grammar.Value :- Value(js); Success(MkStructural(val))
      }

      import Seq = Collections.Seq

      import Math

      import Values

      import Spec

      import opened Wrappers

      import opened BoundedInts

      import opened Strings

      import opened Errors

      import opened DynamicArray

      import opened Grammar

      import opened Core = Utils.Views.Core

      import ByteStrConversion

      type Result<+T> = SerializationResult<T>

      type bytes = seq<uint8>

      type bytes32 = bs: bytes
        | |bs| < TWO_TO_THE_32

      type string32 = s: string
        | |s| < TWO_TO_THE_32
    }

    module Spec {
      function EscapeUnicode(c: uint16): seq<uint16>
        decreases c
      {
        var sStr: String := Strings.HexConversion.OfNat(c as nat);
        Seq.MembershipImpliesIndexing((c: char) => 0 <= c as int < 128, sStr);
        var s: seq<uint16> := ASCIIToUTF16(sStr);
        assert |s| <= 4 by {
          assert c as nat <= 65535;
          assert Log(16, c as nat) <= Log(16, 65535) by {
            LemmaLogIsOrdered(16, c as nat, 65535);
          }
          assert Log(16, 65535) == 3 by {
            reveal Log();
          }
        }
        s + seq(4 - |s|, (_ /* _v8 */: int) => ' ' as uint16)
      }

      function Escape(str: seq<uint16>, start: nat := 0): seq<uint16>
        decreases |str| - start
      {
        if start >= |str| then
          []
        else
          (match str[start] case 34 => ASCIIToUTF16(""\\\"""") case 92 => ASCIIToUTF16(""\\\\"") case 8 => ASCIIToUTF16(""\\b"") case 12 => ASCIIToUTF16(""\\f"") case 10 => ASCIIToUTF16(""\\n"") case 13 => ASCIIToUTF16(""\\r"") case 9 => ASCIIToUTF16(""\\t"") case c => (if c < 31 then ASCIIToUTF16(""\\u"") + EscapeUnicode(c) else [str[start]])) + Escape(str, start + 1)
      }

      function EscapeToUTF8(str: string, start: nat := 0): Result<bytes>
        decreases str, start
      {
        var utf16: seq<uint16> :- ToUTF16Checked(str).ToResult(SerializationError.InvalidUnicode); var escaped: seq<uint16> := Escape(utf16); var utf32: string :- FromUTF16Checked(escaped).ToResult(SerializationError.InvalidUnicode); ToUTF8Checked(utf32).ToResult(SerializationError.InvalidUnicode)
      }

      function String(str: string): Result<bytes>
        decreases str
      {
        var inBytes: bytes :- EscapeToUTF8(str); Success(ASCIIToUTF8(""\"""") + inBytes + ASCIIToUTF8(""\""""))
      }

      lemma OfIntOnlyASCII(n: int)
        ensures true && ghost var s: string := Strings.OfInt(n); true && forall i: int {:trigger s[i]} | 0 <= i < |s| :: 0 <= s[i] as int && s[i] as int < 128
        decreases n
      {
        ghost var s := Strings.OfInt(n);
        forall i: int | 0 <= i < |s|
          ensures 0 <= s[i] as int < 128
        {
          if i == 0 {
          } else {
            ghost var isHexDigit := (c: char) => c in Strings.HexConversion.HEX_DIGITS;
            assert Strings.HexConversion.IsNumberStr(s, '-');
            assert isHexDigit(s[i]);
          }
        }
      }

      function IntToBytes(n: int): bytes
        decreases n
      {
        var s: string := Strings.OfInt(n);
        OfIntOnlyASCII(n);
        ASCIIToUTF8(s)
      }

      function Number(dec: Decimal): Result<bytes>
        decreases dec
      {
        Success(IntToBytes(dec.n) + if dec.e10 == 0 then [] else ASCIIToUTF8(""e"") + IntToBytes(dec.e10))
      }

      function KeyValue(kv: (string, JSON)): Result<bytes>
        decreases kv
      {
        var key: bytes :- String(kv.0); var value: bytes :- JSON(kv.1); Success(key + ASCIIToUTF8("":"") + value)
      }

      function Join(sep: bytes, items: seq<Result<bytes>>): Result<bytes>
        decreases sep, items
      {
        if |items| == 0 then
          Success([])
        else
          var first: bytes :- items[0]; if |items| == 1 then Success(first) else var rest: bytes :- Join(sep, items[1..]); Success(first + sep + rest)
      }

      function Object(obj: seq<(string, JSON)>): Result<bytes>
        decreases obj
      {
        var middle: bytes :- Join(ASCIIToUTF8("",""), seq(|obj|, (i: int) requires 0 <= i < |obj| => KeyValue(obj[i]))); Success(ASCIIToUTF8(""{"") + middle + ASCIIToUTF8(""}""))
      }

      function Array(arr: seq<JSON>): Result<bytes>
        decreases arr
      {
        var middle: bytes :- Join(ASCIIToUTF8("",""), seq(|arr|, (i: int) requires 0 <= i < |arr| => JSON(arr[i]))); Success(ASCIIToUTF8(""["") + middle + ASCIIToUTF8(""]""))
      }

      function JSON(js: JSON): Result<bytes>
        decreases js
      {
        match js
        case Null() =>
          Success(ASCIIToUTF8(""null""))
        case Bool(b) =>
          Success(if b then ASCIIToUTF8(""true"") else ASCIIToUTF8(""false""))
        case String(str) =>
          String(str)
        case Number(dec) =>
          Number(dec)
        case Object(obj) =>
          Object(obj)
        case Array(arr) =>
          Array(arr)
      }

      import Seq = Collections.Seq

      import opened BoundedInts

      import opened Strings

      import opened Values

      import opened Wrappers

      import opened Errors

      import opened UnicodeStringsWithUnicodeChar = Unicode.UnicodeStringsWithUnicodeChar

      import opened Logarithm = Arithmetic.Logarithm

      type Result<+T> = SerializationResult<T>
    }

    module Values {
      function Int(n: int): Decimal
        decreases n
      {
        Decimal(n, 0)
      }

      datatype Decimal = Decimal(n: int, e10: int)

      datatype JSON = Null | Bool(b: bool) | String(str: string) | Number(num: Decimal) | Object(obj: seq<(string, JSON)>) | Array(arr: seq<JSON>)
    }

    module ConcreteSyntax {

      module Spec {
        function View(v: Vs.View): bytes
          decreases v
        {
          v.Bytes()
        }

        function Structural<T>(self: Structural<T>, fT: T -> bytes): bytes
          decreases self
        {
          View(self.before) + fT(self.t) + View(self.after)
        }

        function StructuralView(self: Structural<Vs.View>): bytes
          decreases self
        {
          Structural<Vs.View>(self, View)
        }

        function Maybe<T>(self: Maybe<T>, fT: T -> bytes): (bs: bytes)
          ensures self.Empty? ==> bs == []
          ensures self.NonEmpty? ==> bs == fT(self.t)
          decreases self
        {
          if self.Empty? then
            []
          else
            fT(self.t)
        }

        function ConcatBytes<T>(ts: seq<T>, fT: T --> bytes): (b: bytes)
          requires forall d: T {:trigger fT.requires(d)} {:trigger d in ts} | d in ts :: fT.requires(d)
          ensures |ts| == 1 ==> b == fT(ts[0])
          decreases ts
        {
          if |ts| == 0 then
            []
          else
            fT(ts[0]) + ConcatBytes(ts[1..], fT)
        }

        function Bracketed<D, S>(self: Bracketed<Vs.View, D, S, Vs.View>, fDatum: Suffixed<D, S> --> bytes): bytes
          requires forall d: Suffixed<D, S> {:trigger fDatum.requires(d)} | d < self :: fDatum.requires(d)
          decreases self
        {
          StructuralView(self.l) + ConcatBytes(self.data, fDatum) + StructuralView(self.r)
        }

        function KeyValue(self: jKeyValue): bytes
          decreases self
        {
          String(self.k) + StructuralView(self.colon) + Value(self.v)
        }

        function Frac(self: jfrac): bytes
          decreases self
        {
          View(self.period) + View(self.num)
        }

        function Exp(self: jexp): bytes
          decreases self
        {
          View(self.e) + View(self.sign) + View(self.num)
        }

        function Number(self: jnumber): bytes
          decreases self
        {
          View(self.minus) + View(self.num) + Maybe(self.frac, Frac) + Maybe(self.exp, Exp)
        }

        function String(self: jstring): bytes
          decreases self
        {
          View(self.lq) + View(self.contents) + View(self.rq)
        }

        function CommaSuffix(c: Maybe<Structural<jcomma>>): bytes
          decreases c
        {
          Maybe<Structural<Vs.View>>(c, StructuralView)
        }

        function Member(self: jmember): bytes
          decreases self
        {
          KeyValue(self.t) + CommaSuffix(self.suffix)
        }

        function Item(self: jitem): bytes
          decreases self
        {
          Value(self.t) + CommaSuffix(self.suffix)
        }

        function Object(obj: jobject): bytes
          decreases obj
        {
          Bracketed(obj, (d: jmember) requires d < obj => Member(d))
        }

        function Array(arr: jarray): bytes
          decreases arr
        {
          Bracketed(arr, (d: jitem) requires d < arr => Item(d))
        }

        function Value(self: Value): (b: bytes)
          ensures self.String? ==> b == String(self.str)
          ensures self.Number? ==> b == Number(self.num)
          ensures self.Object? ==> b == Object(self.obj)
          ensures self.Array? ==> b == Array(self.arr)
          decreases self
        {
          match self {
            case Null(n) =>
              View(n)
            case Bool(b) =>
              View(b)
            case String(str) =>
              String(str)
            case Number(num) =>
              Number(num)
            case Object(obj) =>
              Object(obj)
            case Array(arr) =>
              Array(arr)
          }
        }

        lemma /*{:_induction v}*/ UnfoldValueNumber(v: Value)
          requires v.Number?
          ensures Value(v) == Number(v.num)
          decreases v
        {
          assert Value(v) == match v { case Number(num) => Number(num) case _ /* _v1 */ => [] };
        }

        lemma /*{:_induction v}*/ UnfoldValueObject(v: Value)
          requires v.Object?
          ensures Value(v) == Object(v.obj)
          decreases v
        {
          assert Value(v) == match v { case Object(obj) => Object(obj) case _ /* _v2 */ => [] };
        }

        lemma /*{:_induction v}*/ UnfoldValueArray(v: Value)
          requires v.Array?
          ensures Value(v) == Array(v.arr)
          decreases v
        {
          assert Value(v) == match v { case Array(arr) => Array(arr) case _ /* _v3 */ => [] };
        }

        function JSON(js: JSON): bytes
          decreases js
        {
          Structural(js, Value)
        }

        import Vs = Utils.Views.Core

        import opened BoundedInts

        import opened Grammar
      }

      module SpecProperties {
        ghost predicate Bracketed_Morphism_Requires<D, S>(bracketed: Bracketed<Vs.View, D, S, Vs.View>, pd0: Suffixed<D, S> --> bytes, pd1: Suffixed<D, S> --> bytes)
          decreases bracketed
        {
          (forall d: Suffixed<D, S> {:trigger pd0.requires(d)} | d < bracketed :: 
            pd0.requires(d)) &&
          (forall d: Suffixed<D, S> {:trigger pd1.requires(d)} | d < bracketed :: 
            pd1.requires(d)) &&
          forall d: Suffixed<D, S> {:trigger pd1(d)} {:trigger pd0(d)} | d < bracketed :: 
            pd0(d) == pd1(d)
        }

        lemma Bracketed_Morphism<D, S>(bracketed: Bracketed<Vs.View, D, S, Vs.View>, pd0: Suffixed<D, S> --> bytes, pd1: Suffixed<D, S> --> bytes)
          requires Bracketed_Morphism_Requires(bracketed, pd0, pd1)
          ensures Spec.Bracketed(bracketed, pd0) == Spec.Bracketed(bracketed, pd1)
          decreases bracketed
        {
          calc {
            Spec.Bracketed(bracketed, pd0);
            {
              ConcatBytes_Morphism(bracketed.data, pd0, pd1);
            }
            Spec.Bracketed(bracketed, pd1);
          }
        }

        lemma {:induction ts} /*{:_induction ts}*/ ConcatBytes_Morphism<T>(ts: seq<T>, pt0: T --> bytes, pt1: T --> bytes)
          requires forall d: T {:trigger pt0.requires(d)} {:trigger d in ts} | d in ts :: pt0.requires(d)
          requires forall d: T {:trigger pt1.requires(d)} {:trigger d in ts} | d in ts :: pt1.requires(d)
          requires forall d: T {:trigger pt1(d)} {:trigger pt0(d)} {:trigger d in ts} | d in ts :: pt0(d) == pt1(d)
          ensures Spec.ConcatBytes(ts, pt0) == Spec.ConcatBytes(ts, pt1)
          decreases ts
        {
        }

        lemma {:induction ts0} {:resource_limit 10000000} /*{:_induction ts0}*/ ConcatBytes_Linear<T>(ts0: seq<T>, ts1: seq<T>, pt: T --> bytes)
          requires forall d: T {:trigger pt.requires(d)} {:trigger d in ts0} | d in ts0 :: pt.requires(d)
          requires forall d: T {:trigger pt.requires(d)} {:trigger d in ts1} | d in ts1 :: pt.requires(d)
          ensures Spec.ConcatBytes(ts0 + ts1, pt) == Spec.ConcatBytes(ts0, pt) + Spec.ConcatBytes(ts1, pt)
          decreases ts0, ts1
        {
          if |ts0| == 0 {
            assert [] + ts1 == ts1;
          } else {
            assert ts0 + ts1 == [ts0[0]] + (ts0[1..] + ts1);
          }
        }

        import Spec

        import Vs = Utils.Views.Core

        import opened BoundedInts

        import opened Grammar
      }
    }

    module Utils {

      module Cursors {

        import opened BoundedInts

        import opened Wrappers

        import opened Vs = Views.Core

        import opened Lx = Lexers.Core
        datatype Split<+T> = SP(t: T, cs: FreshCursor) {
          ghost predicate BytesSplitFrom?(cs0: Cursor, spec: T -> bytes)
            decreases this, cs0
          {
            cs0.Bytes() == spec(t) + cs.Bytes()
          }

          ghost predicate SplitFrom?(cs0: Cursor, spec: T -> bytes)
            decreases this, cs0
          {
            cs.SplitFrom?(cs0) &&
            BytesSplitFrom?(cs0, spec)
          }

          ghost predicate StrictlySplitFrom?(cs0: Cursor, spec: T -> bytes)
            decreases this, cs0
          {
            cs.StrictlySplitFrom?(cs0) &&
            BytesSplitFrom?(cs0, spec)
          }
        }

        type Cursor = ps: Cursor_
          | ps.Valid?
          witness Cursor([], 0, 0, 0)

        type FreshCursor = ps: Cursor
          | ps.BOF?
          witness Cursor([], 0, 0, 0)

        datatype CursorError<+R> = EOF | ExpectingByte(expected: byte, b: opt_byte) | ExpectingAnyByte(expected_sq: seq<byte>, b: opt_byte) | OtherError(err: R) {
          function ToString(pr: R -> string): string
            decreases this
          {
            match this
            case EOF() =>
              ""Reached EOF""
            case ExpectingByte(b0, b) =>
              var c: seq<char> := if b > 0 then ""'"" + [b as char] + ""'"" else ""EOF"";
              ""Expecting '"" + [b0 as char] + ""', read "" + c
            case ExpectingAnyByte(bs0, b) =>
              var c: seq<char> := if b > 0 then ""'"" + [b as char] + ""'"" else ""EOF"";
              var c0s: seq<char> := seq(|bs0|, (idx: int) requires 0 <= idx < |bs0| => bs0[idx] as char);
              ""Expecting one of '"" + c0s + ""', read "" + c
            case OtherError(err) =>
              pr(err)
          }
        }

        type CursorResult<+R> = Result<Cursor, CursorError<R>>

        datatype Cursor_ = Cursor(s: bytes, beg: uint32, point: uint32, end: uint32) {
          ghost const Valid?: bool := 0 <= beg as int <= point as int <= end as int <= |s| < TWO_TO_THE_32
          const BOF? := point == beg
          const EOF? := point == end

          static function OfView(v: View): FreshCursor
            decreases v
          {
            Cursor(v.s, v.beg, v.beg, v.end)
          }

          static function OfBytes(bs: bytes): FreshCursor
            requires |bs| < TWO_TO_THE_32
            decreases bs
          {
            Cursor(bs, 0, 0, |bs| as uint32)
          }

          function Bytes(): bytes
            requires Valid?
            decreases this
          {
            s[beg .. end]
          }

          ghost predicate StrictlyAdvancedFrom?(other: Cursor): (b: bool)
            requires Valid?
            ensures b ==> SuffixLength() < other.SuffixLength()
            ensures b ==> beg == other.beg && end == other.end ==> forall idx: uint32 {:trigger other.s[idx]} {:trigger s[idx]} | beg <= idx < point :: s[idx] == other.s[idx]
            decreases this, other
          {
            s == other.s &&
            beg == other.beg &&
            end == other.end &&
            point > other.point
          }

          ghost predicate AdvancedFrom?(other: Cursor)
            requires Valid?
            decreases this, other
          {
            this == other || StrictlyAdvancedFrom?(other)
          }

          ghost predicate StrictSuffixOf?(other: Cursor)
            requires Valid?
            ensures StrictSuffixOf?(other) ==> Length() < other.Length()
            decreases this, other
          {
            s == other.s &&
            beg > other.beg &&
            end == other.end
          }

          ghost predicate SuffixOf?(other: Cursor)
            requires Valid?
            decreases this, other
          {
            this == other || StrictSuffixOf?(other)
          }

          ghost predicate StrictlySplitFrom?(other: Cursor)
            requires Valid?
            decreases this, other
          {
            BOF? &&
            StrictSuffixOf?(other)
          }

          ghost predicate SplitFrom?(other: Cursor)
            requires Valid?
            decreases this, other
          {
            this == other || StrictlySplitFrom?(other)
          }

          function Prefix(): View
            requires Valid?
            decreases this
          {
            View(s, beg, point)
          }

          function Suffix(): Cursor
            requires Valid?
            decreases this
          {
            this.(beg := point)
          }

          function Split(): (sp: Split<View>)
            requires Valid?
            ensures sp.SplitFrom?(this, (v: View) => v.Bytes())
            ensures beg != point ==> sp.StrictlySplitFrom?(this, (v: View) => v.Bytes())
            ensures !BOF? ==> sp.StrictlySplitFrom?(this, (v: View) => v.Bytes()) && sp.cs.StrictSuffixOf?(this)
            ensures !EOF? <==> !sp.cs.EOF?
            decreases this
          {
            SP(this.Prefix(), this.Suffix())
          }

          function PrefixLength(): uint32
            requires Valid?
            decreases this
          {
            point - beg
          }

          function SuffixLength(): uint32
            requires Valid?
            decreases this
          {
            end - point
          }

          function Length(): uint32
            requires Valid?
            decreases this
          {
            end - beg
          }

          lemma /*{:_induction this}*/ PrefixSuffixLength()
            requires Valid?
            ensures Length() == PrefixLength() + SuffixLength()
            decreases this
          {
          }

          ghost predicate ValidIndex?(idx: uint32)
            decreases this, idx
          {
            beg as int + idx as int < end as int
          }

          function At(idx: uint32): byte
            requires Valid?
            requires ValidIndex?(idx)
            decreases this, idx
          {
            s[beg + idx]
          }

          ghost predicate ValidSuffixIndex?(idx: uint32)
            decreases this, idx
          {
            point as int + idx as int < end as int
          }

          function SuffixAt(idx: uint32): byte
            requires Valid?
            requires ValidSuffixIndex?(idx)
            decreases this, idx
          {
            s[point + idx]
          }

          function Peek(): (r: opt_byte)
            requires Valid?
            ensures r < 0 <==> EOF?
            decreases this
          {
            if EOF? then
              -1
            else
              SuffixAt(0) as opt_byte
          }

          predicate LookingAt(c: char): (b: bool)
            requires Valid?
            requires c as int < 256
            ensures b <==> !EOF? && SuffixAt(0) == c as byte
            decreases this, c
          {
            Peek() == c as opt_byte
          }

          function Skip(n: uint32): (ps: Cursor)
            requires Valid?
            requires point as int + n as int <= end as int
            ensures n == 0 ==> ps == this
            ensures n > 0 ==> ps.StrictlyAdvancedFrom?(this)
            decreases this, n
          {
            this.(point := point + n)
          }

          function Unskip(n: uint32): Cursor
            requires Valid?
            requires beg as int <= point as int - n as int
            decreases this, n
          {
            this.(point := point - n)
          }

          function Get<R>(err: R): (ppr: CursorResult<R>)
            requires Valid?
            ensures ppr.Success? ==> ppr.value.StrictlyAdvancedFrom?(this)
            decreases this
          {
            if EOF? then
              Failure(OtherError(err))
            else
              Success(Skip(1))
          }

          function AssertByte<R>(b: byte): (pr: CursorResult<R>)
            requires Valid?
            ensures pr.Success? ==> !EOF?
            ensures pr.Success? ==> s[point] == b
            ensures pr.Success? ==> pr.value.StrictlyAdvancedFrom?(this)
            decreases this, b
          {
            var nxt: opt_byte := Peek();
            if nxt == b as opt_byte then
              Success(Skip(1))
            else
              Failure(ExpectingByte(b, nxt))
          }

          function {:tailrecursion} AssertBytes<R>(bs: bytes, offset: uint32 := 0): (pr: CursorResult<R>)
            requires Valid?
            requires |bs| < TWO_TO_THE_32
            requires offset <= |bs| as uint32
            requires forall b: uint8 {:trigger b in bs} | b in bs :: b as int < 256
            ensures pr.Success? ==> pr.value.AdvancedFrom?(this)
            ensures pr.Success? && offset < |bs| as uint32 ==> pr.value.StrictlyAdvancedFrom?(this)
            ensures pr.Success? ==> s[point .. pr.value.point] == bs[offset..]
            decreases SuffixLength()
          {
            if offset == |bs| as uint32 then
              Success(this)
            else
              var ps: Cursor :- AssertByte(bs[offset] as byte); ps.AssertBytes(bs, offset + 1)
          }

          function AssertChar<R>(c0: char): (pr: CursorResult<R>)
            requires Valid?
            requires c0 as int < 256
            ensures pr.Success? ==> pr.value.StrictlyAdvancedFrom?(this)
            decreases this, c0
          {
            AssertByte(c0 as byte)
          }

          function SkipByte(): (ps: Cursor)
            requires Valid?
            ensures ps.AdvancedFrom?(this)
            ensures !EOF? ==> ps.StrictlyAdvancedFrom?(this)
            decreases SuffixLength()
          {
            if EOF? then
              this
            else
              Skip(1)
          }

          function SkipIf(p: byte -> bool): (ps: Cursor)
            requires Valid?
            ensures ps.AdvancedFrom?(this)
            ensures !EOF? && p(SuffixAt(0)) ==> ps.StrictlyAdvancedFrom?(this)
            decreases SuffixLength()
          {
            if EOF? || !p(SuffixAt(0)) then
              this
            else
              Skip(1)
          }

          function SkipWhile(p: byte -> bool): (ps: Cursor)
            requires Valid?
            ensures ps.AdvancedFrom?(this)
            ensures forall idx: uint32 {:trigger ps.s[idx]} | point <= idx < ps.point :: p(ps.s[idx])
            decreases SuffixLength()
          {
            if EOF? || !p(SuffixAt(0)) then
              this
            else
              Skip(1).SkipWhile(p)
          } by method {
            var point' := this.point;
            var end := this.end;
            while point' < end && p(this.s[point'])
              invariant var thisAfter: Cursor_ := this.(point := point'); thisAfter.Valid?
              invariant var thisAfter: Cursor_ := this.(point := point'); thisAfter.SkipWhile(p) == this.SkipWhile(p)
              decreases end as int - point' as int
            {
              point' := point' + 1;
            }
            return Cursor(this.s, this.beg, point', this.end);
          }

          function SkipWhileLexer<A, R>(step: Lexer<A, R>, st: A): (pr: CursorResult<R>)
            requires Valid?
            ensures pr.Success? ==> pr.value.AdvancedFrom?(this)
            decreases SuffixLength()
          {
            match step(st, Peek())
            case Accept() =>
              Success(this)
            case Reject(err) =>
              Failure(OtherError(err))
            case Partial(st) =>
              if EOF? then
                Failure(EOF)
              else
                Skip(1).SkipWhileLexer(step, st)
          } by method {
            var point' := point;
            var end := this.end;
            var st' := st;
            while true
              invariant var thisAfter: Cursor_ := this.(point := point'); thisAfter.Valid?
              invariant var thisAfter: Cursor_ := this.(point := point'); thisAfter.SkipWhileLexer(step, st') == this.SkipWhileLexer(step, st)
              decreases var thisAfter: Cursor_ := this.(point := point'); thisAfter.SuffixLength()
            {
              var eof := point' == end;
              var minusone: opt_byte := -1;
              var c := if eof then minusone else this.s[point'] as opt_byte;
              match step(st', c)
              case {:split false} Accept() =>
                return Success(Cursor(this.s, this.beg, point', this.end));
              case {:split false} Reject(err) =>
                return Failure(OtherError(err));
              case {:split false} Partial(st'') =>
                if eof {
                  return Failure(EOF);
                } else {
                  st' := st'';
                  point' := point' + 1;
                }
            }
          }
        }
      }

      module Lexers {

        module Core {

          import opened Wrappers

          import opened BoundedInts
          datatype LexerResult<+T, +R> = Accept | Reject(err: R) | Partial(st: T)

          type Lexer<!T, +R> = (T, opt_byte) -> LexerResult<T, R>
        }

        module Strings {
          const StringBodyLexerStart: StringBodyLexerState := false

          function StringBody<R>(escaped: StringBodyLexerState, byte: opt_byte): LexerResult<StringBodyLexerState, R>
            decreases escaped, byte
          {
            if byte == '\\' as opt_byte then
              Partial(!escaped)
            else if byte == '\""' as opt_byte && !escaped then
              Accept
            else
              Partial(false)
          }

          const StringLexerStart: StringLexerState := Start

          function String(st: StringLexerState, byte: opt_byte): LexerResult<StringLexerState, string>
            decreases st, byte
          {
            match st
            case Start() =>
              if byte == '\""' as opt_byte then
                Partial(Body(false))
              else
                Reject(""String must start with double quote"")
            case End() =>
              Accept
            case Body(escaped) =>
              if byte == '\\' as opt_byte then
                Partial(Body(!escaped))
              else if byte == '\""' as opt_byte && !escaped then
                Partial(End)
              else
                Partial(Body(false))
          }

          import opened Core

          import opened BoundedInts

          type StringBodyLexerState = bool

          datatype StringLexerState = Start | Body(escaped: bool) | End
        }
      }

      module Parsers {
        opaque function ParserWitness<T, R>(): (p: Parser_<T, R>)
          ensures p.Valid?()
        {
          Parser((_ /* _v9 */: FreshCursor) => Failure(EOF), (_ /* _v10 */: T) => [])
        }

        opaque function SubParserWitness<T, R>(): (subp: SubParser_<T, R>)
          ensures subp.Valid?()
        {
          SubParser(Cursor([], 0, 0, 0), (cs: FreshCursor) => false, (cs: FreshCursor) => Failure(EOF), (_ /* _v11 */: T) => [])
        }

        import opened BoundedInts

        import opened Wrappers

        import opened Core = Views.Core

        import opened Cursors

        type SplitResult<+T, +R> = Result<Split<T>, CursorError<R>>

        type Parser<!T, +R> = p: Parser_<T, R>
          | p.Valid?()
          witness ParserWitness<T, R>()

        datatype Parser_<!T, +R> = Parser(fn: FreshCursor -> SplitResult<T, R>, ghost spec: T -> bytes) {
          ghost predicate Valid?()
            decreases this
          {
            forall cs': FreshCursor {:trigger fn(cs')} :: 
              fn(cs').Success? ==>
                fn(cs').value.StrictlySplitFrom?(cs', spec)
          }
        }

        datatype SubParser_<!T, +R> = SubParser(ghost cs: Cursor, ghost pre: FreshCursor -> bool, fn: FreshCursor --> SplitResult<T, R>, ghost spec: T -> bytes) {
          ghost predicate Valid?()
            decreases this
          {
            (forall cs': FreshCursor {:trigger fn.requires(cs')} {:trigger pre(cs')} | pre(cs') :: 
              fn.requires(cs')) &&
            (forall cs': FreshCursor {:trigger pre(cs')} {:trigger cs'.StrictlySplitFrom?(cs)} | cs'.StrictlySplitFrom?(cs) :: 
              pre(cs')) &&
            forall cs': FreshCursor {:trigger fn(cs')} {:trigger pre(cs')} | pre(cs') :: 
              fn(cs').Success? ==>
                fn(cs').value.StrictlySplitFrom?(cs', spec)
          }
        }

        type SubParser<!T, +R> = p: SubParser_<T, R>
          | p.Valid?()
          witness SubParserWitness<T, R>()
      }

      module Views {

        module Core {
          predicate Adjacent(lv: View, rv: View)
            decreases lv, rv
          {
            lv.end == rv.beg &&
            lv.s == rv.s
          }

          function Merge(lv: View, rv: View): (v: View)
            requires Adjacent(lv, rv)
            ensures v.Bytes() == lv.Bytes() + rv.Bytes()
            decreases lv, rv
          {
            lv.(end := rv.end)
          }

          import opened BoundedInts

          type View = v: View_
            | v.Valid?
            witness View([], 0, 0)

          datatype View_ = View(s: bytes, beg: uint32, end: uint32) {
            ghost const Valid?: bool := 0 <= beg as int <= end as int <= |s| < TWO_TO_THE_32
            static const Empty: View := View([], 0, 0)
            const Empty? := beg == end

            function Length(): uint32
              requires Valid?
              decreases this
            {
              end - beg
            }

            function Bytes(): bytes
              requires Valid?
              decreases this
            {
              s[beg .. end]
            }

            static function OfBytes(bs: bytes): (v: View)
              requires |bs| < TWO_TO_THE_32
              ensures v.Bytes() == bs
              decreases bs
            {
              View(bs, 0 as uint32, |bs| as uint32)
            }

            static function OfString(s: string): bytes
              requires forall c: char {:trigger c in s} | c in s :: c as int < 256
              decreases s
            {
              seq(|s|, (i: int) requires 0 <= i < |s| => assert s[i] in s; s[i] as byte)
            }

            ghost predicate SliceOf?(v': View)
              decreases this, v'
            {
              v'.s == s &&
              v'.beg <= beg &&
              end <= v'.end
            }

            ghost predicate StrictPrefixOf?(v': View)
              decreases this, v'
            {
              v'.s == s &&
              v'.beg == beg &&
              end < v'.end
            }

            ghost predicate StrictSuffixOf?(v': View)
              decreases this, v'
            {
              v'.s == s &&
              v'.beg < beg &&
              end == v'.end
            }

            predicate Byte?(c: byte)
              requires Valid?
              decreases this, c
            {
              Bytes() == [c]
            } by method {
              return Length() == 1 && At(0) == c;
            }

            predicate Char?(c: char)
              requires Valid?
              requires c as int < 256
              decreases this, c
            {
              Byte?(c as byte)
            }

            ghost predicate ValidIndex?(idx: uint32)
              decreases this, idx
            {
              beg as int + idx as int < end as int
            }

            function At(idx: uint32): byte
              requires Valid?
              requires ValidIndex?(idx)
              decreases this, idx
            {
              s[beg + idx]
            }

            function Peek(): (r: opt_byte)
              requires Valid?
              ensures r < 0 <==> Empty?
              decreases this
            {
              if Empty? then
                -1
              else
                At(0) as opt_byte
            }

            method CopyTo(dest: array<byte>, start: uint32 := 0)
              requires Valid?
              requires start as int + Length() as int <= dest.Length
              requires start as int + Length() as int < TWO_TO_THE_32
              modifies dest
              ensures dest[start .. start + Length()] == Bytes()
              ensures dest[start + Length()..] == old(dest[start + Length()..])
              decreases this, dest, start
            {
              for idx: uint32 := 0 to Length()
                invariant dest[start .. start + idx] == Bytes()[..idx]
                invariant dest[start + Length()..] == old(dest[start + Length()..])
              {
                dest[start + idx] := s[beg + idx];
              }
            }
          }
        }

        module Writers {

          import opened BoundedInts

          import opened Wrappers

          import opened Core
          datatype Chain = Empty | Chain(previous: Chain, v: View) {
            function Length(): nat
              decreases this
            {
              if Empty? then
                0
              else
                previous.Length() + v.Length() as int
            }

            function Count(): nat
              decreases this
            {
              if Empty? then
                0
              else
                previous.Count() + 1
            }

            function Bytes(): (bs: bytes)
              ensures |bs| == Length()
              decreases this
            {
              if Empty? then
                []
              else
                previous.Bytes() + v.Bytes()
            }

            function Append(v': View): (c: Chain)
              ensures c.Bytes() == Bytes() + v'.Bytes()
              decreases this, v'
            {
              if Chain? && Adjacent(v, v') then
                Chain(previous, Merge(v, v'))
              else
                Chain(this, v')
            }

            method {:tailrecursion} CopyTo(dest: array<byte>, end: uint32)
              requires end as int == Length() <= dest.Length
              modifies dest
              ensures dest[..end] == Bytes()
              ensures dest[end..] == old(dest[end..])
              decreases this, dest, end
            {
              if Chain? {
                var end := end - v.Length();
                v.CopyTo(dest, end);
                previous.CopyTo(dest, end);
              }
            }
          }

          type Writer = w: Writer_
            | w.Valid?
            witness Writer(0, Chain.Empty)

          datatype Writer_ = Writer(length: uint32, chain: Chain) {
            static const Empty: Writer := Writer(0, Chain.Empty)
            const Empty? := chain.Empty?
            const Unsaturated? := length != UINT32_MAX

            ghost function Length(): nat
              decreases this
            {
              chain.Length()
            }

            ghost const Valid? := length == if chain.Length() >= TWO_TO_THE_32 then UINT32_MAX else chain.Length() as uint32

            function Bytes(): (bs: bytes)
              ensures |bs| == Length()
              decreases this
            {
              chain.Bytes()
            }

            static function SaturatedAddU32(a: uint32, b: uint32): uint32
              decreases a, b
            {
              if a <= UINT32_MAX - b then
                a + b
              else
                UINT32_MAX
            }

            opaque function Append(v': View): (rw: Writer)
              requires Valid?
              ensures rw.Unsaturated? <==> v'.Length() < UINT32_MAX - length
              ensures rw.Bytes() == Bytes() + v'.Bytes()
              decreases this, v'
            {
              Writer(SaturatedAddU32(length, v'.Length()), chain.Append(v'))
            }

            function Then(fn: Writer ~> Writer): Writer
              requires Valid?
              requires fn.requires(this)
              reads fn.reads(this)
              decreases fn.reads(this), this
            {
              fn(this)
            }

            method {:tailrecursion} CopyTo(dest: array<byte>)
              requires Valid?
              requires Unsaturated?
              requires Length() <= dest.Length
              modifies dest
              ensures dest[..length] == Bytes()
              ensures dest[length..] == old(dest[length..])
              decreases this, dest
            {
              chain.CopyTo(dest, length);
            }

            method ToArray() returns (bs: array<byte>)
              requires Valid?
              requires Unsaturated?
              ensures fresh(bs)
              ensures bs[..] == Bytes()
              decreases this
            {
              bs := new byte[length] ((i: nat) => 0);
              CopyTo(bs);
            }
          }
        }
      }
    }

    module ZeroCopy {

      module API {
        opaque function Serialize(js: Grammar.JSON): (bs: SerializationResult<seq<byte>>)
          ensures bs == Success(Spec.JSON(js))
          decreases js
        {
          Success(Serializer.Text(js).Bytes())
        }

        method SerializeAlloc(js: Grammar.JSON) returns (bs: SerializationResult<array<byte>>)
          ensures bs.Success? ==> fresh(bs.value)
          ensures bs.Success? ==> bs.value[..] == Spec.JSON(js)
          decreases js
        {
          bs := Serializer.Serialize(js);
        }

        method SerializeInto(js: Grammar.JSON, bs: array<byte>) returns (len: SerializationResult<uint32>)
          modifies bs
          ensures len.Success? ==> len.value as int <= bs.Length
          ensures len.Success? ==> bs[..len.value] == Spec.JSON(js)
          ensures len.Success? ==> bs[len.value..] == old(bs[len.value..])
          ensures len.Failure? ==> unchanged(bs)
          decreases js, bs
        {
          len := Serializer.SerializeTo(js, bs);
        }

        opaque function Deserialize(bs: seq<byte>): (js: DeserializationResult<Grammar.JSON>)
          ensures js.Success? ==> bs == Spec.JSON(js.value)
          decreases bs
        {
          Deserializer.API.OfBytes(bs)
        }

        import Grammar

        import Spec = ConcreteSyntax.Spec

        import Serializer

        import Deserializer

        import opened BoundedInts

        import opened Wrappers

        import opened Errors
      }

      module Deserializer {

        module Core {
          const SpecView := (v: Vs.View) => Spec.View(v)

          opaque function Get(cs: FreshCursor, err: JSONError): (pr: ParseResult<jchar>)
            ensures pr.Success? ==> pr.value.StrictlySplitFrom?(cs, SpecView)
            decreases cs, err
          {
            var cs: Cursor :- cs.Get(err); Success(cs.Split())
          }

          opaque function WS(cs: FreshCursor): (sp: Split<jblanks>)
            ensures sp.SplitFrom?(cs, SpecView)
            ensures sp.cs.SuffixOf?(cs)
            ensures !cs.BOF? ==> sp.cs.StrictSuffixOf?(cs)
            ensures cs.EOF? ==> sp.cs.SuffixOf?(cs.Suffix())
            decreases cs
          {
            cs.SkipWhile(Blank?).Split()
          } by method {
            reveal WS();
            var point' := cs.point;
            var end := cs.end;
            while point' < end && Blank?(cs.s[point'])
              invariant var csAfter: Cursor_ := cs.(point := point'); csAfter.Valid?
              invariant var csAfter: Cursor_ := cs.(point := point'); csAfter.SkipWhile(Blank?) == cs.SkipWhile(Blank?)
              decreases end as int - point' as int
            {
              point' := point' + 1;
            }
            return Cursor(cs.s, cs.beg, point', cs.end).Split();
          }

          opaque function {:isolate_assertions} {:resource_limit 1000000000} Structural<T>(cs: FreshCursor, parser: Parser<T>): (pr: ParseResult<Structural<T>>)
            requires forall cs: FreshCursor {:trigger parser.fn.requires(cs)} :: parser.fn.requires(cs)
            ensures pr.Success? ==> pr.value.StrictlySplitFrom?(cs, (st: Structural<T>) => Spec.Structural(st, parser.spec))
            decreases cs, parser
          {
            var SP(before: jblanks, cs: FreshCursor) := WS(cs);
            var SP(val: T, cs: FreshCursor) :- parser.fn(cs); var SP(after: jblanks, cs: FreshCursor) := WS(cs); Success(SP(Grammar.Structural(before, val, after), cs))
          }

          function {:resource_limit 100000000} TryStructural(cs: FreshCursor): (sp: Split<Structural<jopt>>)
            ensures sp.SplitFrom?(cs, (st: Structural<jopt>) => Spec.Structural(st, SpecView))
            decreases cs
          {
            var SP(before: jblanks, cs: FreshCursor) := WS(cs);
            var SP(val: View, cs: FreshCursor) := cs.SkipByte().Split();
            var SP(after: jblanks, cs: FreshCursor) := WS(cs);
            SP(Grammar.Structural(before, val, after), cs)
          }

          ghost predicate ValueParserValid(sp: SubParser<Value>)
            decreases sp
          {
            forall t: Value {:trigger Spec.Value(t)} {:trigger sp.spec(t)} :: 
              sp.spec(t) == Spec.Value(t)
          }

          import opened BoundedInts

          import opened Wrappers

          import Spec = ConcreteSyntax.Spec

          import Vs = Utils.Views.Core

          import opened Cursors = Utils.Cursors

          import opened Parsers = Utils.Parsers

          import opened Grammar

          import Errors

          import opened Seq = Collections.Seq

          type JSONError = Errors.DeserializationError

          type Error = CursorError<JSONError>

          type ParseResult<+T> = SplitResult<T, JSONError>

          type Parser<!T> = Parsers.Parser<T, JSONError>

          type SubParser<!T> = Parsers.SubParser<T, JSONError>

          type jopt = v: Vs.View
            | v.Length() <= 1
            witness Vs.View.OfBytes([])

          type ValueParser = sp: SubParser<Value>
            | ValueParserValid(sp)
            witness *
        }
        type Error = Core.Error

        abstract module SequenceParams {
          const OPEN: byte
          const CLOSE: byte

          ghost function ElementSpec(t: TElement): bytes

          function Element(cs: FreshCursor, json: ValueParser): (pr: ParseResult<TElement>)
            requires cs.StrictlySplitFrom?(json.cs)
            ensures pr.Success? ==> pr.value.StrictlySplitFrom?(cs, ElementSpec)
            decreases cs.Length()

          import opened BoundedInts

          import opened Grammar

          import opened Cursors = Utils.Cursors

          import opened Core

          type TElement
        }

        abstract module Sequences {
          const SEPARATOR: byte := ',' as byte
          const SpecViewClose: jclose -> bytes := SpecView
          const SpecViewOpen: jopen -> bytes := SpecView

          ghost function SuffixedElementSpec(e: TSuffixedElement): bytes
            decreases e
          {
            ElementSpec(e.t) + Spec.CommaSuffix(e.suffix)
          }

          ghost function BracketedSpec(ts: TBracketed): bytes
            decreases ts
          {
            Spec.Bracketed(ts, SuffixedElementSpec)
          }

          ghost function SuffixedElementsSpec(ts: seq<TSuffixedElement>): bytes
            decreases ts
          {
            Spec.ConcatBytes(ts, SuffixedElementSpec)
          }

          opaque function Open(cs: FreshCursor): (pr: ParseResult<jopen>)
            ensures pr.Success? ==> pr.value.StrictlySplitFrom?(cs, SpecViewOpen)
            decreases cs
          {
            var cs: Cursor :- cs.AssertByte(OPEN); Success(cs.Split())
          }

          opaque function Close(cs: FreshCursor): (pr: ParseResult<jclose>)
            ensures pr.Success? ==> pr.value.StrictlySplitFrom?(cs, SpecViewClose)
            decreases cs
          {
            var cs: Cursor :- cs.AssertByte(CLOSE); Success(cs.Split())
          }

          opaque function BracketedFromParts(ghost cs: Cursor, open: Split<Structural<jopen>>, elems: Split<seq<TSuffixedElement>>, close: Split<Structural<jclose>>): (sp: Split<TBracketed>)
            requires Grammar.NoTrailingSuffix(elems.t)
            requires open.StrictlySplitFrom?(cs, (c: Structural<jopen>) => Spec.Structural(c, SpecView))
            requires elems.SplitFrom?(open.cs, SuffixedElementsSpec)
            requires close.StrictlySplitFrom?(elems.cs, (c: Structural<jclose>) => Spec.Structural(c, SpecView))
            ensures sp.StrictlySplitFrom?(cs, BracketedSpec)
            decreases cs, open, elems, close
          {
            var sp: Split<Bracketed<jopen, TElement, jcomma, jclose>> := SP(Grammar.Bracketed(open.t, elems.t, close.t), close.cs);
            calc {
              cs.Bytes();
              Spec.Structural(open.t, SpecView) + open.cs.Bytes();
              {
                assert open.cs.Bytes() == SuffixedElementsSpec(elems.t) + elems.cs.Bytes();
              }
              Spec.Structural(open.t, SpecView) + (SuffixedElementsSpec(elems.t) + elems.cs.Bytes());
              {
                Seq.LemmaConcatIsAssociative(Spec.Structural(open.t, SpecView), SuffixedElementsSpec(elems.t), elems.cs.Bytes());
              }
              Spec.Structural(open.t, SpecView) + SuffixedElementsSpec(elems.t) + elems.cs.Bytes();
              {
                assert elems.cs.Bytes() == Spec.Structural(close.t, SpecView) + close.cs.Bytes();
              }
              Spec.Structural(open.t, SpecView) + SuffixedElementsSpec(elems.t) + (Spec.Structural(close.t, SpecView) + close.cs.Bytes());
              {
                Seq.LemmaConcatIsAssociative(Spec.Structural(open.t, SpecView) + SuffixedElementsSpec(elems.t), Spec.Structural(close.t, SpecView), close.cs.Bytes());
              }
              Spec.Structural(open.t, SpecView) + SuffixedElementsSpec(elems.t) + Spec.Structural(close.t, SpecView) + close.cs.Bytes();
              Spec.Bracketed(sp.t, SuffixedElementSpec) + close.cs.Bytes();
            }
            assert sp.StrictlySplitFrom?(cs, BracketedSpec);
            sp
          }

          opaque function AppendWithSuffix(ghost cs0: FreshCursor, ghost json: ValueParser, elems: Split<seq<TSuffixedElement>>, elem: Split<TElement>, sep: Split<Structural<jcomma>>): (elems': Split<seq<TSuffixedElement>>)
            requires elems.cs.StrictlySplitFrom?(json.cs)
            requires elems.SplitFrom?(cs0, SuffixedElementsSpec)
            requires elem.StrictlySplitFrom?(elems.cs, ElementSpec)
            requires sep.StrictlySplitFrom?(elem.cs, (c: Structural<jcomma>) => Spec.Structural(c, SpecView))
            requires forall e: Suffixed<TElement, jcomma> {:trigger e.suffix} {:trigger e in elems.t} | e in elems.t :: e.suffix.NonEmpty?
            ensures elems'.StrictlySplitFrom?(cs0, SuffixedElementsSpec)
            ensures forall e: Suffixed<TElement, jcomma> {:trigger e.suffix} {:trigger e in elems'.t} | e in elems'.t :: e.suffix.NonEmpty?
            ensures elems'.cs.Length() < elems.cs.Length()
            ensures elems'.cs.StrictlySplitFrom?(json.cs)
            ensures elems'.SplitFrom?(cs0, SuffixedElementsSpec)
            decreases cs0, json, elems, elem, sep
          {
            var suffixed: Suffixed<TElement, jcomma> := Suffixed(elem.t, NonEmpty(sep.t));
            var elems': Split<seq<Suffixed<TElement, jcomma>>> := SP(elems.t + [suffixed], sep.cs);
            assert cs0.Bytes() == SuffixedElementsSpec(elems'.t) + sep.cs.Bytes() by {
              assert {:focus} cs0.Bytes() == SuffixedElementsSpec(elems.t) + (ElementSpec(suffixed.t) + Spec.CommaSuffix(suffixed.suffix)) + sep.cs.Bytes() by {
                assert cs0.Bytes() == SuffixedElementsSpec(elems.t) + ElementSpec(suffixed.t) + Spec.CommaSuffix(suffixed.suffix) + sep.cs.Bytes() by {
                  assert cs0.Bytes() == SuffixedElementsSpec(elems.t) + elems.cs.Bytes();
                  assert elems.cs.Bytes() == ElementSpec(suffixed.t) + elem.cs.Bytes();
                  assert elem.cs.Bytes() == Spec.CommaSuffix(suffixed.suffix) + sep.cs.Bytes();
                  Seq.LemmaConcatIsAssociative(SuffixedElementsSpec(elems.t), ElementSpec(suffixed.t), elem.cs.Bytes());
                  Seq.LemmaConcatIsAssociative(SuffixedElementsSpec(elems.t) + ElementSpec(suffixed.t), Spec.CommaSuffix(suffixed.suffix), sep.cs.Bytes());
                }
                Seq.LemmaConcatIsAssociative(SuffixedElementsSpec(elems.t), ElementSpec(suffixed.t), Spec.CommaSuffix(suffixed.suffix));
              }
              assert SuffixedElementsSpec(elems.t) + (ElementSpec(suffixed.t) + Spec.CommaSuffix(suffixed.suffix)) + sep.cs.Bytes() == SuffixedElementsSpec(elems'.t) + sep.cs.Bytes() by {
                assert SuffixedElementsSpec(elems.t) + SuffixedElementSpec(suffixed) == SuffixedElementsSpec(elems.t + [suffixed]) by {
                  SpecProperties.ConcatBytes_Linear(elems.t, [suffixed], SuffixedElementSpec);
                  assert Spec.ConcatBytes(elems.t, SuffixedElementSpec) + Spec.ConcatBytes([suffixed], SuffixedElementSpec) == Spec.ConcatBytes(elems.t + [suffixed], SuffixedElementSpec);
                }
              }
            }
            assert elems'.StrictlySplitFrom?(cs0, SuffixedElementsSpec);
            assert forall e: Suffixed<TElement, jcomma> {:trigger e.suffix} {:trigger e in elems'.t} | e in elems'.t :: e.suffix.NonEmpty? by {
              assert elems'.t == elems.t + [suffixed];
            }
            assert {:split_here} elems'.cs.Length() < elems.cs.Length();
            assert elems'.SplitFrom?(cs0, SuffixedElementsSpec) by {
              assert elems'.BytesSplitFrom?(cs0, SuffixedElementsSpec) by {
                assert elems'.StrictlySplitFrom?(cs0, SuffixedElementsSpec);
              }
              assert elems'.cs.SplitFrom?(cs0) by {
                assert elems'.cs.StrictlySplitFrom?(cs0) by {
                  assert elems'.StrictlySplitFrom?(cs0, SuffixedElementsSpec);
                }
              }
            }
            elems'
          }

          opaque function {:resource_limit 10000000} {:isolate_assertions} AppendLast(ghost cs0: FreshCursor, ghost json: ValueParser, elems: Split<seq<TSuffixedElement>>, elem: Split<TElement>, sep: Split<Structural<jclose>>): (elems': Split<seq<TSuffixedElement>>)
            requires elems.cs.StrictlySplitFrom?(json.cs)
            requires elems.SplitFrom?(cs0, SuffixedElementsSpec)
            requires elem.StrictlySplitFrom?(elems.cs, ElementSpec)
            requires sep.StrictlySplitFrom?(elem.cs, (c: Structural<jclose>) => Spec.Structural(c, SpecView))
            requires forall e: Suffixed<TElement, jcomma> {:trigger e.suffix} {:trigger e in elems.t} | e in elems.t :: e.suffix.NonEmpty?
            ensures elems'.StrictlySplitFrom?(cs0, SuffixedElementsSpec)
            ensures NoTrailingSuffix(elems'.t)
            ensures elems'.cs.Length() < elems.cs.Length()
            ensures elems'.cs.StrictlySplitFrom?(json.cs)
            ensures sep.StrictlySplitFrom?(elems'.cs, (c: Structural<jclose>) => Spec.Structural(c, SpecView))
            decreases cs0, json, elems, elem, sep
          {
            var suffixed: Suffixed<TElement, jcomma> := Suffixed(elem.t, Empty());
            var elems': Split<seq<Suffixed<TElement, jcomma>>> := SP(elems.t + [suffixed], elem.cs);
            assert cs0.Bytes() == SuffixedElementsSpec(elems'.t) + elem.cs.Bytes() by {
              assert cs0.Bytes() == SuffixedElementsSpec(elems.t) + ElementSpec(suffixed.t) + elem.cs.Bytes() by {
                assert elem.t == suffixed.t;
              }
              assert SuffixedElementsSpec(elems.t) + ElementSpec(suffixed.t) + elem.cs.Bytes() == SuffixedElementsSpec(elems'.t) + elem.cs.Bytes() by {
                assert SuffixedElementsSpec(elems.t) + SuffixedElementSpec(suffixed) == SuffixedElementsSpec(elems.t + [suffixed]) by {
                  SpecProperties.ConcatBytes_Linear(elems.t, [suffixed], SuffixedElementSpec);
                  assert Spec.ConcatBytes(elems.t, SuffixedElementSpec) + Spec.ConcatBytes([suffixed], SuffixedElementSpec) == Spec.ConcatBytes(elems.t + [suffixed], SuffixedElementSpec);
                }
              }
            }
            assert elems'.StrictlySplitFrom?(cs0, SuffixedElementsSpec);
            elems'
          }

          lemma {:resource_limit ""10e6""} {:isolate_assertions} AboutTryStructural(cs: FreshCursor)
            ensures ghost var sp: Split<Structural<jopt>> := Core.TryStructural(cs); ghost var s0: opt_byte := sp.t.t.Peek(); ((!cs.BOF? || !cs.EOF?) && s0 == SEPARATOR as opt_byte ==> ghost var sp: Split<Structural<jcomma>> := sp; sp.cs.StrictSuffixOf?(cs)) && (s0 == SEPARATOR as opt_byte ==> ghost var sp: Split<Structural<jcomma>> := sp; sp.SplitFrom?(cs, (st: Structural<jcomma>) => Spec.Structural(st, SpecView))) && ((!cs.BOF? || !cs.EOF?) && s0 == CLOSE as opt_byte ==> ghost var sp: Split<Structural<jclose>> := sp; sp.cs.StrictSuffixOf?(cs)) && (s0 == CLOSE as opt_byte ==> ghost var sp: Split<Structural<jclose>> := sp; sp.SplitFrom?(cs, (st: Structural<jclose>) => Spec.Structural(st, SpecView)))
            decreases cs
          {
          }

          lemma {:isolate_assertions} AboutLists<T>(xs: seq<T>, i: uint32)
            requires 0 <= i as int < |xs|
            ensures xs[i as int .. i as int + 1] == [xs[i as int]]
            decreases xs, i
          {
          }

          opaque function {:isolate_assertions} {:tailrecursion} Elements(ghost cs0: FreshCursor, json: ValueParser, open: Split<Structural<jopen>>, elems: Split<seq<TSuffixedElement>>): (pr: ParseResult<TBracketed>)
            requires open.StrictlySplitFrom?(cs0, (c: Structural<jopen>) => Spec.Structural(c, SpecView))
            requires elems.cs.StrictlySplitFrom?(json.cs)
            requires elems.SplitFrom?(open.cs, SuffixedElementsSpec)
            requires forall e: Suffixed<TElement, jcomma> {:trigger e.suffix} {:trigger e in elems.t} | e in elems.t :: e.suffix.NonEmpty?
            ensures pr.Success? ==> pr.value.StrictlySplitFrom?(cs0, BracketedSpec)
            decreases elems.cs.Length()
          {
            var elem: Split<TElement> :- Element(elems.cs, json); if elem.cs.EOF? then Failure(EOF) else AboutTryStructural(elem.cs); var sep: Split<Structural<jopt>> := Core.TryStructural(elem.cs); var s0: opt_byte := sep.t.t.Peek(); if s0 == SEPARATOR as opt_byte && sep.t.t.Length() == 1 then assert sep.t.t.Char?(',') by {
    calc {
      sep.t.t.Char?(',');
      sep.t.t.Byte?(',' as byte);
      sep.t.t.Byte?(SEPARATOR);
      sep.t.t.Bytes() == [SEPARATOR];
      sep.t.t.s[sep.t.t.beg as int .. sep.t.t.end as int] == [SEPARATOR];
      {
        assert sep.t.t.beg as int + 1 == sep.t.t.end as int by {
          assert sep.t.t.Length() == 1;
        }
      }
      sep.t.t.s[sep.t.t.beg as int .. sep.t.t.beg as int + 1] == [SEPARATOR];
      {
        assert sep.t.t.s[sep.t.t.beg as int .. sep.t.t.beg as int + 1] == [sep.t.t.s[sep.t.t.beg as int]] by {
          AboutLists(sep.t.t.s, sep.t.t.beg);
        }
      }
      [sep.t.t.s[sep.t.t.beg as int]] == [SEPARATOR];
      sep.t.t.s[sep.t.t.beg as int] as opt_byte == SEPARATOR as opt_byte;
      sep.t.t.At(0) as opt_byte == SEPARATOR as opt_byte;
      s0 == SEPARATOR as opt_byte;
      true;
    }
  } var sep: Split<Structural<jcomma>> := sep; assert AppendWithSuffix.requires(open.cs, json, elems, elem, sep) by {
    assert {:focus} elems.cs.StrictlySplitFrom?(json.cs);
    assert elems.SplitFrom?(open.cs, SuffixedElementsSpec);
    assert elem.StrictlySplitFrom?(elems.cs, ElementSpec);
    assert sep.StrictlySplitFrom?(elem.cs, (c: Structural<jcomma>) => Spec.Structural(c, SpecView)) by {
      assert sep.BytesSplitFrom?(elem.cs, (c: Structural<jcomma>) => Spec.Structural(c, SpecView)) by {
        assert sep.SplitFrom?(elem.cs, (c: Structural<jcomma>) => Spec.Structural(c, SpecView));
      }
      assert sep.cs.StrictlySplitFrom?(elem.cs) by {
        assert sep.cs.BOF?;
        assert sep.cs.StrictSuffixOf?(elem.cs) by {
          assert !elem.cs.EOF?;
        }
      }
    }
    assert forall e: Suffixed<TElement, jcomma> {:trigger e.suffix} {:trigger e in elems.t} | e in elems.t :: e.suffix.NonEmpty?;
    assert {:split_here} true;
  } var elems: Split<seq<TSuffixedElement>> := AppendWithSuffix(open.cs, json, elems, elem, sep); Elements(cs0, json, open, elems) else if s0 == CLOSE as opt_byte && sep.t.t.Length() == 1 then assert sep.t.t.Byte?(CLOSE) by {
    calc {
      sep.t.t.Byte?(CLOSE);
      sep.t.t.Bytes() == [CLOSE];
      sep.t.t.s[sep.t.t.beg as int .. sep.t.t.end as int] == [CLOSE];
      {
        assert sep.t.t.beg as int + 1 == sep.t.t.end as int by {
          assert sep.t.t.Length() == 1;
        }
      }
      sep.t.t.s[sep.t.t.beg as int .. sep.t.t.beg as int + 1] == [CLOSE];
      {
        assert sep.t.t.s[sep.t.t.beg as int .. sep.t.t.beg as int + 1] == [sep.t.t.s[sep.t.t.beg as int]] by {
          AboutLists(sep.t.t.s, sep.t.t.beg);
        }
      }
      [sep.t.t.s[sep.t.t.beg as int]] == [CLOSE];
      sep.t.t.s[sep.t.t.beg as int] as opt_byte == CLOSE as opt_byte;
      sep.t.t.At(0) as opt_byte == CLOSE as opt_byte;
      s0 == CLOSE as opt_byte;
      true;
    }
  } var sep: Split<Structural<jclose>> := sep; assert AppendLast.requires(open.cs, json, elems, elem, sep) by {
    assert elems.cs.StrictlySplitFrom?(json.cs);
    assert elems.SplitFrom?(open.cs, SuffixedElementsSpec);
    assert elem.StrictlySplitFrom?(elems.cs, ElementSpec);
    assert sep.StrictlySplitFrom?(elem.cs, (c: Structural<jclose>) => Spec.Structural(c, SpecView)) by {
      assert sep.BytesSplitFrom?(elem.cs, (c: Structural<jclose>) => Spec.Structural(c, SpecView)) by {
        assert sep.SplitFrom?(elem.cs, (c: Structural<jclose>) => Spec.Structural(c, SpecView));
      }
      assert sep.cs.StrictlySplitFrom?(elem.cs) by {
        assert sep.cs.BOF?;
        assert sep.cs.StrictSuffixOf?(elem.cs) by {
          assert !elem.cs.EOF?;
        }
      }
    }
    assert forall e: Suffixed<TElement, jcomma> {:trigger e.suffix} {:trigger e in elems.t} | e in elems.t :: e.suffix.NonEmpty?;
  } var elems': Split<seq<TSuffixedElement>> := AppendLast(open.cs, json, elems, elem, sep); assert elems'.SplitFrom?(open.cs, SuffixedElementsSpec) by {
    assert elems'.StrictlySplitFrom?(open.cs, SuffixedElementsSpec);
  } var bracketed: Split<TBracketed> := BracketedFromParts(cs0, open, elems', sep); assert bracketed.StrictlySplitFrom?(cs0, BracketedSpec); Success(bracketed) else var separator: byte := SEPARATOR; var pr: Result<Split<Bracketed<jopen, TElement, jcomma, jclose>>, CursorError<Errors.DeserializationError>> := Failure(ExpectingAnyByte([CLOSE, separator], s0)); pr
          }

          lemma AboutCloseParser()
            ensures Parsers.Parser(Close, SpecViewClose).Valid?()
          {
            assert Parsers.Parser(Close, SpecViewClose).Valid?() by {
              forall cs': FreshCursor | true
                ensures Close(cs').Success? ==> Close(cs').value.StrictlySplitFrom?(cs', SpecViewClose)
              {
                if Close(cs').Success? {
                  assert Close(cs').value.StrictlySplitFrom?(cs', SpecViewClose) by {
                    assert Close(cs').Success? ==> Close(cs').value.StrictlySplitFrom?(cs', SpecViewClose);
                  }
                }
              }
            }
          }

          opaque function {:isolate_assertions} Bracketed(cs: FreshCursor, json: ValueParser): (pr: ParseResult<TBracketed>)
            requires cs.SplitFrom?(json.cs)
            ensures pr.Success? ==> pr.value.StrictlySplitFrom?(cs, BracketedSpec)
            decreases cs, json
          {
            var open: Split<Structural<jopen>> :- Core.Structural<jopen>(cs, Parsers.Parser(Open, SpecViewOpen)); assert open.cs.StrictlySplitFrom?(json.cs); var elems: Split<seq<Suffixed<TElement, jcomma>>> := SP([], open.cs); if open.cs.Peek() == CLOSE as opt_byte then var p: Parser_<jclose, JSONError> := Parsers.Parser(Close, SpecViewClose); assert p.Valid?() by {
    AboutCloseParser();
  } var close: Split<Structural<jclose>> :- Core.Structural<jclose>(open.cs, p); Success(BracketedFromParts(cs, open, elems, close)) else Elements(cs, json, open, elems)
          }

          lemma Valid(x: TBracketed)
            ensures x.l.t.Byte?(OPEN)
            ensures x.r.t.Byte?(CLOSE)
            ensures NoTrailingSuffix(x.data)
            ensures forall pf: Suffixed<TElement, jcomma> {:trigger pf.suffix} {:trigger pf in x.data} | pf in x.data :: pf.suffix.NonEmpty? ==> pf.suffix.t.t.Byte?(SEPARATOR)
            decreases x
          {
            ghost var xlt: jopen := x.l.t;
            ghost var xrt: jclose := x.r.t;
            forall pf: Suffixed<TElement, jcomma> | pf in x.data
              ensures pf.suffix.NonEmpty? ==> pf.suffix.t.t.Byte?(SEPARATOR)
            {
              if pf.suffix.NonEmpty? {
                ghost var xtt := pf.suffix.t.t;
              }
            }
          }

          import opened Wrappers

          import opened BoundedInts

          import opened Params : SequenceParams

          import SpecProperties = ConcreteSyntax.SpecProperties

          import opened Vs = Utils.Views.Core

          import opened Grammar

          import opened Cursors = Utils.Cursors

          import Parsers = Utils.Parsers

          import opened Core

          type jopen = v: Vs.View
            | v.Byte?(OPEN)
            witness Vs.View.OfBytes([OPEN])

          type jclose = v: Vs.View
            | v.Byte?(CLOSE)
            witness Vs.View.OfBytes([CLOSE])

          type TBracketed = Bracketed<jopen, TElement, jcomma, jclose>

          type TSuffixedElement = Suffixed<TElement, jcomma>
        }

        module API {
          function LiftCursorError(err: Cursors.CursorError<DeserializationError>): DeserializationError
            decreases err
          {
            match err
            case EOF() =>
              ReachedEOF
            case ExpectingByte(expected, b) =>
              ExpectingByte(expected, b)
            case ExpectingAnyByte(expected_sq, b) =>
              ExpectingAnyByte(expected_sq, b)
            case OtherError(err) =>
              err
          }

          opaque function {:isolate_assertions} {:resource_limit 10000000} JSON(cs: Cursors.FreshCursor): (pr: DeserializationResult<Cursors.Split<JSON>>)
            ensures pr.Success? ==> pr.value.StrictlySplitFrom?(cs, Spec.JSON)
            decreases cs
          {
            Core.Structural(cs, Parsers.Parser(Values.Value, Spec.Value)).MapFailure(LiftCursorError)
          }

          opaque function Text(v: View): (jsr: DeserializationResult<JSON>)
            ensures jsr.Success? ==> v.Bytes() == Spec.JSON(jsr.value)
            decreases v
          {
            var SP(text: JSON, cs: FreshCursor) :- JSON(Cursors.Cursor.OfView(v)); assert Cursors.SP(text, cs).BytesSplitFrom?(Cursors.Cursor.OfView(v), Spec.JSON); assert v.Bytes() == Spec.JSON(text) + cs.Bytes(); :- Need(cs.EOF?, Errors.ExpectingEOF); assert cs.Bytes() == []; Success(text)
          }

          opaque function OfBytes(bs: bytes): (jsr: DeserializationResult<JSON>)
            ensures jsr.Success? ==> bs == Spec.JSON(jsr.value)
            decreases bs
          {
            :- Need(|bs| < TWO_TO_THE_32, Errors.IntOverflow); Text(Vs.View.OfBytes(bs))
          }

          import opened BoundedInts

          import opened Wrappers

          import opened Vs = Utils.Views.Core

          import opened Grammar

          import opened Core

          import opened Errors

          import Cursors = Utils.Cursors

          import Values
        }

        module Values {
          opaque function {:isolate_assertions} Value(cs: FreshCursor): (pr: ParseResult<Value>)
            ensures pr.Success? ==> pr.value.StrictlySplitFrom?(cs, Spec.Value)
            decreases cs.Length(), 1
          {
            var c: opt_byte := cs.Peek();
            if c == '{' as opt_byte then
              var SP(obj: jobject, cs': FreshCursor) :- Objects.Object(cs, ValueParser(cs)); var v: Value := Grammar.Object(obj); var sp: Split<Value> := SP(v, cs'); assert sp.StrictlySplitFrom?(cs, Spec.Value) by {
    Spec.UnfoldValueObject(v);
    assert SP(obj, cs').StrictlySplitFrom?(cs, Spec.Object);
  } Spec.UnfoldValueObject(v); assert sp.StrictlySplitFrom?(cs, Spec.Value); Success(sp)
            else if c == '[' as opt_byte then
              var SP(arr: jarray, cs': FreshCursor) :- Arrays.Array(cs, ValueParser(cs)); var v: Value := Grammar.Array(arr); var sp: Split<Value> := SP(v, cs'); assert sp.StrictlySplitFrom?(cs, Spec.Value) by {
    assert SP(arr, cs').StrictlySplitFrom?(cs, Spec.Array);
    Spec.UnfoldValueArray(v);
  } assert sp.StrictlySplitFrom?(cs, Spec.Value); Success(sp)
            else if c == '\""' as opt_byte then
              var SP(str: jstring, cs': FreshCursor) :- Strings.String(cs); assert SP(Grammar.String(str), cs').StrictlySplitFrom?(cs, Spec.Value) by {
    calc {
      SP(Grammar.String(str), cs').StrictlySplitFrom?(cs, Spec.Value);
      cs'.StrictlySplitFrom?(cs) &&
      SP(Grammar.String(str), cs').BytesSplitFrom?(cs, Spec.Value);
      cs'.StrictlySplitFrom?(cs) &&
      cs.Bytes() == Spec.Value(Grammar.String(str)) + cs'.Bytes();
      cs'.StrictlySplitFrom?(cs) &&
      cs.Bytes() == Spec.String(str) + cs'.Bytes();
      cs'.StrictlySplitFrom?(cs) &&
      SP(str, cs').BytesSplitFrom?(cs, Spec.String);
      SP(str, cs').StrictlySplitFrom?(cs, Spec.String);
      true;
    }
  } Success(SP(Grammar.String(str), cs'))
            else if c == 't' as opt_byte then
              var SP(cst: Vs.View, cs': FreshCursor) :- Constants.Constant(cs, TRUE); assert SP(Grammar.Bool(cst), cs').StrictlySplitFrom?(cs, Spec.Value) by {
    ghost var f := (_ /* _v12 */: Value) => TRUE;
    calc {
      SP(Grammar.Bool(cst), cs').StrictlySplitFrom?(cs, Spec.Value);
      cs'.StrictlySplitFrom?(cs) &&
      SP(Grammar.Bool(cst), cs').BytesSplitFrom?(cs, Spec.Value);
      cs'.StrictlySplitFrom?(cs) &&
      cs.Bytes() == Spec.Value(Grammar.Bool(cst)) + cs'.Bytes();
      cs'.StrictlySplitFrom?(cs) &&
      cs.Bytes() == Spec.View(cst) + cs'.Bytes();
      cs'.StrictlySplitFrom?(cs) &&
      cs.Bytes() == cst.Bytes() + cs'.Bytes();
      cs'.StrictlySplitFrom?(cs) &&
      cs.Bytes() == TRUE + cs'.Bytes();
      cs'.StrictlySplitFrom?(cs) &&
      cs.Bytes() == f(Grammar.Bool(cst)) + cs'.Bytes();
      cs'.StrictlySplitFrom?(cs) &&
      SP(Grammar.Bool(cst), cs').BytesSplitFrom?(cs, f);
      {
        assert cs'.StrictlySplitFrom?(cs) <==> cs'.SplitFrom?(cs) by {
          assert cs' != cs;
        }
      }
      cs'.SplitFrom?(cs) &&
      SP(Grammar.Bool(cst), cs').BytesSplitFrom?(cs, f);
      SP(Grammar.Bool(cst), cs').SplitFrom?(cs, f);
      true;
    }
  } Success(SP(Grammar.Bool(cst), cs'))
            else if c == 'f' as opt_byte then
              var SP(cst: Vs.View, cs': FreshCursor) :- Constants.Constant(cs, FALSE); assert SP(Grammar.Bool(cst), cs').StrictlySplitFrom?(cs, Spec.Value) by {
    ghost var f := (_ /* _v13 */: Value) => FALSE;
    calc {
      SP(Grammar.Bool(cst), cs').StrictlySplitFrom?(cs, Spec.Value);
      cs'.StrictlySplitFrom?(cs) &&
      SP(Grammar.Bool(cst), cs').BytesSplitFrom?(cs, Spec.Value);
      cs'.StrictlySplitFrom?(cs) &&
      cs.Bytes() == Spec.Value(Grammar.Bool(cst)) + cs'.Bytes();
      cs'.StrictlySplitFrom?(cs) &&
      cs.Bytes() == Spec.View(cst) + cs'.Bytes();
      cs'.StrictlySplitFrom?(cs) &&
      cs.Bytes() == cst.Bytes() + cs'.Bytes();
      cs'.StrictlySplitFrom?(cs) &&
      cs.Bytes() == FALSE + cs'.Bytes();
      cs'.StrictlySplitFrom?(cs) &&
      cs.Bytes() == f(Grammar.Bool(cst)) + cs'.Bytes();
      cs'.StrictlySplitFrom?(cs) &&
      SP(Grammar.Bool(cst), cs').BytesSplitFrom?(cs, f);
      {
        assert cs'.StrictlySplitFrom?(cs) <==> cs'.SplitFrom?(cs) by {
          assert cs' != cs;
        }
      }
      cs'.SplitFrom?(cs) &&
      SP(Grammar.Bool(cst), cs').BytesSplitFrom?(cs, f);
      SP(Grammar.Bool(cst), cs').SplitFrom?(cs, f);
      true;
    }
  } Success(SP(Grammar.Bool(cst), cs'))
            else if c == 'n' as opt_byte then
              var SP(cst: Vs.View, cs': FreshCursor) :- Constants.Constant(cs, NULL); assert SP(Grammar.Null(cst), cs').StrictlySplitFrom?(cs, Spec.Value) by {
    ghost var f := (_ /* _v14 */: Value) => NULL;
    calc {
      SP(Grammar.Null(cst), cs').StrictlySplitFrom?(cs, Spec.Value);
      cs'.StrictlySplitFrom?(cs) &&
      SP(Grammar.Null(cst), cs').BytesSplitFrom?(cs, Spec.Value);
      cs'.StrictlySplitFrom?(cs) &&
      cs.Bytes() == Spec.Value(Grammar.Null(cst)) + cs'.Bytes();
      cs'.StrictlySplitFrom?(cs) &&
      cs.Bytes() == Spec.View(cst) + cs'.Bytes();
      cs'.StrictlySplitFrom?(cs) &&
      cs.Bytes() == cst.Bytes() + cs'.Bytes();
      cs'.StrictlySplitFrom?(cs) &&
      cs.Bytes() == NULL + cs'.Bytes();
      cs'.StrictlySplitFrom?(cs) &&
      cs.Bytes() == f(Grammar.Null(cst)) + cs'.Bytes();
      cs'.StrictlySplitFrom?(cs) &&
      SP(Grammar.Null(cst), cs').BytesSplitFrom?(cs, f);
      {
        assert cs'.StrictlySplitFrom?(cs) <==> cs'.SplitFrom?(cs) by {
          assert cs' != cs;
        }
      }
      cs'.SplitFrom?(cs) &&
      SP(Grammar.Null(cst), cs').BytesSplitFrom?(cs, f);
      SP(Grammar.Null(cst), cs').SplitFrom?(cs, f);
      true;
    }
  } Success(SP(Grammar.Null(cst), cs'))
            else
              var SP(num: jnumber, cs': FreshCursor) :- Numbers.Number(cs); var v: Value := Grammar.Number(num); var sp: Split<Value> := SP(v, cs'); assert sp.StrictlySplitFrom?(cs, Spec.Value) by {
    assert SP(num, cs').StrictlySplitFrom?(cs, Spec.Number);
    Spec.UnfoldValueNumber(v);
  } assert sp.StrictlySplitFrom?(cs, Spec.Value); Success(sp)
          }

          opaque function ValueParser(cs: FreshCursor): (p: ValueParser)
            ensures cs.SplitFrom?(p.cs)
            decreases cs.Length(), 0
          {
            var pre: FreshCursor -> bool := (ps': FreshCursor) => ps'.Length() < cs.Length();
            var fn: FreshCursor --> ParseResult<Value> := (ps': FreshCursor) requires pre(ps') => Value(ps');
            Parsers.SubParser(cs, pre, fn, Spec.Value)
          }

          import Strings

          import Numbers

          import Objects

          import Arrays

          import Constants

          import SpecProperties = ConcreteSyntax.SpecProperties

          import opened BoundedInts

          import opened Wrappers

          import opened Grammar

          import opened Cursors = Utils.Cursors

          import opened Core
        }

        module Constants {
          opaque function Constant(cs: FreshCursor, expected: bytes): (pr: ParseResult<Vs.View>)
            requires |expected| < TWO_TO_THE_32
            ensures pr.Success? ==> pr.value.t.Bytes() == expected
            ensures pr.Success? ==> pr.value.SplitFrom?(cs, (_ /* _v15 */: View_) => expected)
            decreases cs, expected
          {
            var cs: Cursor :- cs.AssertBytes(expected); Success(cs.Split())
          }

          import opened BoundedInts

          import opened Wrappers

          import opened Grammar

          import opened Core

          import opened Cursors = Utils.Cursors
        }

        module Strings {
          opaque function StringBody(cs: Cursor): (pr: CursorResult<JSONError>)
            ensures pr.Success? ==> pr.value.AdvancedFrom?(cs)
            decreases cs
          {
            cs.SkipWhileLexer(Strings.StringBody, StringBodyLexerStart)
          } by method {
            reveal StringBody();
            var escaped := false;
            for point': uint32 := cs.point to cs.end
              invariant var csAfter: Cursor_ := cs.(point := point'); csAfter.Valid?
              invariant var csAfter: Cursor_ := cs.(point := point'); csAfter.SkipWhileLexer(Strings.StringBody, escaped) == StringBody(cs)
            {
              var byte := cs.s[point'];
              if byte == '\""' as byte && !escaped {
                return Success(Cursor(cs.s, cs.beg, point', cs.end));
              } else if byte == '\\' as byte {
                escaped := !escaped;
              } else {
                escaped := false;
              }
            }
            return Failure(EOF);
          }

          function Quote(cs: FreshCursor): (pr: ParseResult<jquote>)
            ensures pr.Success? ==> pr.value.StrictlySplitFrom?(cs, SpecView)
            decreases cs
          {
            var cs: Cursor :- cs.AssertChar('\""'); Success(cs.Split())
          }

          opaque function {:resource_limit 10000000} String(cs: FreshCursor): (pr: ParseResult<jstring>)
            ensures pr.Success? ==> pr.value.StrictlySplitFrom?(cs, Spec.String)
            decreases cs
          {
            var SP(lq: jquote, cs: FreshCursor) :- Quote(cs); var contents: Cursor :- StringBody(cs); var SP(contents: View, cs: FreshCursor) := contents.Split(); var SP(rq: jquote, cs: FreshCursor) :- Quote(cs); Success(SP(Grammar.JString(lq, contents, rq), cs))
          }

          import opened Wrappers

          import opened BoundedInts

          import opened Grammar

          import opened Cursors = Utils.Cursors

          import opened LC = Utils.Lexers.Core

          import opened Strings = Utils.Lexers.Strings

          import opened Parsers = Utils.Parsers

          import opened Core
        }

        module Numbers {
          opaque function Digits(cs: FreshCursor): (sp: Split<jdigits>)
            ensures sp.SplitFrom?(cs, SpecView)
            decreases cs
          {
            cs.SkipWhile(Digit?).Split()
          }

          opaque function NonEmptyDigits(cs: FreshCursor): (pr: ParseResult<jnum>)
            ensures pr.Success? ==> pr.value.StrictlySplitFrom?(cs, SpecView)
            decreases cs
          {
            var sp: Split<jdigits> := Digits(cs);
            if sp.t.Empty? then
              Failure(OtherError(Errors.EmptyNumber))
            else
              Success(sp)
          }

          opaque function NonZeroInt(cs: FreshCursor): (pr: ParseResult<jint>)
            requires cs.Peek() != '0' as opt_byte
            ensures pr.Success? ==> pr.value.StrictlySplitFrom?(cs, SpecView)
            decreases cs
          {
            NonEmptyDigits(cs)
          }

          opaque function OptionalMinus(cs: FreshCursor): (sp: Split<jminus>)
            ensures sp.SplitFrom?(cs, SpecView)
            decreases cs
          {
            cs.SkipIf((c: uint8) => c == '-' as byte).Split()
          }

          opaque function OptionalSign(cs: FreshCursor): (sp: Split<jsign>)
            ensures sp.SplitFrom?(cs, SpecView)
            decreases cs
          {
            cs.SkipIf((c: uint8) => c == '-' as byte || c == '+' as byte).Split()
          }

          opaque function TrimmedInt(cs: FreshCursor): (pr: ParseResult<jint>)
            ensures pr.Success? ==> pr.value.StrictlySplitFrom?(cs, SpecView)
            decreases cs
          {
            var sp: Split<View> := cs.SkipIf((c: uint8) => c == '0' as byte).Split();
            if sp.t.Empty? then
              NonZeroInt(sp.cs)
            else
              Success(sp)
          }

          opaque function {:isolate_assertions} {:resource_limit 100000000} Exp(cs: FreshCursor): (pr: ParseResult<Maybe<jexp>>)
            ensures pr.Success? ==> pr.value.SplitFrom?(cs, (exp: Maybe<jexp>) => Spec.Maybe(exp, Spec.Exp))
            decreases cs
          {
            var SP(e: View, cs: FreshCursor) := cs.SkipIf((c: uint8) => c == 'e' as byte || c == 'E' as byte).Split();
            if e.Empty? then
              Success(SP(Empty(), cs))
            else
              assert e.Char?('e') || e.Char?('E'); var SP(sign: jsign, cs: FreshCursor) := OptionalSign(cs); var SP(num: jnum, cs: FreshCursor) :- NonEmptyDigits(cs); Success(SP(NonEmpty(JExp(e, sign, num)), cs))
          }

          opaque function Frac(cs: FreshCursor): (pr: ParseResult<Maybe<jfrac>>)
            ensures pr.Success? ==> pr.value.SplitFrom?(cs, (frac: Maybe<jfrac>) => Spec.Maybe(frac, Spec.Frac))
            decreases cs
          {
            var SP(period: View, cs: FreshCursor) := cs.SkipIf((c: uint8) => c == '.' as byte).Split();
            if period.Empty? then
              Success(SP(Empty(), cs))
            else
              var SP(num: jnum, cs: FreshCursor) :- NonEmptyDigits(cs); Success(SP(NonEmpty(JFrac(period, num)), cs))
          }

          opaque function NumberFromParts(ghost cs: Cursor, minus: Split<jminus>, num: Split<jint>, frac: Split<Maybe<jfrac>>, exp: Split<Maybe<jexp>>): (sp: Split<jnumber>)
            requires minus.SplitFrom?(cs, SpecView)
            requires num.StrictlySplitFrom?(minus.cs, SpecView)
            requires frac.SplitFrom?(num.cs, (frac: Maybe<jfrac>) => Spec.Maybe(frac, Spec.Frac))
            requires exp.SplitFrom?(frac.cs, (exp: Maybe<jexp>) => Spec.Maybe(exp, Spec.Exp))
            ensures sp.StrictlySplitFrom?(cs, Spec.Number)
            decreases cs, minus, num, frac, exp
          {
            var sp: Split<jnumber> := SP(Grammar.JNumber(minus.t, num.t, frac.t, exp.t), exp.cs);
            assert cs.Bytes() == Spec.Number(sp.t) + exp.cs.Bytes() by {
              assert cs.Bytes() == Spec.View(minus.t) + Spec.View(num.t) + Spec.Maybe(frac.t, Spec.Frac) + Spec.Maybe(exp.t, Spec.Exp) + exp.cs.Bytes() by {
                assert cs.Bytes() == Spec.View(minus.t) + minus.cs.Bytes();
                assert minus.cs.Bytes() == Spec.View(num.t) + num.cs.Bytes();
                assert num.cs.Bytes() == Spec.Maybe(frac.t, Spec.Frac) + frac.cs.Bytes();
                assert frac.cs.Bytes() == Spec.Maybe(exp.t, Spec.Exp) + exp.cs.Bytes();
                Seq.LemmaConcatIsAssociative(Spec.View(minus.t), Spec.View(num.t), num.cs.Bytes());
                Seq.LemmaConcatIsAssociative(Spec.View(minus.t) + Spec.View(num.t), Spec.Maybe(frac.t, Spec.Frac), frac.cs.Bytes());
                Seq.LemmaConcatIsAssociative(Spec.View(minus.t) + Spec.View(num.t) + Spec.Maybe(frac.t, Spec.Frac), Spec.Maybe(exp.t, Spec.Exp), exp.cs.Bytes());
              }
            }
            assert sp.StrictlySplitFrom?(cs, Spec.Number);
            sp
          }

          opaque function Number(cs: FreshCursor): (pr: ParseResult<jnumber>)
            ensures pr.Success? ==> pr.value.StrictlySplitFrom?(cs, Spec.Number)
            decreases cs
          {
            var minus: Split<jminus> := OptionalMinus(cs);
            var num: Split<jint> :- TrimmedInt(minus.cs); var frac: Split<Maybe<jfrac>> :- Frac(num.cs); var exp: Split<Maybe<jexp>> :- Exp(frac.cs); Success(NumberFromParts(cs, minus, num, frac, exp))
          }

          import opened BoundedInts

          import opened Wrappers

          import opened Grammar

          import opened Cursors = Utils.Cursors

          import opened Core
        }

        module ArrayParams refines SequenceParams {
          const OPEN: byte := '[' as byte
          const CLOSE: byte := ']' as byte

          function ElementSpec(t: TElement): bytes
            decreases t
          {
            Spec.Value(t)
          }

          function Element(cs: FreshCursor, json: ValueParser): (pr: ParseResult<TElement>)
            requires cs.StrictlySplitFrom?(json.cs)
            ensures pr.Success? ==> pr.value.StrictlySplitFrom?(cs, ElementSpec)
            decreases cs.Length()
          {
            json.fn(cs)
          }

          import opened Strings

          import opened Wrappers

          type TElement = Value

          import opened BoundedInts

          import opened Grammar

          import opened Cursors = Utils.Cursors

          import opened Core
        }

        module Arrays refines Sequences {
          lemma {:isolate_assertions} /*{:_induction arr}*/ BracketedToArray(arr: jarray)
            ensures Spec.Bracketed(arr, SuffixedElementSpec) == Spec.Array(arr)
            decreases arr
          {
            ghost var rItem := (d: jitem) requires d < arr => Spec.Item(d);
            assert Spec.Bracketed(arr, SuffixedElementSpec) == Spec.Bracketed(arr, rItem) by {
              assert SpecProperties.Bracketed_Morphism_Requires(arr, SuffixedElementSpec, rItem);
              SpecProperties.Bracketed_Morphism(arr, SuffixedElementSpec, rItem);
            }
            calc {
              Spec.Bracketed(arr, SuffixedElementSpec);
              Spec.Bracketed(arr, rItem);
              Spec.Array(arr);
            }
          }

          opaque function {:isolate_assertions} Array(cs: FreshCursor, json: ValueParser): (pr: ParseResult<jarray>)
            requires cs.SplitFrom?(json.cs)
            ensures pr.Success? ==> pr.value.StrictlySplitFrom?(cs, Spec.Array)
            decreases cs, json
          {
            var sp: Split<TBracketed> :- Bracketed(cs, json); assert sp.StrictlySplitFrom?(cs, BracketedSpec); BracketedToArray(sp.t); Success(sp)
          }

          const SEPARATOR: byte := ',' as byte
          const SpecViewClose: jclose -> bytes := SpecView
          const SpecViewOpen: jopen -> bytes := SpecView

          ghost function SuffixedElementSpec(e: TSuffixedElement): bytes
            decreases e
          {
            ElementSpec(e.t) + Spec.CommaSuffix(e.suffix)
          }

          ghost function BracketedSpec(ts: TBracketed): bytes
            decreases ts
          {
            Spec.Bracketed(ts, SuffixedElementSpec)
          }

          ghost function SuffixedElementsSpec(ts: seq<TSuffixedElement>): bytes
            decreases ts
          {
            Spec.ConcatBytes(ts, SuffixedElementSpec)
          }

          opaque function Open(cs: FreshCursor): (pr: ParseResult<jopen>)
            ensures pr.Success? ==> pr.value.StrictlySplitFrom?(cs, SpecViewOpen)
            decreases cs
          {
            var cs: Cursor :- cs.AssertByte(OPEN); Success(cs.Split())
          }

          opaque function Close(cs: FreshCursor): (pr: ParseResult<jclose>)
            ensures pr.Success? ==> pr.value.StrictlySplitFrom?(cs, SpecViewClose)
            decreases cs
          {
            var cs: Cursor :- cs.AssertByte(CLOSE); Success(cs.Split())
          }

          opaque function BracketedFromParts(ghost cs: Cursor, open: Split<Structural<jopen>>, elems: Split<seq<TSuffixedElement>>, close: Split<Structural<jclose>>): (sp: Split<TBracketed>)
            requires Grammar.NoTrailingSuffix(elems.t)
            requires open.StrictlySplitFrom?(cs, (c: Structural<jopen>) => Spec.Structural(c, SpecView))
            requires elems.SplitFrom?(open.cs, SuffixedElementsSpec)
            requires close.StrictlySplitFrom?(elems.cs, (c: Structural<jclose>) => Spec.Structural(c, SpecView))
            ensures sp.StrictlySplitFrom?(cs, BracketedSpec)
            decreases cs, open, elems, close
          {
            var sp: Split<Bracketed<jopen, TElement, jcomma, jclose>> := SP(Grammar.Bracketed(open.t, elems.t, close.t), close.cs);
            calc {
              cs.Bytes();
              Spec.Structural(open.t, SpecView) + open.cs.Bytes();
              {
                assert open.cs.Bytes() == SuffixedElementsSpec(elems.t) + elems.cs.Bytes();
              }
              Spec.Structural(open.t, SpecView) + (SuffixedElementsSpec(elems.t) + elems.cs.Bytes());
              {
                Seq.LemmaConcatIsAssociative(Spec.Structural(open.t, SpecView), SuffixedElementsSpec(elems.t), elems.cs.Bytes());
              }
              Spec.Structural(open.t, SpecView) + SuffixedElementsSpec(elems.t) + elems.cs.Bytes();
              {
                assert elems.cs.Bytes() == Spec.Structural(close.t, SpecView) + close.cs.Bytes();
              }
              Spec.Structural(open.t, SpecView) + SuffixedElementsSpec(elems.t) + (Spec.Structural(close.t, SpecView) + close.cs.Bytes());
              {
                Seq.LemmaConcatIsAssociative(Spec.Structural(open.t, SpecView) + SuffixedElementsSpec(elems.t), Spec.Structural(close.t, SpecView), close.cs.Bytes());
              }
              Spec.Structural(open.t, SpecView) + SuffixedElementsSpec(elems.t) + Spec.Structural(close.t, SpecView) + close.cs.Bytes();
              Spec.Bracketed(sp.t, SuffixedElementSpec) + close.cs.Bytes();
            }
            assert sp.StrictlySplitFrom?(cs, BracketedSpec);
            sp
          }

          opaque function AppendWithSuffix(ghost cs0: FreshCursor, ghost json: ValueParser, elems: Split<seq<TSuffixedElement>>, elem: Split<TElement>, sep: Split<Structural<jcomma>>): (elems': Split<seq<TSuffixedElement>>)
            requires elems.cs.StrictlySplitFrom?(json.cs)
            requires elems.SplitFrom?(cs0, SuffixedElementsSpec)
            requires elem.StrictlySplitFrom?(elems.cs, ElementSpec)
            requires sep.StrictlySplitFrom?(elem.cs, (c: Structural<jcomma>) => Spec.Structural(c, SpecView))
            requires forall e: Suffixed<TElement, jcomma> {:trigger e.suffix} {:trigger e in elems.t} | e in elems.t :: e.suffix.NonEmpty?
            ensures elems'.StrictlySplitFrom?(cs0, SuffixedElementsSpec)
            ensures forall e: Suffixed<TElement, jcomma> {:trigger e.suffix} {:trigger e in elems'.t} | e in elems'.t :: e.suffix.NonEmpty?
            ensures elems'.cs.Length() < elems.cs.Length()
            ensures elems'.cs.StrictlySplitFrom?(json.cs)
            ensures elems'.SplitFrom?(cs0, SuffixedElementsSpec)
            decreases cs0, json, elems, elem, sep
          {
            var suffixed: Suffixed<TElement, jcomma> := Suffixed(elem.t, NonEmpty(sep.t));
            var elems': Split<seq<Suffixed<Value, jcomma>>> := SP(elems.t + [suffixed], sep.cs);
            assert cs0.Bytes() == SuffixedElementsSpec(elems'.t) + sep.cs.Bytes() by {
              assert {:focus} cs0.Bytes() == SuffixedElementsSpec(elems.t) + (ElementSpec(suffixed.t) + Spec.CommaSuffix(suffixed.suffix)) + sep.cs.Bytes() by {
                assert cs0.Bytes() == SuffixedElementsSpec(elems.t) + ElementSpec(suffixed.t) + Spec.CommaSuffix(suffixed.suffix) + sep.cs.Bytes() by {
                  assert cs0.Bytes() == SuffixedElementsSpec(elems.t) + elems.cs.Bytes();
                  assert elems.cs.Bytes() == ElementSpec(suffixed.t) + elem.cs.Bytes();
                  assert elem.cs.Bytes() == Spec.CommaSuffix(suffixed.suffix) + sep.cs.Bytes();
                  Seq.LemmaConcatIsAssociative(SuffixedElementsSpec(elems.t), ElementSpec(suffixed.t), elem.cs.Bytes());
                  Seq.LemmaConcatIsAssociative(SuffixedElementsSpec(elems.t) + ElementSpec(suffixed.t), Spec.CommaSuffix(suffixed.suffix), sep.cs.Bytes());
                }
                Seq.LemmaConcatIsAssociative(SuffixedElementsSpec(elems.t), ElementSpec(suffixed.t), Spec.CommaSuffix(suffixed.suffix));
              }
              assert SuffixedElementsSpec(elems.t) + (ElementSpec(suffixed.t) + Spec.CommaSuffix(suffixed.suffix)) + sep.cs.Bytes() == SuffixedElementsSpec(elems'.t) + sep.cs.Bytes() by {
                assert SuffixedElementsSpec(elems.t) + SuffixedElementSpec(suffixed) == SuffixedElementsSpec(elems.t + [suffixed]) by {
                  SpecProperties.ConcatBytes_Linear(elems.t, [suffixed], SuffixedElementSpec);
                  assert Spec.ConcatBytes(elems.t, SuffixedElementSpec) + Spec.ConcatBytes([suffixed], SuffixedElementSpec) == Spec.ConcatBytes(elems.t + [suffixed], SuffixedElementSpec);
                }
              }
            }
            assert elems'.StrictlySplitFrom?(cs0, SuffixedElementsSpec);
            assert forall e: Suffixed<Value, jcomma> {:trigger e.suffix} {:trigger e in elems'.t} | e in elems'.t :: e.suffix.NonEmpty? by {
              assert elems'.t == elems.t + [suffixed];
            }
            assert {:split_here} elems'.cs.Length() < elems.cs.Length();
            assert elems'.SplitFrom?(cs0, SuffixedElementsSpec) by {
              assert elems'.BytesSplitFrom?(cs0, SuffixedElementsSpec) by {
                assert elems'.StrictlySplitFrom?(cs0, SuffixedElementsSpec);
              }
              assert elems'.cs.SplitFrom?(cs0) by {
                assert elems'.cs.StrictlySplitFrom?(cs0) by {
                  assert elems'.StrictlySplitFrom?(cs0, SuffixedElementsSpec);
                }
              }
            }
            elems'
          }

          opaque function {:resource_limit 10000000} {:isolate_assertions} AppendLast(ghost cs0: FreshCursor, ghost json: ValueParser, elems: Split<seq<TSuffixedElement>>, elem: Split<TElement>, sep: Split<Structural<jclose>>): (elems': Split<seq<TSuffixedElement>>)
            requires elems.cs.StrictlySplitFrom?(json.cs)
            requires elems.SplitFrom?(cs0, SuffixedElementsSpec)
            requires elem.StrictlySplitFrom?(elems.cs, ElementSpec)
            requires sep.StrictlySplitFrom?(elem.cs, (c: Structural<jclose>) => Spec.Structural(c, SpecView))
            requires forall e: Suffixed<TElement, jcomma> {:trigger e.suffix} {:trigger e in elems.t} | e in elems.t :: e.suffix.NonEmpty?
            ensures elems'.StrictlySplitFrom?(cs0, SuffixedElementsSpec)
            ensures NoTrailingSuffix(elems'.t)
            ensures elems'.cs.Length() < elems.cs.Length()
            ensures elems'.cs.StrictlySplitFrom?(json.cs)
            ensures sep.StrictlySplitFrom?(elems'.cs, (c: Structural<jclose>) => Spec.Structural(c, SpecView))
            decreases cs0, json, elems, elem, sep
          {
            var suffixed: Suffixed<TElement, jcomma> := Suffixed(elem.t, Empty());
            var elems': Split<seq<Suffixed<Value, jcomma>>> := SP(elems.t + [suffixed], elem.cs);
            assert cs0.Bytes() == SuffixedElementsSpec(elems'.t) + elem.cs.Bytes() by {
              assert cs0.Bytes() == SuffixedElementsSpec(elems.t) + ElementSpec(suffixed.t) + elem.cs.Bytes() by {
                assert elem.t == suffixed.t;
              }
              assert SuffixedElementsSpec(elems.t) + ElementSpec(suffixed.t) + elem.cs.Bytes() == SuffixedElementsSpec(elems'.t) + elem.cs.Bytes() by {
                assert SuffixedElementsSpec(elems.t) + SuffixedElementSpec(suffixed) == SuffixedElementsSpec(elems.t + [suffixed]) by {
                  SpecProperties.ConcatBytes_Linear(elems.t, [suffixed], SuffixedElementSpec);
                  assert Spec.ConcatBytes(elems.t, SuffixedElementSpec) + Spec.ConcatBytes([suffixed], SuffixedElementSpec) == Spec.ConcatBytes(elems.t + [suffixed], SuffixedElementSpec);
                }
              }
            }
            assert elems'.StrictlySplitFrom?(cs0, SuffixedElementsSpec);
            elems'
          }

          lemma {:resource_limit ""10e6""} {:isolate_assertions} AboutTryStructural(cs: FreshCursor)
            ensures ghost var sp: Split<Structural<jopt>> := Core.TryStructural(cs); ghost var s0: opt_byte := sp.t.t.Peek(); ((!cs.BOF? || !cs.EOF?) && s0 == SEPARATOR as opt_byte ==> ghost var sp: Split<Structural<jcomma>> := sp; sp.cs.StrictSuffixOf?(cs)) && (s0 == SEPARATOR as opt_byte ==> ghost var sp: Split<Structural<jcomma>> := sp; sp.SplitFrom?(cs, (st: Structural<jcomma>) => Spec.Structural(st, SpecView))) && ((!cs.BOF? || !cs.EOF?) && s0 == CLOSE as opt_byte ==> ghost var sp: Split<Structural<jclose>> := sp; sp.cs.StrictSuffixOf?(cs)) && (s0 == CLOSE as opt_byte ==> ghost var sp: Split<Structural<jclose>> := sp; sp.SplitFrom?(cs, (st: Structural<jclose>) => Spec.Structural(st, SpecView)))
            decreases cs
          {
          }

          lemma {:isolate_assertions} AboutLists<T>(xs: seq<T>, i: uint32)
            requires 0 <= i as int < |xs|
            ensures xs[i as int .. i as int + 1] == [xs[i as int]]
            decreases xs, i
          {
          }

          opaque function {:isolate_assertions} {:tailrecursion} Elements(ghost cs0: FreshCursor, json: ValueParser, open: Split<Structural<jopen>>, elems: Split<seq<TSuffixedElement>>): (pr: ParseResult<TBracketed>)
            requires open.StrictlySplitFrom?(cs0, (c: Structural<jopen>) => Spec.Structural(c, SpecView))
            requires elems.cs.StrictlySplitFrom?(json.cs)
            requires elems.SplitFrom?(open.cs, SuffixedElementsSpec)
            requires forall e: Suffixed<TElement, jcomma> {:trigger e.suffix} {:trigger e in elems.t} | e in elems.t :: e.suffix.NonEmpty?
            ensures pr.Success? ==> pr.value.StrictlySplitFrom?(cs0, BracketedSpec)
            decreases elems.cs.Length()
          {
            var elem: Split<TElement> :- Element(elems.cs, json); if elem.cs.EOF? then Failure(EOF) else AboutTryStructural(elem.cs); var sep: Split<Structural<jopt>> := Core.TryStructural(elem.cs); var s0: opt_byte := sep.t.t.Peek(); if s0 == SEPARATOR as opt_byte && sep.t.t.Length() == 1 then assert sep.t.t.Char?(',') by {
    calc {
      sep.t.t.Char?(',');
      sep.t.t.Byte?(',' as byte);
      sep.t.t.Byte?(SEPARATOR);
      sep.t.t.Bytes() == [SEPARATOR];
      sep.t.t.s[sep.t.t.beg as int .. sep.t.t.end as int] == [SEPARATOR];
      {
        assert sep.t.t.beg as int + 1 == sep.t.t.end as int by {
          assert sep.t.t.Length() == 1;
        }
      }
      sep.t.t.s[sep.t.t.beg as int .. sep.t.t.beg as int + 1] == [SEPARATOR];
      {
        assert sep.t.t.s[sep.t.t.beg as int .. sep.t.t.beg as int + 1] == [sep.t.t.s[sep.t.t.beg as int]] by {
          AboutLists(sep.t.t.s, sep.t.t.beg);
        }
      }
      [sep.t.t.s[sep.t.t.beg as int]] == [SEPARATOR];
      sep.t.t.s[sep.t.t.beg as int] as opt_byte == SEPARATOR as opt_byte;
      sep.t.t.At(0) as opt_byte == SEPARATOR as opt_byte;
      s0 == SEPARATOR as opt_byte;
      true;
    }
  } var sep: Split<Structural<jcomma>> := sep; assert AppendWithSuffix.requires(open.cs, json, elems, elem, sep) by {
    assert {:focus} elems.cs.StrictlySplitFrom?(json.cs);
    assert elems.SplitFrom?(open.cs, SuffixedElementsSpec);
    assert elem.StrictlySplitFrom?(elems.cs, ElementSpec);
    assert sep.StrictlySplitFrom?(elem.cs, (c: Structural<jcomma>) => Spec.Structural(c, SpecView)) by {
      assert sep.BytesSplitFrom?(elem.cs, (c: Structural<jcomma>) => Spec.Structural(c, SpecView)) by {
        assert sep.SplitFrom?(elem.cs, (c: Structural<jcomma>) => Spec.Structural(c, SpecView));
      }
      assert sep.cs.StrictlySplitFrom?(elem.cs) by {
        assert sep.cs.BOF?;
        assert sep.cs.StrictSuffixOf?(elem.cs) by {
          assert !elem.cs.EOF?;
        }
      }
    }
    assert forall e: Suffixed<TElement, jcomma> {:trigger e.suffix} {:trigger e in elems.t} | e in elems.t :: e.suffix.NonEmpty?;
    assert {:split_here} true;
  } var elems: Split<seq<TSuffixedElement>> := AppendWithSuffix(open.cs, json, elems, elem, sep); Elements(cs0, json, open, elems) else if s0 == CLOSE as opt_byte && sep.t.t.Length() == 1 then assert sep.t.t.Byte?(CLOSE) by {
    calc {
      sep.t.t.Byte?(CLOSE);
      sep.t.t.Bytes() == [CLOSE];
      sep.t.t.s[sep.t.t.beg as int .. sep.t.t.end as int] == [CLOSE];
      {
        assert sep.t.t.beg as int + 1 == sep.t.t.end as int by {
          assert sep.t.t.Length() == 1;
        }
      }
      sep.t.t.s[sep.t.t.beg as int .. sep.t.t.beg as int + 1] == [CLOSE];
      {
        assert sep.t.t.s[sep.t.t.beg as int .. sep.t.t.beg as int + 1] == [sep.t.t.s[sep.t.t.beg as int]] by {
          AboutLists(sep.t.t.s, sep.t.t.beg);
        }
      }
      [sep.t.t.s[sep.t.t.beg as int]] == [CLOSE];
      sep.t.t.s[sep.t.t.beg as int] as opt_byte == CLOSE as opt_byte;
      sep.t.t.At(0) as opt_byte == CLOSE as opt_byte;
      s0 == CLOSE as opt_byte;
      true;
    }
  } var sep: Split<Structural<jclose>> := sep; assert AppendLast.requires(open.cs, json, elems, elem, sep) by {
    assert elems.cs.StrictlySplitFrom?(json.cs);
    assert elems.SplitFrom?(open.cs, SuffixedElementsSpec);
    assert elem.StrictlySplitFrom?(elems.cs, ElementSpec);
    assert sep.StrictlySplitFrom?(elem.cs, (c: Structural<jclose>) => Spec.Structural(c, SpecView)) by {
      assert sep.BytesSplitFrom?(elem.cs, (c: Structural<jclose>) => Spec.Structural(c, SpecView)) by {
        assert sep.SplitFrom?(elem.cs, (c: Structural<jclose>) => Spec.Structural(c, SpecView));
      }
      assert sep.cs.StrictlySplitFrom?(elem.cs) by {
        assert sep.cs.BOF?;
        assert sep.cs.StrictSuffixOf?(elem.cs) by {
          assert !elem.cs.EOF?;
        }
      }
    }
    assert forall e: Suffixed<TElement, jcomma> {:trigger e.suffix} {:trigger e in elems.t} | e in elems.t :: e.suffix.NonEmpty?;
  } var elems': Split<seq<TSuffixedElement>> := AppendLast(open.cs, json, elems, elem, sep); assert elems'.SplitFrom?(open.cs, SuffixedElementsSpec) by {
    assert elems'.StrictlySplitFrom?(open.cs, SuffixedElementsSpec);
  } var bracketed: Split<TBracketed> := BracketedFromParts(cs0, open, elems', sep); assert bracketed.StrictlySplitFrom?(cs0, BracketedSpec); Success(bracketed) else var separator: byte := SEPARATOR; var pr: Result<Split<Bracketed<jopen, Value, jcomma, jclose>>, CursorError<Errors.DeserializationError>> := Failure(ExpectingAnyByte([CLOSE, separator], s0)); pr
          }

          lemma AboutCloseParser()
            ensures Parsers.Parser(Close, SpecViewClose).Valid?()
          {
            assert Parsers.Parser(Close, SpecViewClose).Valid?() by {
              forall cs': FreshCursor | true
                ensures Close(cs').Success? ==> Close(cs').value.StrictlySplitFrom?(cs', SpecViewClose)
              {
                if Close(cs').Success? {
                  assert Close(cs').value.StrictlySplitFrom?(cs', SpecViewClose) by {
                    assert Close(cs').Success? ==> Close(cs').value.StrictlySplitFrom?(cs', SpecViewClose);
                  }
                }
              }
            }
          }

          opaque function {:isolate_assertions} Bracketed(cs: FreshCursor, json: ValueParser): (pr: ParseResult<TBracketed>)
            requires cs.SplitFrom?(json.cs)
            ensures pr.Success? ==> pr.value.StrictlySplitFrom?(cs, BracketedSpec)
            decreases cs, json
          {
            var open: Split<Structural<jopen>> :- Core.Structural<jopen>(cs, Parsers.Parser(Open, SpecViewOpen)); assert open.cs.StrictlySplitFrom?(json.cs); var elems: Split<seq<Suffixed<Value, jcomma>>> := SP([], open.cs); if open.cs.Peek() == CLOSE as opt_byte then var p: Parser_<jclose, JSONError> := Parsers.Parser(Close, SpecViewClose); assert p.Valid?() by {
    AboutCloseParser();
  } var close: Split<Structural<jclose>> :- Core.Structural<jclose>(open.cs, p); Success(BracketedFromParts(cs, open, elems, close)) else Elements(cs, json, open, elems)
          }

          lemma Valid(x: TBracketed)
            ensures x.l.t.Byte?(OPEN)
            ensures x.r.t.Byte?(CLOSE)
            ensures NoTrailingSuffix(x.data)
            ensures forall pf: Suffixed<TElement, jcomma> {:trigger pf.suffix} {:trigger pf in x.data} | pf in x.data :: pf.suffix.NonEmpty? ==> pf.suffix.t.t.Byte?(SEPARATOR)
            decreases x
          {
            ghost var xlt: jopen := x.l.t;
            ghost var xrt: jclose := x.r.t;
            forall pf: Suffixed<TElement, jcomma> | pf in x.data
              ensures pf.suffix.NonEmpty? ==> pf.suffix.t.t.Byte?(SEPARATOR)
            {
              if pf.suffix.NonEmpty? {
                ghost var xtt := pf.suffix.t.t;
              }
            }
          }

          import opened Params = ArrayParams

          import opened Wrappers

          import opened BoundedInts

          import SpecProperties = ConcreteSyntax.SpecProperties

          import opened Vs = Utils.Views.Core

          import opened Grammar

          import opened Cursors = Utils.Cursors

          import Parsers = Utils.Parsers

          import opened Core

          type jopen = v: Vs.View
            | v.Byte?(OPEN)
            witness Vs.View.OfBytes([OPEN])

          type jclose = v: Vs.View
            | v.Byte?(CLOSE)
            witness Vs.View.OfBytes([CLOSE])

          type TBracketed = Bracketed<jopen, TElement, jcomma, jclose>

          type TSuffixedElement = Suffixed<TElement, jcomma>
        }

        module ObjectParams refines SequenceParams {
          const OPEN: byte := '{' as byte
          const CLOSE: byte := '}' as byte

          function Colon(cs: FreshCursor): (pr: ParseResult<jcolon>)
            ensures pr.Success? ==> pr.value.StrictlySplitFrom?(cs, SpecView)
            decreases cs
          {
            var cs: Cursor :- cs.AssertChar(':'); Success(cs.Split())
          }

          opaque function KeyValueFromParts(ghost cs: Cursor, k: Split<jstring>, colon: Split<Structural<jcolon>>, v: Split<Value>): (sp: Split<jKeyValue>)
            requires k.StrictlySplitFrom?(cs, Spec.String)
            requires colon.StrictlySplitFrom?(k.cs, (c: Structural<jcolon>) => Spec.Structural(c, SpecView))
            requires v.StrictlySplitFrom?(colon.cs, Spec.Value)
            ensures sp.StrictlySplitFrom?(cs, ElementSpec)
            decreases cs, k, colon, v
          {
            var sp: Split<jKeyValue> := SP(Grammar.KeyValue(k.t, colon.t, v.t), v.cs);
            assert cs.Bytes() == Spec.KeyValue(sp.t) + v.cs.Bytes() by {
              assert cs.Bytes() == Spec.String(k.t) + Spec.Structural(colon.t, SpecView) + Spec.Value(v.t) + v.cs.Bytes() by {
                assert cs.Bytes() == Spec.String(k.t) + k.cs.Bytes();
                assert k.cs.Bytes() == Spec.Structural(colon.t, SpecView) + colon.cs.Bytes();
                assert colon.cs.Bytes() == Spec.Value(v.t) + v.cs.Bytes();
                Seq.LemmaConcatIsAssociative(Spec.String(k.t), Spec.Structural(colon.t, SpecView), colon.cs.Bytes());
                Seq.LemmaConcatIsAssociative(Spec.String(k.t) + Spec.Structural(colon.t, SpecView), Spec.Value(v.t), v.cs.Bytes());
              }
            }
            assert sp.StrictlySplitFrom?(cs, ElementSpec);
            sp
          }

          function ElementSpec(t: TElement): bytes
            decreases t
          {
            Spec.KeyValue(t)
          }

          function {:isolate_assertions} Element(cs: FreshCursor, json: ValueParser): (pr: ParseResult<TElement>)
            requires cs.StrictlySplitFrom?(json.cs)
            ensures pr.Success? ==> pr.value.StrictlySplitFrom?(cs, ElementSpec)
            decreases cs.Length()
          {
            var k: Split<jstring> :- Strings.String(cs); assert k.cs.StrictlySplitFrom?(json.cs); assert k.StrictlySplitFrom?(cs, Spec.String); var p: Parser_<jcolon, JSONError> := Parsers.Parser(Colon, SpecView); assert p.Valid?(); var colon: Split<Structural<jcolon>> :- Core.Structural(k.cs, p); assert colon.StrictlySplitFrom?(k.cs, (st: Structural<jcolon>) => Spec.Structural(st, SpecView)); assert colon.cs.StrictlySplitFrom?(json.cs); assert json.fn.requires(colon.cs) by {
    assert json.pre(colon.cs) by {
      assert colon.cs.StrictlySplitFrom?(json.cs);
      assert json.Valid?();
    }
    assert json.Valid?();
  } var v: Split<Value> :- json.fn(colon.cs); assert v.StrictlySplitFrom?(colon.cs, Spec.Value) by {
    assert v.cs.StrictlySplitFrom?(colon.cs) by {
      assert v.StrictlySplitFrom?(colon.cs, json.spec) by {
        assert json.Valid?();
      }
    }
    assert v.BytesSplitFrom?(colon.cs, Spec.Value) by {
      calc {
        colon.cs.Bytes();
        {
          assert v.BytesSplitFrom?(colon.cs, json.spec) by {
            assert json.Valid?();
          }
        }
        json.spec(v.t) + v.cs.Bytes();
        {
          assert json.spec(v.t) == Spec.Value(v.t) by {
            assert ValueParserValid(json);
          }
        }
        Spec.Value(v.t) + v.cs.Bytes();
      }
    }
  } var kv: Split<jKeyValue> := KeyValueFromParts(cs, k, colon, v); Success(kv)
          }

          import Strings

          import opened Wrappers

          type TElement = jKeyValue

          import opened BoundedInts

          import opened Grammar

          import opened Cursors = Utils.Cursors

          import opened Core
        }

        module Objects refines Sequences {
          lemma {:isolate_assertions} /*{:_induction obj}*/ BracketedToObject(obj: jobject)
            ensures Spec.Bracketed(obj, SuffixedElementSpec) == Spec.Object(obj)
            decreases obj
          {
            ghost var rMember := (d: jmember) requires d < obj => Spec.Member(d);
            assert Spec.Bracketed(obj, SuffixedElementSpec) == Spec.Bracketed(obj, rMember) by {
              assert Spec.Bracketed(obj, SuffixedElementSpec) == Spec.Bracketed(obj, rMember) by {
                assert SpecProperties.Bracketed_Morphism_Requires(obj, SuffixedElementSpec, rMember);
                SpecProperties.Bracketed_Morphism(obj, SuffixedElementSpec, rMember);
              }
            }
            calc {
              Spec.Bracketed(obj, SuffixedElementSpec);
              Spec.Bracketed(obj, rMember);
              Spec.Object(obj);
            }
          }

          opaque function {:isolate_assertions} {:resource_limit 10000000} Object(cs: FreshCursor, json: ValueParser): (pr: ParseResult<jobject>)
            requires cs.SplitFrom?(json.cs)
            ensures pr.Success? ==> pr.value.StrictlySplitFrom?(cs, Spec.Object)
            decreases cs, json
          {
            var sp: Split<TBracketed> :- Bracketed(cs, json); assert sp.StrictlySplitFrom?(cs, BracketedSpec); BracketedToObject(sp.t); Success(sp)
          }

          const SEPARATOR: byte := ',' as byte
          const SpecViewClose: jclose -> bytes := SpecView
          const SpecViewOpen: jopen -> bytes := SpecView

          ghost function SuffixedElementSpec(e: TSuffixedElement): bytes
            decreases e
          {
            ElementSpec(e.t) + Spec.CommaSuffix(e.suffix)
          }

          ghost function BracketedSpec(ts: TBracketed): bytes
            decreases ts
          {
            Spec.Bracketed(ts, SuffixedElementSpec)
          }

          ghost function SuffixedElementsSpec(ts: seq<TSuffixedElement>): bytes
            decreases ts
          {
            Spec.ConcatBytes(ts, SuffixedElementSpec)
          }

          opaque function Open(cs: FreshCursor): (pr: ParseResult<jopen>)
            ensures pr.Success? ==> pr.value.StrictlySplitFrom?(cs, SpecViewOpen)
            decreases cs
          {
            var cs: Cursor :- cs.AssertByte(OPEN); Success(cs.Split())
          }

          opaque function Close(cs: FreshCursor): (pr: ParseResult<jclose>)
            ensures pr.Success? ==> pr.value.StrictlySplitFrom?(cs, SpecViewClose)
            decreases cs
          {
            var cs: Cursor :- cs.AssertByte(CLOSE); Success(cs.Split())
          }

          opaque function BracketedFromParts(ghost cs: Cursor, open: Split<Structural<jopen>>, elems: Split<seq<TSuffixedElement>>, close: Split<Structural<jclose>>): (sp: Split<TBracketed>)
            requires Grammar.NoTrailingSuffix(elems.t)
            requires open.StrictlySplitFrom?(cs, (c: Structural<jopen>) => Spec.Structural(c, SpecView))
            requires elems.SplitFrom?(open.cs, SuffixedElementsSpec)
            requires close.StrictlySplitFrom?(elems.cs, (c: Structural<jclose>) => Spec.Structural(c, SpecView))
            ensures sp.StrictlySplitFrom?(cs, BracketedSpec)
            decreases cs, open, elems, close
          {
            var sp: Split<Bracketed<jopen, TElement, jcomma, jclose>> := SP(Grammar.Bracketed(open.t, elems.t, close.t), close.cs);
            calc {
              cs.Bytes();
              Spec.Structural(open.t, SpecView) + open.cs.Bytes();
              {
                assert open.cs.Bytes() == SuffixedElementsSpec(elems.t) + elems.cs.Bytes();
              }
              Spec.Structural(open.t, SpecView) + (SuffixedElementsSpec(elems.t) + elems.cs.Bytes());
              {
                Seq.LemmaConcatIsAssociative(Spec.Structural(open.t, SpecView), SuffixedElementsSpec(elems.t), elems.cs.Bytes());
              }
              Spec.Structural(open.t, SpecView) + SuffixedElementsSpec(elems.t) + elems.cs.Bytes();
              {
                assert elems.cs.Bytes() == Spec.Structural(close.t, SpecView) + close.cs.Bytes();
              }
              Spec.Structural(open.t, SpecView) + SuffixedElementsSpec(elems.t) + (Spec.Structural(close.t, SpecView) + close.cs.Bytes());
              {
                Seq.LemmaConcatIsAssociative(Spec.Structural(open.t, SpecView) + SuffixedElementsSpec(elems.t), Spec.Structural(close.t, SpecView), close.cs.Bytes());
              }
              Spec.Structural(open.t, SpecView) + SuffixedElementsSpec(elems.t) + Spec.Structural(close.t, SpecView) + close.cs.Bytes();
              Spec.Bracketed(sp.t, SuffixedElementSpec) + close.cs.Bytes();
            }
            assert sp.StrictlySplitFrom?(cs, BracketedSpec);
            sp
          }

          opaque function AppendWithSuffix(ghost cs0: FreshCursor, ghost json: ValueParser, elems: Split<seq<TSuffixedElement>>, elem: Split<TElement>, sep: Split<Structural<jcomma>>): (elems': Split<seq<TSuffixedElement>>)
            requires elems.cs.StrictlySplitFrom?(json.cs)
            requires elems.SplitFrom?(cs0, SuffixedElementsSpec)
            requires elem.StrictlySplitFrom?(elems.cs, ElementSpec)
            requires sep.StrictlySplitFrom?(elem.cs, (c: Structural<jcomma>) => Spec.Structural(c, SpecView))
            requires forall e: Suffixed<TElement, jcomma> {:trigger e.suffix} {:trigger e in elems.t} | e in elems.t :: e.suffix.NonEmpty?
            ensures elems'.StrictlySplitFrom?(cs0, SuffixedElementsSpec)
            ensures forall e: Suffixed<TElement, jcomma> {:trigger e.suffix} {:trigger e in elems'.t} | e in elems'.t :: e.suffix.NonEmpty?
            ensures elems'.cs.Length() < elems.cs.Length()
            ensures elems'.cs.StrictlySplitFrom?(json.cs)
            ensures elems'.SplitFrom?(cs0, SuffixedElementsSpec)
            decreases cs0, json, elems, elem, sep
          {
            var suffixed: Suffixed<TElement, jcomma> := Suffixed(elem.t, NonEmpty(sep.t));
            var elems': Split<seq<Suffixed<jKeyValue, jcomma>>> := SP(elems.t + [suffixed], sep.cs);
            assert cs0.Bytes() == SuffixedElementsSpec(elems'.t) + sep.cs.Bytes() by {
              assert {:focus} cs0.Bytes() == SuffixedElementsSpec(elems.t) + (ElementSpec(suffixed.t) + Spec.CommaSuffix(suffixed.suffix)) + sep.cs.Bytes() by {
                assert cs0.Bytes() == SuffixedElementsSpec(elems.t) + ElementSpec(suffixed.t) + Spec.CommaSuffix(suffixed.suffix) + sep.cs.Bytes() by {
                  assert cs0.Bytes() == SuffixedElementsSpec(elems.t) + elems.cs.Bytes();
                  assert elems.cs.Bytes() == ElementSpec(suffixed.t) + elem.cs.Bytes();
                  assert elem.cs.Bytes() == Spec.CommaSuffix(suffixed.suffix) + sep.cs.Bytes();
                  Seq.LemmaConcatIsAssociative(SuffixedElementsSpec(elems.t), ElementSpec(suffixed.t), elem.cs.Bytes());
                  Seq.LemmaConcatIsAssociative(SuffixedElementsSpec(elems.t) + ElementSpec(suffixed.t), Spec.CommaSuffix(suffixed.suffix), sep.cs.Bytes());
                }
                Seq.LemmaConcatIsAssociative(SuffixedElementsSpec(elems.t), ElementSpec(suffixed.t), Spec.CommaSuffix(suffixed.suffix));
              }
              assert SuffixedElementsSpec(elems.t) + (ElementSpec(suffixed.t) + Spec.CommaSuffix(suffixed.suffix)) + sep.cs.Bytes() == SuffixedElementsSpec(elems'.t) + sep.cs.Bytes() by {
                assert SuffixedElementsSpec(elems.t) + SuffixedElementSpec(suffixed) == SuffixedElementsSpec(elems.t + [suffixed]) by {
                  SpecProperties.ConcatBytes_Linear(elems.t, [suffixed], SuffixedElementSpec);
                  assert Spec.ConcatBytes(elems.t, SuffixedElementSpec) + Spec.ConcatBytes([suffixed], SuffixedElementSpec) == Spec.ConcatBytes(elems.t + [suffixed], SuffixedElementSpec);
                }
              }
            }
            assert elems'.StrictlySplitFrom?(cs0, SuffixedElementsSpec);
            assert forall e: Suffixed<jKeyValue, jcomma> {:trigger e.suffix} {:trigger e in elems'.t} | e in elems'.t :: e.suffix.NonEmpty? by {
              assert elems'.t == elems.t + [suffixed];
            }
            assert {:split_here} elems'.cs.Length() < elems.cs.Length();
            assert elems'.SplitFrom?(cs0, SuffixedElementsSpec) by {
              assert elems'.BytesSplitFrom?(cs0, SuffixedElementsSpec) by {
                assert elems'.StrictlySplitFrom?(cs0, SuffixedElementsSpec);
              }
              assert elems'.cs.SplitFrom?(cs0) by {
                assert elems'.cs.StrictlySplitFrom?(cs0) by {
                  assert elems'.StrictlySplitFrom?(cs0, SuffixedElementsSpec);
                }
              }
            }
            elems'
          }

          opaque function {:resource_limit 10000000} {:isolate_assertions} AppendLast(ghost cs0: FreshCursor, ghost json: ValueParser, elems: Split<seq<TSuffixedElement>>, elem: Split<TElement>, sep: Split<Structural<jclose>>): (elems': Split<seq<TSuffixedElement>>)
            requires elems.cs.StrictlySplitFrom?(json.cs)
            requires elems.SplitFrom?(cs0, SuffixedElementsSpec)
            requires elem.StrictlySplitFrom?(elems.cs, ElementSpec)
            requires sep.StrictlySplitFrom?(elem.cs, (c: Structural<jclose>) => Spec.Structural(c, SpecView))
            requires forall e: Suffixed<TElement, jcomma> {:trigger e.suffix} {:trigger e in elems.t} | e in elems.t :: e.suffix.NonEmpty?
            ensures elems'.StrictlySplitFrom?(cs0, SuffixedElementsSpec)
            ensures NoTrailingSuffix(elems'.t)
            ensures elems'.cs.Length() < elems.cs.Length()
            ensures elems'.cs.StrictlySplitFrom?(json.cs)
            ensures sep.StrictlySplitFrom?(elems'.cs, (c: Structural<jclose>) => Spec.Structural(c, SpecView))
            decreases cs0, json, elems, elem, sep
          {
            var suffixed: Suffixed<TElement, jcomma> := Suffixed(elem.t, Empty());
            var elems': Split<seq<Suffixed<jKeyValue, jcomma>>> := SP(elems.t + [suffixed], elem.cs);
            assert cs0.Bytes() == SuffixedElementsSpec(elems'.t) + elem.cs.Bytes() by {
              assert cs0.Bytes() == SuffixedElementsSpec(elems.t) + ElementSpec(suffixed.t) + elem.cs.Bytes() by {
                assert elem.t == suffixed.t;
              }
              assert SuffixedElementsSpec(elems.t) + ElementSpec(suffixed.t) + elem.cs.Bytes() == SuffixedElementsSpec(elems'.t) + elem.cs.Bytes() by {
                assert SuffixedElementsSpec(elems.t) + SuffixedElementSpec(suffixed) == SuffixedElementsSpec(elems.t + [suffixed]) by {
                  SpecProperties.ConcatBytes_Linear(elems.t, [suffixed], SuffixedElementSpec);
                  assert Spec.ConcatBytes(elems.t, SuffixedElementSpec) + Spec.ConcatBytes([suffixed], SuffixedElementSpec) == Spec.ConcatBytes(elems.t + [suffixed], SuffixedElementSpec);
                }
              }
            }
            assert elems'.StrictlySplitFrom?(cs0, SuffixedElementsSpec);
            elems'
          }

          lemma {:resource_limit ""10e6""} {:isolate_assertions} AboutTryStructural(cs: FreshCursor)
            ensures ghost var sp: Split<Structural<jopt>> := Core.TryStructural(cs); ghost var s0: opt_byte := sp.t.t.Peek(); ((!cs.BOF? || !cs.EOF?) && s0 == SEPARATOR as opt_byte ==> ghost var sp: Split<Structural<jcomma>> := sp; sp.cs.StrictSuffixOf?(cs)) && (s0 == SEPARATOR as opt_byte ==> ghost var sp: Split<Structural<jcomma>> := sp; sp.SplitFrom?(cs, (st: Structural<jcomma>) => Spec.Structural(st, SpecView))) && ((!cs.BOF? || !cs.EOF?) && s0 == CLOSE as opt_byte ==> ghost var sp: Split<Structural<jclose>> := sp; sp.cs.StrictSuffixOf?(cs)) && (s0 == CLOSE as opt_byte ==> ghost var sp: Split<Structural<jclose>> := sp; sp.SplitFrom?(cs, (st: Structural<jclose>) => Spec.Structural(st, SpecView)))
            decreases cs
          {
          }

          lemma {:isolate_assertions} AboutLists<T>(xs: seq<T>, i: uint32)
            requires 0 <= i as int < |xs|
            ensures xs[i as int .. i as int + 1] == [xs[i as int]]
            decreases xs, i
          {
          }

          opaque function {:isolate_assertions} {:tailrecursion} Elements(ghost cs0: FreshCursor, json: ValueParser, open: Split<Structural<jopen>>, elems: Split<seq<TSuffixedElement>>): (pr: ParseResult<TBracketed>)
            requires open.StrictlySplitFrom?(cs0, (c: Structural<jopen>) => Spec.Structural(c, SpecView))
            requires elems.cs.StrictlySplitFrom?(json.cs)
            requires elems.SplitFrom?(open.cs, SuffixedElementsSpec)
            requires forall e: Suffixed<TElement, jcomma> {:trigger e.suffix} {:trigger e in elems.t} | e in elems.t :: e.suffix.NonEmpty?
            ensures pr.Success? ==> pr.value.StrictlySplitFrom?(cs0, BracketedSpec)
            decreases elems.cs.Length()
          {
            var elem: Split<TElement> :- Element(elems.cs, json); if elem.cs.EOF? then Failure(EOF) else AboutTryStructural(elem.cs); var sep: Split<Structural<jopt>> := Core.TryStructural(elem.cs); var s0: opt_byte := sep.t.t.Peek(); if s0 == SEPARATOR as opt_byte && sep.t.t.Length() == 1 then assert sep.t.t.Char?(',') by {
    calc {
      sep.t.t.Char?(',');
      sep.t.t.Byte?(',' as byte);
      sep.t.t.Byte?(SEPARATOR);
      sep.t.t.Bytes() == [SEPARATOR];
      sep.t.t.s[sep.t.t.beg as int .. sep.t.t.end as int] == [SEPARATOR];
      {
        assert sep.t.t.beg as int + 1 == sep.t.t.end as int by {
          assert sep.t.t.Length() == 1;
        }
      }
      sep.t.t.s[sep.t.t.beg as int .. sep.t.t.beg as int + 1] == [SEPARATOR];
      {
        assert sep.t.t.s[sep.t.t.beg as int .. sep.t.t.beg as int + 1] == [sep.t.t.s[sep.t.t.beg as int]] by {
          AboutLists(sep.t.t.s, sep.t.t.beg);
        }
      }
      [sep.t.t.s[sep.t.t.beg as int]] == [SEPARATOR];
      sep.t.t.s[sep.t.t.beg as int] as opt_byte == SEPARATOR as opt_byte;
      sep.t.t.At(0) as opt_byte == SEPARATOR as opt_byte;
      s0 == SEPARATOR as opt_byte;
      true;
    }
  } var sep: Split<Structural<jcomma>> := sep; assert AppendWithSuffix.requires(open.cs, json, elems, elem, sep) by {
    assert {:focus} elems.cs.StrictlySplitFrom?(json.cs);
    assert elems.SplitFrom?(open.cs, SuffixedElementsSpec);
    assert elem.StrictlySplitFrom?(elems.cs, ElementSpec);
    assert sep.StrictlySplitFrom?(elem.cs, (c: Structural<jcomma>) => Spec.Structural(c, SpecView)) by {
      assert sep.BytesSplitFrom?(elem.cs, (c: Structural<jcomma>) => Spec.Structural(c, SpecView)) by {
        assert sep.SplitFrom?(elem.cs, (c: Structural<jcomma>) => Spec.Structural(c, SpecView));
      }
      assert sep.cs.StrictlySplitFrom?(elem.cs) by {
        assert sep.cs.BOF?;
        assert sep.cs.StrictSuffixOf?(elem.cs) by {
          assert !elem.cs.EOF?;
        }
      }
    }
    assert forall e: Suffixed<TElement, jcomma> {:trigger e.suffix} {:trigger e in elems.t} | e in elems.t :: e.suffix.NonEmpty?;
    assert {:split_here} true;
  } var elems: Split<seq<TSuffixedElement>> := AppendWithSuffix(open.cs, json, elems, elem, sep); Elements(cs0, json, open, elems) else if s0 == CLOSE as opt_byte && sep.t.t.Length() == 1 then assert sep.t.t.Byte?(CLOSE) by {
    calc {
      sep.t.t.Byte?(CLOSE);
      sep.t.t.Bytes() == [CLOSE];
      sep.t.t.s[sep.t.t.beg as int .. sep.t.t.end as int] == [CLOSE];
      {
        assert sep.t.t.beg as int + 1 == sep.t.t.end as int by {
          assert sep.t.t.Length() == 1;
        }
      }
      sep.t.t.s[sep.t.t.beg as int .. sep.t.t.beg as int + 1] == [CLOSE];
      {
        assert sep.t.t.s[sep.t.t.beg as int .. sep.t.t.beg as int + 1] == [sep.t.t.s[sep.t.t.beg as int]] by {
          AboutLists(sep.t.t.s, sep.t.t.beg);
        }
      }
      [sep.t.t.s[sep.t.t.beg as int]] == [CLOSE];
      sep.t.t.s[sep.t.t.beg as int] as opt_byte == CLOSE as opt_byte;
      sep.t.t.At(0) as opt_byte == CLOSE as opt_byte;
      s0 == CLOSE as opt_byte;
      true;
    }
  } var sep: Split<Structural<jclose>> := sep; assert AppendLast.requires(open.cs, json, elems, elem, sep) by {
    assert elems.cs.StrictlySplitFrom?(json.cs);
    assert elems.SplitFrom?(open.cs, SuffixedElementsSpec);
    assert elem.StrictlySplitFrom?(elems.cs, ElementSpec);
    assert sep.StrictlySplitFrom?(elem.cs, (c: Structural<jclose>) => Spec.Structural(c, SpecView)) by {
      assert sep.BytesSplitFrom?(elem.cs, (c: Structural<jclose>) => Spec.Structural(c, SpecView)) by {
        assert sep.SplitFrom?(elem.cs, (c: Structural<jclose>) => Spec.Structural(c, SpecView));
      }
      assert sep.cs.StrictlySplitFrom?(elem.cs) by {
        assert sep.cs.BOF?;
        assert sep.cs.StrictSuffixOf?(elem.cs) by {
          assert !elem.cs.EOF?;
        }
      }
    }
    assert forall e: Suffixed<TElement, jcomma> {:trigger e.suffix} {:trigger e in elems.t} | e in elems.t :: e.suffix.NonEmpty?;
  } var elems': Split<seq<TSuffixedElement>> := AppendLast(open.cs, json, elems, elem, sep); assert elems'.SplitFrom?(open.cs, SuffixedElementsSpec) by {
    assert elems'.StrictlySplitFrom?(open.cs, SuffixedElementsSpec);
  } var bracketed: Split<TBracketed> := BracketedFromParts(cs0, open, elems', sep); assert bracketed.StrictlySplitFrom?(cs0, BracketedSpec); Success(bracketed) else var separator: byte := SEPARATOR; var pr: Result<Split<Bracketed<jopen, jKeyValue, jcomma, jclose>>, CursorError<Errors.DeserializationError>> := Failure(ExpectingAnyByte([CLOSE, separator], s0)); pr
          }

          lemma AboutCloseParser()
            ensures Parsers.Parser(Close, SpecViewClose).Valid?()
          {
            assert Parsers.Parser(Close, SpecViewClose).Valid?() by {
              forall cs': FreshCursor | true
                ensures Close(cs').Success? ==> Close(cs').value.StrictlySplitFrom?(cs', SpecViewClose)
              {
                if Close(cs').Success? {
                  assert Close(cs').value.StrictlySplitFrom?(cs', SpecViewClose) by {
                    assert Close(cs').Success? ==> Close(cs').value.StrictlySplitFrom?(cs', SpecViewClose);
                  }
                }
              }
            }
          }

          opaque function {:isolate_assertions} Bracketed(cs: FreshCursor, json: ValueParser): (pr: ParseResult<TBracketed>)
            requires cs.SplitFrom?(json.cs)
            ensures pr.Success? ==> pr.value.StrictlySplitFrom?(cs, BracketedSpec)
            decreases cs, json
          {
            var open: Split<Structural<jopen>> :- Core.Structural<jopen>(cs, Parsers.Parser(Open, SpecViewOpen)); assert open.cs.StrictlySplitFrom?(json.cs); var elems: Split<seq<Suffixed<jKeyValue, jcomma>>> := SP([], open.cs); if open.cs.Peek() == CLOSE as opt_byte then var p: Parser_<jclose, JSONError> := Parsers.Parser(Close, SpecViewClose); assert p.Valid?() by {
    AboutCloseParser();
  } var close: Split<Structural<jclose>> :- Core.Structural<jclose>(open.cs, p); Success(BracketedFromParts(cs, open, elems, close)) else Elements(cs, json, open, elems)
          }

          lemma Valid(x: TBracketed)
            ensures x.l.t.Byte?(OPEN)
            ensures x.r.t.Byte?(CLOSE)
            ensures NoTrailingSuffix(x.data)
            ensures forall pf: Suffixed<TElement, jcomma> {:trigger pf.suffix} {:trigger pf in x.data} | pf in x.data :: pf.suffix.NonEmpty? ==> pf.suffix.t.t.Byte?(SEPARATOR)
            decreases x
          {
            ghost var xlt: jopen := x.l.t;
            ghost var xrt: jclose := x.r.t;
            forall pf: Suffixed<TElement, jcomma> | pf in x.data
              ensures pf.suffix.NonEmpty? ==> pf.suffix.t.t.Byte?(SEPARATOR)
            {
              if pf.suffix.NonEmpty? {
                ghost var xtt := pf.suffix.t.t;
              }
            }
          }

          import opened Params = ObjectParams

          import opened Wrappers

          import opened BoundedInts

          import SpecProperties = ConcreteSyntax.SpecProperties

          import opened Vs = Utils.Views.Core

          import opened Grammar

          import opened Cursors = Utils.Cursors

          import Parsers = Utils.Parsers

          import opened Core

          type jopen = v: Vs.View
            | v.Byte?(OPEN)
            witness Vs.View.OfBytes([OPEN])

          type jclose = v: Vs.View
            | v.Byte?(CLOSE)
            witness Vs.View.OfBytes([CLOSE])

          type TBracketed = Bracketed<jopen, TElement, jcomma, jclose>

          type TSuffixedElement = Suffixed<TElement, jcomma>
        }
      }

      module Serializer {
        method Serialize(js: JSON) returns (rbs: SerializationResult<array<byte>>)
          ensures rbs.Success? ==> fresh(rbs.value)
          ensures rbs.Success? ==> rbs.value[..] == Spec.JSON(js)
          decreases js
        {
          var writer := Text(js);
          :- Need(writer.Unsaturated?, OutOfMemory);
          var bs := writer.ToArray();
          return Success(bs);
        }

        method SerializeTo(js: JSON, dest: array<byte>) returns (len: SerializationResult<uint32>)
          modifies dest
          ensures len.Success? ==> len.value as int <= dest.Length
          ensures len.Success? ==> dest[..len.value] == Spec.JSON(js)
          ensures len.Success? ==> dest[len.value..] == old(dest[len.value..])
          ensures len.Failure? ==> unchanged(dest)
          decreases js, dest
        {
          var writer := Text(js);
          :- Need(writer.Unsaturated?, OutOfMemory);
          :- Need(writer.length as int <= dest.Length, OutOfMemory);
          writer.CopyTo(dest);
          return Success(writer.length);
        }

        opaque function Text(js: JSON): (wr: Writer)
          ensures wr.Bytes() == Spec.JSON(js)
          decreases js
        {
          JSON(js)
        }

        opaque function JSON(js: JSON, writer: Writer := Writer.Empty): (wr: Writer)
          ensures wr.Bytes() == writer.Bytes() + Spec.JSON(js)
          decreases js, writer
        {
          Seq.LemmaConcatIsAssociative2(writer.Bytes(), js.before.Bytes(), Spec.Value(js.t), js.after.Bytes());
          writer.Append(js.before).Then((wr: Writer) => Value(js.t, wr)).Append(js.after)
        }

        opaque function {:isolate_assertions} Value(v: Grammar.Value, writer: Writer): (wr: Writer)
          ensures wr.Bytes() == writer.Bytes() + Spec.Value(v)
          decreases v, 4
        {
          match v
          case Null(n) =>
            var wr: Writer := writer.Append(n);
            wr
          case Bool(b) =>
            var wr: Writer := writer.Append(b);
            wr
          case String(str) =>
            var wr: Writer := String(str, writer);
            calc {
              wr.Bytes();
              {
                assert wr == String(v.str, writer);
              }
              writer.Bytes() + Spec.String(v.str);
              {
                assert v.String?;
                assert v.String? ==> Spec.Value(v) == Spec.String(v.str);
              }
              writer.Bytes() + Spec.Value(v);
            } wr
          case Number(num) =>
            var wr: Writer := Number(num, writer);
            calc {
              wr.Bytes();
              {
                assert wr == Number(v.num, writer);
              }
              writer.Bytes() + Spec.Number(v.num);
              {
                assert v.Number?;
                assert v.Number? ==> Spec.Value(v) == Spec.Number(v.num);
              }
              writer.Bytes() + Spec.Value(v);
            } wr
          case Object(obj) =>
            var wr: Writer := Object(obj, writer);
            calc {
              wr.Bytes();
              {
                assert wr == Object(v.obj, writer);
              }
              writer.Bytes() + Spec.Object(v.obj);
              {
                assert v.Object?;
                assert v.Object? ==> Spec.Value(v) == Spec.Object(v.obj);
              }
              writer.Bytes() + Spec.Value(v);
            } wr
          case Array(arr) =>
            var wr: Writer := Array(arr, writer);
            calc {
              wr.Bytes();
              {
                assert wr == Array(v.arr, writer);
              }
              writer.Bytes() + Spec.Array(v.arr);
              {
                assert v.Array?;
                assert v.Array? ==> Spec.Value(v) == Spec.Array(v.arr);
              }
              writer.Bytes() + Spec.Value(v);
            }
            wr
        }

        opaque function String(str: jstring, writer: Writer): (wr: Writer)
          ensures wr.Bytes() == writer.Bytes() + Spec.String(str)
          decreases str, 0
        {
          writer.Append(str.lq).Append(str.contents).Append(str.rq)
        }

        lemma {:isolate_assertions} NumberHelper1(num: jnumber, writer: Writer)
          ensures if num.exp.NonEmpty? then if num.frac.NonEmpty? then writer.Append(num.minus).Append(num.num).Append(num.frac.t.period).Append(num.frac.t.num).Append(num.exp.t.e).Append(num.exp.t.sign).Append(num.exp.t.num).Bytes() == writer.Bytes() + num.minus.Bytes() + num.num.Bytes() + num.frac.t.period.Bytes() + num.frac.t.num.Bytes() + num.exp.t.e.Bytes() + num.exp.t.sign.Bytes() + num.exp.t.num.Bytes() else writer.Append(num.minus).Append(num.num).Append(num.exp.t.e).Append(num.exp.t.sign).Append(num.exp.t.num).Bytes() == writer.Bytes() + num.minus.Bytes() + num.num.Bytes() + num.exp.t.e.Bytes() + num.exp.t.sign.Bytes() + num.exp.t.num.Bytes() else if num.frac.NonEmpty? then writer.Append(num.minus).Append(num.num).Append(num.frac.t.period).Append(num.frac.t.num).Bytes() == writer.Bytes() + num.minus.Bytes() + num.num.Bytes() + num.frac.t.period.Bytes() + num.frac.t.num.Bytes() else writer.Append(num.minus).Append(num.num).Bytes() == writer.Bytes() + num.minus.Bytes() + num.num.Bytes()
          decreases num, writer
        {
          if num.exp.NonEmpty? {
            if num.frac.NonEmpty? {
              assert writer.Append(num.minus).Append(num.num).Append(num.frac.t.period).Append(num.frac.t.num).Append(num.exp.t.e).Append(num.exp.t.sign).Append(num.exp.t.num).Bytes() == writer.Bytes() + num.minus.Bytes() + num.num.Bytes() + num.frac.t.period.Bytes() + num.frac.t.num.Bytes() + num.exp.t.e.Bytes() + num.exp.t.sign.Bytes() + num.exp.t.num.Bytes();
            } else {
              assert writer.Append(num.minus).Append(num.num).Append(num.exp.t.e).Append(num.exp.t.sign).Append(num.exp.t.num).Bytes() == writer.Bytes() + num.minus.Bytes() + num.num.Bytes() + num.exp.t.e.Bytes() + num.exp.t.sign.Bytes() + num.exp.t.num.Bytes();
            }
          } else {
            if num.frac.NonEmpty? {
              assert writer.Append(num.minus).Append(num.num).Append(num.frac.t.period).Append(num.frac.t.num).Bytes() == writer.Bytes() + num.minus.Bytes() + num.num.Bytes() + num.frac.t.period.Bytes() + num.frac.t.num.Bytes();
            } else {
              assert writer.Append(num.minus).Append(num.num).Bytes() == writer.Bytes() + num.minus.Bytes() + num.num.Bytes();
            }
          }
        }

        lemma {:isolate_assertions} NumberHelper2a(num: jnumber, writer: Writer)
          ensures Spec.Number(num) == num.minus.Bytes() + num.num.Bytes() + Spec.Maybe(num.frac, Spec.Frac) + Spec.Maybe(num.exp, Spec.Exp)
          decreases num, writer
        {
        }

        lemma {:isolate_assertions} {:resource_limit 10000000} NumberHelper2(num: jnumber, writer: Writer)
          ensures if num.exp.NonEmpty? then if num.frac.NonEmpty? then writer.Bytes() + Spec.Number(num) == writer.Bytes() + num.minus.Bytes() + num.num.Bytes() + num.frac.t.period.Bytes() + num.frac.t.num.Bytes() + num.exp.t.e.Bytes() + num.exp.t.sign.Bytes() + num.exp.t.num.Bytes() else writer.Bytes() + Spec.Number(num) == writer.Bytes() + num.minus.Bytes() + num.num.Bytes() + num.exp.t.e.Bytes() + num.exp.t.sign.Bytes() + num.exp.t.num.Bytes() else if num.frac.NonEmpty? then writer.Bytes() + Spec.Number(num) == writer.Bytes() + num.minus.Bytes() + num.num.Bytes() + num.frac.t.period.Bytes() + num.frac.t.num.Bytes() else writer.Bytes() + Spec.Number(num) == writer.Bytes() + num.minus.Bytes() + num.num.Bytes()
          decreases num, writer
        {
          if num.exp.NonEmpty? {
            if num.frac.NonEmpty? {
              calc {
                writer.Bytes() + Spec.Number(num);
                {
                  NumberHelper2a(num, writer);
                }
                writer.Bytes() + (num.minus.Bytes() + num.num.Bytes() + Spec.Maybe(num.frac, Spec.Frac) + Spec.Maybe(num.exp, Spec.Exp));
                writer.Bytes() + num.minus.Bytes() + num.num.Bytes() + (Spec.Maybe(num.frac, Spec.Frac) + Spec.Maybe(num.exp, Spec.Exp));
                {
                  assert Spec.Maybe(num.frac, Spec.Frac) == Spec.Frac(num.frac.t);
                  assert Spec.Maybe(num.exp, Spec.Exp) == Spec.Exp(num.exp.t);
                }
                writer.Bytes() + num.minus.Bytes() + num.num.Bytes() + (Spec.Frac(num.frac.t) + Spec.Exp(num.exp.t));
                {
                  assert Spec.Frac(num.frac.t) == num.frac.t.period.Bytes() + num.frac.t.num.Bytes();
                  assert Spec.Exp(num.exp.t) == num.exp.t.e.Bytes() + num.exp.t.sign.Bytes() + num.exp.t.num.Bytes();
                }
                writer.Bytes() + num.minus.Bytes() + num.num.Bytes() + (num.frac.t.period.Bytes() + num.frac.t.num.Bytes() + (num.exp.t.e.Bytes() + num.exp.t.sign.Bytes() + num.exp.t.num.Bytes()));
                writer.Bytes() + num.minus.Bytes() + num.num.Bytes() + num.frac.t.period.Bytes() + num.frac.t.num.Bytes() + num.exp.t.e.Bytes() + num.exp.t.sign.Bytes() + num.exp.t.num.Bytes();
              }
            } else {
              calc {
                writer.Bytes() + Spec.Number(num);
                {
                  NumberHelper2a(num, writer);
                }
                writer.Bytes() + (num.minus.Bytes() + num.num.Bytes() + Spec.Maybe(num.frac, Spec.Frac) + Spec.Maybe(num.exp, Spec.Exp));
                writer.Bytes() + num.minus.Bytes() + num.num.Bytes() + (Spec.Maybe(num.frac, Spec.Frac) + Spec.Maybe(num.exp, Spec.Exp));
                {
                  assert Spec.Maybe(num.frac, Spec.Frac) == [];
                  assert Spec.Maybe(num.exp, Spec.Exp) == Spec.Exp(num.exp.t);
                }
                writer.Bytes() + num.minus.Bytes() + num.num.Bytes() + ([] + Spec.Exp(num.exp.t));
                {
                  assert [] + Spec.Exp(num.exp.t) == Spec.Exp(num.exp.t);
                }
                writer.Bytes() + num.minus.Bytes() + num.num.Bytes() + Spec.Exp(num.exp.t);
                {
                  assert Spec.Exp(num.exp.t) == num.exp.t.e.Bytes() + num.exp.t.sign.Bytes() + num.exp.t.num.Bytes();
                }
                writer.Bytes() + num.minus.Bytes() + num.num.Bytes() + (num.exp.t.e.Bytes() + num.exp.t.sign.Bytes() + num.exp.t.num.Bytes());
                writer.Bytes() + num.minus.Bytes() + num.num.Bytes() + num.exp.t.e.Bytes() + num.exp.t.sign.Bytes() + num.exp.t.num.Bytes();
              }
            }
          } else {
            if num.frac.NonEmpty? {
              calc {
                writer.Bytes() + Spec.Number(num);
                {
                  NumberHelper2a(num, writer);
                }
                writer.Bytes() + (num.minus.Bytes() + num.num.Bytes() + Spec.Maybe(num.frac, Spec.Frac) + Spec.Maybe(num.exp, Spec.Exp));
                writer.Bytes() + num.minus.Bytes() + num.num.Bytes() + (Spec.Maybe(num.frac, Spec.Frac) + Spec.Maybe(num.exp, Spec.Exp));
                {
                  assert Spec.Maybe(num.exp, Spec.Exp) == [];
                  assert Spec.Maybe(num.frac, Spec.Frac) == Spec.Frac(num.frac.t);
                }
                writer.Bytes() + num.minus.Bytes() + num.num.Bytes() + (Spec.Frac(num.frac.t) + []);
                writer.Bytes() + num.minus.Bytes() + num.num.Bytes() + Spec.Frac(num.frac.t);
                {
                  assert Spec.Frac(num.frac.t) == num.frac.t.period.Bytes() + num.frac.t.num.Bytes();
                }
                writer.Bytes() + num.minus.Bytes() + num.num.Bytes() + num.frac.t.period.Bytes() + num.frac.t.num.Bytes();
              }
            } else {
              calc {
                writer.Bytes() + Spec.Number(num);
                {
                  NumberHelper2a(num, writer);
                }
                writer.Bytes() + (num.minus.Bytes() + num.num.Bytes() + Spec.Maybe(num.frac, Spec.Frac) + Spec.Maybe(num.exp, Spec.Exp));
                {
                  assert Spec.Maybe(num.frac, Spec.Frac) == [];
                  assert Spec.Maybe(num.exp, Spec.Exp) == [];
                }
                writer.Bytes() + num.minus.Bytes() + num.num.Bytes() + [] + [];
                writer.Bytes() + num.minus.Bytes() + num.num.Bytes();
              }
            }
          }
        }

        opaque function {:isolate_assertions} Number(num: jnumber, writer: Writer): (wr: Writer)
          ensures wr.Bytes() == writer.Bytes() + Spec.Number(num)
          decreases num, 0
        {
          var wr1: Writer := writer.Append(num.minus).Append(num.num);
          var wr2: Writer_ := if num.frac.NonEmpty? then wr1.Append(num.frac.t.period).Append(num.frac.t.num) else wr1;
          var wr3: Writer_ := if num.exp.NonEmpty? then wr2.Append(num.exp.t.e).Append(num.exp.t.sign).Append(num.exp.t.num) else wr2;
          var wr: Writer_ := wr3;
          calc {
            wr.Bytes();
            {
              assert wr == wr3;
            }
            wr3.Bytes();
            {
              assert wr3 == if num.exp.NonEmpty? then wr2.Append(num.exp.t.e).Append(num.exp.t.sign).Append(num.exp.t.num) else wr2;
            }
            if num.exp.NonEmpty? then wr2.Append(num.exp.t.e).Append(num.exp.t.sign).Append(num.exp.t.num).Bytes() else wr2.Bytes();
            {
              assert wr2 == if num.frac.NonEmpty? then wr1.Append(num.frac.t.period).Append(num.frac.t.num) else wr1;
            }
            if num.exp.NonEmpty? then if num.frac.NonEmpty? then wr1.Append(num.frac.t.period).Append(num.frac.t.num).Append(num.exp.t.e).Append(num.exp.t.sign).Append(num.exp.t.num).Bytes() else wr1.Append(num.exp.t.e).Append(num.exp.t.sign).Append(num.exp.t.num).Bytes() else if num.frac.NonEmpty? then wr1.Append(num.frac.t.period).Append(num.frac.t.num).Bytes() else wr1.Bytes();
            {
              assert wr1 == writer.Append(num.minus).Append(num.num);
            }
            if num.exp.NonEmpty? then if num.frac.NonEmpty? then writer.Append(num.minus).Append(num.num).Append(num.frac.t.period).Append(num.frac.t.num).Append(num.exp.t.e).Append(num.exp.t.sign).Append(num.exp.t.num).Bytes() else writer.Append(num.minus).Append(num.num).Append(num.exp.t.e).Append(num.exp.t.sign).Append(num.exp.t.num).Bytes() else if num.frac.NonEmpty? then writer.Append(num.minus).Append(num.num).Append(num.frac.t.period).Append(num.frac.t.num).Bytes() else writer.Append(num.minus).Append(num.num).Bytes();
            {
              NumberHelper1(num, writer);
            }
            if num.exp.NonEmpty? then if num.frac.NonEmpty? then writer.Bytes() + num.minus.Bytes() + num.num.Bytes() + num.frac.t.period.Bytes() + num.frac.t.num.Bytes() + num.exp.t.e.Bytes() + num.exp.t.sign.Bytes() + num.exp.t.num.Bytes() else writer.Bytes() + num.minus.Bytes() + num.num.Bytes() + num.exp.t.e.Bytes() + num.exp.t.sign.Bytes() + num.exp.t.num.Bytes() else if num.frac.NonEmpty? then writer.Bytes() + num.minus.Bytes() + num.num.Bytes() + num.frac.t.period.Bytes() + num.frac.t.num.Bytes() else writer.Bytes() + num.minus.Bytes() + num.num.Bytes();
            {
              NumberHelper2(num, writer);
            }
            if num.exp.NonEmpty? then if num.frac.NonEmpty? then writer.Bytes() + Spec.Number(num) else writer.Bytes() + Spec.Number(num) else if num.frac.NonEmpty? then writer.Bytes() + Spec.Number(num) else writer.Bytes() + Spec.Number(num);
            writer.Bytes() + Spec.Number(num);
          }
          wr
        }

        function {:isolate_assertions} StructuralView(st: Structural<View>, writer: Writer): (wr: Writer)
          ensures wr.Bytes() == writer.Bytes() + Spec.Structural(st, Spec.View)
          decreases st, writer
        {
          writer.Append(st.before).Append(st.t).Append(st.after)
        }

        lemma StructuralViewEns(st: Structural<View>, writer: Writer)
          ensures StructuralView(st, writer).Bytes() == writer.Bytes() + Spec.Structural(st, Spec.View)
          decreases st, writer
        {
        }

        lemma /*{:_induction obj}*/ BracketedToObject(obj: jobject)
          ensures Spec.Bracketed(obj, Spec.Member) == Spec.Object(obj)
          decreases obj
        {
          ghost var rMember := (d: jmember) requires d < obj => Spec.Member(d);
          assert Spec.Bracketed(obj, Spec.Member) == Spec.Bracketed(obj, rMember) by {
            assert SpecProperties.Bracketed_Morphism_Requires(obj, Spec.Member, rMember);
            SpecProperties.Bracketed_Morphism(obj, Spec.Member, rMember);
          }
          calc {
            Spec.Bracketed(obj, Spec.Member);
            Spec.Bracketed(obj, rMember);
            Spec.Object(obj);
          }
        }

        opaque function Object(obj: jobject, writer: Writer): (wr: Writer)
          ensures wr.Bytes() == writer.Bytes() + Spec.Object(obj)
          decreases obj, 3
        {
          var wr: Writer := StructuralView(obj.l, writer);
          StructuralViewEns(obj.l, writer);
          var wr: Writer := Members(obj, wr);
          var wr: Writer := StructuralView(obj.r, wr);
          Seq.LemmaConcatIsAssociative2(writer.Bytes(), Spec.Structural<View>(obj.l, Spec.View), Spec.ConcatBytes(obj.data, Spec.Member), Spec.Structural<View>(obj.r, Spec.View));
          assert wr.Bytes() == writer.Bytes() + Spec.Bracketed(obj, Spec.Member);
          assert Spec.Bracketed(obj, Spec.Member) == Spec.Object(obj) by {
            BracketedToObject(obj);
          }
          wr
        }

        lemma /*{:_induction arr}*/ BracketedToArray(arr: jarray)
          ensures Spec.Bracketed(arr, Spec.Item) == Spec.Array(arr)
          decreases arr
        {
          ghost var rItem := (d: jitem) requires d < arr => Spec.Item(d);
          assert Spec.Bracketed(arr, Spec.Item) == Spec.Bracketed(arr, rItem) by {
            assert SpecProperties.Bracketed_Morphism_Requires(arr, Spec.Item, rItem);
            SpecProperties.Bracketed_Morphism(arr, Spec.Item, rItem);
          }
          calc {
            Spec.Bracketed(arr, Spec.Item);
            Spec.Bracketed(arr, rItem);
            Spec.Array(arr);
          }
        }

        opaque function Array(arr: jarray, writer: Writer): (wr: Writer)
          ensures wr.Bytes() == writer.Bytes() + Spec.Array(arr)
          decreases arr, 3
        {
          var wr: Writer := StructuralView(arr.l, writer);
          StructuralViewEns(arr.l, writer);
          var wr: Writer := Items(arr, wr);
          var wr: Writer := StructuralView(arr.r, wr);
          Seq.LemmaConcatIsAssociative2(writer.Bytes(), Spec.Structural<View>(arr.l, Spec.View), Spec.ConcatBytes(arr.data, Spec.Item), Spec.Structural<View>(arr.r, Spec.View));
          assert wr.Bytes() == writer.Bytes() + Spec.Bracketed(arr, Spec.Item);
          assert Spec.Bracketed(arr, Spec.Item) == Spec.Array(arr) by {
            BracketedToArray(arr);
          }
          wr
        }

        opaque function Members(obj: jobject, writer: Writer): (wr: Writer)
          ensures wr.Bytes() == writer.Bytes() + Spec.ConcatBytes(obj.data, Spec.Member)
          decreases obj, 2
        {
          MembersSpec(obj, obj.data, writer)
        } by method {
          assume {:axiom} false;
          wr := MembersImpl(obj, writer);
        }

        opaque function Items(arr: jarray, writer: Writer): (wr: Writer)
          ensures wr.Bytes() == writer.Bytes() + Spec.ConcatBytes(arr.data, Spec.Item)
          decreases arr, 2
        {
          ItemsSpec(arr, arr.data, writer)
        } by method {
          assume {:axiom} false;
          wr := ItemsImpl(arr, writer);
        }

        ghost function MembersSpec(obj: jobject, members: seq<jmember>, writer: Writer): (wr: Writer)
          requires forall j: int {:trigger members[j]} | 0 <= j < |members| :: members[j] < obj
          ensures wr.Bytes() == writer.Bytes() + Spec.ConcatBytes(members, Spec.Member)
          decreases obj, 1, members
        {
          if members == [] then
            writer
          else
            ghost var butLast: seq<Suffixed<jKeyValue, jcomma>>, last: Suffixed<jKeyValue, jcomma> := members[..|members| - 1], members[|members| - 1]; assert members == butLast + [last]; ghost var wr: Writer := MembersSpec(obj, butLast, writer); ghost var wr: Writer := Member(obj, last, wr); assert wr.Bytes() == writer.Bytes() + (Spec.ConcatBytes(butLast, Spec.Member) + Spec.ConcatBytes([last], Spec.Member)) by {
    Seq.LemmaConcatIsAssociative(writer.Bytes(), Spec.ConcatBytes(butLast, Spec.Member), Spec.ConcatBytes([last], Spec.Member));
  } SpecProperties.ConcatBytes_Linear(butLast, [last], Spec.Member); wr
        }

        ghost predicate SequenceSpecRequiresHelper<T>(v: Value, items: seq<T>, spec: T -> bytes, impl: (Value, T, Writer) --> Writer, writer: Writer, item: T, wr: Writer)
          requires item in items
          decreases v, items, writer, wr
        {
          impl.requires(v, item, wr) &&
          impl(v, item, wr).Bytes() == wr.Bytes() + spec(item)
        }

        ghost predicate SequenceSpecRequires<T>(v: Value, items: seq<T>, spec: T -> bytes, impl: (Value, T, Writer) --> Writer, writer: Writer)
          decreases v, items, writer
        {
          forall item: T, wr: Writer {:trigger SequenceSpecRequiresHelper<T>(v, items, spec, impl, writer, item, wr)} | item in items :: 
            SequenceSpecRequiresHelper(v, items, spec, impl, writer, item, wr)
        }

        ghost function {:isolate_assertions} SequenceSpec<T>(v: Value, items: seq<T>, spec: T -> bytes, impl: (Value, T, Writer) --> Writer, writer: Writer): (wr: Writer)
          requires SequenceSpecRequires(v, items, spec, impl, writer)
          ensures wr.Bytes() == writer.Bytes() + Spec.ConcatBytes(items, spec)
          decreases v, 1, items
        {
          if items == [] then
            writer
          else
            assert SequenceSpecRequires(v, items[..|items| - 1], spec, impl, writer) by {
    assert forall item: T, wr: Writer {:trigger SequenceSpecRequiresHelper(v, items[..|items| - 1], spec, impl, writer, item, wr)} | item in items[..|items| - 1] :: SequenceSpecRequiresHelper(v, items[..|items| - 1], spec, impl, writer, item, wr) by {
      forall item: T, wr: Writer {:trigger SequenceSpecRequiresHelper(v, items[..|items| - 1], spec, impl, writer, item, wr)} | item in items[..|items| - 1]
        ensures SequenceSpecRequiresHelper(v, items[..|items| - 1], spec, impl, writer, item, wr)
      {
        assert item in items;
        assert SequenceSpecRequiresHelper(v, items, spec, impl, writer, item, wr);
      }
    }
  } ghost var writer': Writer := SequenceSpec(v, items[..|items| - 1], spec, impl, writer); assert impl.requires(v, items[|items| - 1], writer') by {
    assert SequenceSpecRequiresHelper(v, items, spec, impl, writer, items[|items| - 1], writer') by {
      assert SequenceSpecRequires(v, items, spec, impl, writer);
      assert items[|items| - 1] in items;
    }
  } ghost var wr: Writer := impl(v, items[|items| - 1], writer'); assert wr.Bytes() == writer.Bytes() + Spec.ConcatBytes(items, spec) by {
    calc {
      wr.Bytes();
      {
        assert wr == impl(v, items[|items| - 1], writer');
      }
      impl(v, items[|items| - 1], writer').Bytes();
      {
        assert SequenceSpecRequires(v, items, spec, impl, writer);
        assert items[|items| - 1] in items;
        assert SequenceSpecRequiresHelper(v, items, spec, impl, writer, items[|items| - 1], writer');
      }
      writer'.Bytes() + spec(items[|items| - 1]);
      {
        assert writer' == SequenceSpec(v, items[..|items| - 1], spec, impl, writer);
      }
      writer.Bytes() + Spec.ConcatBytes(items[..|items| - 1], spec) + spec(items[|items| - 1]);
      {
        assert spec(items[|items| - 1]) == Spec.ConcatBytes([items[|items| - 1]], spec);
      }
      writer.Bytes() + Spec.ConcatBytes(items[..|items| - 1], spec) + Spec.ConcatBytes([items[|items| - 1]], spec);
      {
        SpecProperties.ConcatBytes_Linear(items[..|items| - 1], [items[|items| - 1]], spec);
      }
      writer.Bytes() + Spec.ConcatBytes(items[..|items| - 1] + [items[|items| - 1]], spec);
      {
        assert items == items[..|items| - 1] + [items[|items| - 1]];
      }
      writer.Bytes() + Spec.ConcatBytes(items, spec);
    }
  } wr
        }

        ghost function ItemsSpec(arr: jarray, items: seq<jitem>, writer: Writer): (wr: Writer)
          requires forall j: int {:trigger items[j]} | 0 <= j < |items| :: items[j] < arr
          ensures wr.Bytes() == writer.Bytes() + Spec.ConcatBytes(items, Spec.Item)
          decreases arr, 1, items
        {
          if items == [] then
            writer
          else
            ghost var butLast: seq<Suffixed<Value, jcomma>>, last: Suffixed<Value, jcomma> := items[..|items| - 1], items[|items| - 1]; assert items == butLast + [last]; ghost var wr: Writer := ItemsSpec(arr, butLast, writer); ghost var wr: Writer := Item(arr, last, wr); assert wr.Bytes() == writer.Bytes() + (Spec.ConcatBytes(butLast, Spec.Item) + Spec.ConcatBytes([last], Spec.Item)) by {
    Seq.LemmaConcatIsAssociative(writer.Bytes(), Spec.ConcatBytes(butLast, Spec.Item), Spec.ConcatBytes([last], Spec.Item));
  } SpecProperties.ConcatBytes_Linear(butLast, [last], Spec.Item); wr
        }

        method {:resource_limit 10000000} MembersImpl(obj: jobject, writer: Writer) returns (wr: Writer)
          ensures wr == MembersSpec(obj, obj.data, writer)
          decreases obj, 1
        {
          wr := writer;
          var members := obj.data;
          assert wr == MembersSpec(obj, members[..0], writer);
          for i: int := 0 to |members|
            invariant wr == MembersSpec(obj, members[..i], writer)
          {
            assert members[..i + 1][..i] == members[..i];
            wr := Member(obj, members[i], wr);
          }
          assert members[..|members|] == members;
          assert wr == MembersSpec(obj, members, writer);
        }

        method {:isolate_assertions} ItemsImpl(arr: jarray, writer: Writer) returns (wr: Writer)
          ensures wr == ItemsSpec(arr, arr.data, writer)
          decreases arr, 1
        {
          wr := writer;
          var items := arr.data;
          assert wr == ItemsSpec(arr, items[..0], writer);
          for i: int := 0 to |items|
            invariant wr == ItemsSpec(arr, items[..i], writer)
          {
            assert items[..i + 1][..i] == items[..i] by {
              AboutList(items, i, i + 1);
            }
            wr := Item(arr, items[i], wr);
          }
          assert items[..|items|] == items;
        }

        lemma AboutList<T>(xs: seq<T>, i: nat, j: nat)
          requires i < j <= |xs|
          ensures xs[..j][..i] == xs[..i]
          decreases xs, i, j
        {
        }

        opaque function Member(ghost obj: jobject, m: jmember, writer: Writer): (wr: Writer)
          requires m < obj
          ensures wr.Bytes() == writer.Bytes() + Spec.Member(m)
          decreases obj, 0
        {
          var wr: Writer := String(m.t.k, writer);
          var wr: Writer := StructuralView(m.t.colon, wr);
          var wr: Writer := Value(m.t.v, wr);
          assert wr.Bytes() == writer.Bytes() + (Spec.String(m.t.k) + Spec.Structural<View>(m.t.colon, Spec.View) + Spec.Value(m.t.v)) by {
            Seq.LemmaConcatIsAssociative2(writer.Bytes(), Spec.String(m.t.k), Spec.Structural<View>(m.t.colon, Spec.View), Spec.Value(m.t.v));
          }
          var wr: Writer_ := if m.suffix.Empty? then wr else StructuralView(m.suffix.t, wr);
          assert wr.Bytes() == writer.Bytes() + Spec.KeyValue(m.t) + Spec.CommaSuffix(m.suffix) by {
            if m.suffix.Empty? {
              EmptySequenceIsRightIdentity(Spec.KeyValue(m.t));
              Seq.LemmaConcatIsAssociative(writer.Bytes(), Spec.KeyValue(m.t), []);
            } else {
              assert Spec.StructuralView(m.suffix.t) == Spec.CommaSuffix(m.suffix);
            }
          }
          assert wr.Bytes() == writer.Bytes() + (Spec.KeyValue(m.t) + Spec.CommaSuffix(m.suffix)) by {
            Seq.LemmaConcatIsAssociative(writer.Bytes(), Spec.KeyValue(m.t), Spec.CommaSuffix(m.suffix));
          }
          wr
        }

        opaque function Item(ghost arr: jarray, m: jitem, writer: Writer): (wr: Writer)
          requires m < arr
          ensures wr.Bytes() == writer.Bytes() + Spec.Item(m)
          decreases arr, 0
        {
          var wr: Writer := Value(m.t, writer);
          var wr: Writer_ := if m.suffix.Empty? then wr else StructuralView(m.suffix.t, wr);
          assert wr.Bytes() == writer.Bytes() + (Spec.Value(m.t) + Spec.CommaSuffix(m.suffix)) by {
            Seq.LemmaConcatIsAssociative(writer.Bytes(), Spec.Value(m.t), Spec.CommaSuffix(m.suffix));
          }
          wr
        }

        import Spec = ConcreteSyntax.Spec

        import SpecProperties = ConcreteSyntax.SpecProperties

        import opened BoundedInts

        import opened Wrappers

        import opened Seq = Collections.Seq

        import opened Errors

        import opened Grammar

        import opened Writers = Utils.Views.Writers

        import opened Vs = Utils.Views.Core
      }
    }
  }
}
")]

//-----------------------------------------------------------------------------
//
// Copyright by the contributors to the Dafny Project
// SPDX-License-Identifier: MIT
//
//-----------------------------------------------------------------------------

// When --include-runtime is true, this file is directly prepended
// to the output program. We have to avoid these using directives in that case
// since they can only appear before any other declarations.
// The DafnyRuntime.csproj file is the only place that ISDAFNYRUNTIMELIB is defined,
// so these are only active when building the C# DafnyRuntime.dll library.
#if ISDAFNYRUNTIMELIB
using System; // for Func
using System.Numerics;
using System.Collections;
#endif

namespace DafnyAssembly {
  [AttributeUsage(AttributeTargets.Assembly)]
  public class DafnySourceAttribute : Attribute {
    public readonly string dafnySourceText;
    public DafnySourceAttribute(string txt) { dafnySourceText = txt; }
  }
}

namespace Dafny {
  using System.Collections.Generic;
  using System.Collections.Immutable;
  using System.Linq;

  // Similar to System.Text.Rune, which would be perfect to use
  // except that it isn't available in the platforms we support
  // (.NET Standard 2.0 and .NET Framework 4.5.2)
  public readonly struct Rune : IComparable, IComparable<Rune>, IEquatable<Rune> {

    private readonly uint _value;

    public Rune(int value)
      : this((uint)value) {
    }

    public Rune(uint value) {
      if (!(value < 0xD800 || (0xE000 <= value && value < 0x11_0000))) {
        throw new ArgumentException();
      }

      _value = value;
    }

    public static bool IsRune(BigInteger i) {
      return (0 <= i && i < 0xD800) || (0xE000 <= i && i < 0x11_0000);
    }

    public int Value => (int)_value;

    public bool Equals(Rune other) => this == other;

    public override bool Equals(object obj) => (obj is Rune other) && Equals(other);

    public override int GetHashCode() => Value;

    // Values are always between 0 and 0x11_0000, so overflow isn't possible
    public int CompareTo(Rune other) => this.Value - other.Value;

    int IComparable.CompareTo(object obj) {
      switch (obj) {
        case null:
          return 1; // non-null ("this") always sorts after null
        case Rune other:
          return CompareTo(other);
        default:
          throw new ArgumentException();
      }
    }

    public static bool operator ==(Rune left, Rune right) => left._value == right._value;

    public static bool operator !=(Rune left, Rune right) => left._value != right._value;

    public static bool operator <(Rune left, Rune right) => left._value < right._value;

    public static bool operator <=(Rune left, Rune right) => left._value <= right._value;

    public static bool operator >(Rune left, Rune right) => left._value > right._value;

    public static bool operator >=(Rune left, Rune right) => left._value >= right._value;

    public static explicit operator Rune(int value) => new Rune(value);
    public static explicit operator Rune(BigInteger value) => new Rune((uint)value);

    // Defined this way to be consistent with System.Text.Rune,
    // but note that Dafny will use Helpers.ToString(rune),
    // which will print in the style of a character literal instead.
    public override string ToString() {
      return char.ConvertFromUtf32(Value);
    }

    // Replacement for String.EnumerateRunes() from newer platforms
    public static IEnumerable<Rune> Enumerate(string s) {
      var sLength = s.Length;
      for (var i = 0; i < sLength; i++) {
        if (char.IsHighSurrogate(s[i])) {
          if (char.IsLowSurrogate(s[i + 1])) {
            yield return (Rune)char.ConvertToUtf32(s[i], s[i + 1]);
            i++;
          } else {
            throw new ArgumentException();
          }
        } else if (char.IsLowSurrogate(s[i])) {
          throw new ArgumentException();
        } else {
          yield return (Rune)s[i];
        }
      }
    }
  }

  public interface ISet<out T> {
    int Count { get; }
    long LongCount { get; }
    IEnumerable<T> Elements { get; }
    IEnumerable<ISet<T>> AllSubsets { get; }
    bool Contains<G>(G t);
    bool EqualsAux(ISet<object> other);
    ISet<U> DowncastClone<U>(Func<T, U> converter);
  }

  public class Set<T> : ISet<T> {
    readonly ImmutableHashSet<T> setImpl;
    readonly bool containsNull;
    Set(ImmutableHashSet<T> d, bool containsNull) {
      this.setImpl = d;
      this.containsNull = containsNull;
    }

    public static readonly ISet<T> Empty = new Set<T>(ImmutableHashSet<T>.Empty, false);

    private static readonly TypeDescriptor<ISet<T>> _TYPE = new Dafny.TypeDescriptor<ISet<T>>(Empty);
    public static TypeDescriptor<ISet<T>> _TypeDescriptor() {
      return _TYPE;
    }

    public static ISet<T> FromElements(params T[] values) {
      return FromCollection(values);
    }

    public static Set<T> FromISet(ISet<T> s) {
      return s as Set<T> ?? FromCollection(s.Elements);
    }

    public static Set<T> FromCollection(IEnumerable<T> values) {
      var d = ImmutableHashSet<T>.Empty.ToBuilder();
      var containsNull = false;
      foreach (T t in values) {
        if (t == null) {
          containsNull = true;
        } else {
          d.Add(t);
        }
      }

      return new Set<T>(d.ToImmutable(), containsNull);
    }

    public static ISet<T> FromCollectionPlusOne(IEnumerable<T> values, T oneMoreValue) {
      var d = ImmutableHashSet<T>.Empty.ToBuilder();
      var containsNull = false;
      if (oneMoreValue == null) {
        containsNull = true;
      } else {
        d.Add(oneMoreValue);
      }

      foreach (T t in values) {
        if (t == null) {
          containsNull = true;
        } else {
          d.Add(t);
        }
      }

      return new Set<T>(d.ToImmutable(), containsNull);
    }

    public ISet<U> DowncastClone<U>(Func<T, U> converter) {
      if (this is ISet<U> th) {
        return th;
      } else {
        var d = ImmutableHashSet<U>.Empty.ToBuilder();
        foreach (var t in this.setImpl) {
          var u = converter(t);
          d.Add(u);
        }

        return new Set<U>(d.ToImmutable(), this.containsNull);
      }
    }

    public int Count {
      get { return this.setImpl.Count + (containsNull ? 1 : 0); }
    }

    public long LongCount {
      get { return this.setImpl.Count + (containsNull ? 1 : 0); }
    }

    public IEnumerable<T> Elements {
      get {
        if (containsNull) {
          yield return default(T);
        }

        foreach (var t in this.setImpl) {
          yield return t;
        }
      }
    }

    /// <summary>
    /// This is an inefficient iterator for producing all subsets of "this".
    /// </summary>
    public IEnumerable<ISet<T>> AllSubsets {
      get {
        // Start by putting all set elements into a list, but don't include null
        var elmts = new List<T>();
        elmts.AddRange(this.setImpl);
        var n = elmts.Count;
        var which = new bool[n];
        var s = ImmutableHashSet<T>.Empty.ToBuilder();
        while (true) {
          // yield both the subset without null and, if null is in the original set, the subset with null included
          var ihs = s.ToImmutable();
          yield return new Set<T>(ihs, false);
          if (containsNull) {
            yield return new Set<T>(ihs, true);
          }

          // "add 1" to "which", as if doing a carry chain.  For every digit changed, change the membership of the corresponding element in "s".
          int i = 0;
          for (; i < n && which[i]; i++) {
            which[i] = false;
            s.Remove(elmts[i]);
          }

          if (i == n) {
            // we have cycled through all the subsets
            break;
          }

          which[i] = true;
          s.Add(elmts[i]);
        }
      }
    }

    public bool Equals(ISet<T> other) {
      if (ReferenceEquals(this, other)) {
        return true;
      }

      if (other == null || Count != other.Count) {
        return false;
      }

      foreach (var elmt in Elements) {
        if (!other.Contains(elmt)) {
          return false;
        }
      }

      return true;
    }

    public override bool Equals(object other) {
      if (other is ISet<T>) {
        return Equals((ISet<T>)other);
      }

      var th = this as ISet<object>;
      var oth = other as ISet<object>;
      if (th != null && oth != null) {
        // We'd like to obtain the more specific type parameter U for oth's type ISet<U>.
        // We do that by making a dynamically dispatched call, like:
        //     oth.Equals(this)
        // The hope is then that its comparison "this is ISet<U>" (that is, the first "if" test
        // above, but in the call "oth.Equals(this)") will be true and the non-virtual Equals
        // can be called. However, such a recursive call to "oth.Equals(this)" could turn
        // into infinite recursion. Therefore, we instead call "oth.EqualsAux(this)", which
        // performs the desired type test, but doesn't recurse any further.
        return oth.EqualsAux(th);
      } else {
        return false;
      }
    }

    public bool EqualsAux(ISet<object> other) {
      var s = other as ISet<T>;
      if (s != null) {
        return Equals(s);
      } else {
        return false;
      }
    }

    public override int GetHashCode() {
      var hashCode = 1;
      if (containsNull) {
        hashCode = hashCode * (Dafny.Helpers.GetHashCode(default(T)) + 3);
      }

      foreach (var t in this.setImpl) {
        hashCode = hashCode * (Dafny.Helpers.GetHashCode(t) + 3);
      }

      return hashCode;
    }

    public override string ToString() {
      var s = "{";
      var sep = "";
      if (containsNull) {
        s += sep + Dafny.Helpers.ToString(default(T));
        sep = ", ";
      }

      foreach (var t in this.setImpl) {
        s += sep + Dafny.Helpers.ToString(t);
        sep = ", ";
      }

      return s + "}";
    }
    public static bool IsProperSubsetOf(ISet<T> th, ISet<T> other) {
      return th.Count < other.Count && IsSubsetOf(th, other);
    }
    public static bool IsSubsetOf(ISet<T> th, ISet<T> other) {
      if (other.Count < th.Count) {
        return false;
      }
      foreach (T t in th.Elements) {
        if (!other.Contains(t)) {
          return false;
        }
      }
      return true;
    }
    public static bool IsDisjointFrom(ISet<T> th, ISet<T> other) {
      ISet<T> a, b;
      if (th.Count < other.Count) {
        a = th; b = other;
      } else {
        a = other; b = th;
      }
      foreach (T t in a.Elements) {
        if (b.Contains(t)) {
          return false;
        }
      }
      return true;
    }
    public bool Contains<G>(G t) {
      return t == null ? containsNull : t is T && this.setImpl.Contains((T)(object)t);
    }
    public static ISet<T> Union(ISet<T> th, ISet<T> other) {
      var a = FromISet(th);
      var b = FromISet(other);
      return new Set<T>(a.setImpl.Union(b.setImpl), a.containsNull || b.containsNull);
    }
    public static ISet<T> Intersect(ISet<T> th, ISet<T> other) {
      var a = FromISet(th);
      var b = FromISet(other);
      return new Set<T>(a.setImpl.Intersect(b.setImpl), a.containsNull && b.containsNull);
    }
    public static ISet<T> Difference(ISet<T> th, ISet<T> other) {
      var a = FromISet(th);
      var b = FromISet(other);
      return new Set<T>(a.setImpl.Except(b.setImpl), a.containsNull && !b.containsNull);
    }
  }

  public interface IMultiSet<out T> {
    bool IsEmpty { get; }
    int Count { get; }
    long LongCount { get; }
    BigInteger ElementCount { get; }
    IEnumerable<T> Elements { get; }
    IEnumerable<T> UniqueElements { get; }
    bool Contains<G>(G t);
    BigInteger Select<G>(G t);
    IMultiSet<T> Update<G>(G t, BigInteger i);
    bool EqualsAux(IMultiSet<object> other);
    IMultiSet<U> DowncastClone<U>(Func<T, U> converter);
  }

  public class MultiSet<T> : IMultiSet<T> {
    readonly ImmutableDictionary<T, BigInteger> dict;
    readonly BigInteger occurrencesOfNull;  // stupidly, a Dictionary in .NET cannot use "null" as a key
    MultiSet(ImmutableDictionary<T, BigInteger>.Builder d, BigInteger occurrencesOfNull) {
      dict = d.ToImmutable();
      this.occurrencesOfNull = occurrencesOfNull;
    }
    public static readonly MultiSet<T> Empty = new MultiSet<T>(ImmutableDictionary<T, BigInteger>.Empty.ToBuilder(), BigInteger.Zero);

    private static readonly TypeDescriptor<IMultiSet<T>> _TYPE = new Dafny.TypeDescriptor<IMultiSet<T>>(Empty);
    public static TypeDescriptor<IMultiSet<T>> _TypeDescriptor() {
      return _TYPE;
    }

    public static MultiSet<T> FromIMultiSet(IMultiSet<T> s) {
      return s as MultiSet<T> ?? FromCollection(s.Elements);
    }
    public static MultiSet<T> FromElements(params T[] values) {
      var d = ImmutableDictionary<T, BigInteger>.Empty.ToBuilder();
      var occurrencesOfNull = BigInteger.Zero;
      foreach (T t in values) {
        if (t == null) {
          occurrencesOfNull++;
        } else {
          if (!d.TryGetValue(t, out var i)) {
            i = BigInteger.Zero;
          }
          d[t] = i + 1;
        }
      }
      return new MultiSet<T>(d, occurrencesOfNull);
    }

    public static MultiSet<T> FromCollection(IEnumerable<T> values) {
      var d = ImmutableDictionary<T, BigInteger>.Empty.ToBuilder();
      var occurrencesOfNull = BigInteger.Zero;
      foreach (T t in values) {
        if (t == null) {
          occurrencesOfNull++;
        } else {
          if (!d.TryGetValue(t,
                out var i)) {
            i = BigInteger.Zero;
          }

          d[t] = i + 1;
        }
      }

      return new MultiSet<T>(d,
        occurrencesOfNull);
    }

    public static MultiSet<T> FromSeq(ISequence<T> values) {
      var d = ImmutableDictionary<T, BigInteger>.Empty.ToBuilder();
      var occurrencesOfNull = BigInteger.Zero;
      foreach (var t in values) {
        if (t == null) {
          occurrencesOfNull++;
        } else {
          if (!d.TryGetValue(t,
                out var i)) {
            i = BigInteger.Zero;
          }

          d[t] = i + 1;
        }
      }

      return new MultiSet<T>(d,
        occurrencesOfNull);
    }
    public static MultiSet<T> FromSet(ISet<T> values) {
      var d = ImmutableDictionary<T, BigInteger>.Empty.ToBuilder();
      var containsNull = false;
      foreach (T t in values.Elements) {
        if (t == null) {
          containsNull = true;
        } else {
          d[t] = BigInteger.One;
        }
      }
      return new MultiSet<T>(d, containsNull ? BigInteger.One : BigInteger.Zero);
    }
    public IMultiSet<U> DowncastClone<U>(Func<T, U> converter) {
      if (this is IMultiSet<U> th) {
        return th;
      } else {
        var d = ImmutableDictionary<U, BigInteger>.Empty.ToBuilder();
        foreach (var item in this.dict) {
          var k = converter(item.Key);
          d.Add(k, item.Value);
        }
        return new MultiSet<U>(d, this.occurrencesOfNull);
      }
    }

    public bool Equals(IMultiSet<T> other) {
      return IsSubsetOf(this, other) && IsSubsetOf(other, this);
    }
    public override bool Equals(object other) {
      if (other is IMultiSet<T>) {
        return Equals((IMultiSet<T>)other);
      }
      var th = this as IMultiSet<object>;
      var oth = other as IMultiSet<object>;
      if (th != null && oth != null) {
        // See comment in Set.Equals
        return oth.EqualsAux(th);
      } else {
        return false;
      }
    }

    public bool EqualsAux(IMultiSet<object> other) {
      var s = other as IMultiSet<T>;
      if (s != null) {
        return Equals(s);
      } else {
        return false;
      }
    }

    public override int GetHashCode() {
      var hashCode = 1;
      if (occurrencesOfNull > 0) {
        var key = Dafny.Helpers.GetHashCode(default(T));
        key = (key << 3) | (key >> 29) ^ occurrencesOfNull.GetHashCode();
        hashCode = hashCode * (key + 3);
      }
      foreach (var kv in dict) {
        var key = Dafny.Helpers.GetHashCode(kv.Key);
        key = (key << 3) | (key >> 29) ^ kv.Value.GetHashCode();
        hashCode = hashCode * (key + 3);
      }
      return hashCode;
    }
    public override string ToString() {
      var s = "multiset{";
      var sep = "";
      for (var i = BigInteger.Zero; i < occurrencesOfNull; i++) {
        s += sep + Dafny.Helpers.ToString(default(T));
        sep = ", ";
      }
      foreach (var kv in dict) {
        var t = Dafny.Helpers.ToString(kv.Key);
        for (var i = BigInteger.Zero; i < kv.Value; i++) {
          s += sep + t;
          sep = ", ";
        }
      }
      return s + "}";
    }
    public static bool IsProperSubsetOf(IMultiSet<T> th, IMultiSet<T> other) {
      return th.Count < other.Count && IsSubsetOf(th, other);
    }
    public static bool IsSubsetOf(IMultiSet<T> th, IMultiSet<T> other) {
      var a = FromIMultiSet(th);
      var b = FromIMultiSet(other);
      if (b.occurrencesOfNull < a.occurrencesOfNull) {
        return false;
      }
      foreach (T t in a.dict.Keys) {
        if (b.dict.ContainsKey(t)) {
          if (b.dict[t] < a.dict[t]) {
            return false;
          }
        } else {
          if (a.dict[t] != BigInteger.Zero) {
            return false;
          }
        }
      }
      return true;
    }
    public static bool IsDisjointFrom(IMultiSet<T> th, IMultiSet<T> other) {
      foreach (T t in th.UniqueElements) {
        if (other.Contains(t)) {
          return false;
        }
      }
      return true;
    }

    public bool Contains<G>(G t) {
      return Select(t) != 0;
    }
    public BigInteger Select<G>(G t) {
      if (t == null) {
        return occurrencesOfNull;
      }

      if (t is T && dict.TryGetValue((T)(object)t, out var m)) {
        return m;
      } else {
        return BigInteger.Zero;
      }
    }
    public IMultiSet<T> Update<G>(G t, BigInteger i) {
      if (Select(t) == i) {
        return this;
      } else if (t == null) {
        var r = dict.ToBuilder();
        return new MultiSet<T>(r, i);
      } else {
        var r = dict.ToBuilder();
        r[(T)(object)t] = i;
        return new MultiSet<T>(r, occurrencesOfNull);
      }
    }
    public static IMultiSet<T> Union(IMultiSet<T> th, IMultiSet<T> other) {
      if (th.IsEmpty) {
        return other;
      } else if (other.IsEmpty) {
        return th;
      }
      var a = FromIMultiSet(th);
      var b = FromIMultiSet(other);
      var r = ImmutableDictionary<T, BigInteger>.Empty.ToBuilder();
      foreach (T t in a.dict.Keys) {
        if (!r.TryGetValue(t, out var i)) {
          i = BigInteger.Zero;
        }
        r[t] = i + a.dict[t];
      }
      foreach (T t in b.dict.Keys) {
        if (!r.TryGetValue(t, out var i)) {
          i = BigInteger.Zero;
        }
        r[t] = i + b.dict[t];
      }
      return new MultiSet<T>(r, a.occurrencesOfNull + b.occurrencesOfNull);
    }
    public static IMultiSet<T> Intersect(IMultiSet<T> th, IMultiSet<T> other) {
      if (th.IsEmpty) {
        return th;
      } else if (other.IsEmpty) {
        return other;
      }
      var a = FromIMultiSet(th);
      var b = FromIMultiSet(other);
      var r = ImmutableDictionary<T, BigInteger>.Empty.ToBuilder();
      foreach (T t in a.dict.Keys) {
        if (b.dict.ContainsKey(t)) {
          r.Add(t, a.dict[t] < b.dict[t] ? a.dict[t] : b.dict[t]);
        }
      }
      return new MultiSet<T>(r, a.occurrencesOfNull < b.occurrencesOfNull ? a.occurrencesOfNull : b.occurrencesOfNull);
    }
    public static IMultiSet<T> Difference(IMultiSet<T> th, IMultiSet<T> other) { // \result == this - other
      if (other.IsEmpty) {
        return th;
      }
      var a = FromIMultiSet(th);
      var b = FromIMultiSet(other);
      var r = ImmutableDictionary<T, BigInteger>.Empty.ToBuilder();
      foreach (T t in a.dict.Keys) {
        if (!b.dict.ContainsKey(t)) {
          r.Add(t, a.dict[t]);
        } else if (b.dict[t] < a.dict[t]) {
          r.Add(t, a.dict[t] - b.dict[t]);
        }
      }
      return new MultiSet<T>(r, b.occurrencesOfNull < a.occurrencesOfNull ? a.occurrencesOfNull - b.occurrencesOfNull : BigInteger.Zero);
    }

    public bool IsEmpty { get { return occurrencesOfNull == 0 && dict.IsEmpty; } }

    public int Count {
      get { return (int)ElementCount; }
    }
    public long LongCount {
      get { return (long)ElementCount; }
    }

    public BigInteger ElementCount {
      get {
        // This is inefficient
        var c = occurrencesOfNull;
        foreach (var item in dict) {
          c += item.Value;
        }
        return c;
      }
    }

    public IEnumerable<T> Elements {
      get {
        for (var i = BigInteger.Zero; i < occurrencesOfNull; i++) {
          yield return default(T);
        }
        foreach (var item in dict) {
          for (var i = BigInteger.Zero; i < item.Value; i++) {
            yield return item.Key;
          }
        }
      }
    }

    public IEnumerable<T> UniqueElements {
      get {
        if (!occurrencesOfNull.IsZero) {
          yield return default(T);
        }
        foreach (var key in dict.Keys) {
          if (dict[key] != 0) {
            yield return key;
          }
        }
      }
    }
  }

  public interface IMap<out U, out V> {
    int Count { get; }
    long LongCount { get; }
    ISet<U> Keys { get; }
    ISet<V> Values { get; }
    IEnumerable<IPair<U, V>> ItemEnumerable { get; }
    bool Contains<G>(G t);
    /// <summary>
    /// Returns "true" iff "this is IMap<object, object>" and "this" equals "other".
    /// </summary>
    bool EqualsObjObj(IMap<object, object> other);
    IMap<UU, VV> DowncastClone<UU, VV>(Func<U, UU> keyConverter, Func<V, VV> valueConverter);
  }

  public class Map<U, V> : IMap<U, V> {
    readonly ImmutableDictionary<U, V> dict;
    readonly bool hasNullKey;  // true when "null" is a key of the Map
    readonly V nullValue;  // if "hasNullKey", the value that "null" maps to

    private Map(ImmutableDictionary<U, V>.Builder d, bool hasNullKey, V nullValue) {
      dict = d.ToImmutable();
      this.hasNullKey = hasNullKey;
      this.nullValue = nullValue;
    }
    public static readonly Map<U, V> Empty = new Map<U, V>(ImmutableDictionary<U, V>.Empty.ToBuilder(), false, default(V));

    private Map(ImmutableDictionary<U, V> d, bool hasNullKey, V nullValue) {
      dict = d;
      this.hasNullKey = hasNullKey;
      this.nullValue = nullValue;
    }

    private static readonly TypeDescriptor<IMap<U, V>> _TYPE = new Dafny.TypeDescriptor<IMap<U, V>>(Empty);
    public static TypeDescriptor<IMap<U, V>> _TypeDescriptor() {
      return _TYPE;
    }

    public static Map<U, V> FromElements(params IPair<U, V>[] values) {
      var d = ImmutableDictionary<U, V>.Empty.ToBuilder();
      var hasNullKey = false;
      var nullValue = default(V);
      foreach (var p in values) {
        if (p.Car == null) {
          hasNullKey = true;
          nullValue = p.Cdr;
        } else {
          d[p.Car] = p.Cdr;
        }
      }
      return new Map<U, V>(d, hasNullKey, nullValue);
    }
    public static Map<U, V> FromCollection(IEnumerable<IPair<U, V>> values) {
      var d = ImmutableDictionary<U, V>.Empty.ToBuilder();
      var hasNullKey = false;
      var nullValue = default(V);
      foreach (var p in values) {
        if (p.Car == null) {
          hasNullKey = true;
          nullValue = p.Cdr;
        } else {
          d[p.Car] = p.Cdr;
        }
      }
      return new Map<U, V>(d, hasNullKey, nullValue);
    }
    public static Map<U, V> FromIMap(IMap<U, V> m) {
      return m as Map<U, V> ?? FromCollection(m.ItemEnumerable);
    }
    public IMap<UU, VV> DowncastClone<UU, VV>(Func<U, UU> keyConverter, Func<V, VV> valueConverter) {
      if (this is IMap<UU, VV> th) {
        return th;
      } else {
        var d = ImmutableDictionary<UU, VV>.Empty.ToBuilder();
        foreach (var item in this.dict) {
          var k = keyConverter(item.Key);
          var v = valueConverter(item.Value);
          d.Add(k, v);
        }
        return new Map<UU, VV>(d, this.hasNullKey, (VV)(object)this.nullValue);
      }
    }
    public int Count {
      get { return dict.Count + (hasNullKey ? 1 : 0); }
    }
    public long LongCount {
      get { return dict.Count + (hasNullKey ? 1 : 0); }
    }

    public bool Equals(IMap<U, V> other) {
      if (ReferenceEquals(this, other)) {
        return true;
      }

      if (other == null || LongCount != other.LongCount) {
        return false;
      }

      if (hasNullKey) {
        if (!other.Contains(default(U)) || !object.Equals(nullValue, Select(other, default(U)))) {
          return false;
        }
      }

      foreach (var item in dict) {
        if (!other.Contains(item.Key) || !object.Equals(item.Value, Select(other, item.Key))) {
          return false;
        }
      }
      return true;
    }
    public bool EqualsObjObj(IMap<object, object> other) {
      if (ReferenceEquals(this, other)) {
        return true;
      }
      if (!(this is IMap<object, object>) || other == null || LongCount != other.LongCount) {
        return false;
      }
      var oth = Map<object, object>.FromIMap(other);
      if (hasNullKey) {
        if (!oth.Contains(default(U)) || !object.Equals(nullValue, Map<object, object>.Select(oth, default(U)))) {
          return false;
        }
      }
      foreach (var item in dict) {
        if (!other.Contains(item.Key) || !object.Equals(item.Value, Map<object, object>.Select(oth, item.Key))) {
          return false;
        }
      }
      return true;
    }
    public override bool Equals(object other) {
      // See comment in Set.Equals
      var m = other as IMap<U, V>;
      if (m != null) {
        return Equals(m);
      }
      var imapoo = other as IMap<object, object>;
      if (imapoo != null) {
        return EqualsObjObj(imapoo);
      } else {
        return false;
      }
    }

    public override int GetHashCode() {
      var hashCode = 1;
      if (hasNullKey) {
        var key = Dafny.Helpers.GetHashCode(default(U));
        key = (key << 3) | (key >> 29) ^ Dafny.Helpers.GetHashCode(nullValue);
        hashCode = hashCode * (key + 3);
      }
      foreach (var kv in dict) {
        var key = Dafny.Helpers.GetHashCode(kv.Key);
        key = (key << 3) | (key >> 29) ^ Dafny.Helpers.GetHashCode(kv.Value);
        hashCode = hashCode * (key + 3);
      }
      return hashCode;
    }
    public override string ToString() {
      var s = "map[";
      var sep = "";
      if (hasNullKey) {
        s += sep + Dafny.Helpers.ToString(default(U)) + " := " + Dafny.Helpers.ToString(nullValue);
        sep = ", ";
      }
      foreach (var kv in dict) {
        s += sep + Dafny.Helpers.ToString(kv.Key) + " := " + Dafny.Helpers.ToString(kv.Value);
        sep = ", ";
      }
      return s + "]";
    }
    public bool Contains<G>(G u) {
      return u == null ? hasNullKey : u is U && dict.ContainsKey((U)(object)u);
    }
    public static V Select(IMap<U, V> th, U index) {
      // the following will throw an exception if "index" in not a key of the map
      var m = FromIMap(th);
      return index == null && m.hasNullKey ? m.nullValue : m.dict[index];
    }
    public static IMap<U, V> Update(IMap<U, V> th, U index, V val) {
      var m = FromIMap(th);
      var d = m.dict.ToBuilder();
      if (index == null) {
        return new Map<U, V>(d, true, val);
      } else {
        d[index] = val;
        return new Map<U, V>(d, m.hasNullKey, m.nullValue);
      }
    }

    public static IMap<U, V> Merge(IMap<U, V> th, IMap<U, V> other) {
      var a = FromIMap(th);
      var b = FromIMap(other);
      ImmutableDictionary<U, V> d = a.dict.SetItems(b.dict);
      return new Map<U, V>(d, a.hasNullKey || b.hasNullKey, b.hasNullKey ? b.nullValue : a.nullValue);
    }

    public static IMap<U, V> Subtract(IMap<U, V> th, ISet<U> keys) {
      var a = FromIMap(th);
      ImmutableDictionary<U, V> d = a.dict.RemoveRange(keys.Elements);
      return new Map<U, V>(d, a.hasNullKey && !keys.Contains<object>(null), a.nullValue);
    }

    public ISet<U> Keys {
      get {
        if (hasNullKey) {
          return Dafny.Set<U>.FromCollectionPlusOne(dict.Keys, default(U));
        } else {
          return Dafny.Set<U>.FromCollection(dict.Keys);
        }
      }
    }
    public ISet<V> Values {
      get {
        if (hasNullKey) {
          return Dafny.Set<V>.FromCollectionPlusOne(dict.Values, nullValue);
        } else {
          return Dafny.Set<V>.FromCollection(dict.Values);
        }
      }
    }

    public IEnumerable<IPair<U, V>> ItemEnumerable {
      get {
        if (hasNullKey) {
          yield return new Pair<U, V>(default(U), nullValue);
        }
        foreach (KeyValuePair<U, V> kvp in dict) {
          yield return new Pair<U, V>(kvp.Key, kvp.Value);
        }
      }
    }

    public static ISet<_System._ITuple2<U, V>> Items(IMap<U, V> m) {
      var result = new HashSet<_System._ITuple2<U, V>>();
      foreach (var item in m.ItemEnumerable) {
        result.Add(_System.Tuple2<U, V>.create(item.Car, item.Cdr));
      }
      return Dafny.Set<_System._ITuple2<U, V>>.FromCollection(result);
    }
  }

  public interface ISequence<out T> : IEnumerable<T> {
    long LongCount { get; }
    int Count { get; }
    [Obsolete("Use CloneAsArray() instead of Elements (both perform a copy).")]
    T[] Elements { get; }
    T[] CloneAsArray();
    IEnumerable<T> UniqueElements { get; }
    T Select(ulong index);
    T Select(long index);
    T Select(uint index);
    T Select(int index);
    T Select(BigInteger index);
    bool Contains<G>(G g);
    ISequence<T> Take(long m);
    ISequence<T> Take(ulong n);
    ISequence<T> Take(BigInteger n);
    ISequence<T> Drop(long m);
    ISequence<T> Drop(ulong n);
    ISequence<T> Drop(BigInteger n);
    ISequence<T> Subsequence(long lo, long hi);
    ISequence<T> Subsequence(long lo, ulong hi);
    ISequence<T> Subsequence(long lo, BigInteger hi);
    ISequence<T> Subsequence(ulong lo, long hi);
    ISequence<T> Subsequence(ulong lo, ulong hi);
    ISequence<T> Subsequence(ulong lo, BigInteger hi);
    ISequence<T> Subsequence(BigInteger lo, long hi);
    ISequence<T> Subsequence(BigInteger lo, ulong hi);
    ISequence<T> Subsequence(BigInteger lo, BigInteger hi);
    bool EqualsAux(ISequence<object> other);
    ISequence<U> DowncastClone<U>(Func<T, U> converter);
    string ToVerbatimString(bool asLiteral);
  }

  public abstract class Sequence<T> : ISequence<T> {
    public static readonly ISequence<T> Empty = new ArraySequence<T>(new T[0]);

    private static readonly TypeDescriptor<ISequence<T>> _TYPE = new Dafny.TypeDescriptor<ISequence<T>>(Empty);
    public static TypeDescriptor<ISequence<T>> _TypeDescriptor() {
      return _TYPE;
    }

    public static ISequence<T> Create(BigInteger length, System.Func<BigInteger, T> init) {
      var len = (int)length;
      var builder = ImmutableArray.CreateBuilder<T>(len);
      for (int i = 0; i < len; i++) {
        builder.Add(init(new BigInteger(i)));
      }
      return new ArraySequence<T>(builder.MoveToImmutable());
    }
    public static ISequence<T> FromArray(T[] values) {
      return new ArraySequence<T>(values);
    }
    public static ISequence<T> FromElements(params T[] values) {
      return new ArraySequence<T>(values);
    }
    public static ISequence<char> FromString(string s) {
      return new ArraySequence<char>(s.ToCharArray());
    }
    public static ISequence<Rune> UnicodeFromString(string s) {
      var runes = new List<Rune>();

      foreach (var rune in Rune.Enumerate(s)) {
        runes.Add(rune);
      }
      return new ArraySequence<Rune>(runes.ToArray());
    }

    public static ISequence<ISequence<char>> FromMainArguments(string[] args) {
      Dafny.ISequence<char>[] dafnyArgs = new Dafny.ISequence<char>[args.Length + 1];
      dafnyArgs[0] = Dafny.Sequence<char>.FromString("dotnet");
      for (var i = 0; i < args.Length; i++) {
        dafnyArgs[i + 1] = Dafny.Sequence<char>.FromString(args[i]);
      }

      return Sequence<ISequence<char>>.FromArray(dafnyArgs);
    }
    public static ISequence<ISequence<Rune>> UnicodeFromMainArguments(string[] args) {
      Dafny.ISequence<Rune>[] dafnyArgs = new Dafny.ISequence<Rune>[args.Length + 1];
      dafnyArgs[0] = Dafny.Sequence<Rune>.UnicodeFromString("dotnet");
      for (var i = 0; i < args.Length; i++) {
        dafnyArgs[i + 1] = Dafny.Sequence<Rune>.UnicodeFromString(args[i]);
      }

      return Sequence<ISequence<Rune>>.FromArray(dafnyArgs);
    }

    public ISequence<U> DowncastClone<U>(Func<T, U> converter) {
      if (this is ISequence<U> th) {
        return th;
      } else {
        var values = new U[this.LongCount];
        for (long i = 0; i < this.LongCount; i++) {
          var val = converter(this.Select(i));
          values[i] = val;
        }
        return new ArraySequence<U>(values);
      }
    }
    public static ISequence<T> Update(ISequence<T> sequence, long index, T t) {
      T[] tmp = sequence.CloneAsArray();
      tmp[index] = t;
      return new ArraySequence<T>(tmp);
    }
    public static ISequence<T> Update(ISequence<T> sequence, ulong index, T t) {
      return Update(sequence, (long)index, t);
    }
    public static ISequence<T> Update(ISequence<T> sequence, BigInteger index, T t) {
      return Update(sequence, (long)index, t);
    }
    public static bool EqualUntil(ISequence<T> left, ISequence<T> right, int n) {
      for (int i = 0; i < n; i++) {
        if (!Equals(left.Select(i), right.Select(i))) {
          return false;
        }
      }
      return true;
    }
    public static bool IsPrefixOf(ISequence<T> left, ISequence<T> right) {
      int n = left.Count;
      return n <= right.Count && EqualUntil(left, right, n);
    }
    public static bool IsProperPrefixOf(ISequence<T> left, ISequence<T> right) {
      int n = left.Count;
      return n < right.Count && EqualUntil(left, right, n);
    }
    public static ISequence<T> Concat(ISequence<T> left, ISequence<T> right) {
      if (left.Count == 0) {
        return right;
      }
      if (right.Count == 0) {
        return left;
      }
      return new ConcatSequence<T>(left, right);
    }
    // Make Count a public abstract instead of LongCount, since the "array size is limited to a total of 4 billion
    // elements, and to a maximum index of 0X7FEFFFFF". Therefore, as a protection, limit this to int32.
    // https://docs.microsoft.com/en-us/dotnet/api/system.array
    public abstract int Count { get; }
    public long LongCount {
      get { return Count; }
    }
    // ImmutableElements cannot be public in the interface since ImmutableArray<T> leads to a
    // "covariant type T occurs in invariant position" error. There do not appear to be interfaces for ImmutableArray<T>
    // that resolve this.
    internal abstract ImmutableArray<T> ImmutableElements { get; }

    public T[] Elements { get { return CloneAsArray(); } }

    public T[] CloneAsArray() {
      return ImmutableElements.ToArray();
    }

    public IEnumerable<T> UniqueElements {
      get {
        return Set<T>.FromCollection(ImmutableElements).Elements;
      }
    }

    public IEnumerator<T> GetEnumerator() {
      foreach (var el in ImmutableElements) {
        yield return el;
      }
    }

    IEnumerator IEnumerable.GetEnumerator() {
      return GetEnumerator();
    }

    public T Select(ulong index) {
      return ImmutableElements[checked((int)index)];
    }
    public T Select(long index) {
      return ImmutableElements[checked((int)index)];
    }
    public T Select(uint index) {
      return ImmutableElements[checked((int)index)];
    }
    public T Select(int index) {
      return ImmutableElements[index];
    }
    public T Select(BigInteger index) {
      return ImmutableElements[(int)index];
    }
    public bool Equals(ISequence<T> other) {
      return ReferenceEquals(this, other) || (Count == other.Count && EqualUntil(this, other, Count));
    }
    public override bool Equals(object other) {
      if (other is ISequence<T>) {
        return Equals((ISequence<T>)other);
      }
      var th = this as ISequence<object>;
      var oth = other as ISequence<object>;
      if (th != null && oth != null) {
        // see explanation in Set.Equals
        return oth.EqualsAux(th);
      } else {
        return false;
      }
    }
    public bool EqualsAux(ISequence<object> other) {
      var s = other as ISequence<T>;
      if (s != null) {
        return Equals(s);
      } else {
        return false;
      }
    }
    public override int GetHashCode() {
      ImmutableArray<T> elmts = ImmutableElements;
      // https://devblogs.microsoft.com/dotnet/please-welcome-immutablearrayt/
      if (elmts.IsDefaultOrEmpty) {
        return 0;
      }

      var hashCode = 0;
      for (var i = 0; i < elmts.Length; i++) {
        hashCode = (hashCode << 3) | (hashCode >> 29) ^ Dafny.Helpers.GetHashCode(elmts[i]);
      }
      return hashCode;
    }
    public override string ToString() {
      if (typeof(T) == typeof(char)) {
        return string.Concat(this);
      } else {
        return "[" + string.Join(", ", ImmutableElements.Select(Dafny.Helpers.ToString)) + "]";
      }
    }

    public string ToVerbatimString(bool asLiteral) {
      var builder = new System.Text.StringBuilder();
      if (asLiteral) {
        builder.Append('"');
      }
      foreach (var c in this) {
        var rune = (Rune)(object)c;
        if (asLiteral) {
          builder.Append(Helpers.EscapeCharacter(rune));
        } else {
          builder.Append(char.ConvertFromUtf32(rune.Value));
        }
      }
      if (asLiteral) {
        builder.Append('"');
      }
      return builder.ToString();
    }

    public bool Contains<G>(G g) {
      if (g == null || g is T) {
        var t = (T)(object)g;
        return ImmutableElements.Contains(t);
      }
      return false;
    }
    public ISequence<T> Take(long m) {
      return Subsequence(0, m);
    }
    public ISequence<T> Take(ulong n) {
      return Take((long)n);
    }
    public ISequence<T> Take(BigInteger n) {
      return Take((long)n);
    }
    public ISequence<T> Drop(long m) {
      return Subsequence(m, Count);
    }
    public ISequence<T> Drop(ulong n) {
      return Drop((long)n);
    }
    public ISequence<T> Drop(BigInteger n) {
      return Drop((long)n);
    }
    public ISequence<T> Subsequence(long lo, long hi) {
      if (lo == 0 && hi == Count) {
        return this;
      }
      int startingIndex = checked((int)lo);
      var length = checked((int)hi) - startingIndex;
      return new ArraySequence<T>(ImmutableArray.Create<T>(ImmutableElements, startingIndex, length));
    }
    public ISequence<T> Subsequence(long lo, ulong hi) {
      return Subsequence(lo, (long)hi);
    }
    public ISequence<T> Subsequence(long lo, BigInteger hi) {
      return Subsequence(lo, (long)hi);
    }
    public ISequence<T> Subsequence(ulong lo, long hi) {
      return Subsequence((long)lo, hi);
    }
    public ISequence<T> Subsequence(ulong lo, ulong hi) {
      return Subsequence((long)lo, (long)hi);
    }
    public ISequence<T> Subsequence(ulong lo, BigInteger hi) {
      return Subsequence((long)lo, (long)hi);
    }
    public ISequence<T> Subsequence(BigInteger lo, long hi) {
      return Subsequence((long)lo, hi);
    }
    public ISequence<T> Subsequence(BigInteger lo, ulong hi) {
      return Subsequence((long)lo, (long)hi);
    }
    public ISequence<T> Subsequence(BigInteger lo, BigInteger hi) {
      return Subsequence((long)lo, (long)hi);
    }
  }

  internal class ArraySequence<T> : Sequence<T> {
    private readonly ImmutableArray<T> elmts;

    internal ArraySequence(ImmutableArray<T> ee) {
      elmts = ee;
    }
    internal ArraySequence(T[] ee) {
      elmts = ImmutableArray.Create<T>(ee);
    }

    internal override ImmutableArray<T> ImmutableElements {
      get {
        return elmts;
      }
    }

    public override int Count {
      get {
        return elmts.Length;
      }
    }
  }

  internal class ConcatSequence<T> : Sequence<T> {
    // INVARIANT: Either left != null, right != null, and elmts's underlying array == null or
    // left == null, right == null, and elmts's underlying array != null
    internal volatile ISequence<T> left, right;
    internal ImmutableArray<T> elmts;
    private readonly int count;

    internal ConcatSequence(ISequence<T> left, ISequence<T> right) {
      this.left = left;
      this.right = right;
      this.count = left.Count + right.Count;
    }

    internal override ImmutableArray<T> ImmutableElements {
      get {
        // IsDefault returns true if the underlying array is a null reference
        // https://devblogs.microsoft.com/dotnet/please-welcome-immutablearrayt/
        if (elmts.IsDefault) {
          elmts = ComputeElements();
          // We don't need the original sequences anymore; let them be
          // garbage-collected
          left = null;
          right = null;
        }
        return elmts;
      }
    }

    public override int Count {
      get {
        return count;
      }
    }

    internal ImmutableArray<T> ComputeElements() {
      // Traverse the tree formed by all descendants which are ConcatSequences
      var ansBuilder = ImmutableArray.CreateBuilder<T>(count);
      var toVisit = new Stack<ISequence<T>>();
      var leftBuffer = left;
      var rightBuffer = right;
      if (left == null || right == null) {
        // elmts can't be .IsDefault while either left, or right are null
        return elmts;
      }
      toVisit.Push(rightBuffer);
      toVisit.Push(leftBuffer);

      while (toVisit.Count != 0) {
        var seq = toVisit.Pop();
        if (seq is ConcatSequence<T> cs && cs.elmts.IsDefault) {
          leftBuffer = cs.left;
          rightBuffer = cs.right;
          if (cs.left == null || cs.right == null) {
            // !cs.elmts.IsDefault, due to concurrent enumeration
            toVisit.Push(cs);
          } else {
            toVisit.Push(rightBuffer);
            toVisit.Push(leftBuffer);
          }
        } else {
          if (seq is Sequence<T> sq) {
            ansBuilder.AddRange(sq.ImmutableElements); // Optimized path for ImmutableArray
          } else {
            ansBuilder.AddRange(seq); // Slower path using IEnumerable
          }
        }
      }
      return ansBuilder.MoveToImmutable();
    }
  }

  public interface IPair<out A, out B> {
    A Car { get; }
    B Cdr { get; }
  }

  public class Pair<A, B> : IPair<A, B> {
    private A car;
    private B cdr;
    public A Car { get { return car; } }
    public B Cdr { get { return cdr; } }
    public Pair(A a, B b) {
      this.car = a;
      this.cdr = b;
    }
  }

  public class TypeDescriptor<T> {
    private readonly T initValue;
    public TypeDescriptor(T initValue) {
      this.initValue = initValue;
    }
    public T Default() {
      return initValue;
    }
  }

  public partial class Helpers {
    public static int GetHashCode<G>(G g) {
      return g == null ? 1001 : g.GetHashCode();
    }

    public static int ToIntChecked(BigInteger i, string msg) {
      if (i > Int32.MaxValue || i < Int32.MinValue) {
        if (msg == null) {
          msg = "value out of range for a 32-bit int";
        }

        throw new HaltException(msg + ": " + i);
      }
      return (int)i;
    }
    public static int ToIntChecked(long i, string msg) {
      if (i > Int32.MaxValue || i < Int32.MinValue) {
        if (msg == null) {
          msg = "value out of range for a 32-bit int";
        }

        throw new HaltException(msg + ": " + i);
      }
      return (int)i;
    }
    public static int ToIntChecked(int i, string msg) {
      return i;
    }

    public static string ToString<G>(G g) {
      if (g == null) {
        return "null";
      } else if (g is bool) {
        return (bool)(object)g ? "true" : "false";  // capitalize boolean literals like in Dafny
      } else if (g is Rune) {
        return "'" + EscapeCharacter((Rune)(object)g) + "'";
      } else {
        return g.ToString();
      }
    }

    public static string EscapeCharacter(Rune r) {
      switch (r.Value) {
        case '\n': return "\\n";
        case '\r': return "\\r";
        case '\t': return "\\t";
        case '\0': return "\\0";
        case '\'': return "\\'";
        case '\"': return "\\\"";
        case '\\': return "\\\\";
        default: return r.ToString();
      };
    }

    public static void Print<G>(G g) {
      System.Console.Write(ToString(g));
    }

    public static readonly TypeDescriptor<bool> BOOL = new TypeDescriptor<bool>(false);
    public static readonly TypeDescriptor<char> CHAR = new TypeDescriptor<char>('D');  // See CharType.DefaultValue in Dafny source code
    public static readonly TypeDescriptor<Rune> RUNE = new TypeDescriptor<Rune>(new Rune('D'));  // See CharType.DefaultValue in Dafny source code
    public static readonly TypeDescriptor<BigInteger> INT = new TypeDescriptor<BigInteger>(BigInteger.Zero);
    public static readonly TypeDescriptor<BigRational> REAL = new TypeDescriptor<BigRational>(BigRational.ZERO);
    public static readonly TypeDescriptor<byte> UINT8 = new TypeDescriptor<byte>(0);
    public static readonly TypeDescriptor<ushort> UINT16 = new TypeDescriptor<ushort>(0);
    public static readonly TypeDescriptor<uint> UINT32 = new TypeDescriptor<uint>(0);
    public static readonly TypeDescriptor<ulong> UINT64 = new TypeDescriptor<ulong>(0);

    public static TypeDescriptor<T> NULL<T>() where T : class {
      return new TypeDescriptor<T>(null);
    }

    public static TypeDescriptor<A[]> ARRAY<A>() {
      return new TypeDescriptor<A[]>(new A[0]);
    }

    public static bool Quantifier<T>(IEnumerable<T> vals, bool frall, System.Predicate<T> pred) {
      foreach (var u in vals) {
        if (pred(u) != frall) { return !frall; }
      }
      return frall;
    }
    // Enumerating other collections
    public static IEnumerable<bool> AllBooleans() {
      yield return false;
      yield return true;
    }
    public static IEnumerable<char> AllChars() {
      for (int i = 0; i < 0x1_0000; i++) {
        yield return (char)i;
      }
    }
    public static IEnumerable<Rune> AllUnicodeChars() {
      for (int i = 0; i < 0xD800; i++) {
        yield return new Rune(i);
      }
      for (int i = 0xE000; i < 0x11_0000; i++) {
        yield return new Rune(i);
      }
    }
    public static IEnumerable<BigInteger> AllIntegers() {
      yield return new BigInteger(0);
      for (var j = new BigInteger(1); ; j++) {
        yield return j;
        yield return -j;
      }
    }
    public static IEnumerable<BigInteger> IntegerRange(Nullable<BigInteger> lo, Nullable<BigInteger> hi) {
      if (lo == null) {
        for (var j = (BigInteger)hi; true;) {
          j--;
          yield return j;
        }
      } else if (hi == null) {
        for (var j = (BigInteger)lo; true; j++) {
          yield return j;
        }
      } else {
        for (var j = (BigInteger)lo; j < hi; j++) {
          yield return j;
        }
      }
    }
    public static IEnumerable<T> SingleValue<T>(T e) {
      yield return e;
    }
    // pre: b != 0
    // post: result == a/b, as defined by Euclidean Division (http://en.wikipedia.org/wiki/Modulo_operation)
    public static sbyte EuclideanDivision_sbyte(sbyte a, sbyte b) {
      return (sbyte)EuclideanDivision_int(a, b);
    }
    public static short EuclideanDivision_short(short a, short b) {
      return (short)EuclideanDivision_int(a, b);
    }
    public static int EuclideanDivision_int(int a, int b) {
      if (0 <= a) {
        if (0 <= b) {
          // +a +b: a/b
          return (int)(((uint)(a)) / ((uint)(b)));
        } else {
          // +a -b: -(a/(-b))
          return -((int)(((uint)(a)) / ((uint)(unchecked(-b)))));
        }
      } else {
        if (0 <= b) {
          // -a +b: -((-a-1)/b) - 1
          return -((int)(((uint)(-(a + 1))) / ((uint)(b)))) - 1;
        } else {
          // -a -b: ((-a-1)/(-b)) + 1
          return ((int)(((uint)(-(a + 1))) / ((uint)(unchecked(-b))))) + 1;
        }
      }
    }
    public static long EuclideanDivision_long(long a, long b) {
      if (0 <= a) {
        if (0 <= b) {
          // +a +b: a/b
          return (long)(((ulong)(a)) / ((ulong)(b)));
        } else {
          // +a -b: -(a/(-b))
          return -((long)(((ulong)(a)) / ((ulong)(unchecked(-b)))));
        }
      } else {
        if (0 <= b) {
          // -a +b: -((-a-1)/b) - 1
          return -((long)(((ulong)(-(a + 1))) / ((ulong)(b)))) - 1;
        } else {
          // -a -b: ((-a-1)/(-b)) + 1
          return ((long)(((ulong)(-(a + 1))) / ((ulong)(unchecked(-b))))) + 1;
        }
      }
    }
    public static BigInteger EuclideanDivision(BigInteger a, BigInteger b) {
      if (0 <= a.Sign) {
        if (0 <= b.Sign) {
          // +a +b: a/b
          return BigInteger.Divide(a, b);
        } else {
          // +a -b: -(a/(-b))
          return BigInteger.Negate(BigInteger.Divide(a, BigInteger.Negate(b)));
        }
      } else {
        if (0 <= b.Sign) {
          // -a +b: -((-a-1)/b) - 1
          return BigInteger.Negate(BigInteger.Divide(BigInteger.Negate(a) - 1, b)) - 1;
        } else {
          // -a -b: ((-a-1)/(-b)) + 1
          return BigInteger.Divide(BigInteger.Negate(a) - 1, BigInteger.Negate(b)) + 1;
        }
      }
    }
    // pre: b != 0
    // post: result == a%b, as defined by Euclidean Division (http://en.wikipedia.org/wiki/Modulo_operation)
    public static sbyte EuclideanModulus_sbyte(sbyte a, sbyte b) {
      return (sbyte)EuclideanModulus_int(a, b);
    }
    public static short EuclideanModulus_short(short a, short b) {
      return (short)EuclideanModulus_int(a, b);
    }
    public static int EuclideanModulus_int(int a, int b) {
      uint bp = (0 <= b) ? (uint)b : (uint)(unchecked(-b));
      if (0 <= a) {
        // +a: a % b'
        return (int)(((uint)a) % bp);
      } else {
        // c = ((-a) % b')
        // -a: b' - c if c > 0
        // -a: 0 if c == 0
        uint c = ((uint)(unchecked(-a))) % bp;
        return (int)(c == 0 ? c : bp - c);
      }
    }
    public static long EuclideanModulus_long(long a, long b) {
      ulong bp = (0 <= b) ? (ulong)b : (ulong)(unchecked(-b));
      if (0 <= a) {
        // +a: a % b'
        return (long)(((ulong)a) % bp);
      } else {
        // c = ((-a) % b')
        // -a: b' - c if c > 0
        // -a: 0 if c == 0
        ulong c = ((ulong)(unchecked(-a))) % bp;
        return (long)(c == 0 ? c : bp - c);
      }
    }
    public static BigInteger EuclideanModulus(BigInteger a, BigInteger b) {
      var bp = BigInteger.Abs(b);
      if (0 <= a.Sign) {
        // +a: a % b'
        return BigInteger.Remainder(a, bp);
      } else {
        // c = ((-a) % b')
        // -a: b' - c if c > 0
        // -a: 0 if c == 0
        var c = BigInteger.Remainder(BigInteger.Negate(a), bp);
        return c.IsZero ? c : BigInteger.Subtract(bp, c);
      }
    }

    public static U CastConverter<T, U>(T t) {
      return (U)(object)t;
    }

    public static Sequence<T> SeqFromArray<T>(T[] array) {
      return new ArraySequence<T>(array);
    }
    // In .NET version 4.5, it is possible to mark a method with "AggressiveInlining", which says to inline the
    // method if possible.  Method "ExpressionSequence" would be a good candidate for it:
    // [System.Runtime.CompilerServices.MethodImpl(System.Runtime.CompilerServices.MethodImplOptions.AggressiveInlining)]
    public static U ExpressionSequence<T, U>(T t, U u) {
      return u;
    }

    public static U Let<T, U>(T t, Func<T, U> f) {
      return f(t);
    }

    public static A Id<A>(A a) {
      return a;
    }

    public static void WithHaltHandling(Action action) {
      try {
        action();
      } catch (HaltException e) {
        Console.WriteLine("[Program halted] " + e.Message);
        // This is unfriendly given that Dafny's C# compiler will
        // invoke the compiled main method directly,
        // so we might be exiting the whole Dafny process here.
        // That's the best we can do until Dafny main methods support
        // a return value though (https://github.com/dafny-lang/dafny/issues/2699).
        // If we just set Environment.ExitCode here, the Dafny CLI
        // will just override that with 0.
        Environment.Exit(1);
      }
    }

    public static Rune AddRunes(Rune left, Rune right) {
      return (Rune)(left.Value + right.Value);
    }

    public static Rune SubtractRunes(Rune left, Rune right) {
      return (Rune)(left.Value - right.Value);
    }

    public static uint Bv32ShiftLeft(uint a, int amount) {
      return 32 <= amount ? 0 : a << amount;
    }
    public static ulong Bv64ShiftLeft(ulong a, int amount) {
      return 64 <= amount ? 0 : a << amount;
    }

    public static uint Bv32ShiftRight(uint a, int amount) {
      return 32 <= amount ? 0 : a >> amount;
    }
    public static ulong Bv64ShiftRight(ulong a, int amount) {
      return 64 <= amount ? 0 : a >> amount;
    }
  }

  public class BigOrdinal {
    public static bool IsLimit(BigInteger ord) {
      return ord == 0;
    }
    public static bool IsSucc(BigInteger ord) {
      return 0 < ord;
    }
    public static BigInteger Offset(BigInteger ord) {
      return ord;
    }
    public static bool IsNat(BigInteger ord) {
      return true;  // at run time, every ORDINAL is a natural number
    }
  }

  public struct BigRational {
    public static readonly BigRational ZERO = new BigRational(0);

    // We need to deal with the special case "num == 0 && den == 0", because
    // that's what C#'s default struct constructor will produce for BigRational. :(
    // To deal with it, we ignore "den" when "num" is 0.
    public readonly BigInteger num, den;  // invariant 1 <= den || (num == 0 && den == 0)

    public override string ToString() {
      if (num.IsZero || den.IsOne) {
        return string.Format("{0}.0", num);
      } else if (DividesAPowerOf10(den, out var factor, out var log10)) {
        var n = num * factor;
        string sign;
        string digits;
        if (n.Sign < 0) {
          sign = "-"; digits = (-n).ToString();
        } else {
          sign = ""; digits = n.ToString();
        }
        if (log10 < digits.Length) {
          var digitCount = digits.Length - log10;
          return string.Format("{0}{1}.{2}", sign, digits.Substring(0, digitCount), digits.Substring(digitCount));
        } else {
          return string.Format("{0}0.{1}{2}", sign, new string('0', log10 - digits.Length), digits);
        }
      } else {
        return string.Format("({0}.0 / {1}.0)", num, den);
      }
    }
    public static bool IsPowerOf10(BigInteger x, out int log10) {
      log10 = 0;
      if (x.IsZero) {
        return false;
      }
      while (true) {  // invariant: x != 0 && x * 10^log10 == old(x)
        if (x.IsOne) {
          return true;
        } else if (x % 10 == 0) {
          log10++;
          x /= 10;
        } else {
          return false;
        }
      }
    }
    /// <summary>
    /// If this method return true, then
    ///     10^log10 == factor * i
    /// Otherwise, factor and log10 should not be used.
    /// </summary>
    public static bool DividesAPowerOf10(BigInteger i, out BigInteger factor, out int log10) {
      factor = BigInteger.One;
      log10 = 0;
      if (i <= 0) {
        return false;
      }

      BigInteger ten = 10;
      BigInteger five = 5;
      BigInteger two = 2;

      // invariant: 1 <= i && i * 10^log10 == factor * old(i)
      while (i % ten == 0) {
        i /= ten;
        log10++;
      }

      while (i % five == 0) {
        i /= five;
        factor *= two;
        log10++;
      }
      while (i % two == 0) {
        i /= two;
        factor *= five;
        log10++;
      }

      return i == BigInteger.One;
    }

    public BigRational(int n) {
      num = new BigInteger(n);
      den = BigInteger.One;
    }
    public BigRational(uint n) {
      num = new BigInteger(n);
      den = BigInteger.One;
    }
    public BigRational(long n) {
      num = new BigInteger(n);
      den = BigInteger.One;
    }
    public BigRational(ulong n) {
      num = new BigInteger(n);
      den = BigInteger.One;
    }
    public BigRational(BigInteger n, BigInteger d) {
      // requires 1 <= d
      num = n;
      den = d;
    }
    /// <summary>
    /// Construct an exact rational representation of a double value.
    /// Throw an exception on NaN or infinite values. Does not support
    /// subnormal values, though it would be possible to extend it to.
    /// </summary>
    public BigRational(double n) {
      if (Double.IsNaN(n)) {
        throw new ArgumentException("Can't convert NaN to a rational.");
      }
      if (Double.IsInfinity(n)) {
        throw new ArgumentException(
          "Can't convert +/- infinity to a rational.");
      }

      // Double-specific values
      const int exptBias = 1023;
      const ulong signMask = 0x8000000000000000;
      const ulong exptMask = 0x7FF0000000000000;
      const ulong mantMask = 0x000FFFFFFFFFFFFF;
      const int mantBits = 52;
      ulong bits = BitConverter.ToUInt64(BitConverter.GetBytes(n), 0);

      // Generic conversion
      bool isNeg = (bits & signMask) != 0;
      int expt = ((int)((bits & exptMask) >> mantBits)) - exptBias;
      var mant = (bits & mantMask);

      if (expt == -exptBias && mant != 0) {
        throw new ArgumentException(
          "Can't convert a subnormal value to a rational (yet).");
      }

      var one = BigInteger.One;
      var negFactor = isNeg ? BigInteger.Negate(one) : one;
      var two = new BigInteger(2);
      var exptBI = BigInteger.Pow(two, Math.Abs(expt));
      var twoToMantBits = BigInteger.Pow(two, mantBits);
      var mantNum = negFactor * (twoToMantBits + new BigInteger(mant));
      if (expt == -exptBias && mant == 0) {
        num = den = 0;
      } else if (expt < 0) {
        num = mantNum;
        den = twoToMantBits * exptBI;
      } else {
        num = exptBI * mantNum;
        den = twoToMantBits;
      }
    }
    public BigInteger ToBigInteger() {
      if (num.IsZero || den.IsOne) {
        return num;
      } else if (0 < num.Sign) {
        return num / den;
      } else {
        return (num - den + 1) / den;
      }
    }

    public bool IsInteger() {
      var floored = new BigRational(this.ToBigInteger(), BigInteger.One);
      return this == floored;
    }

    /// <summary>
    /// Returns values such that aa/dd == a and bb/dd == b.
    /// </summary>
    private static void Normalize(BigRational a, BigRational b, out BigInteger aa, out BigInteger bb, out BigInteger dd) {
      if (a.num.IsZero) {
        aa = a.num;
        bb = b.num;
        dd = b.den;
      } else if (b.num.IsZero) {
        aa = a.num;
        dd = a.den;
        bb = b.num;
      } else {
        var gcd = BigInteger.GreatestCommonDivisor(a.den, b.den);
        var xx = a.den / gcd;
        var yy = b.den / gcd;
        // We now have a == a.num / (xx * gcd) and b == b.num / (yy * gcd).
        aa = a.num * yy;
        bb = b.num * xx;
        dd = a.den * yy;
      }
    }
    public int CompareTo(BigRational that) {
      // simple things first
      int asign = this.num.Sign;
      int bsign = that.num.Sign;
      if (asign < 0 && 0 <= bsign) {
        return -1;
      } else if (asign <= 0 && 0 < bsign) {
        return -1;
      } else if (bsign < 0 && 0 <= asign) {
        return 1;
      } else if (bsign <= 0 && 0 < asign) {
        return 1;
      }

      Normalize(this, that, out var aa, out var bb, out var dd);
      return aa.CompareTo(bb);
    }
    public int Sign {
      get {
        return num.Sign;
      }
    }
    public override int GetHashCode() {
      return num.GetHashCode() + 29 * den.GetHashCode();
    }
    public override bool Equals(object obj) {
      if (obj is BigRational) {
        return this == (BigRational)obj;
      } else {
        return false;
      }
    }
    public static bool operator ==(BigRational a, BigRational b) {
      return a.CompareTo(b) == 0;
    }
    public static bool operator !=(BigRational a, BigRational b) {
      return a.CompareTo(b) != 0;
    }
    public static bool operator >(BigRational a, BigRational b) {
      return a.CompareTo(b) > 0;
    }
    public static bool operator >=(BigRational a, BigRational b) {
      return a.CompareTo(b) >= 0;
    }
    public static bool operator <(BigRational a, BigRational b) {
      return a.CompareTo(b) < 0;
    }
    public static bool operator <=(BigRational a, BigRational b) {
      return a.CompareTo(b) <= 0;
    }
    public static BigRational operator +(BigRational a, BigRational b) {
      Normalize(a, b, out var aa, out var bb, out var dd);
      return new BigRational(aa + bb, dd);
    }
    public static BigRational operator -(BigRational a, BigRational b) {
      Normalize(a, b, out var aa, out var bb, out var dd);
      return new BigRational(aa - bb, dd);
    }
    public static BigRational operator -(BigRational a) {
      return new BigRational(-a.num, a.den);
    }
    public static BigRational operator *(BigRational a, BigRational b) {
      return new BigRational(a.num * b.num, a.den * b.den);
    }
    public static BigRational operator /(BigRational a, BigRational b) {
      // Compute the reciprocal of b
      BigRational bReciprocal;
      if (0 < b.num.Sign) {
        bReciprocal = new BigRational(b.den, b.num);
      } else {
        // this is the case b.num < 0
        bReciprocal = new BigRational(-b.den, -b.num);
      }
      return a * bReciprocal;
    }
  }

  public class HaltException : Exception {
    public HaltException(object message) : base(message.ToString()) {
    }
  }
}
// Dafny program systemModulePopulator.dfy compiled into C#
// To recompile, you will need the libraries
//     System.Runtime.Numerics.dll System.Collections.Immutable.dll
// but the 'dotnet' tool in net6.0 should pick those up automatically.
// Optionally, you may want to include compiler switches like
//     /debug /nowarn:162,164,168,183,219,436,1717,1718

#if ISDAFNYRUNTIMELIB
using System;
using System.Numerics;
using System.Collections;
#endif
#if ISDAFNYRUNTIMELIB
namespace Dafny {
  internal class ArrayHelpers {
    public static T[] InitNewArray1<T>(T z, BigInteger size0) {
      int s0 = (int)size0;
      T[] a = new T[s0];
      for (int i0 = 0; i0 < s0; i0++) {
        a[i0] = z;
      }
      return a;
    }
    public static T[,] InitNewArray2<T>(T z, BigInteger size0, BigInteger size1) {
      int s0 = (int)size0;
      int s1 = (int)size1;
      T[,] a = new T[s0,s1];
      for (int i0 = 0; i0 < s0; i0++) {
        for (int i1 = 0; i1 < s1; i1++) {
          a[i0,i1] = z;
        }
      }
      return a;
    }
    public static T[,,] InitNewArray3<T>(T z, BigInteger size0, BigInteger size1, BigInteger size2) {
      int s0 = (int)size0;
      int s1 = (int)size1;
      int s2 = (int)size2;
      T[,,] a = new T[s0,s1,s2];
      for (int i0 = 0; i0 < s0; i0++) {
        for (int i1 = 0; i1 < s1; i1++) {
          for (int i2 = 0; i2 < s2; i2++) {
            a[i0,i1,i2] = z;
          }
        }
      }
      return a;
    }
    public static T[,,,] InitNewArray4<T>(T z, BigInteger size0, BigInteger size1, BigInteger size2, BigInteger size3) {
      int s0 = (int)size0;
      int s1 = (int)size1;
      int s2 = (int)size2;
      int s3 = (int)size3;
      T[,,,] a = new T[s0,s1,s2,s3];
      for (int i0 = 0; i0 < s0; i0++) {
        for (int i1 = 0; i1 < s1; i1++) {
          for (int i2 = 0; i2 < s2; i2++) {
            for (int i3 = 0; i3 < s3; i3++) {
              a[i0,i1,i2,i3] = z;
            }
          }
        }
      }
      return a;
    }
    public static T[,,,,] InitNewArray5<T>(T z, BigInteger size0, BigInteger size1, BigInteger size2, BigInteger size3, BigInteger size4) {
      int s0 = (int)size0;
      int s1 = (int)size1;
      int s2 = (int)size2;
      int s3 = (int)size3;
      int s4 = (int)size4;
      T[,,,,] a = new T[s0,s1,s2,s3,s4];
      for (int i0 = 0; i0 < s0; i0++) {
        for (int i1 = 0; i1 < s1; i1++) {
          for (int i2 = 0; i2 < s2; i2++) {
            for (int i3 = 0; i3 < s3; i3++) {
              for (int i4 = 0; i4 < s4; i4++) {
                a[i0,i1,i2,i3,i4] = z;
              }
            }
          }
        }
      }
      return a;
    }
    public static T[,,,,,] InitNewArray6<T>(T z, BigInteger size0, BigInteger size1, BigInteger size2, BigInteger size3, BigInteger size4, BigInteger size5) {
      int s0 = (int)size0;
      int s1 = (int)size1;
      int s2 = (int)size2;
      int s3 = (int)size3;
      int s4 = (int)size4;
      int s5 = (int)size5;
      T[,,,,,] a = new T[s0,s1,s2,s3,s4,s5];
      for (int i0 = 0; i0 < s0; i0++) {
        for (int i1 = 0; i1 < s1; i1++) {
          for (int i2 = 0; i2 < s2; i2++) {
            for (int i3 = 0; i3 < s3; i3++) {
              for (int i4 = 0; i4 < s4; i4++) {
                for (int i5 = 0; i5 < s5; i5++) {
                  a[i0,i1,i2,i3,i4,i5] = z;
                }
              }
            }
          }
        }
      }
      return a;
    }
    public static T[,,,,,,] InitNewArray7<T>(T z, BigInteger size0, BigInteger size1, BigInteger size2, BigInteger size3, BigInteger size4, BigInteger size5, BigInteger size6) {
      int s0 = (int)size0;
      int s1 = (int)size1;
      int s2 = (int)size2;
      int s3 = (int)size3;
      int s4 = (int)size4;
      int s5 = (int)size5;
      int s6 = (int)size6;
      T[,,,,,,] a = new T[s0,s1,s2,s3,s4,s5,s6];
      for (int i0 = 0; i0 < s0; i0++) {
        for (int i1 = 0; i1 < s1; i1++) {
          for (int i2 = 0; i2 < s2; i2++) {
            for (int i3 = 0; i3 < s3; i3++) {
              for (int i4 = 0; i4 < s4; i4++) {
                for (int i5 = 0; i5 < s5; i5++) {
                  for (int i6 = 0; i6 < s6; i6++) {
                    a[i0,i1,i2,i3,i4,i5,i6] = z;
                  }
                }
              }
            }
          }
        }
      }
      return a;
    }
    public static T[,,,,,,,] InitNewArray8<T>(T z, BigInteger size0, BigInteger size1, BigInteger size2, BigInteger size3, BigInteger size4, BigInteger size5, BigInteger size6, BigInteger size7) {
      int s0 = (int)size0;
      int s1 = (int)size1;
      int s2 = (int)size2;
      int s3 = (int)size3;
      int s4 = (int)size4;
      int s5 = (int)size5;
      int s6 = (int)size6;
      int s7 = (int)size7;
      T[,,,,,,,] a = new T[s0,s1,s2,s3,s4,s5,s6,s7];
      for (int i0 = 0; i0 < s0; i0++) {
        for (int i1 = 0; i1 < s1; i1++) {
          for (int i2 = 0; i2 < s2; i2++) {
            for (int i3 = 0; i3 < s3; i3++) {
              for (int i4 = 0; i4 < s4; i4++) {
                for (int i5 = 0; i5 < s5; i5++) {
                  for (int i6 = 0; i6 < s6; i6++) {
                    for (int i7 = 0; i7 < s7; i7++) {
                      a[i0,i1,i2,i3,i4,i5,i6,i7] = z;
                    }
                  }
                }
              }
            }
          }
        }
      }
      return a;
    }
    public static T[,,,,,,,,] InitNewArray9<T>(T z, BigInteger size0, BigInteger size1, BigInteger size2, BigInteger size3, BigInteger size4, BigInteger size5, BigInteger size6, BigInteger size7, BigInteger size8) {
      int s0 = (int)size0;
      int s1 = (int)size1;
      int s2 = (int)size2;
      int s3 = (int)size3;
      int s4 = (int)size4;
      int s5 = (int)size5;
      int s6 = (int)size6;
      int s7 = (int)size7;
      int s8 = (int)size8;
      T[,,,,,,,,] a = new T[s0,s1,s2,s3,s4,s5,s6,s7,s8];
      for (int i0 = 0; i0 < s0; i0++) {
        for (int i1 = 0; i1 < s1; i1++) {
          for (int i2 = 0; i2 < s2; i2++) {
            for (int i3 = 0; i3 < s3; i3++) {
              for (int i4 = 0; i4 < s4; i4++) {
                for (int i5 = 0; i5 < s5; i5++) {
                  for (int i6 = 0; i6 < s6; i6++) {
                    for (int i7 = 0; i7 < s7; i7++) {
                      for (int i8 = 0; i8 < s8; i8++) {
                        a[i0,i1,i2,i3,i4,i5,i6,i7,i8] = z;
                      }
                    }
                  }
                }
              }
            }
          }
        }
      }
      return a;
    }
    public static T[,,,,,,,,,] InitNewArray10<T>(T z, BigInteger size0, BigInteger size1, BigInteger size2, BigInteger size3, BigInteger size4, BigInteger size5, BigInteger size6, BigInteger size7, BigInteger size8, BigInteger size9) {
      int s0 = (int)size0;
      int s1 = (int)size1;
      int s2 = (int)size2;
      int s3 = (int)size3;
      int s4 = (int)size4;
      int s5 = (int)size5;
      int s6 = (int)size6;
      int s7 = (int)size7;
      int s8 = (int)size8;
      int s9 = (int)size9;
      T[,,,,,,,,,] a = new T[s0,s1,s2,s3,s4,s5,s6,s7,s8,s9];
      for (int i0 = 0; i0 < s0; i0++) {
        for (int i1 = 0; i1 < s1; i1++) {
          for (int i2 = 0; i2 < s2; i2++) {
            for (int i3 = 0; i3 < s3; i3++) {
              for (int i4 = 0; i4 < s4; i4++) {
                for (int i5 = 0; i5 < s5; i5++) {
                  for (int i6 = 0; i6 < s6; i6++) {
                    for (int i7 = 0; i7 < s7; i7++) {
                      for (int i8 = 0; i8 < s8; i8++) {
                        for (int i9 = 0; i9 < s9; i9++) {
                          a[i0,i1,i2,i3,i4,i5,i6,i7,i8,i9] = z;
                        }
                      }
                    }
                  }
                }
              }
            }
          }
        }
      }
      return a;
    }
    public static T[,,,,,,,,,,] InitNewArray11<T>(T z, BigInteger size0, BigInteger size1, BigInteger size2, BigInteger size3, BigInteger size4, BigInteger size5, BigInteger size6, BigInteger size7, BigInteger size8, BigInteger size9, BigInteger size10) {
      int s0 = (int)size0;
      int s1 = (int)size1;
      int s2 = (int)size2;
      int s3 = (int)size3;
      int s4 = (int)size4;
      int s5 = (int)size5;
      int s6 = (int)size6;
      int s7 = (int)size7;
      int s8 = (int)size8;
      int s9 = (int)size9;
      int s10 = (int)size10;
      T[,,,,,,,,,,] a = new T[s0,s1,s2,s3,s4,s5,s6,s7,s8,s9,s10];
      for (int i0 = 0; i0 < s0; i0++) {
        for (int i1 = 0; i1 < s1; i1++) {
          for (int i2 = 0; i2 < s2; i2++) {
            for (int i3 = 0; i3 < s3; i3++) {
              for (int i4 = 0; i4 < s4; i4++) {
                for (int i5 = 0; i5 < s5; i5++) {
                  for (int i6 = 0; i6 < s6; i6++) {
                    for (int i7 = 0; i7 < s7; i7++) {
                      for (int i8 = 0; i8 < s8; i8++) {
                        for (int i9 = 0; i9 < s9; i9++) {
                          for (int i10 = 0; i10 < s10; i10++) {
                            a[i0,i1,i2,i3,i4,i5,i6,i7,i8,i9,i10] = z;
                          }
                        }
                      }
                    }
                  }
                }
              }
            }
          }
        }
      }
      return a;
    }
    public static T[,,,,,,,,,,,] InitNewArray12<T>(T z, BigInteger size0, BigInteger size1, BigInteger size2, BigInteger size3, BigInteger size4, BigInteger size5, BigInteger size6, BigInteger size7, BigInteger size8, BigInteger size9, BigInteger size10, BigInteger size11) {
      int s0 = (int)size0;
      int s1 = (int)size1;
      int s2 = (int)size2;
      int s3 = (int)size3;
      int s4 = (int)size4;
      int s5 = (int)size5;
      int s6 = (int)size6;
      int s7 = (int)size7;
      int s8 = (int)size8;
      int s9 = (int)size9;
      int s10 = (int)size10;
      int s11 = (int)size11;
      T[,,,,,,,,,,,] a = new T[s0,s1,s2,s3,s4,s5,s6,s7,s8,s9,s10,s11];
      for (int i0 = 0; i0 < s0; i0++) {
        for (int i1 = 0; i1 < s1; i1++) {
          for (int i2 = 0; i2 < s2; i2++) {
            for (int i3 = 0; i3 < s3; i3++) {
              for (int i4 = 0; i4 < s4; i4++) {
                for (int i5 = 0; i5 < s5; i5++) {
                  for (int i6 = 0; i6 < s6; i6++) {
                    for (int i7 = 0; i7 < s7; i7++) {
                      for (int i8 = 0; i8 < s8; i8++) {
                        for (int i9 = 0; i9 < s9; i9++) {
                          for (int i10 = 0; i10 < s10; i10++) {
                            for (int i11 = 0; i11 < s11; i11++) {
                              a[i0,i1,i2,i3,i4,i5,i6,i7,i8,i9,i10,i11] = z;
                            }
                          }
                        }
                      }
                    }
                  }
                }
              }
            }
          }
        }
      }
      return a;
    }
    public static T[,,,,,,,,,,,,] InitNewArray13<T>(T z, BigInteger size0, BigInteger size1, BigInteger size2, BigInteger size3, BigInteger size4, BigInteger size5, BigInteger size6, BigInteger size7, BigInteger size8, BigInteger size9, BigInteger size10, BigInteger size11, BigInteger size12) {
      int s0 = (int)size0;
      int s1 = (int)size1;
      int s2 = (int)size2;
      int s3 = (int)size3;
      int s4 = (int)size4;
      int s5 = (int)size5;
      int s6 = (int)size6;
      int s7 = (int)size7;
      int s8 = (int)size8;
      int s9 = (int)size9;
      int s10 = (int)size10;
      int s11 = (int)size11;
      int s12 = (int)size12;
      T[,,,,,,,,,,,,] a = new T[s0,s1,s2,s3,s4,s5,s6,s7,s8,s9,s10,s11,s12];
      for (int i0 = 0; i0 < s0; i0++) {
        for (int i1 = 0; i1 < s1; i1++) {
          for (int i2 = 0; i2 < s2; i2++) {
            for (int i3 = 0; i3 < s3; i3++) {
              for (int i4 = 0; i4 < s4; i4++) {
                for (int i5 = 0; i5 < s5; i5++) {
                  for (int i6 = 0; i6 < s6; i6++) {
                    for (int i7 = 0; i7 < s7; i7++) {
                      for (int i8 = 0; i8 < s8; i8++) {
                        for (int i9 = 0; i9 < s9; i9++) {
                          for (int i10 = 0; i10 < s10; i10++) {
                            for (int i11 = 0; i11 < s11; i11++) {
                              for (int i12 = 0; i12 < s12; i12++) {
                                a[i0,i1,i2,i3,i4,i5,i6,i7,i8,i9,i10,i11,i12] = z;
                              }
                            }
                          }
                        }
                      }
                    }
                  }
                }
              }
            }
          }
        }
      }
      return a;
    }
    public static T[,,,,,,,,,,,,,] InitNewArray14<T>(T z, BigInteger size0, BigInteger size1, BigInteger size2, BigInteger size3, BigInteger size4, BigInteger size5, BigInteger size6, BigInteger size7, BigInteger size8, BigInteger size9, BigInteger size10, BigInteger size11, BigInteger size12, BigInteger size13) {
      int s0 = (int)size0;
      int s1 = (int)size1;
      int s2 = (int)size2;
      int s3 = (int)size3;
      int s4 = (int)size4;
      int s5 = (int)size5;
      int s6 = (int)size6;
      int s7 = (int)size7;
      int s8 = (int)size8;
      int s9 = (int)size9;
      int s10 = (int)size10;
      int s11 = (int)size11;
      int s12 = (int)size12;
      int s13 = (int)size13;
      T[,,,,,,,,,,,,,] a = new T[s0,s1,s2,s3,s4,s5,s6,s7,s8,s9,s10,s11,s12,s13];
      for (int i0 = 0; i0 < s0; i0++) {
        for (int i1 = 0; i1 < s1; i1++) {
          for (int i2 = 0; i2 < s2; i2++) {
            for (int i3 = 0; i3 < s3; i3++) {
              for (int i4 = 0; i4 < s4; i4++) {
                for (int i5 = 0; i5 < s5; i5++) {
                  for (int i6 = 0; i6 < s6; i6++) {
                    for (int i7 = 0; i7 < s7; i7++) {
                      for (int i8 = 0; i8 < s8; i8++) {
                        for (int i9 = 0; i9 < s9; i9++) {
                          for (int i10 = 0; i10 < s10; i10++) {
                            for (int i11 = 0; i11 < s11; i11++) {
                              for (int i12 = 0; i12 < s12; i12++) {
                                for (int i13 = 0; i13 < s13; i13++) {
                                  a[i0,i1,i2,i3,i4,i5,i6,i7,i8,i9,i10,i11,i12,i13] = z;
                                }
                              }
                            }
                          }
                        }
                      }
                    }
                  }
                }
              }
            }
          }
        }
      }
      return a;
    }
    public static T[,,,,,,,,,,,,,,] InitNewArray15<T>(T z, BigInteger size0, BigInteger size1, BigInteger size2, BigInteger size3, BigInteger size4, BigInteger size5, BigInteger size6, BigInteger size7, BigInteger size8, BigInteger size9, BigInteger size10, BigInteger size11, BigInteger size12, BigInteger size13, BigInteger size14) {
      int s0 = (int)size0;
      int s1 = (int)size1;
      int s2 = (int)size2;
      int s3 = (int)size3;
      int s4 = (int)size4;
      int s5 = (int)size5;
      int s6 = (int)size6;
      int s7 = (int)size7;
      int s8 = (int)size8;
      int s9 = (int)size9;
      int s10 = (int)size10;
      int s11 = (int)size11;
      int s12 = (int)size12;
      int s13 = (int)size13;
      int s14 = (int)size14;
      T[,,,,,,,,,,,,,,] a = new T[s0,s1,s2,s3,s4,s5,s6,s7,s8,s9,s10,s11,s12,s13,s14];
      for (int i0 = 0; i0 < s0; i0++) {
        for (int i1 = 0; i1 < s1; i1++) {
          for (int i2 = 0; i2 < s2; i2++) {
            for (int i3 = 0; i3 < s3; i3++) {
              for (int i4 = 0; i4 < s4; i4++) {
                for (int i5 = 0; i5 < s5; i5++) {
                  for (int i6 = 0; i6 < s6; i6++) {
                    for (int i7 = 0; i7 < s7; i7++) {
                      for (int i8 = 0; i8 < s8; i8++) {
                        for (int i9 = 0; i9 < s9; i9++) {
                          for (int i10 = 0; i10 < s10; i10++) {
                            for (int i11 = 0; i11 < s11; i11++) {
                              for (int i12 = 0; i12 < s12; i12++) {
                                for (int i13 = 0; i13 < s13; i13++) {
                                  for (int i14 = 0; i14 < s14; i14++) {
                                    a[i0,i1,i2,i3,i4,i5,i6,i7,i8,i9,i10,i11,i12,i13,i14] = z;
                                  }
                                }
                              }
                            }
                          }
                        }
                      }
                    }
                  }
                }
              }
            }
          }
        }
      }
      return a;
    }
    public static T[,,,,,,,,,,,,,,,] InitNewArray16<T>(T z, BigInteger size0, BigInteger size1, BigInteger size2, BigInteger size3, BigInteger size4, BigInteger size5, BigInteger size6, BigInteger size7, BigInteger size8, BigInteger size9, BigInteger size10, BigInteger size11, BigInteger size12, BigInteger size13, BigInteger size14, BigInteger size15) {
      int s0 = (int)size0;
      int s1 = (int)size1;
      int s2 = (int)size2;
      int s3 = (int)size3;
      int s4 = (int)size4;
      int s5 = (int)size5;
      int s6 = (int)size6;
      int s7 = (int)size7;
      int s8 = (int)size8;
      int s9 = (int)size9;
      int s10 = (int)size10;
      int s11 = (int)size11;
      int s12 = (int)size12;
      int s13 = (int)size13;
      int s14 = (int)size14;
      int s15 = (int)size15;
      T[,,,,,,,,,,,,,,,] a = new T[s0,s1,s2,s3,s4,s5,s6,s7,s8,s9,s10,s11,s12,s13,s14,s15];
      for (int i0 = 0; i0 < s0; i0++) {
        for (int i1 = 0; i1 < s1; i1++) {
          for (int i2 = 0; i2 < s2; i2++) {
            for (int i3 = 0; i3 < s3; i3++) {
              for (int i4 = 0; i4 < s4; i4++) {
                for (int i5 = 0; i5 < s5; i5++) {
                  for (int i6 = 0; i6 < s6; i6++) {
                    for (int i7 = 0; i7 < s7; i7++) {
                      for (int i8 = 0; i8 < s8; i8++) {
                        for (int i9 = 0; i9 < s9; i9++) {
                          for (int i10 = 0; i10 < s10; i10++) {
                            for (int i11 = 0; i11 < s11; i11++) {
                              for (int i12 = 0; i12 < s12; i12++) {
                                for (int i13 = 0; i13 < s13; i13++) {
                                  for (int i14 = 0; i14 < s14; i14++) {
                                    for (int i15 = 0; i15 < s15; i15++) {
                                      a[i0,i1,i2,i3,i4,i5,i6,i7,i8,i9,i10,i11,i12,i13,i14,i15] = z;
                                    }
                                  }
                                }
                              }
                            }
                          }
                        }
                      }
                    }
                  }
                }
              }
            }
          }
        }
      }
      return a;
    }
  }
} // end of namespace Dafny
internal static class FuncExtensions {
  public static Func<U, UResult> DowncastClone<T, TResult, U, UResult>(this Func<T, TResult> F, Func<U, T> ArgConv, Func<TResult, UResult> ResConv) {
    return arg => ResConv(F(ArgConv(arg)));
  }
  public static Func<UResult> DowncastClone<TResult, UResult>(this Func<TResult> F, Func<TResult, UResult> ResConv) {
    return () => ResConv(F());
  }
  public static Func<U1, U2, UResult> DowncastClone<T1, T2, TResult, U1, U2, UResult>(this Func<T1, T2, TResult> F, Func<U1, T1> ArgConv1, Func<U2, T2> ArgConv2, Func<TResult, UResult> ResConv) {
    return (arg1, arg2) => ResConv(F(ArgConv1(arg1), ArgConv2(arg2)));
  }
  public static Func<U1, U2, U3, UResult> DowncastClone<T1, T2, T3, TResult, U1, U2, U3, UResult>(this Func<T1, T2, T3, TResult> F, Func<U1, T1> ArgConv1, Func<U2, T2> ArgConv2, Func<U3, T3> ArgConv3, Func<TResult, UResult> ResConv) {
    return (arg1, arg2, arg3) => ResConv(F(ArgConv1(arg1), ArgConv2(arg2), ArgConv3(arg3)));
  }
  public static Func<U1, U2, U3, U4, UResult> DowncastClone<T1, T2, T3, T4, TResult, U1, U2, U3, U4, UResult>(this Func<T1, T2, T3, T4, TResult> F, Func<U1, T1> ArgConv1, Func<U2, T2> ArgConv2, Func<U3, T3> ArgConv3, Func<U4, T4> ArgConv4, Func<TResult, UResult> ResConv) {
    return (arg1, arg2, arg3, arg4) => ResConv(F(ArgConv1(arg1), ArgConv2(arg2), ArgConv3(arg3), ArgConv4(arg4)));
  }
  public static Func<U1, U2, U3, U4, U5, UResult> DowncastClone<T1, T2, T3, T4, T5, TResult, U1, U2, U3, U4, U5, UResult>(this Func<T1, T2, T3, T4, T5, TResult> F, Func<U1, T1> ArgConv1, Func<U2, T2> ArgConv2, Func<U3, T3> ArgConv3, Func<U4, T4> ArgConv4, Func<U5, T5> ArgConv5, Func<TResult, UResult> ResConv) {
    return (arg1, arg2, arg3, arg4, arg5) => ResConv(F(ArgConv1(arg1), ArgConv2(arg2), ArgConv3(arg3), ArgConv4(arg4), ArgConv5(arg5)));
  }
  public static Func<U1, U2, U3, U4, U5, U6, UResult> DowncastClone<T1, T2, T3, T4, T5, T6, TResult, U1, U2, U3, U4, U5, U6, UResult>(this Func<T1, T2, T3, T4, T5, T6, TResult> F, Func<U1, T1> ArgConv1, Func<U2, T2> ArgConv2, Func<U3, T3> ArgConv3, Func<U4, T4> ArgConv4, Func<U5, T5> ArgConv5, Func<U6, T6> ArgConv6, Func<TResult, UResult> ResConv) {
    return (arg1, arg2, arg3, arg4, arg5, arg6) => ResConv(F(ArgConv1(arg1), ArgConv2(arg2), ArgConv3(arg3), ArgConv4(arg4), ArgConv5(arg5), ArgConv6(arg6)));
  }
  public static Func<U1, U2, U3, U4, U5, U6, U7, UResult> DowncastClone<T1, T2, T3, T4, T5, T6, T7, TResult, U1, U2, U3, U4, U5, U6, U7, UResult>(this Func<T1, T2, T3, T4, T5, T6, T7, TResult> F, Func<U1, T1> ArgConv1, Func<U2, T2> ArgConv2, Func<U3, T3> ArgConv3, Func<U4, T4> ArgConv4, Func<U5, T5> ArgConv5, Func<U6, T6> ArgConv6, Func<U7, T7> ArgConv7, Func<TResult, UResult> ResConv) {
    return (arg1, arg2, arg3, arg4, arg5, arg6, arg7) => ResConv(F(ArgConv1(arg1), ArgConv2(arg2), ArgConv3(arg3), ArgConv4(arg4), ArgConv5(arg5), ArgConv6(arg6), ArgConv7(arg7)));
  }
  public static Func<U1, U2, U3, U4, U5, U6, U7, U8, UResult> DowncastClone<T1, T2, T3, T4, T5, T6, T7, T8, TResult, U1, U2, U3, U4, U5, U6, U7, U8, UResult>(this Func<T1, T2, T3, T4, T5, T6, T7, T8, TResult> F, Func<U1, T1> ArgConv1, Func<U2, T2> ArgConv2, Func<U3, T3> ArgConv3, Func<U4, T4> ArgConv4, Func<U5, T5> ArgConv5, Func<U6, T6> ArgConv6, Func<U7, T7> ArgConv7, Func<U8, T8> ArgConv8, Func<TResult, UResult> ResConv) {
    return (arg1, arg2, arg3, arg4, arg5, arg6, arg7, arg8) => ResConv(F(ArgConv1(arg1), ArgConv2(arg2), ArgConv3(arg3), ArgConv4(arg4), ArgConv5(arg5), ArgConv6(arg6), ArgConv7(arg7), ArgConv8(arg8)));
  }
  public static Func<U1, U2, U3, U4, U5, U6, U7, U8, U9, UResult> DowncastClone<T1, T2, T3, T4, T5, T6, T7, T8, T9, TResult, U1, U2, U3, U4, U5, U6, U7, U8, U9, UResult>(this Func<T1, T2, T3, T4, T5, T6, T7, T8, T9, TResult> F, Func<U1, T1> ArgConv1, Func<U2, T2> ArgConv2, Func<U3, T3> ArgConv3, Func<U4, T4> ArgConv4, Func<U5, T5> ArgConv5, Func<U6, T6> ArgConv6, Func<U7, T7> ArgConv7, Func<U8, T8> ArgConv8, Func<U9, T9> ArgConv9, Func<TResult, UResult> ResConv) {
    return (arg1, arg2, arg3, arg4, arg5, arg6, arg7, arg8, arg9) => ResConv(F(ArgConv1(arg1), ArgConv2(arg2), ArgConv3(arg3), ArgConv4(arg4), ArgConv5(arg5), ArgConv6(arg6), ArgConv7(arg7), ArgConv8(arg8), ArgConv9(arg9)));
  }
  public static Func<U1, U2, U3, U4, U5, U6, U7, U8, U9, U10, UResult> DowncastClone<T1, T2, T3, T4, T5, T6, T7, T8, T9, T10, TResult, U1, U2, U3, U4, U5, U6, U7, U8, U9, U10, UResult>(this Func<T1, T2, T3, T4, T5, T6, T7, T8, T9, T10, TResult> F, Func<U1, T1> ArgConv1, Func<U2, T2> ArgConv2, Func<U3, T3> ArgConv3, Func<U4, T4> ArgConv4, Func<U5, T5> ArgConv5, Func<U6, T6> ArgConv6, Func<U7, T7> ArgConv7, Func<U8, T8> ArgConv8, Func<U9, T9> ArgConv9, Func<U10, T10> ArgConv10, Func<TResult, UResult> ResConv) {
    return (arg1, arg2, arg3, arg4, arg5, arg6, arg7, arg8, arg9, arg10) => ResConv(F(ArgConv1(arg1), ArgConv2(arg2), ArgConv3(arg3), ArgConv4(arg4), ArgConv5(arg5), ArgConv6(arg6), ArgConv7(arg7), ArgConv8(arg8), ArgConv9(arg9), ArgConv10(arg10)));
  }
  public static Func<U1, U2, U3, U4, U5, U6, U7, U8, U9, U10, U11, UResult> DowncastClone<T1, T2, T3, T4, T5, T6, T7, T8, T9, T10, T11, TResult, U1, U2, U3, U4, U5, U6, U7, U8, U9, U10, U11, UResult>(this Func<T1, T2, T3, T4, T5, T6, T7, T8, T9, T10, T11, TResult> F, Func<U1, T1> ArgConv1, Func<U2, T2> ArgConv2, Func<U3, T3> ArgConv3, Func<U4, T4> ArgConv4, Func<U5, T5> ArgConv5, Func<U6, T6> ArgConv6, Func<U7, T7> ArgConv7, Func<U8, T8> ArgConv8, Func<U9, T9> ArgConv9, Func<U10, T10> ArgConv10, Func<U11, T11> ArgConv11, Func<TResult, UResult> ResConv) {
    return (arg1, arg2, arg3, arg4, arg5, arg6, arg7, arg8, arg9, arg10, arg11) => ResConv(F(ArgConv1(arg1), ArgConv2(arg2), ArgConv3(arg3), ArgConv4(arg4), ArgConv5(arg5), ArgConv6(arg6), ArgConv7(arg7), ArgConv8(arg8), ArgConv9(arg9), ArgConv10(arg10), ArgConv11(arg11)));
  }
  public static Func<U1, U2, U3, U4, U5, U6, U7, U8, U9, U10, U11, U12, UResult> DowncastClone<T1, T2, T3, T4, T5, T6, T7, T8, T9, T10, T11, T12, TResult, U1, U2, U3, U4, U5, U6, U7, U8, U9, U10, U11, U12, UResult>(this Func<T1, T2, T3, T4, T5, T6, T7, T8, T9, T10, T11, T12, TResult> F, Func<U1, T1> ArgConv1, Func<U2, T2> ArgConv2, Func<U3, T3> ArgConv3, Func<U4, T4> ArgConv4, Func<U5, T5> ArgConv5, Func<U6, T6> ArgConv6, Func<U7, T7> ArgConv7, Func<U8, T8> ArgConv8, Func<U9, T9> ArgConv9, Func<U10, T10> ArgConv10, Func<U11, T11> ArgConv11, Func<U12, T12> ArgConv12, Func<TResult, UResult> ResConv) {
    return (arg1, arg2, arg3, arg4, arg5, arg6, arg7, arg8, arg9, arg10, arg11, arg12) => ResConv(F(ArgConv1(arg1), ArgConv2(arg2), ArgConv3(arg3), ArgConv4(arg4), ArgConv5(arg5), ArgConv6(arg6), ArgConv7(arg7), ArgConv8(arg8), ArgConv9(arg9), ArgConv10(arg10), ArgConv11(arg11), ArgConv12(arg12)));
  }
  public static Func<U1, U2, U3, U4, U5, U6, U7, U8, U9, U10, U11, U12, U13, UResult> DowncastClone<T1, T2, T3, T4, T5, T6, T7, T8, T9, T10, T11, T12, T13, TResult, U1, U2, U3, U4, U5, U6, U7, U8, U9, U10, U11, U12, U13, UResult>(this Func<T1, T2, T3, T4, T5, T6, T7, T8, T9, T10, T11, T12, T13, TResult> F, Func<U1, T1> ArgConv1, Func<U2, T2> ArgConv2, Func<U3, T3> ArgConv3, Func<U4, T4> ArgConv4, Func<U5, T5> ArgConv5, Func<U6, T6> ArgConv6, Func<U7, T7> ArgConv7, Func<U8, T8> ArgConv8, Func<U9, T9> ArgConv9, Func<U10, T10> ArgConv10, Func<U11, T11> ArgConv11, Func<U12, T12> ArgConv12, Func<U13, T13> ArgConv13, Func<TResult, UResult> ResConv) {
    return (arg1, arg2, arg3, arg4, arg5, arg6, arg7, arg8, arg9, arg10, arg11, arg12, arg13) => ResConv(F(ArgConv1(arg1), ArgConv2(arg2), ArgConv3(arg3), ArgConv4(arg4), ArgConv5(arg5), ArgConv6(arg6), ArgConv7(arg7), ArgConv8(arg8), ArgConv9(arg9), ArgConv10(arg10), ArgConv11(arg11), ArgConv12(arg12), ArgConv13(arg13)));
  }
  public static Func<U1, U2, U3, U4, U5, U6, U7, U8, U9, U10, U11, U12, U13, U14, UResult> DowncastClone<T1, T2, T3, T4, T5, T6, T7, T8, T9, T10, T11, T12, T13, T14, TResult, U1, U2, U3, U4, U5, U6, U7, U8, U9, U10, U11, U12, U13, U14, UResult>(this Func<T1, T2, T3, T4, T5, T6, T7, T8, T9, T10, T11, T12, T13, T14, TResult> F, Func<U1, T1> ArgConv1, Func<U2, T2> ArgConv2, Func<U3, T3> ArgConv3, Func<U4, T4> ArgConv4, Func<U5, T5> ArgConv5, Func<U6, T6> ArgConv6, Func<U7, T7> ArgConv7, Func<U8, T8> ArgConv8, Func<U9, T9> ArgConv9, Func<U10, T10> ArgConv10, Func<U11, T11> ArgConv11, Func<U12, T12> ArgConv12, Func<U13, T13> ArgConv13, Func<U14, T14> ArgConv14, Func<TResult, UResult> ResConv) {
    return (arg1, arg2, arg3, arg4, arg5, arg6, arg7, arg8, arg9, arg10, arg11, arg12, arg13, arg14) => ResConv(F(ArgConv1(arg1), ArgConv2(arg2), ArgConv3(arg3), ArgConv4(arg4), ArgConv5(arg5), ArgConv6(arg6), ArgConv7(arg7), ArgConv8(arg8), ArgConv9(arg9), ArgConv10(arg10), ArgConv11(arg11), ArgConv12(arg12), ArgConv13(arg13), ArgConv14(arg14)));
  }
  public static Func<U1, U2, U3, U4, U5, U6, U7, U8, U9, U10, U11, U12, U13, U14, U15, UResult> DowncastClone<T1, T2, T3, T4, T5, T6, T7, T8, T9, T10, T11, T12, T13, T14, T15, TResult, U1, U2, U3, U4, U5, U6, U7, U8, U9, U10, U11, U12, U13, U14, U15, UResult>(this Func<T1, T2, T3, T4, T5, T6, T7, T8, T9, T10, T11, T12, T13, T14, T15, TResult> F, Func<U1, T1> ArgConv1, Func<U2, T2> ArgConv2, Func<U3, T3> ArgConv3, Func<U4, T4> ArgConv4, Func<U5, T5> ArgConv5, Func<U6, T6> ArgConv6, Func<U7, T7> ArgConv7, Func<U8, T8> ArgConv8, Func<U9, T9> ArgConv9, Func<U10, T10> ArgConv10, Func<U11, T11> ArgConv11, Func<U12, T12> ArgConv12, Func<U13, T13> ArgConv13, Func<U14, T14> ArgConv14, Func<U15, T15> ArgConv15, Func<TResult, UResult> ResConv) {
    return (arg1, arg2, arg3, arg4, arg5, arg6, arg7, arg8, arg9, arg10, arg11, arg12, arg13, arg14, arg15) => ResConv(F(ArgConv1(arg1), ArgConv2(arg2), ArgConv3(arg3), ArgConv4(arg4), ArgConv5(arg5), ArgConv6(arg6), ArgConv7(arg7), ArgConv8(arg8), ArgConv9(arg9), ArgConv10(arg10), ArgConv11(arg11), ArgConv12(arg12), ArgConv13(arg13), ArgConv14(arg14), ArgConv15(arg15)));
  }
  public static Func<U1, U2, U3, U4, U5, U6, U7, U8, U9, U10, U11, U12, U13, U14, U15, U16, UResult> DowncastClone<T1, T2, T3, T4, T5, T6, T7, T8, T9, T10, T11, T12, T13, T14, T15, T16, TResult, U1, U2, U3, U4, U5, U6, U7, U8, U9, U10, U11, U12, U13, U14, U15, U16, UResult>(this Func<T1, T2, T3, T4, T5, T6, T7, T8, T9, T10, T11, T12, T13, T14, T15, T16, TResult> F, Func<U1, T1> ArgConv1, Func<U2, T2> ArgConv2, Func<U3, T3> ArgConv3, Func<U4, T4> ArgConv4, Func<U5, T5> ArgConv5, Func<U6, T6> ArgConv6, Func<U7, T7> ArgConv7, Func<U8, T8> ArgConv8, Func<U9, T9> ArgConv9, Func<U10, T10> ArgConv10, Func<U11, T11> ArgConv11, Func<U12, T12> ArgConv12, Func<U13, T13> ArgConv13, Func<U14, T14> ArgConv14, Func<U15, T15> ArgConv15, Func<U16, T16> ArgConv16, Func<TResult, UResult> ResConv) {
    return (arg1, arg2, arg3, arg4, arg5, arg6, arg7, arg8, arg9, arg10, arg11, arg12, arg13, arg14, arg15, arg16) => ResConv(F(ArgConv1(arg1), ArgConv2(arg2), ArgConv3(arg3), ArgConv4(arg4), ArgConv5(arg5), ArgConv6(arg6), ArgConv7(arg7), ArgConv8(arg8), ArgConv9(arg9), ArgConv10(arg10), ArgConv11(arg11), ArgConv12(arg12), ArgConv13(arg13), ArgConv14(arg14), ArgConv15(arg15), ArgConv16(arg16)));
  }
}
#endif
namespace _System {

  public partial class nat {
    private static readonly Dafny.TypeDescriptor<BigInteger> _TYPE = new Dafny.TypeDescriptor<BigInteger>(BigInteger.Zero);
    public static Dafny.TypeDescriptor<BigInteger> _TypeDescriptor() {
      return _TYPE;
    }
    public static bool _Is(BigInteger __source) {
      BigInteger _0_x = __source;
      return (_0_x).Sign != -1;
    }
  }

  public interface _ITuple2<out T0, out T1> {
    T0 dtor__0 { get; }
    T1 dtor__1 { get; }
    _ITuple2<__T0, __T1> DowncastClone<__T0, __T1>(Func<T0, __T0> converter0, Func<T1, __T1> converter1);
  }
  public class Tuple2<T0, T1> : _ITuple2<T0, T1> {
    public readonly T0 __0;
    public readonly T1 __1;
    public Tuple2(T0 _0, T1 _1) {
      this.__0 = _0;
      this.__1 = _1;
    }
    public _ITuple2<__T0, __T1> DowncastClone<__T0, __T1>(Func<T0, __T0> converter0, Func<T1, __T1> converter1) {
      if (this is _ITuple2<__T0, __T1> dt) { return dt; }
      return new Tuple2<__T0, __T1>(converter0(__0), converter1(__1));
    }
    public override bool Equals(object other) {
      var oth = other as _System.Tuple2<T0, T1>;
      return oth != null && object.Equals(this.__0, oth.__0) && object.Equals(this.__1, oth.__1);
    }
    public override int GetHashCode() {
      ulong hash = 5381;
      hash = ((hash << 5) + hash) + 0;
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this.__0));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this.__1));
      return (int) hash;
    }
    public override string ToString() {
      string s = "";
      s += "(";
      s += Dafny.Helpers.ToString(this.__0);
      s += ", ";
      s += Dafny.Helpers.ToString(this.__1);
      s += ")";
      return s;
    }
    public static _System._ITuple2<T0, T1> Default(T0 _default_T0, T1 _default_T1) {
      return create(_default_T0, _default_T1);
    }
    public static Dafny.TypeDescriptor<_System._ITuple2<T0, T1>> _TypeDescriptor(Dafny.TypeDescriptor<T0> _td_T0, Dafny.TypeDescriptor<T1> _td_T1) {
      return new Dafny.TypeDescriptor<_System._ITuple2<T0, T1>>(_System.Tuple2<T0, T1>.Default(_td_T0.Default(), _td_T1.Default()));
    }
    public static _ITuple2<T0, T1> create(T0 _0, T1 _1) {
      return new Tuple2<T0, T1>(_0, _1);
    }
    public static _ITuple2<T0, T1> create____hMake2(T0 _0, T1 _1) {
      return create(_0, _1);
    }
    public T0 dtor__0 {
      get {
        return this.__0;
      }
    }
    public T1 dtor__1 {
      get {
        return this.__1;
      }
    }
  }

  public interface _ITuple0 {
    _ITuple0 DowncastClone();
  }
  public class Tuple0 : _ITuple0 {
    public Tuple0() {
    }
    public _ITuple0 DowncastClone() {
      if (this is _ITuple0 dt) { return dt; }
      return new Tuple0();
    }
    public override bool Equals(object other) {
      var oth = other as _System.Tuple0;
      return oth != null;
    }
    public override int GetHashCode() {
      ulong hash = 5381;
      hash = ((hash << 5) + hash) + 0;
      return (int) hash;
    }
    public override string ToString() {
      return "()";
    }
    private static readonly _System._ITuple0 theDefault = create();
    public static _System._ITuple0 Default() {
      return theDefault;
    }
    private static readonly Dafny.TypeDescriptor<_System._ITuple0> _TYPE = new Dafny.TypeDescriptor<_System._ITuple0>(_System.Tuple0.Default());
    public static Dafny.TypeDescriptor<_System._ITuple0> _TypeDescriptor() {
      return _TYPE;
    }
    public static _ITuple0 create() {
      return new Tuple0();
    }
    public static _ITuple0 create____hMake0() {
      return create();
    }
    public static System.Collections.Generic.IEnumerable<_ITuple0> AllSingletonConstructors {
      get {
        yield return Tuple0.create();
      }
    }
  }

  public interface _ITuple1<out T0> {
    T0 dtor__0 { get; }
    _ITuple1<__T0> DowncastClone<__T0>(Func<T0, __T0> converter0);
  }
  public class Tuple1<T0> : _ITuple1<T0> {
    public readonly T0 __0;
    public Tuple1(T0 _0) {
      this.__0 = _0;
    }
    public _ITuple1<__T0> DowncastClone<__T0>(Func<T0, __T0> converter0) {
      if (this is _ITuple1<__T0> dt) { return dt; }
      return new Tuple1<__T0>(converter0(__0));
    }
    public override bool Equals(object other) {
      var oth = other as _System.Tuple1<T0>;
      return oth != null && object.Equals(this.__0, oth.__0);
    }
    public override int GetHashCode() {
      ulong hash = 5381;
      hash = ((hash << 5) + hash) + 0;
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this.__0));
      return (int) hash;
    }
    public override string ToString() {
      string s = "";
      s += "(";
      s += Dafny.Helpers.ToString(this.__0);
      s += ")";
      return s;
    }
    public static _System._ITuple1<T0> Default(T0 _default_T0) {
      return create(_default_T0);
    }
    public static Dafny.TypeDescriptor<_System._ITuple1<T0>> _TypeDescriptor(Dafny.TypeDescriptor<T0> _td_T0) {
      return new Dafny.TypeDescriptor<_System._ITuple1<T0>>(_System.Tuple1<T0>.Default(_td_T0.Default()));
    }
    public static _ITuple1<T0> create(T0 _0) {
      return new Tuple1<T0>(_0);
    }
    public static _ITuple1<T0> create____hMake1(T0 _0) {
      return create(_0);
    }
    public T0 dtor__0 {
      get {
        return this.__0;
      }
    }
  }

  public interface _ITuple3<out T0, out T1, out T2> {
    T0 dtor__0 { get; }
    T1 dtor__1 { get; }
    T2 dtor__2 { get; }
    _ITuple3<__T0, __T1, __T2> DowncastClone<__T0, __T1, __T2>(Func<T0, __T0> converter0, Func<T1, __T1> converter1, Func<T2, __T2> converter2);
  }
  public class Tuple3<T0, T1, T2> : _ITuple3<T0, T1, T2> {
    public readonly T0 __0;
    public readonly T1 __1;
    public readonly T2 __2;
    public Tuple3(T0 _0, T1 _1, T2 _2) {
      this.__0 = _0;
      this.__1 = _1;
      this.__2 = _2;
    }
    public _ITuple3<__T0, __T1, __T2> DowncastClone<__T0, __T1, __T2>(Func<T0, __T0> converter0, Func<T1, __T1> converter1, Func<T2, __T2> converter2) {
      if (this is _ITuple3<__T0, __T1, __T2> dt) { return dt; }
      return new Tuple3<__T0, __T1, __T2>(converter0(__0), converter1(__1), converter2(__2));
    }
    public override bool Equals(object other) {
      var oth = other as _System.Tuple3<T0, T1, T2>;
      return oth != null && object.Equals(this.__0, oth.__0) && object.Equals(this.__1, oth.__1) && object.Equals(this.__2, oth.__2);
    }
    public override int GetHashCode() {
      ulong hash = 5381;
      hash = ((hash << 5) + hash) + 0;
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this.__0));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this.__1));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this.__2));
      return (int) hash;
    }
    public override string ToString() {
      string s = "";
      s += "(";
      s += Dafny.Helpers.ToString(this.__0);
      s += ", ";
      s += Dafny.Helpers.ToString(this.__1);
      s += ", ";
      s += Dafny.Helpers.ToString(this.__2);
      s += ")";
      return s;
    }
    public static _System._ITuple3<T0, T1, T2> Default(T0 _default_T0, T1 _default_T1, T2 _default_T2) {
      return create(_default_T0, _default_T1, _default_T2);
    }
    public static Dafny.TypeDescriptor<_System._ITuple3<T0, T1, T2>> _TypeDescriptor(Dafny.TypeDescriptor<T0> _td_T0, Dafny.TypeDescriptor<T1> _td_T1, Dafny.TypeDescriptor<T2> _td_T2) {
      return new Dafny.TypeDescriptor<_System._ITuple3<T0, T1, T2>>(_System.Tuple3<T0, T1, T2>.Default(_td_T0.Default(), _td_T1.Default(), _td_T2.Default()));
    }
    public static _ITuple3<T0, T1, T2> create(T0 _0, T1 _1, T2 _2) {
      return new Tuple3<T0, T1, T2>(_0, _1, _2);
    }
    public static _ITuple3<T0, T1, T2> create____hMake3(T0 _0, T1 _1, T2 _2) {
      return create(_0, _1, _2);
    }
    public T0 dtor__0 {
      get {
        return this.__0;
      }
    }
    public T1 dtor__1 {
      get {
        return this.__1;
      }
    }
    public T2 dtor__2 {
      get {
        return this.__2;
      }
    }
  }

  public interface _ITuple4<out T0, out T1, out T2, out T3> {
    T0 dtor__0 { get; }
    T1 dtor__1 { get; }
    T2 dtor__2 { get; }
    T3 dtor__3 { get; }
    _ITuple4<__T0, __T1, __T2, __T3> DowncastClone<__T0, __T1, __T2, __T3>(Func<T0, __T0> converter0, Func<T1, __T1> converter1, Func<T2, __T2> converter2, Func<T3, __T3> converter3);
  }
  public class Tuple4<T0, T1, T2, T3> : _ITuple4<T0, T1, T2, T3> {
    public readonly T0 __0;
    public readonly T1 __1;
    public readonly T2 __2;
    public readonly T3 __3;
    public Tuple4(T0 _0, T1 _1, T2 _2, T3 _3) {
      this.__0 = _0;
      this.__1 = _1;
      this.__2 = _2;
      this.__3 = _3;
    }
    public _ITuple4<__T0, __T1, __T2, __T3> DowncastClone<__T0, __T1, __T2, __T3>(Func<T0, __T0> converter0, Func<T1, __T1> converter1, Func<T2, __T2> converter2, Func<T3, __T3> converter3) {
      if (this is _ITuple4<__T0, __T1, __T2, __T3> dt) { return dt; }
      return new Tuple4<__T0, __T1, __T2, __T3>(converter0(__0), converter1(__1), converter2(__2), converter3(__3));
    }
    public override bool Equals(object other) {
      var oth = other as _System.Tuple4<T0, T1, T2, T3>;
      return oth != null && object.Equals(this.__0, oth.__0) && object.Equals(this.__1, oth.__1) && object.Equals(this.__2, oth.__2) && object.Equals(this.__3, oth.__3);
    }
    public override int GetHashCode() {
      ulong hash = 5381;
      hash = ((hash << 5) + hash) + 0;
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this.__0));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this.__1));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this.__2));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this.__3));
      return (int) hash;
    }
    public override string ToString() {
      string s = "";
      s += "(";
      s += Dafny.Helpers.ToString(this.__0);
      s += ", ";
      s += Dafny.Helpers.ToString(this.__1);
      s += ", ";
      s += Dafny.Helpers.ToString(this.__2);
      s += ", ";
      s += Dafny.Helpers.ToString(this.__3);
      s += ")";
      return s;
    }
    public static _System._ITuple4<T0, T1, T2, T3> Default(T0 _default_T0, T1 _default_T1, T2 _default_T2, T3 _default_T3) {
      return create(_default_T0, _default_T1, _default_T2, _default_T3);
    }
    public static Dafny.TypeDescriptor<_System._ITuple4<T0, T1, T2, T3>> _TypeDescriptor(Dafny.TypeDescriptor<T0> _td_T0, Dafny.TypeDescriptor<T1> _td_T1, Dafny.TypeDescriptor<T2> _td_T2, Dafny.TypeDescriptor<T3> _td_T3) {
      return new Dafny.TypeDescriptor<_System._ITuple4<T0, T1, T2, T3>>(_System.Tuple4<T0, T1, T2, T3>.Default(_td_T0.Default(), _td_T1.Default(), _td_T2.Default(), _td_T3.Default()));
    }
    public static _ITuple4<T0, T1, T2, T3> create(T0 _0, T1 _1, T2 _2, T3 _3) {
      return new Tuple4<T0, T1, T2, T3>(_0, _1, _2, _3);
    }
    public static _ITuple4<T0, T1, T2, T3> create____hMake4(T0 _0, T1 _1, T2 _2, T3 _3) {
      return create(_0, _1, _2, _3);
    }
    public T0 dtor__0 {
      get {
        return this.__0;
      }
    }
    public T1 dtor__1 {
      get {
        return this.__1;
      }
    }
    public T2 dtor__2 {
      get {
        return this.__2;
      }
    }
    public T3 dtor__3 {
      get {
        return this.__3;
      }
    }
  }

  public interface _ITuple5<out T0, out T1, out T2, out T3, out T4> {
    T0 dtor__0 { get; }
    T1 dtor__1 { get; }
    T2 dtor__2 { get; }
    T3 dtor__3 { get; }
    T4 dtor__4 { get; }
    _ITuple5<__T0, __T1, __T2, __T3, __T4> DowncastClone<__T0, __T1, __T2, __T3, __T4>(Func<T0, __T0> converter0, Func<T1, __T1> converter1, Func<T2, __T2> converter2, Func<T3, __T3> converter3, Func<T4, __T4> converter4);
  }
  public class Tuple5<T0, T1, T2, T3, T4> : _ITuple5<T0, T1, T2, T3, T4> {
    public readonly T0 __0;
    public readonly T1 __1;
    public readonly T2 __2;
    public readonly T3 __3;
    public readonly T4 __4;
    public Tuple5(T0 _0, T1 _1, T2 _2, T3 _3, T4 _4) {
      this.__0 = _0;
      this.__1 = _1;
      this.__2 = _2;
      this.__3 = _3;
      this.__4 = _4;
    }
    public _ITuple5<__T0, __T1, __T2, __T3, __T4> DowncastClone<__T0, __T1, __T2, __T3, __T4>(Func<T0, __T0> converter0, Func<T1, __T1> converter1, Func<T2, __T2> converter2, Func<T3, __T3> converter3, Func<T4, __T4> converter4) {
      if (this is _ITuple5<__T0, __T1, __T2, __T3, __T4> dt) { return dt; }
      return new Tuple5<__T0, __T1, __T2, __T3, __T4>(converter0(__0), converter1(__1), converter2(__2), converter3(__3), converter4(__4));
    }
    public override bool Equals(object other) {
      var oth = other as _System.Tuple5<T0, T1, T2, T3, T4>;
      return oth != null && object.Equals(this.__0, oth.__0) && object.Equals(this.__1, oth.__1) && object.Equals(this.__2, oth.__2) && object.Equals(this.__3, oth.__3) && object.Equals(this.__4, oth.__4);
    }
    public override int GetHashCode() {
      ulong hash = 5381;
      hash = ((hash << 5) + hash) + 0;
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this.__0));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this.__1));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this.__2));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this.__3));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this.__4));
      return (int) hash;
    }
    public override string ToString() {
      string s = "";
      s += "(";
      s += Dafny.Helpers.ToString(this.__0);
      s += ", ";
      s += Dafny.Helpers.ToString(this.__1);
      s += ", ";
      s += Dafny.Helpers.ToString(this.__2);
      s += ", ";
      s += Dafny.Helpers.ToString(this.__3);
      s += ", ";
      s += Dafny.Helpers.ToString(this.__4);
      s += ")";
      return s;
    }
    public static _System._ITuple5<T0, T1, T2, T3, T4> Default(T0 _default_T0, T1 _default_T1, T2 _default_T2, T3 _default_T3, T4 _default_T4) {
      return create(_default_T0, _default_T1, _default_T2, _default_T3, _default_T4);
    }
    public static Dafny.TypeDescriptor<_System._ITuple5<T0, T1, T2, T3, T4>> _TypeDescriptor(Dafny.TypeDescriptor<T0> _td_T0, Dafny.TypeDescriptor<T1> _td_T1, Dafny.TypeDescriptor<T2> _td_T2, Dafny.TypeDescriptor<T3> _td_T3, Dafny.TypeDescriptor<T4> _td_T4) {
      return new Dafny.TypeDescriptor<_System._ITuple5<T0, T1, T2, T3, T4>>(_System.Tuple5<T0, T1, T2, T3, T4>.Default(_td_T0.Default(), _td_T1.Default(), _td_T2.Default(), _td_T3.Default(), _td_T4.Default()));
    }
    public static _ITuple5<T0, T1, T2, T3, T4> create(T0 _0, T1 _1, T2 _2, T3 _3, T4 _4) {
      return new Tuple5<T0, T1, T2, T3, T4>(_0, _1, _2, _3, _4);
    }
    public static _ITuple5<T0, T1, T2, T3, T4> create____hMake5(T0 _0, T1 _1, T2 _2, T3 _3, T4 _4) {
      return create(_0, _1, _2, _3, _4);
    }
    public T0 dtor__0 {
      get {
        return this.__0;
      }
    }
    public T1 dtor__1 {
      get {
        return this.__1;
      }
    }
    public T2 dtor__2 {
      get {
        return this.__2;
      }
    }
    public T3 dtor__3 {
      get {
        return this.__3;
      }
    }
    public T4 dtor__4 {
      get {
        return this.__4;
      }
    }
  }

  public interface _ITuple6<out T0, out T1, out T2, out T3, out T4, out T5> {
    T0 dtor__0 { get; }
    T1 dtor__1 { get; }
    T2 dtor__2 { get; }
    T3 dtor__3 { get; }
    T4 dtor__4 { get; }
    T5 dtor__5 { get; }
    _ITuple6<__T0, __T1, __T2, __T3, __T4, __T5> DowncastClone<__T0, __T1, __T2, __T3, __T4, __T5>(Func<T0, __T0> converter0, Func<T1, __T1> converter1, Func<T2, __T2> converter2, Func<T3, __T3> converter3, Func<T4, __T4> converter4, Func<T5, __T5> converter5);
  }
  public class Tuple6<T0, T1, T2, T3, T4, T5> : _ITuple6<T0, T1, T2, T3, T4, T5> {
    public readonly T0 __0;
    public readonly T1 __1;
    public readonly T2 __2;
    public readonly T3 __3;
    public readonly T4 __4;
    public readonly T5 __5;
    public Tuple6(T0 _0, T1 _1, T2 _2, T3 _3, T4 _4, T5 _5) {
      this.__0 = _0;
      this.__1 = _1;
      this.__2 = _2;
      this.__3 = _3;
      this.__4 = _4;
      this.__5 = _5;
    }
    public _ITuple6<__T0, __T1, __T2, __T3, __T4, __T5> DowncastClone<__T0, __T1, __T2, __T3, __T4, __T5>(Func<T0, __T0> converter0, Func<T1, __T1> converter1, Func<T2, __T2> converter2, Func<T3, __T3> converter3, Func<T4, __T4> converter4, Func<T5, __T5> converter5) {
      if (this is _ITuple6<__T0, __T1, __T2, __T3, __T4, __T5> dt) { return dt; }
      return new Tuple6<__T0, __T1, __T2, __T3, __T4, __T5>(converter0(__0), converter1(__1), converter2(__2), converter3(__3), converter4(__4), converter5(__5));
    }
    public override bool Equals(object other) {
      var oth = other as _System.Tuple6<T0, T1, T2, T3, T4, T5>;
      return oth != null && object.Equals(this.__0, oth.__0) && object.Equals(this.__1, oth.__1) && object.Equals(this.__2, oth.__2) && object.Equals(this.__3, oth.__3) && object.Equals(this.__4, oth.__4) && object.Equals(this.__5, oth.__5);
    }
    public override int GetHashCode() {
      ulong hash = 5381;
      hash = ((hash << 5) + hash) + 0;
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this.__0));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this.__1));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this.__2));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this.__3));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this.__4));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this.__5));
      return (int) hash;
    }
    public override string ToString() {
      string s = "";
      s += "(";
      s += Dafny.Helpers.ToString(this.__0);
      s += ", ";
      s += Dafny.Helpers.ToString(this.__1);
      s += ", ";
      s += Dafny.Helpers.ToString(this.__2);
      s += ", ";
      s += Dafny.Helpers.ToString(this.__3);
      s += ", ";
      s += Dafny.Helpers.ToString(this.__4);
      s += ", ";
      s += Dafny.Helpers.ToString(this.__5);
      s += ")";
      return s;
    }
    public static _System._ITuple6<T0, T1, T2, T3, T4, T5> Default(T0 _default_T0, T1 _default_T1, T2 _default_T2, T3 _default_T3, T4 _default_T4, T5 _default_T5) {
      return create(_default_T0, _default_T1, _default_T2, _default_T3, _default_T4, _default_T5);
    }
    public static Dafny.TypeDescriptor<_System._ITuple6<T0, T1, T2, T3, T4, T5>> _TypeDescriptor(Dafny.TypeDescriptor<T0> _td_T0, Dafny.TypeDescriptor<T1> _td_T1, Dafny.TypeDescriptor<T2> _td_T2, Dafny.TypeDescriptor<T3> _td_T3, Dafny.TypeDescriptor<T4> _td_T4, Dafny.TypeDescriptor<T5> _td_T5) {
      return new Dafny.TypeDescriptor<_System._ITuple6<T0, T1, T2, T3, T4, T5>>(_System.Tuple6<T0, T1, T2, T3, T4, T5>.Default(_td_T0.Default(), _td_T1.Default(), _td_T2.Default(), _td_T3.Default(), _td_T4.Default(), _td_T5.Default()));
    }
    public static _ITuple6<T0, T1, T2, T3, T4, T5> create(T0 _0, T1 _1, T2 _2, T3 _3, T4 _4, T5 _5) {
      return new Tuple6<T0, T1, T2, T3, T4, T5>(_0, _1, _2, _3, _4, _5);
    }
    public static _ITuple6<T0, T1, T2, T3, T4, T5> create____hMake6(T0 _0, T1 _1, T2 _2, T3 _3, T4 _4, T5 _5) {
      return create(_0, _1, _2, _3, _4, _5);
    }
    public T0 dtor__0 {
      get {
        return this.__0;
      }
    }
    public T1 dtor__1 {
      get {
        return this.__1;
      }
    }
    public T2 dtor__2 {
      get {
        return this.__2;
      }
    }
    public T3 dtor__3 {
      get {
        return this.__3;
      }
    }
    public T4 dtor__4 {
      get {
        return this.__4;
      }
    }
    public T5 dtor__5 {
      get {
        return this.__5;
      }
    }
  }

  public interface _ITuple7<out T0, out T1, out T2, out T3, out T4, out T5, out T6> {
    T0 dtor__0 { get; }
    T1 dtor__1 { get; }
    T2 dtor__2 { get; }
    T3 dtor__3 { get; }
    T4 dtor__4 { get; }
    T5 dtor__5 { get; }
    T6 dtor__6 { get; }
    _ITuple7<__T0, __T1, __T2, __T3, __T4, __T5, __T6> DowncastClone<__T0, __T1, __T2, __T3, __T4, __T5, __T6>(Func<T0, __T0> converter0, Func<T1, __T1> converter1, Func<T2, __T2> converter2, Func<T3, __T3> converter3, Func<T4, __T4> converter4, Func<T5, __T5> converter5, Func<T6, __T6> converter6);
  }
  public class Tuple7<T0, T1, T2, T3, T4, T5, T6> : _ITuple7<T0, T1, T2, T3, T4, T5, T6> {
    public readonly T0 __0;
    public readonly T1 __1;
    public readonly T2 __2;
    public readonly T3 __3;
    public readonly T4 __4;
    public readonly T5 __5;
    public readonly T6 __6;
    public Tuple7(T0 _0, T1 _1, T2 _2, T3 _3, T4 _4, T5 _5, T6 _6) {
      this.__0 = _0;
      this.__1 = _1;
      this.__2 = _2;
      this.__3 = _3;
      this.__4 = _4;
      this.__5 = _5;
      this.__6 = _6;
    }
    public _ITuple7<__T0, __T1, __T2, __T3, __T4, __T5, __T6> DowncastClone<__T0, __T1, __T2, __T3, __T4, __T5, __T6>(Func<T0, __T0> converter0, Func<T1, __T1> converter1, Func<T2, __T2> converter2, Func<T3, __T3> converter3, Func<T4, __T4> converter4, Func<T5, __T5> converter5, Func<T6, __T6> converter6) {
      if (this is _ITuple7<__T0, __T1, __T2, __T3, __T4, __T5, __T6> dt) { return dt; }
      return new Tuple7<__T0, __T1, __T2, __T3, __T4, __T5, __T6>(converter0(__0), converter1(__1), converter2(__2), converter3(__3), converter4(__4), converter5(__5), converter6(__6));
    }
    public override bool Equals(object other) {
      var oth = other as _System.Tuple7<T0, T1, T2, T3, T4, T5, T6>;
      return oth != null && object.Equals(this.__0, oth.__0) && object.Equals(this.__1, oth.__1) && object.Equals(this.__2, oth.__2) && object.Equals(this.__3, oth.__3) && object.Equals(this.__4, oth.__4) && object.Equals(this.__5, oth.__5) && object.Equals(this.__6, oth.__6);
    }
    public override int GetHashCode() {
      ulong hash = 5381;
      hash = ((hash << 5) + hash) + 0;
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this.__0));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this.__1));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this.__2));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this.__3));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this.__4));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this.__5));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this.__6));
      return (int) hash;
    }
    public override string ToString() {
      string s = "";
      s += "(";
      s += Dafny.Helpers.ToString(this.__0);
      s += ", ";
      s += Dafny.Helpers.ToString(this.__1);
      s += ", ";
      s += Dafny.Helpers.ToString(this.__2);
      s += ", ";
      s += Dafny.Helpers.ToString(this.__3);
      s += ", ";
      s += Dafny.Helpers.ToString(this.__4);
      s += ", ";
      s += Dafny.Helpers.ToString(this.__5);
      s += ", ";
      s += Dafny.Helpers.ToString(this.__6);
      s += ")";
      return s;
    }
    public static _System._ITuple7<T0, T1, T2, T3, T4, T5, T6> Default(T0 _default_T0, T1 _default_T1, T2 _default_T2, T3 _default_T3, T4 _default_T4, T5 _default_T5, T6 _default_T6) {
      return create(_default_T0, _default_T1, _default_T2, _default_T3, _default_T4, _default_T5, _default_T6);
    }
    public static Dafny.TypeDescriptor<_System._ITuple7<T0, T1, T2, T3, T4, T5, T6>> _TypeDescriptor(Dafny.TypeDescriptor<T0> _td_T0, Dafny.TypeDescriptor<T1> _td_T1, Dafny.TypeDescriptor<T2> _td_T2, Dafny.TypeDescriptor<T3> _td_T3, Dafny.TypeDescriptor<T4> _td_T4, Dafny.TypeDescriptor<T5> _td_T5, Dafny.TypeDescriptor<T6> _td_T6) {
      return new Dafny.TypeDescriptor<_System._ITuple7<T0, T1, T2, T3, T4, T5, T6>>(_System.Tuple7<T0, T1, T2, T3, T4, T5, T6>.Default(_td_T0.Default(), _td_T1.Default(), _td_T2.Default(), _td_T3.Default(), _td_T4.Default(), _td_T5.Default(), _td_T6.Default()));
    }
    public static _ITuple7<T0, T1, T2, T3, T4, T5, T6> create(T0 _0, T1 _1, T2 _2, T3 _3, T4 _4, T5 _5, T6 _6) {
      return new Tuple7<T0, T1, T2, T3, T4, T5, T6>(_0, _1, _2, _3, _4, _5, _6);
    }
    public static _ITuple7<T0, T1, T2, T3, T4, T5, T6> create____hMake7(T0 _0, T1 _1, T2 _2, T3 _3, T4 _4, T5 _5, T6 _6) {
      return create(_0, _1, _2, _3, _4, _5, _6);
    }
    public T0 dtor__0 {
      get {
        return this.__0;
      }
    }
    public T1 dtor__1 {
      get {
        return this.__1;
      }
    }
    public T2 dtor__2 {
      get {
        return this.__2;
      }
    }
    public T3 dtor__3 {
      get {
        return this.__3;
      }
    }
    public T4 dtor__4 {
      get {
        return this.__4;
      }
    }
    public T5 dtor__5 {
      get {
        return this.__5;
      }
    }
    public T6 dtor__6 {
      get {
        return this.__6;
      }
    }
  }

  public interface _ITuple8<out T0, out T1, out T2, out T3, out T4, out T5, out T6, out T7> {
    T0 dtor__0 { get; }
    T1 dtor__1 { get; }
    T2 dtor__2 { get; }
    T3 dtor__3 { get; }
    T4 dtor__4 { get; }
    T5 dtor__5 { get; }
    T6 dtor__6 { get; }
    T7 dtor__7 { get; }
    _ITuple8<__T0, __T1, __T2, __T3, __T4, __T5, __T6, __T7> DowncastClone<__T0, __T1, __T2, __T3, __T4, __T5, __T6, __T7>(Func<T0, __T0> converter0, Func<T1, __T1> converter1, Func<T2, __T2> converter2, Func<T3, __T3> converter3, Func<T4, __T4> converter4, Func<T5, __T5> converter5, Func<T6, __T6> converter6, Func<T7, __T7> converter7);
  }
  public class Tuple8<T0, T1, T2, T3, T4, T5, T6, T7> : _ITuple8<T0, T1, T2, T3, T4, T5, T6, T7> {
    public readonly T0 __0;
    public readonly T1 __1;
    public readonly T2 __2;
    public readonly T3 __3;
    public readonly T4 __4;
    public readonly T5 __5;
    public readonly T6 __6;
    public readonly T7 __7;
    public Tuple8(T0 _0, T1 _1, T2 _2, T3 _3, T4 _4, T5 _5, T6 _6, T7 _7) {
      this.__0 = _0;
      this.__1 = _1;
      this.__2 = _2;
      this.__3 = _3;
      this.__4 = _4;
      this.__5 = _5;
      this.__6 = _6;
      this.__7 = _7;
    }
    public _ITuple8<__T0, __T1, __T2, __T3, __T4, __T5, __T6, __T7> DowncastClone<__T0, __T1, __T2, __T3, __T4, __T5, __T6, __T7>(Func<T0, __T0> converter0, Func<T1, __T1> converter1, Func<T2, __T2> converter2, Func<T3, __T3> converter3, Func<T4, __T4> converter4, Func<T5, __T5> converter5, Func<T6, __T6> converter6, Func<T7, __T7> converter7) {
      if (this is _ITuple8<__T0, __T1, __T2, __T3, __T4, __T5, __T6, __T7> dt) { return dt; }
      return new Tuple8<__T0, __T1, __T2, __T3, __T4, __T5, __T6, __T7>(converter0(__0), converter1(__1), converter2(__2), converter3(__3), converter4(__4), converter5(__5), converter6(__6), converter7(__7));
    }
    public override bool Equals(object other) {
      var oth = other as _System.Tuple8<T0, T1, T2, T3, T4, T5, T6, T7>;
      return oth != null && object.Equals(this.__0, oth.__0) && object.Equals(this.__1, oth.__1) && object.Equals(this.__2, oth.__2) && object.Equals(this.__3, oth.__3) && object.Equals(this.__4, oth.__4) && object.Equals(this.__5, oth.__5) && object.Equals(this.__6, oth.__6) && object.Equals(this.__7, oth.__7);
    }
    public override int GetHashCode() {
      ulong hash = 5381;
      hash = ((hash << 5) + hash) + 0;
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this.__0));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this.__1));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this.__2));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this.__3));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this.__4));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this.__5));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this.__6));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this.__7));
      return (int) hash;
    }
    public override string ToString() {
      string s = "";
      s += "(";
      s += Dafny.Helpers.ToString(this.__0);
      s += ", ";
      s += Dafny.Helpers.ToString(this.__1);
      s += ", ";
      s += Dafny.Helpers.ToString(this.__2);
      s += ", ";
      s += Dafny.Helpers.ToString(this.__3);
      s += ", ";
      s += Dafny.Helpers.ToString(this.__4);
      s += ", ";
      s += Dafny.Helpers.ToString(this.__5);
      s += ", ";
      s += Dafny.Helpers.ToString(this.__6);
      s += ", ";
      s += Dafny.Helpers.ToString(this.__7);
      s += ")";
      return s;
    }
    public static _System._ITuple8<T0, T1, T2, T3, T4, T5, T6, T7> Default(T0 _default_T0, T1 _default_T1, T2 _default_T2, T3 _default_T3, T4 _default_T4, T5 _default_T5, T6 _default_T6, T7 _default_T7) {
      return create(_default_T0, _default_T1, _default_T2, _default_T3, _default_T4, _default_T5, _default_T6, _default_T7);
    }
    public static Dafny.TypeDescriptor<_System._ITuple8<T0, T1, T2, T3, T4, T5, T6, T7>> _TypeDescriptor(Dafny.TypeDescriptor<T0> _td_T0, Dafny.TypeDescriptor<T1> _td_T1, Dafny.TypeDescriptor<T2> _td_T2, Dafny.TypeDescriptor<T3> _td_T3, Dafny.TypeDescriptor<T4> _td_T4, Dafny.TypeDescriptor<T5> _td_T5, Dafny.TypeDescriptor<T6> _td_T6, Dafny.TypeDescriptor<T7> _td_T7) {
      return new Dafny.TypeDescriptor<_System._ITuple8<T0, T1, T2, T3, T4, T5, T6, T7>>(_System.Tuple8<T0, T1, T2, T3, T4, T5, T6, T7>.Default(_td_T0.Default(), _td_T1.Default(), _td_T2.Default(), _td_T3.Default(), _td_T4.Default(), _td_T5.Default(), _td_T6.Default(), _td_T7.Default()));
    }
    public static _ITuple8<T0, T1, T2, T3, T4, T5, T6, T7> create(T0 _0, T1 _1, T2 _2, T3 _3, T4 _4, T5 _5, T6 _6, T7 _7) {
      return new Tuple8<T0, T1, T2, T3, T4, T5, T6, T7>(_0, _1, _2, _3, _4, _5, _6, _7);
    }
    public static _ITuple8<T0, T1, T2, T3, T4, T5, T6, T7> create____hMake8(T0 _0, T1 _1, T2 _2, T3 _3, T4 _4, T5 _5, T6 _6, T7 _7) {
      return create(_0, _1, _2, _3, _4, _5, _6, _7);
    }
    public T0 dtor__0 {
      get {
        return this.__0;
      }
    }
    public T1 dtor__1 {
      get {
        return this.__1;
      }
    }
    public T2 dtor__2 {
      get {
        return this.__2;
      }
    }
    public T3 dtor__3 {
      get {
        return this.__3;
      }
    }
    public T4 dtor__4 {
      get {
        return this.__4;
      }
    }
    public T5 dtor__5 {
      get {
        return this.__5;
      }
    }
    public T6 dtor__6 {
      get {
        return this.__6;
      }
    }
    public T7 dtor__7 {
      get {
        return this.__7;
      }
    }
  }

  public interface _ITuple9<out T0, out T1, out T2, out T3, out T4, out T5, out T6, out T7, out T8> {
    T0 dtor__0 { get; }
    T1 dtor__1 { get; }
    T2 dtor__2 { get; }
    T3 dtor__3 { get; }
    T4 dtor__4 { get; }
    T5 dtor__5 { get; }
    T6 dtor__6 { get; }
    T7 dtor__7 { get; }
    T8 dtor__8 { get; }
    _ITuple9<__T0, __T1, __T2, __T3, __T4, __T5, __T6, __T7, __T8> DowncastClone<__T0, __T1, __T2, __T3, __T4, __T5, __T6, __T7, __T8>(Func<T0, __T0> converter0, Func<T1, __T1> converter1, Func<T2, __T2> converter2, Func<T3, __T3> converter3, Func<T4, __T4> converter4, Func<T5, __T5> converter5, Func<T6, __T6> converter6, Func<T7, __T7> converter7, Func<T8, __T8> converter8);
  }
  public class Tuple9<T0, T1, T2, T3, T4, T5, T6, T7, T8> : _ITuple9<T0, T1, T2, T3, T4, T5, T6, T7, T8> {
    public readonly T0 __0;
    public readonly T1 __1;
    public readonly T2 __2;
    public readonly T3 __3;
    public readonly T4 __4;
    public readonly T5 __5;
    public readonly T6 __6;
    public readonly T7 __7;
    public readonly T8 __8;
    public Tuple9(T0 _0, T1 _1, T2 _2, T3 _3, T4 _4, T5 _5, T6 _6, T7 _7, T8 _8) {
      this.__0 = _0;
      this.__1 = _1;
      this.__2 = _2;
      this.__3 = _3;
      this.__4 = _4;
      this.__5 = _5;
      this.__6 = _6;
      this.__7 = _7;
      this.__8 = _8;
    }
    public _ITuple9<__T0, __T1, __T2, __T3, __T4, __T5, __T6, __T7, __T8> DowncastClone<__T0, __T1, __T2, __T3, __T4, __T5, __T6, __T7, __T8>(Func<T0, __T0> converter0, Func<T1, __T1> converter1, Func<T2, __T2> converter2, Func<T3, __T3> converter3, Func<T4, __T4> converter4, Func<T5, __T5> converter5, Func<T6, __T6> converter6, Func<T7, __T7> converter7, Func<T8, __T8> converter8) {
      if (this is _ITuple9<__T0, __T1, __T2, __T3, __T4, __T5, __T6, __T7, __T8> dt) { return dt; }
      return new Tuple9<__T0, __T1, __T2, __T3, __T4, __T5, __T6, __T7, __T8>(converter0(__0), converter1(__1), converter2(__2), converter3(__3), converter4(__4), converter5(__5), converter6(__6), converter7(__7), converter8(__8));
    }
    public override bool Equals(object other) {
      var oth = other as _System.Tuple9<T0, T1, T2, T3, T4, T5, T6, T7, T8>;
      return oth != null && object.Equals(this.__0, oth.__0) && object.Equals(this.__1, oth.__1) && object.Equals(this.__2, oth.__2) && object.Equals(this.__3, oth.__3) && object.Equals(this.__4, oth.__4) && object.Equals(this.__5, oth.__5) && object.Equals(this.__6, oth.__6) && object.Equals(this.__7, oth.__7) && object.Equals(this.__8, oth.__8);
    }
    public override int GetHashCode() {
      ulong hash = 5381;
      hash = ((hash << 5) + hash) + 0;
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this.__0));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this.__1));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this.__2));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this.__3));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this.__4));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this.__5));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this.__6));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this.__7));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this.__8));
      return (int) hash;
    }
    public override string ToString() {
      string s = "";
      s += "(";
      s += Dafny.Helpers.ToString(this.__0);
      s += ", ";
      s += Dafny.Helpers.ToString(this.__1);
      s += ", ";
      s += Dafny.Helpers.ToString(this.__2);
      s += ", ";
      s += Dafny.Helpers.ToString(this.__3);
      s += ", ";
      s += Dafny.Helpers.ToString(this.__4);
      s += ", ";
      s += Dafny.Helpers.ToString(this.__5);
      s += ", ";
      s += Dafny.Helpers.ToString(this.__6);
      s += ", ";
      s += Dafny.Helpers.ToString(this.__7);
      s += ", ";
      s += Dafny.Helpers.ToString(this.__8);
      s += ")";
      return s;
    }
    public static _System._ITuple9<T0, T1, T2, T3, T4, T5, T6, T7, T8> Default(T0 _default_T0, T1 _default_T1, T2 _default_T2, T3 _default_T3, T4 _default_T4, T5 _default_T5, T6 _default_T6, T7 _default_T7, T8 _default_T8) {
      return create(_default_T0, _default_T1, _default_T2, _default_T3, _default_T4, _default_T5, _default_T6, _default_T7, _default_T8);
    }
    public static Dafny.TypeDescriptor<_System._ITuple9<T0, T1, T2, T3, T4, T5, T6, T7, T8>> _TypeDescriptor(Dafny.TypeDescriptor<T0> _td_T0, Dafny.TypeDescriptor<T1> _td_T1, Dafny.TypeDescriptor<T2> _td_T2, Dafny.TypeDescriptor<T3> _td_T3, Dafny.TypeDescriptor<T4> _td_T4, Dafny.TypeDescriptor<T5> _td_T5, Dafny.TypeDescriptor<T6> _td_T6, Dafny.TypeDescriptor<T7> _td_T7, Dafny.TypeDescriptor<T8> _td_T8) {
      return new Dafny.TypeDescriptor<_System._ITuple9<T0, T1, T2, T3, T4, T5, T6, T7, T8>>(_System.Tuple9<T0, T1, T2, T3, T4, T5, T6, T7, T8>.Default(_td_T0.Default(), _td_T1.Default(), _td_T2.Default(), _td_T3.Default(), _td_T4.Default(), _td_T5.Default(), _td_T6.Default(), _td_T7.Default(), _td_T8.Default()));
    }
    public static _ITuple9<T0, T1, T2, T3, T4, T5, T6, T7, T8> create(T0 _0, T1 _1, T2 _2, T3 _3, T4 _4, T5 _5, T6 _6, T7 _7, T8 _8) {
      return new Tuple9<T0, T1, T2, T3, T4, T5, T6, T7, T8>(_0, _1, _2, _3, _4, _5, _6, _7, _8);
    }
    public static _ITuple9<T0, T1, T2, T3, T4, T5, T6, T7, T8> create____hMake9(T0 _0, T1 _1, T2 _2, T3 _3, T4 _4, T5 _5, T6 _6, T7 _7, T8 _8) {
      return create(_0, _1, _2, _3, _4, _5, _6, _7, _8);
    }
    public T0 dtor__0 {
      get {
        return this.__0;
      }
    }
    public T1 dtor__1 {
      get {
        return this.__1;
      }
    }
    public T2 dtor__2 {
      get {
        return this.__2;
      }
    }
    public T3 dtor__3 {
      get {
        return this.__3;
      }
    }
    public T4 dtor__4 {
      get {
        return this.__4;
      }
    }
    public T5 dtor__5 {
      get {
        return this.__5;
      }
    }
    public T6 dtor__6 {
      get {
        return this.__6;
      }
    }
    public T7 dtor__7 {
      get {
        return this.__7;
      }
    }
    public T8 dtor__8 {
      get {
        return this.__8;
      }
    }
  }

  public interface _ITuple10<out T0, out T1, out T2, out T3, out T4, out T5, out T6, out T7, out T8, out T9> {
    T0 dtor__0 { get; }
    T1 dtor__1 { get; }
    T2 dtor__2 { get; }
    T3 dtor__3 { get; }
    T4 dtor__4 { get; }
    T5 dtor__5 { get; }
    T6 dtor__6 { get; }
    T7 dtor__7 { get; }
    T8 dtor__8 { get; }
    T9 dtor__9 { get; }
    _ITuple10<__T0, __T1, __T2, __T3, __T4, __T5, __T6, __T7, __T8, __T9> DowncastClone<__T0, __T1, __T2, __T3, __T4, __T5, __T6, __T7, __T8, __T9>(Func<T0, __T0> converter0, Func<T1, __T1> converter1, Func<T2, __T2> converter2, Func<T3, __T3> converter3, Func<T4, __T4> converter4, Func<T5, __T5> converter5, Func<T6, __T6> converter6, Func<T7, __T7> converter7, Func<T8, __T8> converter8, Func<T9, __T9> converter9);
  }
  public class Tuple10<T0, T1, T2, T3, T4, T5, T6, T7, T8, T9> : _ITuple10<T0, T1, T2, T3, T4, T5, T6, T7, T8, T9> {
    public readonly T0 __0;
    public readonly T1 __1;
    public readonly T2 __2;
    public readonly T3 __3;
    public readonly T4 __4;
    public readonly T5 __5;
    public readonly T6 __6;
    public readonly T7 __7;
    public readonly T8 __8;
    public readonly T9 __9;
    public Tuple10(T0 _0, T1 _1, T2 _2, T3 _3, T4 _4, T5 _5, T6 _6, T7 _7, T8 _8, T9 _9) {
      this.__0 = _0;
      this.__1 = _1;
      this.__2 = _2;
      this.__3 = _3;
      this.__4 = _4;
      this.__5 = _5;
      this.__6 = _6;
      this.__7 = _7;
      this.__8 = _8;
      this.__9 = _9;
    }
    public _ITuple10<__T0, __T1, __T2, __T3, __T4, __T5, __T6, __T7, __T8, __T9> DowncastClone<__T0, __T1, __T2, __T3, __T4, __T5, __T6, __T7, __T8, __T9>(Func<T0, __T0> converter0, Func<T1, __T1> converter1, Func<T2, __T2> converter2, Func<T3, __T3> converter3, Func<T4, __T4> converter4, Func<T5, __T5> converter5, Func<T6, __T6> converter6, Func<T7, __T7> converter7, Func<T8, __T8> converter8, Func<T9, __T9> converter9) {
      if (this is _ITuple10<__T0, __T1, __T2, __T3, __T4, __T5, __T6, __T7, __T8, __T9> dt) { return dt; }
      return new Tuple10<__T0, __T1, __T2, __T3, __T4, __T5, __T6, __T7, __T8, __T9>(converter0(__0), converter1(__1), converter2(__2), converter3(__3), converter4(__4), converter5(__5), converter6(__6), converter7(__7), converter8(__8), converter9(__9));
    }
    public override bool Equals(object other) {
      var oth = other as _System.Tuple10<T0, T1, T2, T3, T4, T5, T6, T7, T8, T9>;
      return oth != null && object.Equals(this.__0, oth.__0) && object.Equals(this.__1, oth.__1) && object.Equals(this.__2, oth.__2) && object.Equals(this.__3, oth.__3) && object.Equals(this.__4, oth.__4) && object.Equals(this.__5, oth.__5) && object.Equals(this.__6, oth.__6) && object.Equals(this.__7, oth.__7) && object.Equals(this.__8, oth.__8) && object.Equals(this.__9, oth.__9);
    }
    public override int GetHashCode() {
      ulong hash = 5381;
      hash = ((hash << 5) + hash) + 0;
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this.__0));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this.__1));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this.__2));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this.__3));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this.__4));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this.__5));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this.__6));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this.__7));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this.__8));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this.__9));
      return (int) hash;
    }
    public override string ToString() {
      string s = "";
      s += "(";
      s += Dafny.Helpers.ToString(this.__0);
      s += ", ";
      s += Dafny.Helpers.ToString(this.__1);
      s += ", ";
      s += Dafny.Helpers.ToString(this.__2);
      s += ", ";
      s += Dafny.Helpers.ToString(this.__3);
      s += ", ";
      s += Dafny.Helpers.ToString(this.__4);
      s += ", ";
      s += Dafny.Helpers.ToString(this.__5);
      s += ", ";
      s += Dafny.Helpers.ToString(this.__6);
      s += ", ";
      s += Dafny.Helpers.ToString(this.__7);
      s += ", ";
      s += Dafny.Helpers.ToString(this.__8);
      s += ", ";
      s += Dafny.Helpers.ToString(this.__9);
      s += ")";
      return s;
    }
    public static _System._ITuple10<T0, T1, T2, T3, T4, T5, T6, T7, T8, T9> Default(T0 _default_T0, T1 _default_T1, T2 _default_T2, T3 _default_T3, T4 _default_T4, T5 _default_T5, T6 _default_T6, T7 _default_T7, T8 _default_T8, T9 _default_T9) {
      return create(_default_T0, _default_T1, _default_T2, _default_T3, _default_T4, _default_T5, _default_T6, _default_T7, _default_T8, _default_T9);
    }
    public static Dafny.TypeDescriptor<_System._ITuple10<T0, T1, T2, T3, T4, T5, T6, T7, T8, T9>> _TypeDescriptor(Dafny.TypeDescriptor<T0> _td_T0, Dafny.TypeDescriptor<T1> _td_T1, Dafny.TypeDescriptor<T2> _td_T2, Dafny.TypeDescriptor<T3> _td_T3, Dafny.TypeDescriptor<T4> _td_T4, Dafny.TypeDescriptor<T5> _td_T5, Dafny.TypeDescriptor<T6> _td_T6, Dafny.TypeDescriptor<T7> _td_T7, Dafny.TypeDescriptor<T8> _td_T8, Dafny.TypeDescriptor<T9> _td_T9) {
      return new Dafny.TypeDescriptor<_System._ITuple10<T0, T1, T2, T3, T4, T5, T6, T7, T8, T9>>(_System.Tuple10<T0, T1, T2, T3, T4, T5, T6, T7, T8, T9>.Default(_td_T0.Default(), _td_T1.Default(), _td_T2.Default(), _td_T3.Default(), _td_T4.Default(), _td_T5.Default(), _td_T6.Default(), _td_T7.Default(), _td_T8.Default(), _td_T9.Default()));
    }
    public static _ITuple10<T0, T1, T2, T3, T4, T5, T6, T7, T8, T9> create(T0 _0, T1 _1, T2 _2, T3 _3, T4 _4, T5 _5, T6 _6, T7 _7, T8 _8, T9 _9) {
      return new Tuple10<T0, T1, T2, T3, T4, T5, T6, T7, T8, T9>(_0, _1, _2, _3, _4, _5, _6, _7, _8, _9);
    }
    public static _ITuple10<T0, T1, T2, T3, T4, T5, T6, T7, T8, T9> create____hMake10(T0 _0, T1 _1, T2 _2, T3 _3, T4 _4, T5 _5, T6 _6, T7 _7, T8 _8, T9 _9) {
      return create(_0, _1, _2, _3, _4, _5, _6, _7, _8, _9);
    }
    public T0 dtor__0 {
      get {
        return this.__0;
      }
    }
    public T1 dtor__1 {
      get {
        return this.__1;
      }
    }
    public T2 dtor__2 {
      get {
        return this.__2;
      }
    }
    public T3 dtor__3 {
      get {
        return this.__3;
      }
    }
    public T4 dtor__4 {
      get {
        return this.__4;
      }
    }
    public T5 dtor__5 {
      get {
        return this.__5;
      }
    }
    public T6 dtor__6 {
      get {
        return this.__6;
      }
    }
    public T7 dtor__7 {
      get {
        return this.__7;
      }
    }
    public T8 dtor__8 {
      get {
        return this.__8;
      }
    }
    public T9 dtor__9 {
      get {
        return this.__9;
      }
    }
  }

  public interface _ITuple11<out T0, out T1, out T2, out T3, out T4, out T5, out T6, out T7, out T8, out T9, out T10> {
    T0 dtor__0 { get; }
    T1 dtor__1 { get; }
    T2 dtor__2 { get; }
    T3 dtor__3 { get; }
    T4 dtor__4 { get; }
    T5 dtor__5 { get; }
    T6 dtor__6 { get; }
    T7 dtor__7 { get; }
    T8 dtor__8 { get; }
    T9 dtor__9 { get; }
    T10 dtor__10 { get; }
    _ITuple11<__T0, __T1, __T2, __T3, __T4, __T5, __T6, __T7, __T8, __T9, __T10> DowncastClone<__T0, __T1, __T2, __T3, __T4, __T5, __T6, __T7, __T8, __T9, __T10>(Func<T0, __T0> converter0, Func<T1, __T1> converter1, Func<T2, __T2> converter2, Func<T3, __T3> converter3, Func<T4, __T4> converter4, Func<T5, __T5> converter5, Func<T6, __T6> converter6, Func<T7, __T7> converter7, Func<T8, __T8> converter8, Func<T9, __T9> converter9, Func<T10, __T10> converter10);
  }
  public class Tuple11<T0, T1, T2, T3, T4, T5, T6, T7, T8, T9, T10> : _ITuple11<T0, T1, T2, T3, T4, T5, T6, T7, T8, T9, T10> {
    public readonly T0 __0;
    public readonly T1 __1;
    public readonly T2 __2;
    public readonly T3 __3;
    public readonly T4 __4;
    public readonly T5 __5;
    public readonly T6 __6;
    public readonly T7 __7;
    public readonly T8 __8;
    public readonly T9 __9;
    public readonly T10 __10;
    public Tuple11(T0 _0, T1 _1, T2 _2, T3 _3, T4 _4, T5 _5, T6 _6, T7 _7, T8 _8, T9 _9, T10 _10) {
      this.__0 = _0;
      this.__1 = _1;
      this.__2 = _2;
      this.__3 = _3;
      this.__4 = _4;
      this.__5 = _5;
      this.__6 = _6;
      this.__7 = _7;
      this.__8 = _8;
      this.__9 = _9;
      this.__10 = _10;
    }
    public _ITuple11<__T0, __T1, __T2, __T3, __T4, __T5, __T6, __T7, __T8, __T9, __T10> DowncastClone<__T0, __T1, __T2, __T3, __T4, __T5, __T6, __T7, __T8, __T9, __T10>(Func<T0, __T0> converter0, Func<T1, __T1> converter1, Func<T2, __T2> converter2, Func<T3, __T3> converter3, Func<T4, __T4> converter4, Func<T5, __T5> converter5, Func<T6, __T6> converter6, Func<T7, __T7> converter7, Func<T8, __T8> converter8, Func<T9, __T9> converter9, Func<T10, __T10> converter10) {
      if (this is _ITuple11<__T0, __T1, __T2, __T3, __T4, __T5, __T6, __T7, __T8, __T9, __T10> dt) { return dt; }
      return new Tuple11<__T0, __T1, __T2, __T3, __T4, __T5, __T6, __T7, __T8, __T9, __T10>(converter0(__0), converter1(__1), converter2(__2), converter3(__3), converter4(__4), converter5(__5), converter6(__6), converter7(__7), converter8(__8), converter9(__9), converter10(__10));
    }
    public override bool Equals(object other) {
      var oth = other as _System.Tuple11<T0, T1, T2, T3, T4, T5, T6, T7, T8, T9, T10>;
      return oth != null && object.Equals(this.__0, oth.__0) && object.Equals(this.__1, oth.__1) && object.Equals(this.__2, oth.__2) && object.Equals(this.__3, oth.__3) && object.Equals(this.__4, oth.__4) && object.Equals(this.__5, oth.__5) && object.Equals(this.__6, oth.__6) && object.Equals(this.__7, oth.__7) && object.Equals(this.__8, oth.__8) && object.Equals(this.__9, oth.__9) && object.Equals(this.__10, oth.__10);
    }
    public override int GetHashCode() {
      ulong hash = 5381;
      hash = ((hash << 5) + hash) + 0;
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this.__0));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this.__1));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this.__2));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this.__3));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this.__4));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this.__5));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this.__6));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this.__7));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this.__8));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this.__9));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this.__10));
      return (int) hash;
    }
    public override string ToString() {
      string s = "";
      s += "(";
      s += Dafny.Helpers.ToString(this.__0);
      s += ", ";
      s += Dafny.Helpers.ToString(this.__1);
      s += ", ";
      s += Dafny.Helpers.ToString(this.__2);
      s += ", ";
      s += Dafny.Helpers.ToString(this.__3);
      s += ", ";
      s += Dafny.Helpers.ToString(this.__4);
      s += ", ";
      s += Dafny.Helpers.ToString(this.__5);
      s += ", ";
      s += Dafny.Helpers.ToString(this.__6);
      s += ", ";
      s += Dafny.Helpers.ToString(this.__7);
      s += ", ";
      s += Dafny.Helpers.ToString(this.__8);
      s += ", ";
      s += Dafny.Helpers.ToString(this.__9);
      s += ", ";
      s += Dafny.Helpers.ToString(this.__10);
      s += ")";
      return s;
    }
    public static _System._ITuple11<T0, T1, T2, T3, T4, T5, T6, T7, T8, T9, T10> Default(T0 _default_T0, T1 _default_T1, T2 _default_T2, T3 _default_T3, T4 _default_T4, T5 _default_T5, T6 _default_T6, T7 _default_T7, T8 _default_T8, T9 _default_T9, T10 _default_T10) {
      return create(_default_T0, _default_T1, _default_T2, _default_T3, _default_T4, _default_T5, _default_T6, _default_T7, _default_T8, _default_T9, _default_T10);
    }
    public static Dafny.TypeDescriptor<_System._ITuple11<T0, T1, T2, T3, T4, T5, T6, T7, T8, T9, T10>> _TypeDescriptor(Dafny.TypeDescriptor<T0> _td_T0, Dafny.TypeDescriptor<T1> _td_T1, Dafny.TypeDescriptor<T2> _td_T2, Dafny.TypeDescriptor<T3> _td_T3, Dafny.TypeDescriptor<T4> _td_T4, Dafny.TypeDescriptor<T5> _td_T5, Dafny.TypeDescriptor<T6> _td_T6, Dafny.TypeDescriptor<T7> _td_T7, Dafny.TypeDescriptor<T8> _td_T8, Dafny.TypeDescriptor<T9> _td_T9, Dafny.TypeDescriptor<T10> _td_T10) {
      return new Dafny.TypeDescriptor<_System._ITuple11<T0, T1, T2, T3, T4, T5, T6, T7, T8, T9, T10>>(_System.Tuple11<T0, T1, T2, T3, T4, T5, T6, T7, T8, T9, T10>.Default(_td_T0.Default(), _td_T1.Default(), _td_T2.Default(), _td_T3.Default(), _td_T4.Default(), _td_T5.Default(), _td_T6.Default(), _td_T7.Default(), _td_T8.Default(), _td_T9.Default(), _td_T10.Default()));
    }
    public static _ITuple11<T0, T1, T2, T3, T4, T5, T6, T7, T8, T9, T10> create(T0 _0, T1 _1, T2 _2, T3 _3, T4 _4, T5 _5, T6 _6, T7 _7, T8 _8, T9 _9, T10 _10) {
      return new Tuple11<T0, T1, T2, T3, T4, T5, T6, T7, T8, T9, T10>(_0, _1, _2, _3, _4, _5, _6, _7, _8, _9, _10);
    }
    public static _ITuple11<T0, T1, T2, T3, T4, T5, T6, T7, T8, T9, T10> create____hMake11(T0 _0, T1 _1, T2 _2, T3 _3, T4 _4, T5 _5, T6 _6, T7 _7, T8 _8, T9 _9, T10 _10) {
      return create(_0, _1, _2, _3, _4, _5, _6, _7, _8, _9, _10);
    }
    public T0 dtor__0 {
      get {
        return this.__0;
      }
    }
    public T1 dtor__1 {
      get {
        return this.__1;
      }
    }
    public T2 dtor__2 {
      get {
        return this.__2;
      }
    }
    public T3 dtor__3 {
      get {
        return this.__3;
      }
    }
    public T4 dtor__4 {
      get {
        return this.__4;
      }
    }
    public T5 dtor__5 {
      get {
        return this.__5;
      }
    }
    public T6 dtor__6 {
      get {
        return this.__6;
      }
    }
    public T7 dtor__7 {
      get {
        return this.__7;
      }
    }
    public T8 dtor__8 {
      get {
        return this.__8;
      }
    }
    public T9 dtor__9 {
      get {
        return this.__9;
      }
    }
    public T10 dtor__10 {
      get {
        return this.__10;
      }
    }
  }

  public interface _ITuple12<out T0, out T1, out T2, out T3, out T4, out T5, out T6, out T7, out T8, out T9, out T10, out T11> {
    T0 dtor__0 { get; }
    T1 dtor__1 { get; }
    T2 dtor__2 { get; }
    T3 dtor__3 { get; }
    T4 dtor__4 { get; }
    T5 dtor__5 { get; }
    T6 dtor__6 { get; }
    T7 dtor__7 { get; }
    T8 dtor__8 { get; }
    T9 dtor__9 { get; }
    T10 dtor__10 { get; }
    T11 dtor__11 { get; }
    _ITuple12<__T0, __T1, __T2, __T3, __T4, __T5, __T6, __T7, __T8, __T9, __T10, __T11> DowncastClone<__T0, __T1, __T2, __T3, __T4, __T5, __T6, __T7, __T8, __T9, __T10, __T11>(Func<T0, __T0> converter0, Func<T1, __T1> converter1, Func<T2, __T2> converter2, Func<T3, __T3> converter3, Func<T4, __T4> converter4, Func<T5, __T5> converter5, Func<T6, __T6> converter6, Func<T7, __T7> converter7, Func<T8, __T8> converter8, Func<T9, __T9> converter9, Func<T10, __T10> converter10, Func<T11, __T11> converter11);
  }
  public class Tuple12<T0, T1, T2, T3, T4, T5, T6, T7, T8, T9, T10, T11> : _ITuple12<T0, T1, T2, T3, T4, T5, T6, T7, T8, T9, T10, T11> {
    public readonly T0 __0;
    public readonly T1 __1;
    public readonly T2 __2;
    public readonly T3 __3;
    public readonly T4 __4;
    public readonly T5 __5;
    public readonly T6 __6;
    public readonly T7 __7;
    public readonly T8 __8;
    public readonly T9 __9;
    public readonly T10 __10;
    public readonly T11 __11;
    public Tuple12(T0 _0, T1 _1, T2 _2, T3 _3, T4 _4, T5 _5, T6 _6, T7 _7, T8 _8, T9 _9, T10 _10, T11 _11) {
      this.__0 = _0;
      this.__1 = _1;
      this.__2 = _2;
      this.__3 = _3;
      this.__4 = _4;
      this.__5 = _5;
      this.__6 = _6;
      this.__7 = _7;
      this.__8 = _8;
      this.__9 = _9;
      this.__10 = _10;
      this.__11 = _11;
    }
    public _ITuple12<__T0, __T1, __T2, __T3, __T4, __T5, __T6, __T7, __T8, __T9, __T10, __T11> DowncastClone<__T0, __T1, __T2, __T3, __T4, __T5, __T6, __T7, __T8, __T9, __T10, __T11>(Func<T0, __T0> converter0, Func<T1, __T1> converter1, Func<T2, __T2> converter2, Func<T3, __T3> converter3, Func<T4, __T4> converter4, Func<T5, __T5> converter5, Func<T6, __T6> converter6, Func<T7, __T7> converter7, Func<T8, __T8> converter8, Func<T9, __T9> converter9, Func<T10, __T10> converter10, Func<T11, __T11> converter11) {
      if (this is _ITuple12<__T0, __T1, __T2, __T3, __T4, __T5, __T6, __T7, __T8, __T9, __T10, __T11> dt) { return dt; }
      return new Tuple12<__T0, __T1, __T2, __T3, __T4, __T5, __T6, __T7, __T8, __T9, __T10, __T11>(converter0(__0), converter1(__1), converter2(__2), converter3(__3), converter4(__4), converter5(__5), converter6(__6), converter7(__7), converter8(__8), converter9(__9), converter10(__10), converter11(__11));
    }
    public override bool Equals(object other) {
      var oth = other as _System.Tuple12<T0, T1, T2, T3, T4, T5, T6, T7, T8, T9, T10, T11>;
      return oth != null && object.Equals(this.__0, oth.__0) && object.Equals(this.__1, oth.__1) && object.Equals(this.__2, oth.__2) && object.Equals(this.__3, oth.__3) && object.Equals(this.__4, oth.__4) && object.Equals(this.__5, oth.__5) && object.Equals(this.__6, oth.__6) && object.Equals(this.__7, oth.__7) && object.Equals(this.__8, oth.__8) && object.Equals(this.__9, oth.__9) && object.Equals(this.__10, oth.__10) && object.Equals(this.__11, oth.__11);
    }
    public override int GetHashCode() {
      ulong hash = 5381;
      hash = ((hash << 5) + hash) + 0;
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this.__0));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this.__1));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this.__2));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this.__3));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this.__4));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this.__5));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this.__6));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this.__7));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this.__8));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this.__9));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this.__10));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this.__11));
      return (int) hash;
    }
    public override string ToString() {
      string s = "";
      s += "(";
      s += Dafny.Helpers.ToString(this.__0);
      s += ", ";
      s += Dafny.Helpers.ToString(this.__1);
      s += ", ";
      s += Dafny.Helpers.ToString(this.__2);
      s += ", ";
      s += Dafny.Helpers.ToString(this.__3);
      s += ", ";
      s += Dafny.Helpers.ToString(this.__4);
      s += ", ";
      s += Dafny.Helpers.ToString(this.__5);
      s += ", ";
      s += Dafny.Helpers.ToString(this.__6);
      s += ", ";
      s += Dafny.Helpers.ToString(this.__7);
      s += ", ";
      s += Dafny.Helpers.ToString(this.__8);
      s += ", ";
      s += Dafny.Helpers.ToString(this.__9);
      s += ", ";
      s += Dafny.Helpers.ToString(this.__10);
      s += ", ";
      s += Dafny.Helpers.ToString(this.__11);
      s += ")";
      return s;
    }
    public static _System._ITuple12<T0, T1, T2, T3, T4, T5, T6, T7, T8, T9, T10, T11> Default(T0 _default_T0, T1 _default_T1, T2 _default_T2, T3 _default_T3, T4 _default_T4, T5 _default_T5, T6 _default_T6, T7 _default_T7, T8 _default_T8, T9 _default_T9, T10 _default_T10, T11 _default_T11) {
      return create(_default_T0, _default_T1, _default_T2, _default_T3, _default_T4, _default_T5, _default_T6, _default_T7, _default_T8, _default_T9, _default_T10, _default_T11);
    }
    public static Dafny.TypeDescriptor<_System._ITuple12<T0, T1, T2, T3, T4, T5, T6, T7, T8, T9, T10, T11>> _TypeDescriptor(Dafny.TypeDescriptor<T0> _td_T0, Dafny.TypeDescriptor<T1> _td_T1, Dafny.TypeDescriptor<T2> _td_T2, Dafny.TypeDescriptor<T3> _td_T3, Dafny.TypeDescriptor<T4> _td_T4, Dafny.TypeDescriptor<T5> _td_T5, Dafny.TypeDescriptor<T6> _td_T6, Dafny.TypeDescriptor<T7> _td_T7, Dafny.TypeDescriptor<T8> _td_T8, Dafny.TypeDescriptor<T9> _td_T9, Dafny.TypeDescriptor<T10> _td_T10, Dafny.TypeDescriptor<T11> _td_T11) {
      return new Dafny.TypeDescriptor<_System._ITuple12<T0, T1, T2, T3, T4, T5, T6, T7, T8, T9, T10, T11>>(_System.Tuple12<T0, T1, T2, T3, T4, T5, T6, T7, T8, T9, T10, T11>.Default(_td_T0.Default(), _td_T1.Default(), _td_T2.Default(), _td_T3.Default(), _td_T4.Default(), _td_T5.Default(), _td_T6.Default(), _td_T7.Default(), _td_T8.Default(), _td_T9.Default(), _td_T10.Default(), _td_T11.Default()));
    }
    public static _ITuple12<T0, T1, T2, T3, T4, T5, T6, T7, T8, T9, T10, T11> create(T0 _0, T1 _1, T2 _2, T3 _3, T4 _4, T5 _5, T6 _6, T7 _7, T8 _8, T9 _9, T10 _10, T11 _11) {
      return new Tuple12<T0, T1, T2, T3, T4, T5, T6, T7, T8, T9, T10, T11>(_0, _1, _2, _3, _4, _5, _6, _7, _8, _9, _10, _11);
    }
    public static _ITuple12<T0, T1, T2, T3, T4, T5, T6, T7, T8, T9, T10, T11> create____hMake12(T0 _0, T1 _1, T2 _2, T3 _3, T4 _4, T5 _5, T6 _6, T7 _7, T8 _8, T9 _9, T10 _10, T11 _11) {
      return create(_0, _1, _2, _3, _4, _5, _6, _7, _8, _9, _10, _11);
    }
    public T0 dtor__0 {
      get {
        return this.__0;
      }
    }
    public T1 dtor__1 {
      get {
        return this.__1;
      }
    }
    public T2 dtor__2 {
      get {
        return this.__2;
      }
    }
    public T3 dtor__3 {
      get {
        return this.__3;
      }
    }
    public T4 dtor__4 {
      get {
        return this.__4;
      }
    }
    public T5 dtor__5 {
      get {
        return this.__5;
      }
    }
    public T6 dtor__6 {
      get {
        return this.__6;
      }
    }
    public T7 dtor__7 {
      get {
        return this.__7;
      }
    }
    public T8 dtor__8 {
      get {
        return this.__8;
      }
    }
    public T9 dtor__9 {
      get {
        return this.__9;
      }
    }
    public T10 dtor__10 {
      get {
        return this.__10;
      }
    }
    public T11 dtor__11 {
      get {
        return this.__11;
      }
    }
  }

  public interface _ITuple13<out T0, out T1, out T2, out T3, out T4, out T5, out T6, out T7, out T8, out T9, out T10, out T11, out T12> {
    T0 dtor__0 { get; }
    T1 dtor__1 { get; }
    T2 dtor__2 { get; }
    T3 dtor__3 { get; }
    T4 dtor__4 { get; }
    T5 dtor__5 { get; }
    T6 dtor__6 { get; }
    T7 dtor__7 { get; }
    T8 dtor__8 { get; }
    T9 dtor__9 { get; }
    T10 dtor__10 { get; }
    T11 dtor__11 { get; }
    T12 dtor__12 { get; }
    _ITuple13<__T0, __T1, __T2, __T3, __T4, __T5, __T6, __T7, __T8, __T9, __T10, __T11, __T12> DowncastClone<__T0, __T1, __T2, __T3, __T4, __T5, __T6, __T7, __T8, __T9, __T10, __T11, __T12>(Func<T0, __T0> converter0, Func<T1, __T1> converter1, Func<T2, __T2> converter2, Func<T3, __T3> converter3, Func<T4, __T4> converter4, Func<T5, __T5> converter5, Func<T6, __T6> converter6, Func<T7, __T7> converter7, Func<T8, __T8> converter8, Func<T9, __T9> converter9, Func<T10, __T10> converter10, Func<T11, __T11> converter11, Func<T12, __T12> converter12);
  }
  public class Tuple13<T0, T1, T2, T3, T4, T5, T6, T7, T8, T9, T10, T11, T12> : _ITuple13<T0, T1, T2, T3, T4, T5, T6, T7, T8, T9, T10, T11, T12> {
    public readonly T0 __0;
    public readonly T1 __1;
    public readonly T2 __2;
    public readonly T3 __3;
    public readonly T4 __4;
    public readonly T5 __5;
    public readonly T6 __6;
    public readonly T7 __7;
    public readonly T8 __8;
    public readonly T9 __9;
    public readonly T10 __10;
    public readonly T11 __11;
    public readonly T12 __12;
    public Tuple13(T0 _0, T1 _1, T2 _2, T3 _3, T4 _4, T5 _5, T6 _6, T7 _7, T8 _8, T9 _9, T10 _10, T11 _11, T12 _12) {
      this.__0 = _0;
      this.__1 = _1;
      this.__2 = _2;
      this.__3 = _3;
      this.__4 = _4;
      this.__5 = _5;
      this.__6 = _6;
      this.__7 = _7;
      this.__8 = _8;
      this.__9 = _9;
      this.__10 = _10;
      this.__11 = _11;
      this.__12 = _12;
    }
    public _ITuple13<__T0, __T1, __T2, __T3, __T4, __T5, __T6, __T7, __T8, __T9, __T10, __T11, __T12> DowncastClone<__T0, __T1, __T2, __T3, __T4, __T5, __T6, __T7, __T8, __T9, __T10, __T11, __T12>(Func<T0, __T0> converter0, Func<T1, __T1> converter1, Func<T2, __T2> converter2, Func<T3, __T3> converter3, Func<T4, __T4> converter4, Func<T5, __T5> converter5, Func<T6, __T6> converter6, Func<T7, __T7> converter7, Func<T8, __T8> converter8, Func<T9, __T9> converter9, Func<T10, __T10> converter10, Func<T11, __T11> converter11, Func<T12, __T12> converter12) {
      if (this is _ITuple13<__T0, __T1, __T2, __T3, __T4, __T5, __T6, __T7, __T8, __T9, __T10, __T11, __T12> dt) { return dt; }
      return new Tuple13<__T0, __T1, __T2, __T3, __T4, __T5, __T6, __T7, __T8, __T9, __T10, __T11, __T12>(converter0(__0), converter1(__1), converter2(__2), converter3(__3), converter4(__4), converter5(__5), converter6(__6), converter7(__7), converter8(__8), converter9(__9), converter10(__10), converter11(__11), converter12(__12));
    }
    public override bool Equals(object other) {
      var oth = other as _System.Tuple13<T0, T1, T2, T3, T4, T5, T6, T7, T8, T9, T10, T11, T12>;
      return oth != null && object.Equals(this.__0, oth.__0) && object.Equals(this.__1, oth.__1) && object.Equals(this.__2, oth.__2) && object.Equals(this.__3, oth.__3) && object.Equals(this.__4, oth.__4) && object.Equals(this.__5, oth.__5) && object.Equals(this.__6, oth.__6) && object.Equals(this.__7, oth.__7) && object.Equals(this.__8, oth.__8) && object.Equals(this.__9, oth.__9) && object.Equals(this.__10, oth.__10) && object.Equals(this.__11, oth.__11) && object.Equals(this.__12, oth.__12);
    }
    public override int GetHashCode() {
      ulong hash = 5381;
      hash = ((hash << 5) + hash) + 0;
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this.__0));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this.__1));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this.__2));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this.__3));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this.__4));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this.__5));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this.__6));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this.__7));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this.__8));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this.__9));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this.__10));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this.__11));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this.__12));
      return (int) hash;
    }
    public override string ToString() {
      string s = "";
      s += "(";
      s += Dafny.Helpers.ToString(this.__0);
      s += ", ";
      s += Dafny.Helpers.ToString(this.__1);
      s += ", ";
      s += Dafny.Helpers.ToString(this.__2);
      s += ", ";
      s += Dafny.Helpers.ToString(this.__3);
      s += ", ";
      s += Dafny.Helpers.ToString(this.__4);
      s += ", ";
      s += Dafny.Helpers.ToString(this.__5);
      s += ", ";
      s += Dafny.Helpers.ToString(this.__6);
      s += ", ";
      s += Dafny.Helpers.ToString(this.__7);
      s += ", ";
      s += Dafny.Helpers.ToString(this.__8);
      s += ", ";
      s += Dafny.Helpers.ToString(this.__9);
      s += ", ";
      s += Dafny.Helpers.ToString(this.__10);
      s += ", ";
      s += Dafny.Helpers.ToString(this.__11);
      s += ", ";
      s += Dafny.Helpers.ToString(this.__12);
      s += ")";
      return s;
    }
    public static _System._ITuple13<T0, T1, T2, T3, T4, T5, T6, T7, T8, T9, T10, T11, T12> Default(T0 _default_T0, T1 _default_T1, T2 _default_T2, T3 _default_T3, T4 _default_T4, T5 _default_T5, T6 _default_T6, T7 _default_T7, T8 _default_T8, T9 _default_T9, T10 _default_T10, T11 _default_T11, T12 _default_T12) {
      return create(_default_T0, _default_T1, _default_T2, _default_T3, _default_T4, _default_T5, _default_T6, _default_T7, _default_T8, _default_T9, _default_T10, _default_T11, _default_T12);
    }
    public static Dafny.TypeDescriptor<_System._ITuple13<T0, T1, T2, T3, T4, T5, T6, T7, T8, T9, T10, T11, T12>> _TypeDescriptor(Dafny.TypeDescriptor<T0> _td_T0, Dafny.TypeDescriptor<T1> _td_T1, Dafny.TypeDescriptor<T2> _td_T2, Dafny.TypeDescriptor<T3> _td_T3, Dafny.TypeDescriptor<T4> _td_T4, Dafny.TypeDescriptor<T5> _td_T5, Dafny.TypeDescriptor<T6> _td_T6, Dafny.TypeDescriptor<T7> _td_T7, Dafny.TypeDescriptor<T8> _td_T8, Dafny.TypeDescriptor<T9> _td_T9, Dafny.TypeDescriptor<T10> _td_T10, Dafny.TypeDescriptor<T11> _td_T11, Dafny.TypeDescriptor<T12> _td_T12) {
      return new Dafny.TypeDescriptor<_System._ITuple13<T0, T1, T2, T3, T4, T5, T6, T7, T8, T9, T10, T11, T12>>(_System.Tuple13<T0, T1, T2, T3, T4, T5, T6, T7, T8, T9, T10, T11, T12>.Default(_td_T0.Default(), _td_T1.Default(), _td_T2.Default(), _td_T3.Default(), _td_T4.Default(), _td_T5.Default(), _td_T6.Default(), _td_T7.Default(), _td_T8.Default(), _td_T9.Default(), _td_T10.Default(), _td_T11.Default(), _td_T12.Default()));
    }
    public static _ITuple13<T0, T1, T2, T3, T4, T5, T6, T7, T8, T9, T10, T11, T12> create(T0 _0, T1 _1, T2 _2, T3 _3, T4 _4, T5 _5, T6 _6, T7 _7, T8 _8, T9 _9, T10 _10, T11 _11, T12 _12) {
      return new Tuple13<T0, T1, T2, T3, T4, T5, T6, T7, T8, T9, T10, T11, T12>(_0, _1, _2, _3, _4, _5, _6, _7, _8, _9, _10, _11, _12);
    }
    public static _ITuple13<T0, T1, T2, T3, T4, T5, T6, T7, T8, T9, T10, T11, T12> create____hMake13(T0 _0, T1 _1, T2 _2, T3 _3, T4 _4, T5 _5, T6 _6, T7 _7, T8 _8, T9 _9, T10 _10, T11 _11, T12 _12) {
      return create(_0, _1, _2, _3, _4, _5, _6, _7, _8, _9, _10, _11, _12);
    }
    public T0 dtor__0 {
      get {
        return this.__0;
      }
    }
    public T1 dtor__1 {
      get {
        return this.__1;
      }
    }
    public T2 dtor__2 {
      get {
        return this.__2;
      }
    }
    public T3 dtor__3 {
      get {
        return this.__3;
      }
    }
    public T4 dtor__4 {
      get {
        return this.__4;
      }
    }
    public T5 dtor__5 {
      get {
        return this.__5;
      }
    }
    public T6 dtor__6 {
      get {
        return this.__6;
      }
    }
    public T7 dtor__7 {
      get {
        return this.__7;
      }
    }
    public T8 dtor__8 {
      get {
        return this.__8;
      }
    }
    public T9 dtor__9 {
      get {
        return this.__9;
      }
    }
    public T10 dtor__10 {
      get {
        return this.__10;
      }
    }
    public T11 dtor__11 {
      get {
        return this.__11;
      }
    }
    public T12 dtor__12 {
      get {
        return this.__12;
      }
    }
  }

  public interface _ITuple14<out T0, out T1, out T2, out T3, out T4, out T5, out T6, out T7, out T8, out T9, out T10, out T11, out T12, out T13> {
    T0 dtor__0 { get; }
    T1 dtor__1 { get; }
    T2 dtor__2 { get; }
    T3 dtor__3 { get; }
    T4 dtor__4 { get; }
    T5 dtor__5 { get; }
    T6 dtor__6 { get; }
    T7 dtor__7 { get; }
    T8 dtor__8 { get; }
    T9 dtor__9 { get; }
    T10 dtor__10 { get; }
    T11 dtor__11 { get; }
    T12 dtor__12 { get; }
    T13 dtor__13 { get; }
    _ITuple14<__T0, __T1, __T2, __T3, __T4, __T5, __T6, __T7, __T8, __T9, __T10, __T11, __T12, __T13> DowncastClone<__T0, __T1, __T2, __T3, __T4, __T5, __T6, __T7, __T8, __T9, __T10, __T11, __T12, __T13>(Func<T0, __T0> converter0, Func<T1, __T1> converter1, Func<T2, __T2> converter2, Func<T3, __T3> converter3, Func<T4, __T4> converter4, Func<T5, __T5> converter5, Func<T6, __T6> converter6, Func<T7, __T7> converter7, Func<T8, __T8> converter8, Func<T9, __T9> converter9, Func<T10, __T10> converter10, Func<T11, __T11> converter11, Func<T12, __T12> converter12, Func<T13, __T13> converter13);
  }
  public class Tuple14<T0, T1, T2, T3, T4, T5, T6, T7, T8, T9, T10, T11, T12, T13> : _ITuple14<T0, T1, T2, T3, T4, T5, T6, T7, T8, T9, T10, T11, T12, T13> {
    public readonly T0 __0;
    public readonly T1 __1;
    public readonly T2 __2;
    public readonly T3 __3;
    public readonly T4 __4;
    public readonly T5 __5;
    public readonly T6 __6;
    public readonly T7 __7;
    public readonly T8 __8;
    public readonly T9 __9;
    public readonly T10 __10;
    public readonly T11 __11;
    public readonly T12 __12;
    public readonly T13 __13;
    public Tuple14(T0 _0, T1 _1, T2 _2, T3 _3, T4 _4, T5 _5, T6 _6, T7 _7, T8 _8, T9 _9, T10 _10, T11 _11, T12 _12, T13 _13) {
      this.__0 = _0;
      this.__1 = _1;
      this.__2 = _2;
      this.__3 = _3;
      this.__4 = _4;
      this.__5 = _5;
      this.__6 = _6;
      this.__7 = _7;
      this.__8 = _8;
      this.__9 = _9;
      this.__10 = _10;
      this.__11 = _11;
      this.__12 = _12;
      this.__13 = _13;
    }
    public _ITuple14<__T0, __T1, __T2, __T3, __T4, __T5, __T6, __T7, __T8, __T9, __T10, __T11, __T12, __T13> DowncastClone<__T0, __T1, __T2, __T3, __T4, __T5, __T6, __T7, __T8, __T9, __T10, __T11, __T12, __T13>(Func<T0, __T0> converter0, Func<T1, __T1> converter1, Func<T2, __T2> converter2, Func<T3, __T3> converter3, Func<T4, __T4> converter4, Func<T5, __T5> converter5, Func<T6, __T6> converter6, Func<T7, __T7> converter7, Func<T8, __T8> converter8, Func<T9, __T9> converter9, Func<T10, __T10> converter10, Func<T11, __T11> converter11, Func<T12, __T12> converter12, Func<T13, __T13> converter13) {
      if (this is _ITuple14<__T0, __T1, __T2, __T3, __T4, __T5, __T6, __T7, __T8, __T9, __T10, __T11, __T12, __T13> dt) { return dt; }
      return new Tuple14<__T0, __T1, __T2, __T3, __T4, __T5, __T6, __T7, __T8, __T9, __T10, __T11, __T12, __T13>(converter0(__0), converter1(__1), converter2(__2), converter3(__3), converter4(__4), converter5(__5), converter6(__6), converter7(__7), converter8(__8), converter9(__9), converter10(__10), converter11(__11), converter12(__12), converter13(__13));
    }
    public override bool Equals(object other) {
      var oth = other as _System.Tuple14<T0, T1, T2, T3, T4, T5, T6, T7, T8, T9, T10, T11, T12, T13>;
      return oth != null && object.Equals(this.__0, oth.__0) && object.Equals(this.__1, oth.__1) && object.Equals(this.__2, oth.__2) && object.Equals(this.__3, oth.__3) && object.Equals(this.__4, oth.__4) && object.Equals(this.__5, oth.__5) && object.Equals(this.__6, oth.__6) && object.Equals(this.__7, oth.__7) && object.Equals(this.__8, oth.__8) && object.Equals(this.__9, oth.__9) && object.Equals(this.__10, oth.__10) && object.Equals(this.__11, oth.__11) && object.Equals(this.__12, oth.__12) && object.Equals(this.__13, oth.__13);
    }
    public override int GetHashCode() {
      ulong hash = 5381;
      hash = ((hash << 5) + hash) + 0;
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this.__0));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this.__1));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this.__2));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this.__3));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this.__4));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this.__5));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this.__6));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this.__7));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this.__8));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this.__9));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this.__10));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this.__11));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this.__12));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this.__13));
      return (int) hash;
    }
    public override string ToString() {
      string s = "";
      s += "(";
      s += Dafny.Helpers.ToString(this.__0);
      s += ", ";
      s += Dafny.Helpers.ToString(this.__1);
      s += ", ";
      s += Dafny.Helpers.ToString(this.__2);
      s += ", ";
      s += Dafny.Helpers.ToString(this.__3);
      s += ", ";
      s += Dafny.Helpers.ToString(this.__4);
      s += ", ";
      s += Dafny.Helpers.ToString(this.__5);
      s += ", ";
      s += Dafny.Helpers.ToString(this.__6);
      s += ", ";
      s += Dafny.Helpers.ToString(this.__7);
      s += ", ";
      s += Dafny.Helpers.ToString(this.__8);
      s += ", ";
      s += Dafny.Helpers.ToString(this.__9);
      s += ", ";
      s += Dafny.Helpers.ToString(this.__10);
      s += ", ";
      s += Dafny.Helpers.ToString(this.__11);
      s += ", ";
      s += Dafny.Helpers.ToString(this.__12);
      s += ", ";
      s += Dafny.Helpers.ToString(this.__13);
      s += ")";
      return s;
    }
    public static _System._ITuple14<T0, T1, T2, T3, T4, T5, T6, T7, T8, T9, T10, T11, T12, T13> Default(T0 _default_T0, T1 _default_T1, T2 _default_T2, T3 _default_T3, T4 _default_T4, T5 _default_T5, T6 _default_T6, T7 _default_T7, T8 _default_T8, T9 _default_T9, T10 _default_T10, T11 _default_T11, T12 _default_T12, T13 _default_T13) {
      return create(_default_T0, _default_T1, _default_T2, _default_T3, _default_T4, _default_T5, _default_T6, _default_T7, _default_T8, _default_T9, _default_T10, _default_T11, _default_T12, _default_T13);
    }
    public static Dafny.TypeDescriptor<_System._ITuple14<T0, T1, T2, T3, T4, T5, T6, T7, T8, T9, T10, T11, T12, T13>> _TypeDescriptor(Dafny.TypeDescriptor<T0> _td_T0, Dafny.TypeDescriptor<T1> _td_T1, Dafny.TypeDescriptor<T2> _td_T2, Dafny.TypeDescriptor<T3> _td_T3, Dafny.TypeDescriptor<T4> _td_T4, Dafny.TypeDescriptor<T5> _td_T5, Dafny.TypeDescriptor<T6> _td_T6, Dafny.TypeDescriptor<T7> _td_T7, Dafny.TypeDescriptor<T8> _td_T8, Dafny.TypeDescriptor<T9> _td_T9, Dafny.TypeDescriptor<T10> _td_T10, Dafny.TypeDescriptor<T11> _td_T11, Dafny.TypeDescriptor<T12> _td_T12, Dafny.TypeDescriptor<T13> _td_T13) {
      return new Dafny.TypeDescriptor<_System._ITuple14<T0, T1, T2, T3, T4, T5, T6, T7, T8, T9, T10, T11, T12, T13>>(_System.Tuple14<T0, T1, T2, T3, T4, T5, T6, T7, T8, T9, T10, T11, T12, T13>.Default(_td_T0.Default(), _td_T1.Default(), _td_T2.Default(), _td_T3.Default(), _td_T4.Default(), _td_T5.Default(), _td_T6.Default(), _td_T7.Default(), _td_T8.Default(), _td_T9.Default(), _td_T10.Default(), _td_T11.Default(), _td_T12.Default(), _td_T13.Default()));
    }
    public static _ITuple14<T0, T1, T2, T3, T4, T5, T6, T7, T8, T9, T10, T11, T12, T13> create(T0 _0, T1 _1, T2 _2, T3 _3, T4 _4, T5 _5, T6 _6, T7 _7, T8 _8, T9 _9, T10 _10, T11 _11, T12 _12, T13 _13) {
      return new Tuple14<T0, T1, T2, T3, T4, T5, T6, T7, T8, T9, T10, T11, T12, T13>(_0, _1, _2, _3, _4, _5, _6, _7, _8, _9, _10, _11, _12, _13);
    }
    public static _ITuple14<T0, T1, T2, T3, T4, T5, T6, T7, T8, T9, T10, T11, T12, T13> create____hMake14(T0 _0, T1 _1, T2 _2, T3 _3, T4 _4, T5 _5, T6 _6, T7 _7, T8 _8, T9 _9, T10 _10, T11 _11, T12 _12, T13 _13) {
      return create(_0, _1, _2, _3, _4, _5, _6, _7, _8, _9, _10, _11, _12, _13);
    }
    public T0 dtor__0 {
      get {
        return this.__0;
      }
    }
    public T1 dtor__1 {
      get {
        return this.__1;
      }
    }
    public T2 dtor__2 {
      get {
        return this.__2;
      }
    }
    public T3 dtor__3 {
      get {
        return this.__3;
      }
    }
    public T4 dtor__4 {
      get {
        return this.__4;
      }
    }
    public T5 dtor__5 {
      get {
        return this.__5;
      }
    }
    public T6 dtor__6 {
      get {
        return this.__6;
      }
    }
    public T7 dtor__7 {
      get {
        return this.__7;
      }
    }
    public T8 dtor__8 {
      get {
        return this.__8;
      }
    }
    public T9 dtor__9 {
      get {
        return this.__9;
      }
    }
    public T10 dtor__10 {
      get {
        return this.__10;
      }
    }
    public T11 dtor__11 {
      get {
        return this.__11;
      }
    }
    public T12 dtor__12 {
      get {
        return this.__12;
      }
    }
    public T13 dtor__13 {
      get {
        return this.__13;
      }
    }
  }

  public interface _ITuple15<out T0, out T1, out T2, out T3, out T4, out T5, out T6, out T7, out T8, out T9, out T10, out T11, out T12, out T13, out T14> {
    T0 dtor__0 { get; }
    T1 dtor__1 { get; }
    T2 dtor__2 { get; }
    T3 dtor__3 { get; }
    T4 dtor__4 { get; }
    T5 dtor__5 { get; }
    T6 dtor__6 { get; }
    T7 dtor__7 { get; }
    T8 dtor__8 { get; }
    T9 dtor__9 { get; }
    T10 dtor__10 { get; }
    T11 dtor__11 { get; }
    T12 dtor__12 { get; }
    T13 dtor__13 { get; }
    T14 dtor__14 { get; }
    _ITuple15<__T0, __T1, __T2, __T3, __T4, __T5, __T6, __T7, __T8, __T9, __T10, __T11, __T12, __T13, __T14> DowncastClone<__T0, __T1, __T2, __T3, __T4, __T5, __T6, __T7, __T8, __T9, __T10, __T11, __T12, __T13, __T14>(Func<T0, __T0> converter0, Func<T1, __T1> converter1, Func<T2, __T2> converter2, Func<T3, __T3> converter3, Func<T4, __T4> converter4, Func<T5, __T5> converter5, Func<T6, __T6> converter6, Func<T7, __T7> converter7, Func<T8, __T8> converter8, Func<T9, __T9> converter9, Func<T10, __T10> converter10, Func<T11, __T11> converter11, Func<T12, __T12> converter12, Func<T13, __T13> converter13, Func<T14, __T14> converter14);
  }
  public class Tuple15<T0, T1, T2, T3, T4, T5, T6, T7, T8, T9, T10, T11, T12, T13, T14> : _ITuple15<T0, T1, T2, T3, T4, T5, T6, T7, T8, T9, T10, T11, T12, T13, T14> {
    public readonly T0 __0;
    public readonly T1 __1;
    public readonly T2 __2;
    public readonly T3 __3;
    public readonly T4 __4;
    public readonly T5 __5;
    public readonly T6 __6;
    public readonly T7 __7;
    public readonly T8 __8;
    public readonly T9 __9;
    public readonly T10 __10;
    public readonly T11 __11;
    public readonly T12 __12;
    public readonly T13 __13;
    public readonly T14 __14;
    public Tuple15(T0 _0, T1 _1, T2 _2, T3 _3, T4 _4, T5 _5, T6 _6, T7 _7, T8 _8, T9 _9, T10 _10, T11 _11, T12 _12, T13 _13, T14 _14) {
      this.__0 = _0;
      this.__1 = _1;
      this.__2 = _2;
      this.__3 = _3;
      this.__4 = _4;
      this.__5 = _5;
      this.__6 = _6;
      this.__7 = _7;
      this.__8 = _8;
      this.__9 = _9;
      this.__10 = _10;
      this.__11 = _11;
      this.__12 = _12;
      this.__13 = _13;
      this.__14 = _14;
    }
    public _ITuple15<__T0, __T1, __T2, __T3, __T4, __T5, __T6, __T7, __T8, __T9, __T10, __T11, __T12, __T13, __T14> DowncastClone<__T0, __T1, __T2, __T3, __T4, __T5, __T6, __T7, __T8, __T9, __T10, __T11, __T12, __T13, __T14>(Func<T0, __T0> converter0, Func<T1, __T1> converter1, Func<T2, __T2> converter2, Func<T3, __T3> converter3, Func<T4, __T4> converter4, Func<T5, __T5> converter5, Func<T6, __T6> converter6, Func<T7, __T7> converter7, Func<T8, __T8> converter8, Func<T9, __T9> converter9, Func<T10, __T10> converter10, Func<T11, __T11> converter11, Func<T12, __T12> converter12, Func<T13, __T13> converter13, Func<T14, __T14> converter14) {
      if (this is _ITuple15<__T0, __T1, __T2, __T3, __T4, __T5, __T6, __T7, __T8, __T9, __T10, __T11, __T12, __T13, __T14> dt) { return dt; }
      return new Tuple15<__T0, __T1, __T2, __T3, __T4, __T5, __T6, __T7, __T8, __T9, __T10, __T11, __T12, __T13, __T14>(converter0(__0), converter1(__1), converter2(__2), converter3(__3), converter4(__4), converter5(__5), converter6(__6), converter7(__7), converter8(__8), converter9(__9), converter10(__10), converter11(__11), converter12(__12), converter13(__13), converter14(__14));
    }
    public override bool Equals(object other) {
      var oth = other as _System.Tuple15<T0, T1, T2, T3, T4, T5, T6, T7, T8, T9, T10, T11, T12, T13, T14>;
      return oth != null && object.Equals(this.__0, oth.__0) && object.Equals(this.__1, oth.__1) && object.Equals(this.__2, oth.__2) && object.Equals(this.__3, oth.__3) && object.Equals(this.__4, oth.__4) && object.Equals(this.__5, oth.__5) && object.Equals(this.__6, oth.__6) && object.Equals(this.__7, oth.__7) && object.Equals(this.__8, oth.__8) && object.Equals(this.__9, oth.__9) && object.Equals(this.__10, oth.__10) && object.Equals(this.__11, oth.__11) && object.Equals(this.__12, oth.__12) && object.Equals(this.__13, oth.__13) && object.Equals(this.__14, oth.__14);
    }
    public override int GetHashCode() {
      ulong hash = 5381;
      hash = ((hash << 5) + hash) + 0;
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this.__0));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this.__1));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this.__2));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this.__3));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this.__4));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this.__5));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this.__6));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this.__7));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this.__8));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this.__9));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this.__10));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this.__11));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this.__12));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this.__13));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this.__14));
      return (int) hash;
    }
    public override string ToString() {
      string s = "";
      s += "(";
      s += Dafny.Helpers.ToString(this.__0);
      s += ", ";
      s += Dafny.Helpers.ToString(this.__1);
      s += ", ";
      s += Dafny.Helpers.ToString(this.__2);
      s += ", ";
      s += Dafny.Helpers.ToString(this.__3);
      s += ", ";
      s += Dafny.Helpers.ToString(this.__4);
      s += ", ";
      s += Dafny.Helpers.ToString(this.__5);
      s += ", ";
      s += Dafny.Helpers.ToString(this.__6);
      s += ", ";
      s += Dafny.Helpers.ToString(this.__7);
      s += ", ";
      s += Dafny.Helpers.ToString(this.__8);
      s += ", ";
      s += Dafny.Helpers.ToString(this.__9);
      s += ", ";
      s += Dafny.Helpers.ToString(this.__10);
      s += ", ";
      s += Dafny.Helpers.ToString(this.__11);
      s += ", ";
      s += Dafny.Helpers.ToString(this.__12);
      s += ", ";
      s += Dafny.Helpers.ToString(this.__13);
      s += ", ";
      s += Dafny.Helpers.ToString(this.__14);
      s += ")";
      return s;
    }
    public static _System._ITuple15<T0, T1, T2, T3, T4, T5, T6, T7, T8, T9, T10, T11, T12, T13, T14> Default(T0 _default_T0, T1 _default_T1, T2 _default_T2, T3 _default_T3, T4 _default_T4, T5 _default_T5, T6 _default_T6, T7 _default_T7, T8 _default_T8, T9 _default_T9, T10 _default_T10, T11 _default_T11, T12 _default_T12, T13 _default_T13, T14 _default_T14) {
      return create(_default_T0, _default_T1, _default_T2, _default_T3, _default_T4, _default_T5, _default_T6, _default_T7, _default_T8, _default_T9, _default_T10, _default_T11, _default_T12, _default_T13, _default_T14);
    }
    public static Dafny.TypeDescriptor<_System._ITuple15<T0, T1, T2, T3, T4, T5, T6, T7, T8, T9, T10, T11, T12, T13, T14>> _TypeDescriptor(Dafny.TypeDescriptor<T0> _td_T0, Dafny.TypeDescriptor<T1> _td_T1, Dafny.TypeDescriptor<T2> _td_T2, Dafny.TypeDescriptor<T3> _td_T3, Dafny.TypeDescriptor<T4> _td_T4, Dafny.TypeDescriptor<T5> _td_T5, Dafny.TypeDescriptor<T6> _td_T6, Dafny.TypeDescriptor<T7> _td_T7, Dafny.TypeDescriptor<T8> _td_T8, Dafny.TypeDescriptor<T9> _td_T9, Dafny.TypeDescriptor<T10> _td_T10, Dafny.TypeDescriptor<T11> _td_T11, Dafny.TypeDescriptor<T12> _td_T12, Dafny.TypeDescriptor<T13> _td_T13, Dafny.TypeDescriptor<T14> _td_T14) {
      return new Dafny.TypeDescriptor<_System._ITuple15<T0, T1, T2, T3, T4, T5, T6, T7, T8, T9, T10, T11, T12, T13, T14>>(_System.Tuple15<T0, T1, T2, T3, T4, T5, T6, T7, T8, T9, T10, T11, T12, T13, T14>.Default(_td_T0.Default(), _td_T1.Default(), _td_T2.Default(), _td_T3.Default(), _td_T4.Default(), _td_T5.Default(), _td_T6.Default(), _td_T7.Default(), _td_T8.Default(), _td_T9.Default(), _td_T10.Default(), _td_T11.Default(), _td_T12.Default(), _td_T13.Default(), _td_T14.Default()));
    }
    public static _ITuple15<T0, T1, T2, T3, T4, T5, T6, T7, T8, T9, T10, T11, T12, T13, T14> create(T0 _0, T1 _1, T2 _2, T3 _3, T4 _4, T5 _5, T6 _6, T7 _7, T8 _8, T9 _9, T10 _10, T11 _11, T12 _12, T13 _13, T14 _14) {
      return new Tuple15<T0, T1, T2, T3, T4, T5, T6, T7, T8, T9, T10, T11, T12, T13, T14>(_0, _1, _2, _3, _4, _5, _6, _7, _8, _9, _10, _11, _12, _13, _14);
    }
    public static _ITuple15<T0, T1, T2, T3, T4, T5, T6, T7, T8, T9, T10, T11, T12, T13, T14> create____hMake15(T0 _0, T1 _1, T2 _2, T3 _3, T4 _4, T5 _5, T6 _6, T7 _7, T8 _8, T9 _9, T10 _10, T11 _11, T12 _12, T13 _13, T14 _14) {
      return create(_0, _1, _2, _3, _4, _5, _6, _7, _8, _9, _10, _11, _12, _13, _14);
    }
    public T0 dtor__0 {
      get {
        return this.__0;
      }
    }
    public T1 dtor__1 {
      get {
        return this.__1;
      }
    }
    public T2 dtor__2 {
      get {
        return this.__2;
      }
    }
    public T3 dtor__3 {
      get {
        return this.__3;
      }
    }
    public T4 dtor__4 {
      get {
        return this.__4;
      }
    }
    public T5 dtor__5 {
      get {
        return this.__5;
      }
    }
    public T6 dtor__6 {
      get {
        return this.__6;
      }
    }
    public T7 dtor__7 {
      get {
        return this.__7;
      }
    }
    public T8 dtor__8 {
      get {
        return this.__8;
      }
    }
    public T9 dtor__9 {
      get {
        return this.__9;
      }
    }
    public T10 dtor__10 {
      get {
        return this.__10;
      }
    }
    public T11 dtor__11 {
      get {
        return this.__11;
      }
    }
    public T12 dtor__12 {
      get {
        return this.__12;
      }
    }
    public T13 dtor__13 {
      get {
        return this.__13;
      }
    }
    public T14 dtor__14 {
      get {
        return this.__14;
      }
    }
  }

  public interface _ITuple16<out T0, out T1, out T2, out T3, out T4, out T5, out T6, out T7, out T8, out T9, out T10, out T11, out T12, out T13, out T14, out T15> {
    T0 dtor__0 { get; }
    T1 dtor__1 { get; }
    T2 dtor__2 { get; }
    T3 dtor__3 { get; }
    T4 dtor__4 { get; }
    T5 dtor__5 { get; }
    T6 dtor__6 { get; }
    T7 dtor__7 { get; }
    T8 dtor__8 { get; }
    T9 dtor__9 { get; }
    T10 dtor__10 { get; }
    T11 dtor__11 { get; }
    T12 dtor__12 { get; }
    T13 dtor__13 { get; }
    T14 dtor__14 { get; }
    T15 dtor__15 { get; }
    _ITuple16<__T0, __T1, __T2, __T3, __T4, __T5, __T6, __T7, __T8, __T9, __T10, __T11, __T12, __T13, __T14, __T15> DowncastClone<__T0, __T1, __T2, __T3, __T4, __T5, __T6, __T7, __T8, __T9, __T10, __T11, __T12, __T13, __T14, __T15>(Func<T0, __T0> converter0, Func<T1, __T1> converter1, Func<T2, __T2> converter2, Func<T3, __T3> converter3, Func<T4, __T4> converter4, Func<T5, __T5> converter5, Func<T6, __T6> converter6, Func<T7, __T7> converter7, Func<T8, __T8> converter8, Func<T9, __T9> converter9, Func<T10, __T10> converter10, Func<T11, __T11> converter11, Func<T12, __T12> converter12, Func<T13, __T13> converter13, Func<T14, __T14> converter14, Func<T15, __T15> converter15);
  }
  public class Tuple16<T0, T1, T2, T3, T4, T5, T6, T7, T8, T9, T10, T11, T12, T13, T14, T15> : _ITuple16<T0, T1, T2, T3, T4, T5, T6, T7, T8, T9, T10, T11, T12, T13, T14, T15> {
    public readonly T0 __0;
    public readonly T1 __1;
    public readonly T2 __2;
    public readonly T3 __3;
    public readonly T4 __4;
    public readonly T5 __5;
    public readonly T6 __6;
    public readonly T7 __7;
    public readonly T8 __8;
    public readonly T9 __9;
    public readonly T10 __10;
    public readonly T11 __11;
    public readonly T12 __12;
    public readonly T13 __13;
    public readonly T14 __14;
    public readonly T15 __15;
    public Tuple16(T0 _0, T1 _1, T2 _2, T3 _3, T4 _4, T5 _5, T6 _6, T7 _7, T8 _8, T9 _9, T10 _10, T11 _11, T12 _12, T13 _13, T14 _14, T15 _15) {
      this.__0 = _0;
      this.__1 = _1;
      this.__2 = _2;
      this.__3 = _3;
      this.__4 = _4;
      this.__5 = _5;
      this.__6 = _6;
      this.__7 = _7;
      this.__8 = _8;
      this.__9 = _9;
      this.__10 = _10;
      this.__11 = _11;
      this.__12 = _12;
      this.__13 = _13;
      this.__14 = _14;
      this.__15 = _15;
    }
    public _ITuple16<__T0, __T1, __T2, __T3, __T4, __T5, __T6, __T7, __T8, __T9, __T10, __T11, __T12, __T13, __T14, __T15> DowncastClone<__T0, __T1, __T2, __T3, __T4, __T5, __T6, __T7, __T8, __T9, __T10, __T11, __T12, __T13, __T14, __T15>(Func<T0, __T0> converter0, Func<T1, __T1> converter1, Func<T2, __T2> converter2, Func<T3, __T3> converter3, Func<T4, __T4> converter4, Func<T5, __T5> converter5, Func<T6, __T6> converter6, Func<T7, __T7> converter7, Func<T8, __T8> converter8, Func<T9, __T9> converter9, Func<T10, __T10> converter10, Func<T11, __T11> converter11, Func<T12, __T12> converter12, Func<T13, __T13> converter13, Func<T14, __T14> converter14, Func<T15, __T15> converter15) {
      if (this is _ITuple16<__T0, __T1, __T2, __T3, __T4, __T5, __T6, __T7, __T8, __T9, __T10, __T11, __T12, __T13, __T14, __T15> dt) { return dt; }
      return new Tuple16<__T0, __T1, __T2, __T3, __T4, __T5, __T6, __T7, __T8, __T9, __T10, __T11, __T12, __T13, __T14, __T15>(converter0(__0), converter1(__1), converter2(__2), converter3(__3), converter4(__4), converter5(__5), converter6(__6), converter7(__7), converter8(__8), converter9(__9), converter10(__10), converter11(__11), converter12(__12), converter13(__13), converter14(__14), converter15(__15));
    }
    public override bool Equals(object other) {
      var oth = other as _System.Tuple16<T0, T1, T2, T3, T4, T5, T6, T7, T8, T9, T10, T11, T12, T13, T14, T15>;
      return oth != null && object.Equals(this.__0, oth.__0) && object.Equals(this.__1, oth.__1) && object.Equals(this.__2, oth.__2) && object.Equals(this.__3, oth.__3) && object.Equals(this.__4, oth.__4) && object.Equals(this.__5, oth.__5) && object.Equals(this.__6, oth.__6) && object.Equals(this.__7, oth.__7) && object.Equals(this.__8, oth.__8) && object.Equals(this.__9, oth.__9) && object.Equals(this.__10, oth.__10) && object.Equals(this.__11, oth.__11) && object.Equals(this.__12, oth.__12) && object.Equals(this.__13, oth.__13) && object.Equals(this.__14, oth.__14) && object.Equals(this.__15, oth.__15);
    }
    public override int GetHashCode() {
      ulong hash = 5381;
      hash = ((hash << 5) + hash) + 0;
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this.__0));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this.__1));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this.__2));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this.__3));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this.__4));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this.__5));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this.__6));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this.__7));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this.__8));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this.__9));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this.__10));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this.__11));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this.__12));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this.__13));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this.__14));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this.__15));
      return (int) hash;
    }
    public override string ToString() {
      string s = "";
      s += "(";
      s += Dafny.Helpers.ToString(this.__0);
      s += ", ";
      s += Dafny.Helpers.ToString(this.__1);
      s += ", ";
      s += Dafny.Helpers.ToString(this.__2);
      s += ", ";
      s += Dafny.Helpers.ToString(this.__3);
      s += ", ";
      s += Dafny.Helpers.ToString(this.__4);
      s += ", ";
      s += Dafny.Helpers.ToString(this.__5);
      s += ", ";
      s += Dafny.Helpers.ToString(this.__6);
      s += ", ";
      s += Dafny.Helpers.ToString(this.__7);
      s += ", ";
      s += Dafny.Helpers.ToString(this.__8);
      s += ", ";
      s += Dafny.Helpers.ToString(this.__9);
      s += ", ";
      s += Dafny.Helpers.ToString(this.__10);
      s += ", ";
      s += Dafny.Helpers.ToString(this.__11);
      s += ", ";
      s += Dafny.Helpers.ToString(this.__12);
      s += ", ";
      s += Dafny.Helpers.ToString(this.__13);
      s += ", ";
      s += Dafny.Helpers.ToString(this.__14);
      s += ", ";
      s += Dafny.Helpers.ToString(this.__15);
      s += ")";
      return s;
    }
    public static _System._ITuple16<T0, T1, T2, T3, T4, T5, T6, T7, T8, T9, T10, T11, T12, T13, T14, T15> Default(T0 _default_T0, T1 _default_T1, T2 _default_T2, T3 _default_T3, T4 _default_T4, T5 _default_T5, T6 _default_T6, T7 _default_T7, T8 _default_T8, T9 _default_T9, T10 _default_T10, T11 _default_T11, T12 _default_T12, T13 _default_T13, T14 _default_T14, T15 _default_T15) {
      return create(_default_T0, _default_T1, _default_T2, _default_T3, _default_T4, _default_T5, _default_T6, _default_T7, _default_T8, _default_T9, _default_T10, _default_T11, _default_T12, _default_T13, _default_T14, _default_T15);
    }
    public static Dafny.TypeDescriptor<_System._ITuple16<T0, T1, T2, T3, T4, T5, T6, T7, T8, T9, T10, T11, T12, T13, T14, T15>> _TypeDescriptor(Dafny.TypeDescriptor<T0> _td_T0, Dafny.TypeDescriptor<T1> _td_T1, Dafny.TypeDescriptor<T2> _td_T2, Dafny.TypeDescriptor<T3> _td_T3, Dafny.TypeDescriptor<T4> _td_T4, Dafny.TypeDescriptor<T5> _td_T5, Dafny.TypeDescriptor<T6> _td_T6, Dafny.TypeDescriptor<T7> _td_T7, Dafny.TypeDescriptor<T8> _td_T8, Dafny.TypeDescriptor<T9> _td_T9, Dafny.TypeDescriptor<T10> _td_T10, Dafny.TypeDescriptor<T11> _td_T11, Dafny.TypeDescriptor<T12> _td_T12, Dafny.TypeDescriptor<T13> _td_T13, Dafny.TypeDescriptor<T14> _td_T14, Dafny.TypeDescriptor<T15> _td_T15) {
      return new Dafny.TypeDescriptor<_System._ITuple16<T0, T1, T2, T3, T4, T5, T6, T7, T8, T9, T10, T11, T12, T13, T14, T15>>(_System.Tuple16<T0, T1, T2, T3, T4, T5, T6, T7, T8, T9, T10, T11, T12, T13, T14, T15>.Default(_td_T0.Default(), _td_T1.Default(), _td_T2.Default(), _td_T3.Default(), _td_T4.Default(), _td_T5.Default(), _td_T6.Default(), _td_T7.Default(), _td_T8.Default(), _td_T9.Default(), _td_T10.Default(), _td_T11.Default(), _td_T12.Default(), _td_T13.Default(), _td_T14.Default(), _td_T15.Default()));
    }
    public static _ITuple16<T0, T1, T2, T3, T4, T5, T6, T7, T8, T9, T10, T11, T12, T13, T14, T15> create(T0 _0, T1 _1, T2 _2, T3 _3, T4 _4, T5 _5, T6 _6, T7 _7, T8 _8, T9 _9, T10 _10, T11 _11, T12 _12, T13 _13, T14 _14, T15 _15) {
      return new Tuple16<T0, T1, T2, T3, T4, T5, T6, T7, T8, T9, T10, T11, T12, T13, T14, T15>(_0, _1, _2, _3, _4, _5, _6, _7, _8, _9, _10, _11, _12, _13, _14, _15);
    }
    public static _ITuple16<T0, T1, T2, T3, T4, T5, T6, T7, T8, T9, T10, T11, T12, T13, T14, T15> create____hMake16(T0 _0, T1 _1, T2 _2, T3 _3, T4 _4, T5 _5, T6 _6, T7 _7, T8 _8, T9 _9, T10 _10, T11 _11, T12 _12, T13 _13, T14 _14, T15 _15) {
      return create(_0, _1, _2, _3, _4, _5, _6, _7, _8, _9, _10, _11, _12, _13, _14, _15);
    }
    public T0 dtor__0 {
      get {
        return this.__0;
      }
    }
    public T1 dtor__1 {
      get {
        return this.__1;
      }
    }
    public T2 dtor__2 {
      get {
        return this.__2;
      }
    }
    public T3 dtor__3 {
      get {
        return this.__3;
      }
    }
    public T4 dtor__4 {
      get {
        return this.__4;
      }
    }
    public T5 dtor__5 {
      get {
        return this.__5;
      }
    }
    public T6 dtor__6 {
      get {
        return this.__6;
      }
    }
    public T7 dtor__7 {
      get {
        return this.__7;
      }
    }
    public T8 dtor__8 {
      get {
        return this.__8;
      }
    }
    public T9 dtor__9 {
      get {
        return this.__9;
      }
    }
    public T10 dtor__10 {
      get {
        return this.__10;
      }
    }
    public T11 dtor__11 {
      get {
        return this.__11;
      }
    }
    public T12 dtor__12 {
      get {
        return this.__12;
      }
    }
    public T13 dtor__13 {
      get {
        return this.__13;
      }
    }
    public T14 dtor__14 {
      get {
        return this.__14;
      }
    }
    public T15 dtor__15 {
      get {
        return this.__15;
      }
    }
  }

  public interface _ITuple17<out T0, out T1, out T2, out T3, out T4, out T5, out T6, out T7, out T8, out T9, out T10, out T11, out T12, out T13, out T14, out T15, out T16> {
    T0 dtor__0 { get; }
    T1 dtor__1 { get; }
    T2 dtor__2 { get; }
    T3 dtor__3 { get; }
    T4 dtor__4 { get; }
    T5 dtor__5 { get; }
    T6 dtor__6 { get; }
    T7 dtor__7 { get; }
    T8 dtor__8 { get; }
    T9 dtor__9 { get; }
    T10 dtor__10 { get; }
    T11 dtor__11 { get; }
    T12 dtor__12 { get; }
    T13 dtor__13 { get; }
    T14 dtor__14 { get; }
    T15 dtor__15 { get; }
    T16 dtor__16 { get; }
    _ITuple17<__T0, __T1, __T2, __T3, __T4, __T5, __T6, __T7, __T8, __T9, __T10, __T11, __T12, __T13, __T14, __T15, __T16> DowncastClone<__T0, __T1, __T2, __T3, __T4, __T5, __T6, __T7, __T8, __T9, __T10, __T11, __T12, __T13, __T14, __T15, __T16>(Func<T0, __T0> converter0, Func<T1, __T1> converter1, Func<T2, __T2> converter2, Func<T3, __T3> converter3, Func<T4, __T4> converter4, Func<T5, __T5> converter5, Func<T6, __T6> converter6, Func<T7, __T7> converter7, Func<T8, __T8> converter8, Func<T9, __T9> converter9, Func<T10, __T10> converter10, Func<T11, __T11> converter11, Func<T12, __T12> converter12, Func<T13, __T13> converter13, Func<T14, __T14> converter14, Func<T15, __T15> converter15, Func<T16, __T16> converter16);
  }
  public class Tuple17<T0, T1, T2, T3, T4, T5, T6, T7, T8, T9, T10, T11, T12, T13, T14, T15, T16> : _ITuple17<T0, T1, T2, T3, T4, T5, T6, T7, T8, T9, T10, T11, T12, T13, T14, T15, T16> {
    public readonly T0 __0;
    public readonly T1 __1;
    public readonly T2 __2;
    public readonly T3 __3;
    public readonly T4 __4;
    public readonly T5 __5;
    public readonly T6 __6;
    public readonly T7 __7;
    public readonly T8 __8;
    public readonly T9 __9;
    public readonly T10 __10;
    public readonly T11 __11;
    public readonly T12 __12;
    public readonly T13 __13;
    public readonly T14 __14;
    public readonly T15 __15;
    public readonly T16 __16;
    public Tuple17(T0 _0, T1 _1, T2 _2, T3 _3, T4 _4, T5 _5, T6 _6, T7 _7, T8 _8, T9 _9, T10 _10, T11 _11, T12 _12, T13 _13, T14 _14, T15 _15, T16 _16) {
      this.__0 = _0;
      this.__1 = _1;
      this.__2 = _2;
      this.__3 = _3;
      this.__4 = _4;
      this.__5 = _5;
      this.__6 = _6;
      this.__7 = _7;
      this.__8 = _8;
      this.__9 = _9;
      this.__10 = _10;
      this.__11 = _11;
      this.__12 = _12;
      this.__13 = _13;
      this.__14 = _14;
      this.__15 = _15;
      this.__16 = _16;
    }
    public _ITuple17<__T0, __T1, __T2, __T3, __T4, __T5, __T6, __T7, __T8, __T9, __T10, __T11, __T12, __T13, __T14, __T15, __T16> DowncastClone<__T0, __T1, __T2, __T3, __T4, __T5, __T6, __T7, __T8, __T9, __T10, __T11, __T12, __T13, __T14, __T15, __T16>(Func<T0, __T0> converter0, Func<T1, __T1> converter1, Func<T2, __T2> converter2, Func<T3, __T3> converter3, Func<T4, __T4> converter4, Func<T5, __T5> converter5, Func<T6, __T6> converter6, Func<T7, __T7> converter7, Func<T8, __T8> converter8, Func<T9, __T9> converter9, Func<T10, __T10> converter10, Func<T11, __T11> converter11, Func<T12, __T12> converter12, Func<T13, __T13> converter13, Func<T14, __T14> converter14, Func<T15, __T15> converter15, Func<T16, __T16> converter16) {
      if (this is _ITuple17<__T0, __T1, __T2, __T3, __T4, __T5, __T6, __T7, __T8, __T9, __T10, __T11, __T12, __T13, __T14, __T15, __T16> dt) { return dt; }
      return new Tuple17<__T0, __T1, __T2, __T3, __T4, __T5, __T6, __T7, __T8, __T9, __T10, __T11, __T12, __T13, __T14, __T15, __T16>(converter0(__0), converter1(__1), converter2(__2), converter3(__3), converter4(__4), converter5(__5), converter6(__6), converter7(__7), converter8(__8), converter9(__9), converter10(__10), converter11(__11), converter12(__12), converter13(__13), converter14(__14), converter15(__15), converter16(__16));
    }
    public override bool Equals(object other) {
      var oth = other as _System.Tuple17<T0, T1, T2, T3, T4, T5, T6, T7, T8, T9, T10, T11, T12, T13, T14, T15, T16>;
      return oth != null && object.Equals(this.__0, oth.__0) && object.Equals(this.__1, oth.__1) && object.Equals(this.__2, oth.__2) && object.Equals(this.__3, oth.__3) && object.Equals(this.__4, oth.__4) && object.Equals(this.__5, oth.__5) && object.Equals(this.__6, oth.__6) && object.Equals(this.__7, oth.__7) && object.Equals(this.__8, oth.__8) && object.Equals(this.__9, oth.__9) && object.Equals(this.__10, oth.__10) && object.Equals(this.__11, oth.__11) && object.Equals(this.__12, oth.__12) && object.Equals(this.__13, oth.__13) && object.Equals(this.__14, oth.__14) && object.Equals(this.__15, oth.__15) && object.Equals(this.__16, oth.__16);
    }
    public override int GetHashCode() {
      ulong hash = 5381;
      hash = ((hash << 5) + hash) + 0;
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this.__0));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this.__1));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this.__2));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this.__3));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this.__4));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this.__5));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this.__6));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this.__7));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this.__8));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this.__9));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this.__10));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this.__11));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this.__12));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this.__13));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this.__14));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this.__15));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this.__16));
      return (int) hash;
    }
    public override string ToString() {
      string s = "";
      s += "(";
      s += Dafny.Helpers.ToString(this.__0);
      s += ", ";
      s += Dafny.Helpers.ToString(this.__1);
      s += ", ";
      s += Dafny.Helpers.ToString(this.__2);
      s += ", ";
      s += Dafny.Helpers.ToString(this.__3);
      s += ", ";
      s += Dafny.Helpers.ToString(this.__4);
      s += ", ";
      s += Dafny.Helpers.ToString(this.__5);
      s += ", ";
      s += Dafny.Helpers.ToString(this.__6);
      s += ", ";
      s += Dafny.Helpers.ToString(this.__7);
      s += ", ";
      s += Dafny.Helpers.ToString(this.__8);
      s += ", ";
      s += Dafny.Helpers.ToString(this.__9);
      s += ", ";
      s += Dafny.Helpers.ToString(this.__10);
      s += ", ";
      s += Dafny.Helpers.ToString(this.__11);
      s += ", ";
      s += Dafny.Helpers.ToString(this.__12);
      s += ", ";
      s += Dafny.Helpers.ToString(this.__13);
      s += ", ";
      s += Dafny.Helpers.ToString(this.__14);
      s += ", ";
      s += Dafny.Helpers.ToString(this.__15);
      s += ", ";
      s += Dafny.Helpers.ToString(this.__16);
      s += ")";
      return s;
    }
    public static _System._ITuple17<T0, T1, T2, T3, T4, T5, T6, T7, T8, T9, T10, T11, T12, T13, T14, T15, T16> Default(T0 _default_T0, T1 _default_T1, T2 _default_T2, T3 _default_T3, T4 _default_T4, T5 _default_T5, T6 _default_T6, T7 _default_T7, T8 _default_T8, T9 _default_T9, T10 _default_T10, T11 _default_T11, T12 _default_T12, T13 _default_T13, T14 _default_T14, T15 _default_T15, T16 _default_T16) {
      return create(_default_T0, _default_T1, _default_T2, _default_T3, _default_T4, _default_T5, _default_T6, _default_T7, _default_T8, _default_T9, _default_T10, _default_T11, _default_T12, _default_T13, _default_T14, _default_T15, _default_T16);
    }
    public static Dafny.TypeDescriptor<_System._ITuple17<T0, T1, T2, T3, T4, T5, T6, T7, T8, T9, T10, T11, T12, T13, T14, T15, T16>> _TypeDescriptor(Dafny.TypeDescriptor<T0> _td_T0, Dafny.TypeDescriptor<T1> _td_T1, Dafny.TypeDescriptor<T2> _td_T2, Dafny.TypeDescriptor<T3> _td_T3, Dafny.TypeDescriptor<T4> _td_T4, Dafny.TypeDescriptor<T5> _td_T5, Dafny.TypeDescriptor<T6> _td_T6, Dafny.TypeDescriptor<T7> _td_T7, Dafny.TypeDescriptor<T8> _td_T8, Dafny.TypeDescriptor<T9> _td_T9, Dafny.TypeDescriptor<T10> _td_T10, Dafny.TypeDescriptor<T11> _td_T11, Dafny.TypeDescriptor<T12> _td_T12, Dafny.TypeDescriptor<T13> _td_T13, Dafny.TypeDescriptor<T14> _td_T14, Dafny.TypeDescriptor<T15> _td_T15, Dafny.TypeDescriptor<T16> _td_T16) {
      return new Dafny.TypeDescriptor<_System._ITuple17<T0, T1, T2, T3, T4, T5, T6, T7, T8, T9, T10, T11, T12, T13, T14, T15, T16>>(_System.Tuple17<T0, T1, T2, T3, T4, T5, T6, T7, T8, T9, T10, T11, T12, T13, T14, T15, T16>.Default(_td_T0.Default(), _td_T1.Default(), _td_T2.Default(), _td_T3.Default(), _td_T4.Default(), _td_T5.Default(), _td_T6.Default(), _td_T7.Default(), _td_T8.Default(), _td_T9.Default(), _td_T10.Default(), _td_T11.Default(), _td_T12.Default(), _td_T13.Default(), _td_T14.Default(), _td_T15.Default(), _td_T16.Default()));
    }
    public static _ITuple17<T0, T1, T2, T3, T4, T5, T6, T7, T8, T9, T10, T11, T12, T13, T14, T15, T16> create(T0 _0, T1 _1, T2 _2, T3 _3, T4 _4, T5 _5, T6 _6, T7 _7, T8 _8, T9 _9, T10 _10, T11 _11, T12 _12, T13 _13, T14 _14, T15 _15, T16 _16) {
      return new Tuple17<T0, T1, T2, T3, T4, T5, T6, T7, T8, T9, T10, T11, T12, T13, T14, T15, T16>(_0, _1, _2, _3, _4, _5, _6, _7, _8, _9, _10, _11, _12, _13, _14, _15, _16);
    }
    public static _ITuple17<T0, T1, T2, T3, T4, T5, T6, T7, T8, T9, T10, T11, T12, T13, T14, T15, T16> create____hMake17(T0 _0, T1 _1, T2 _2, T3 _3, T4 _4, T5 _5, T6 _6, T7 _7, T8 _8, T9 _9, T10 _10, T11 _11, T12 _12, T13 _13, T14 _14, T15 _15, T16 _16) {
      return create(_0, _1, _2, _3, _4, _5, _6, _7, _8, _9, _10, _11, _12, _13, _14, _15, _16);
    }
    public T0 dtor__0 {
      get {
        return this.__0;
      }
    }
    public T1 dtor__1 {
      get {
        return this.__1;
      }
    }
    public T2 dtor__2 {
      get {
        return this.__2;
      }
    }
    public T3 dtor__3 {
      get {
        return this.__3;
      }
    }
    public T4 dtor__4 {
      get {
        return this.__4;
      }
    }
    public T5 dtor__5 {
      get {
        return this.__5;
      }
    }
    public T6 dtor__6 {
      get {
        return this.__6;
      }
    }
    public T7 dtor__7 {
      get {
        return this.__7;
      }
    }
    public T8 dtor__8 {
      get {
        return this.__8;
      }
    }
    public T9 dtor__9 {
      get {
        return this.__9;
      }
    }
    public T10 dtor__10 {
      get {
        return this.__10;
      }
    }
    public T11 dtor__11 {
      get {
        return this.__11;
      }
    }
    public T12 dtor__12 {
      get {
        return this.__12;
      }
    }
    public T13 dtor__13 {
      get {
        return this.__13;
      }
    }
    public T14 dtor__14 {
      get {
        return this.__14;
      }
    }
    public T15 dtor__15 {
      get {
        return this.__15;
      }
    }
    public T16 dtor__16 {
      get {
        return this.__16;
      }
    }
  }

  public interface _ITuple18<out T0, out T1, out T2, out T3, out T4, out T5, out T6, out T7, out T8, out T9, out T10, out T11, out T12, out T13, out T14, out T15, out T16, out T17> {
    T0 dtor__0 { get; }
    T1 dtor__1 { get; }
    T2 dtor__2 { get; }
    T3 dtor__3 { get; }
    T4 dtor__4 { get; }
    T5 dtor__5 { get; }
    T6 dtor__6 { get; }
    T7 dtor__7 { get; }
    T8 dtor__8 { get; }
    T9 dtor__9 { get; }
    T10 dtor__10 { get; }
    T11 dtor__11 { get; }
    T12 dtor__12 { get; }
    T13 dtor__13 { get; }
    T14 dtor__14 { get; }
    T15 dtor__15 { get; }
    T16 dtor__16 { get; }
    T17 dtor__17 { get; }
    _ITuple18<__T0, __T1, __T2, __T3, __T4, __T5, __T6, __T7, __T8, __T9, __T10, __T11, __T12, __T13, __T14, __T15, __T16, __T17> DowncastClone<__T0, __T1, __T2, __T3, __T4, __T5, __T6, __T7, __T8, __T9, __T10, __T11, __T12, __T13, __T14, __T15, __T16, __T17>(Func<T0, __T0> converter0, Func<T1, __T1> converter1, Func<T2, __T2> converter2, Func<T3, __T3> converter3, Func<T4, __T4> converter4, Func<T5, __T5> converter5, Func<T6, __T6> converter6, Func<T7, __T7> converter7, Func<T8, __T8> converter8, Func<T9, __T9> converter9, Func<T10, __T10> converter10, Func<T11, __T11> converter11, Func<T12, __T12> converter12, Func<T13, __T13> converter13, Func<T14, __T14> converter14, Func<T15, __T15> converter15, Func<T16, __T16> converter16, Func<T17, __T17> converter17);
  }
  public class Tuple18<T0, T1, T2, T3, T4, T5, T6, T7, T8, T9, T10, T11, T12, T13, T14, T15, T16, T17> : _ITuple18<T0, T1, T2, T3, T4, T5, T6, T7, T8, T9, T10, T11, T12, T13, T14, T15, T16, T17> {
    public readonly T0 __0;
    public readonly T1 __1;
    public readonly T2 __2;
    public readonly T3 __3;
    public readonly T4 __4;
    public readonly T5 __5;
    public readonly T6 __6;
    public readonly T7 __7;
    public readonly T8 __8;
    public readonly T9 __9;
    public readonly T10 __10;
    public readonly T11 __11;
    public readonly T12 __12;
    public readonly T13 __13;
    public readonly T14 __14;
    public readonly T15 __15;
    public readonly T16 __16;
    public readonly T17 __17;
    public Tuple18(T0 _0, T1 _1, T2 _2, T3 _3, T4 _4, T5 _5, T6 _6, T7 _7, T8 _8, T9 _9, T10 _10, T11 _11, T12 _12, T13 _13, T14 _14, T15 _15, T16 _16, T17 _17) {
      this.__0 = _0;
      this.__1 = _1;
      this.__2 = _2;
      this.__3 = _3;
      this.__4 = _4;
      this.__5 = _5;
      this.__6 = _6;
      this.__7 = _7;
      this.__8 = _8;
      this.__9 = _9;
      this.__10 = _10;
      this.__11 = _11;
      this.__12 = _12;
      this.__13 = _13;
      this.__14 = _14;
      this.__15 = _15;
      this.__16 = _16;
      this.__17 = _17;
    }
    public _ITuple18<__T0, __T1, __T2, __T3, __T4, __T5, __T6, __T7, __T8, __T9, __T10, __T11, __T12, __T13, __T14, __T15, __T16, __T17> DowncastClone<__T0, __T1, __T2, __T3, __T4, __T5, __T6, __T7, __T8, __T9, __T10, __T11, __T12, __T13, __T14, __T15, __T16, __T17>(Func<T0, __T0> converter0, Func<T1, __T1> converter1, Func<T2, __T2> converter2, Func<T3, __T3> converter3, Func<T4, __T4> converter4, Func<T5, __T5> converter5, Func<T6, __T6> converter6, Func<T7, __T7> converter7, Func<T8, __T8> converter8, Func<T9, __T9> converter9, Func<T10, __T10> converter10, Func<T11, __T11> converter11, Func<T12, __T12> converter12, Func<T13, __T13> converter13, Func<T14, __T14> converter14, Func<T15, __T15> converter15, Func<T16, __T16> converter16, Func<T17, __T17> converter17) {
      if (this is _ITuple18<__T0, __T1, __T2, __T3, __T4, __T5, __T6, __T7, __T8, __T9, __T10, __T11, __T12, __T13, __T14, __T15, __T16, __T17> dt) { return dt; }
      return new Tuple18<__T0, __T1, __T2, __T3, __T4, __T5, __T6, __T7, __T8, __T9, __T10, __T11, __T12, __T13, __T14, __T15, __T16, __T17>(converter0(__0), converter1(__1), converter2(__2), converter3(__3), converter4(__4), converter5(__5), converter6(__6), converter7(__7), converter8(__8), converter9(__9), converter10(__10), converter11(__11), converter12(__12), converter13(__13), converter14(__14), converter15(__15), converter16(__16), converter17(__17));
    }
    public override bool Equals(object other) {
      var oth = other as _System.Tuple18<T0, T1, T2, T3, T4, T5, T6, T7, T8, T9, T10, T11, T12, T13, T14, T15, T16, T17>;
      return oth != null && object.Equals(this.__0, oth.__0) && object.Equals(this.__1, oth.__1) && object.Equals(this.__2, oth.__2) && object.Equals(this.__3, oth.__3) && object.Equals(this.__4, oth.__4) && object.Equals(this.__5, oth.__5) && object.Equals(this.__6, oth.__6) && object.Equals(this.__7, oth.__7) && object.Equals(this.__8, oth.__8) && object.Equals(this.__9, oth.__9) && object.Equals(this.__10, oth.__10) && object.Equals(this.__11, oth.__11) && object.Equals(this.__12, oth.__12) && object.Equals(this.__13, oth.__13) && object.Equals(this.__14, oth.__14) && object.Equals(this.__15, oth.__15) && object.Equals(this.__16, oth.__16) && object.Equals(this.__17, oth.__17);
    }
    public override int GetHashCode() {
      ulong hash = 5381;
      hash = ((hash << 5) + hash) + 0;
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this.__0));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this.__1));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this.__2));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this.__3));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this.__4));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this.__5));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this.__6));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this.__7));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this.__8));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this.__9));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this.__10));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this.__11));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this.__12));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this.__13));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this.__14));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this.__15));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this.__16));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this.__17));
      return (int) hash;
    }
    public override string ToString() {
      string s = "";
      s += "(";
      s += Dafny.Helpers.ToString(this.__0);
      s += ", ";
      s += Dafny.Helpers.ToString(this.__1);
      s += ", ";
      s += Dafny.Helpers.ToString(this.__2);
      s += ", ";
      s += Dafny.Helpers.ToString(this.__3);
      s += ", ";
      s += Dafny.Helpers.ToString(this.__4);
      s += ", ";
      s += Dafny.Helpers.ToString(this.__5);
      s += ", ";
      s += Dafny.Helpers.ToString(this.__6);
      s += ", ";
      s += Dafny.Helpers.ToString(this.__7);
      s += ", ";
      s += Dafny.Helpers.ToString(this.__8);
      s += ", ";
      s += Dafny.Helpers.ToString(this.__9);
      s += ", ";
      s += Dafny.Helpers.ToString(this.__10);
      s += ", ";
      s += Dafny.Helpers.ToString(this.__11);
      s += ", ";
      s += Dafny.Helpers.ToString(this.__12);
      s += ", ";
      s += Dafny.Helpers.ToString(this.__13);
      s += ", ";
      s += Dafny.Helpers.ToString(this.__14);
      s += ", ";
      s += Dafny.Helpers.ToString(this.__15);
      s += ", ";
      s += Dafny.Helpers.ToString(this.__16);
      s += ", ";
      s += Dafny.Helpers.ToString(this.__17);
      s += ")";
      return s;
    }
    public static _System._ITuple18<T0, T1, T2, T3, T4, T5, T6, T7, T8, T9, T10, T11, T12, T13, T14, T15, T16, T17> Default(T0 _default_T0, T1 _default_T1, T2 _default_T2, T3 _default_T3, T4 _default_T4, T5 _default_T5, T6 _default_T6, T7 _default_T7, T8 _default_T8, T9 _default_T9, T10 _default_T10, T11 _default_T11, T12 _default_T12, T13 _default_T13, T14 _default_T14, T15 _default_T15, T16 _default_T16, T17 _default_T17) {
      return create(_default_T0, _default_T1, _default_T2, _default_T3, _default_T4, _default_T5, _default_T6, _default_T7, _default_T8, _default_T9, _default_T10, _default_T11, _default_T12, _default_T13, _default_T14, _default_T15, _default_T16, _default_T17);
    }
    public static Dafny.TypeDescriptor<_System._ITuple18<T0, T1, T2, T3, T4, T5, T6, T7, T8, T9, T10, T11, T12, T13, T14, T15, T16, T17>> _TypeDescriptor(Dafny.TypeDescriptor<T0> _td_T0, Dafny.TypeDescriptor<T1> _td_T1, Dafny.TypeDescriptor<T2> _td_T2, Dafny.TypeDescriptor<T3> _td_T3, Dafny.TypeDescriptor<T4> _td_T4, Dafny.TypeDescriptor<T5> _td_T5, Dafny.TypeDescriptor<T6> _td_T6, Dafny.TypeDescriptor<T7> _td_T7, Dafny.TypeDescriptor<T8> _td_T8, Dafny.TypeDescriptor<T9> _td_T9, Dafny.TypeDescriptor<T10> _td_T10, Dafny.TypeDescriptor<T11> _td_T11, Dafny.TypeDescriptor<T12> _td_T12, Dafny.TypeDescriptor<T13> _td_T13, Dafny.TypeDescriptor<T14> _td_T14, Dafny.TypeDescriptor<T15> _td_T15, Dafny.TypeDescriptor<T16> _td_T16, Dafny.TypeDescriptor<T17> _td_T17) {
      return new Dafny.TypeDescriptor<_System._ITuple18<T0, T1, T2, T3, T4, T5, T6, T7, T8, T9, T10, T11, T12, T13, T14, T15, T16, T17>>(_System.Tuple18<T0, T1, T2, T3, T4, T5, T6, T7, T8, T9, T10, T11, T12, T13, T14, T15, T16, T17>.Default(_td_T0.Default(), _td_T1.Default(), _td_T2.Default(), _td_T3.Default(), _td_T4.Default(), _td_T5.Default(), _td_T6.Default(), _td_T7.Default(), _td_T8.Default(), _td_T9.Default(), _td_T10.Default(), _td_T11.Default(), _td_T12.Default(), _td_T13.Default(), _td_T14.Default(), _td_T15.Default(), _td_T16.Default(), _td_T17.Default()));
    }
    public static _ITuple18<T0, T1, T2, T3, T4, T5, T6, T7, T8, T9, T10, T11, T12, T13, T14, T15, T16, T17> create(T0 _0, T1 _1, T2 _2, T3 _3, T4 _4, T5 _5, T6 _6, T7 _7, T8 _8, T9 _9, T10 _10, T11 _11, T12 _12, T13 _13, T14 _14, T15 _15, T16 _16, T17 _17) {
      return new Tuple18<T0, T1, T2, T3, T4, T5, T6, T7, T8, T9, T10, T11, T12, T13, T14, T15, T16, T17>(_0, _1, _2, _3, _4, _5, _6, _7, _8, _9, _10, _11, _12, _13, _14, _15, _16, _17);
    }
    public static _ITuple18<T0, T1, T2, T3, T4, T5, T6, T7, T8, T9, T10, T11, T12, T13, T14, T15, T16, T17> create____hMake18(T0 _0, T1 _1, T2 _2, T3 _3, T4 _4, T5 _5, T6 _6, T7 _7, T8 _8, T9 _9, T10 _10, T11 _11, T12 _12, T13 _13, T14 _14, T15 _15, T16 _16, T17 _17) {
      return create(_0, _1, _2, _3, _4, _5, _6, _7, _8, _9, _10, _11, _12, _13, _14, _15, _16, _17);
    }
    public T0 dtor__0 {
      get {
        return this.__0;
      }
    }
    public T1 dtor__1 {
      get {
        return this.__1;
      }
    }
    public T2 dtor__2 {
      get {
        return this.__2;
      }
    }
    public T3 dtor__3 {
      get {
        return this.__3;
      }
    }
    public T4 dtor__4 {
      get {
        return this.__4;
      }
    }
    public T5 dtor__5 {
      get {
        return this.__5;
      }
    }
    public T6 dtor__6 {
      get {
        return this.__6;
      }
    }
    public T7 dtor__7 {
      get {
        return this.__7;
      }
    }
    public T8 dtor__8 {
      get {
        return this.__8;
      }
    }
    public T9 dtor__9 {
      get {
        return this.__9;
      }
    }
    public T10 dtor__10 {
      get {
        return this.__10;
      }
    }
    public T11 dtor__11 {
      get {
        return this.__11;
      }
    }
    public T12 dtor__12 {
      get {
        return this.__12;
      }
    }
    public T13 dtor__13 {
      get {
        return this.__13;
      }
    }
    public T14 dtor__14 {
      get {
        return this.__14;
      }
    }
    public T15 dtor__15 {
      get {
        return this.__15;
      }
    }
    public T16 dtor__16 {
      get {
        return this.__16;
      }
    }
    public T17 dtor__17 {
      get {
        return this.__17;
      }
    }
  }

  public interface _ITuple19<out T0, out T1, out T2, out T3, out T4, out T5, out T6, out T7, out T8, out T9, out T10, out T11, out T12, out T13, out T14, out T15, out T16, out T17, out T18> {
    T0 dtor__0 { get; }
    T1 dtor__1 { get; }
    T2 dtor__2 { get; }
    T3 dtor__3 { get; }
    T4 dtor__4 { get; }
    T5 dtor__5 { get; }
    T6 dtor__6 { get; }
    T7 dtor__7 { get; }
    T8 dtor__8 { get; }
    T9 dtor__9 { get; }
    T10 dtor__10 { get; }
    T11 dtor__11 { get; }
    T12 dtor__12 { get; }
    T13 dtor__13 { get; }
    T14 dtor__14 { get; }
    T15 dtor__15 { get; }
    T16 dtor__16 { get; }
    T17 dtor__17 { get; }
    T18 dtor__18 { get; }
    _ITuple19<__T0, __T1, __T2, __T3, __T4, __T5, __T6, __T7, __T8, __T9, __T10, __T11, __T12, __T13, __T14, __T15, __T16, __T17, __T18> DowncastClone<__T0, __T1, __T2, __T3, __T4, __T5, __T6, __T7, __T8, __T9, __T10, __T11, __T12, __T13, __T14, __T15, __T16, __T17, __T18>(Func<T0, __T0> converter0, Func<T1, __T1> converter1, Func<T2, __T2> converter2, Func<T3, __T3> converter3, Func<T4, __T4> converter4, Func<T5, __T5> converter5, Func<T6, __T6> converter6, Func<T7, __T7> converter7, Func<T8, __T8> converter8, Func<T9, __T9> converter9, Func<T10, __T10> converter10, Func<T11, __T11> converter11, Func<T12, __T12> converter12, Func<T13, __T13> converter13, Func<T14, __T14> converter14, Func<T15, __T15> converter15, Func<T16, __T16> converter16, Func<T17, __T17> converter17, Func<T18, __T18> converter18);
  }
  public class Tuple19<T0, T1, T2, T3, T4, T5, T6, T7, T8, T9, T10, T11, T12, T13, T14, T15, T16, T17, T18> : _ITuple19<T0, T1, T2, T3, T4, T5, T6, T7, T8, T9, T10, T11, T12, T13, T14, T15, T16, T17, T18> {
    public readonly T0 __0;
    public readonly T1 __1;
    public readonly T2 __2;
    public readonly T3 __3;
    public readonly T4 __4;
    public readonly T5 __5;
    public readonly T6 __6;
    public readonly T7 __7;
    public readonly T8 __8;
    public readonly T9 __9;
    public readonly T10 __10;
    public readonly T11 __11;
    public readonly T12 __12;
    public readonly T13 __13;
    public readonly T14 __14;
    public readonly T15 __15;
    public readonly T16 __16;
    public readonly T17 __17;
    public readonly T18 __18;
    public Tuple19(T0 _0, T1 _1, T2 _2, T3 _3, T4 _4, T5 _5, T6 _6, T7 _7, T8 _8, T9 _9, T10 _10, T11 _11, T12 _12, T13 _13, T14 _14, T15 _15, T16 _16, T17 _17, T18 _18) {
      this.__0 = _0;
      this.__1 = _1;
      this.__2 = _2;
      this.__3 = _3;
      this.__4 = _4;
      this.__5 = _5;
      this.__6 = _6;
      this.__7 = _7;
      this.__8 = _8;
      this.__9 = _9;
      this.__10 = _10;
      this.__11 = _11;
      this.__12 = _12;
      this.__13 = _13;
      this.__14 = _14;
      this.__15 = _15;
      this.__16 = _16;
      this.__17 = _17;
      this.__18 = _18;
    }
    public _ITuple19<__T0, __T1, __T2, __T3, __T4, __T5, __T6, __T7, __T8, __T9, __T10, __T11, __T12, __T13, __T14, __T15, __T16, __T17, __T18> DowncastClone<__T0, __T1, __T2, __T3, __T4, __T5, __T6, __T7, __T8, __T9, __T10, __T11, __T12, __T13, __T14, __T15, __T16, __T17, __T18>(Func<T0, __T0> converter0, Func<T1, __T1> converter1, Func<T2, __T2> converter2, Func<T3, __T3> converter3, Func<T4, __T4> converter4, Func<T5, __T5> converter5, Func<T6, __T6> converter6, Func<T7, __T7> converter7, Func<T8, __T8> converter8, Func<T9, __T9> converter9, Func<T10, __T10> converter10, Func<T11, __T11> converter11, Func<T12, __T12> converter12, Func<T13, __T13> converter13, Func<T14, __T14> converter14, Func<T15, __T15> converter15, Func<T16, __T16> converter16, Func<T17, __T17> converter17, Func<T18, __T18> converter18) {
      if (this is _ITuple19<__T0, __T1, __T2, __T3, __T4, __T5, __T6, __T7, __T8, __T9, __T10, __T11, __T12, __T13, __T14, __T15, __T16, __T17, __T18> dt) { return dt; }
      return new Tuple19<__T0, __T1, __T2, __T3, __T4, __T5, __T6, __T7, __T8, __T9, __T10, __T11, __T12, __T13, __T14, __T15, __T16, __T17, __T18>(converter0(__0), converter1(__1), converter2(__2), converter3(__3), converter4(__4), converter5(__5), converter6(__6), converter7(__7), converter8(__8), converter9(__9), converter10(__10), converter11(__11), converter12(__12), converter13(__13), converter14(__14), converter15(__15), converter16(__16), converter17(__17), converter18(__18));
    }
    public override bool Equals(object other) {
      var oth = other as _System.Tuple19<T0, T1, T2, T3, T4, T5, T6, T7, T8, T9, T10, T11, T12, T13, T14, T15, T16, T17, T18>;
      return oth != null && object.Equals(this.__0, oth.__0) && object.Equals(this.__1, oth.__1) && object.Equals(this.__2, oth.__2) && object.Equals(this.__3, oth.__3) && object.Equals(this.__4, oth.__4) && object.Equals(this.__5, oth.__5) && object.Equals(this.__6, oth.__6) && object.Equals(this.__7, oth.__7) && object.Equals(this.__8, oth.__8) && object.Equals(this.__9, oth.__9) && object.Equals(this.__10, oth.__10) && object.Equals(this.__11, oth.__11) && object.Equals(this.__12, oth.__12) && object.Equals(this.__13, oth.__13) && object.Equals(this.__14, oth.__14) && object.Equals(this.__15, oth.__15) && object.Equals(this.__16, oth.__16) && object.Equals(this.__17, oth.__17) && object.Equals(this.__18, oth.__18);
    }
    public override int GetHashCode() {
      ulong hash = 5381;
      hash = ((hash << 5) + hash) + 0;
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this.__0));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this.__1));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this.__2));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this.__3));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this.__4));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this.__5));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this.__6));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this.__7));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this.__8));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this.__9));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this.__10));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this.__11));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this.__12));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this.__13));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this.__14));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this.__15));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this.__16));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this.__17));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this.__18));
      return (int) hash;
    }
    public override string ToString() {
      string s = "";
      s += "(";
      s += Dafny.Helpers.ToString(this.__0);
      s += ", ";
      s += Dafny.Helpers.ToString(this.__1);
      s += ", ";
      s += Dafny.Helpers.ToString(this.__2);
      s += ", ";
      s += Dafny.Helpers.ToString(this.__3);
      s += ", ";
      s += Dafny.Helpers.ToString(this.__4);
      s += ", ";
      s += Dafny.Helpers.ToString(this.__5);
      s += ", ";
      s += Dafny.Helpers.ToString(this.__6);
      s += ", ";
      s += Dafny.Helpers.ToString(this.__7);
      s += ", ";
      s += Dafny.Helpers.ToString(this.__8);
      s += ", ";
      s += Dafny.Helpers.ToString(this.__9);
      s += ", ";
      s += Dafny.Helpers.ToString(this.__10);
      s += ", ";
      s += Dafny.Helpers.ToString(this.__11);
      s += ", ";
      s += Dafny.Helpers.ToString(this.__12);
      s += ", ";
      s += Dafny.Helpers.ToString(this.__13);
      s += ", ";
      s += Dafny.Helpers.ToString(this.__14);
      s += ", ";
      s += Dafny.Helpers.ToString(this.__15);
      s += ", ";
      s += Dafny.Helpers.ToString(this.__16);
      s += ", ";
      s += Dafny.Helpers.ToString(this.__17);
      s += ", ";
      s += Dafny.Helpers.ToString(this.__18);
      s += ")";
      return s;
    }
    public static _System._ITuple19<T0, T1, T2, T3, T4, T5, T6, T7, T8, T9, T10, T11, T12, T13, T14, T15, T16, T17, T18> Default(T0 _default_T0, T1 _default_T1, T2 _default_T2, T3 _default_T3, T4 _default_T4, T5 _default_T5, T6 _default_T6, T7 _default_T7, T8 _default_T8, T9 _default_T9, T10 _default_T10, T11 _default_T11, T12 _default_T12, T13 _default_T13, T14 _default_T14, T15 _default_T15, T16 _default_T16, T17 _default_T17, T18 _default_T18) {
      return create(_default_T0, _default_T1, _default_T2, _default_T3, _default_T4, _default_T5, _default_T6, _default_T7, _default_T8, _default_T9, _default_T10, _default_T11, _default_T12, _default_T13, _default_T14, _default_T15, _default_T16, _default_T17, _default_T18);
    }
    public static Dafny.TypeDescriptor<_System._ITuple19<T0, T1, T2, T3, T4, T5, T6, T7, T8, T9, T10, T11, T12, T13, T14, T15, T16, T17, T18>> _TypeDescriptor(Dafny.TypeDescriptor<T0> _td_T0, Dafny.TypeDescriptor<T1> _td_T1, Dafny.TypeDescriptor<T2> _td_T2, Dafny.TypeDescriptor<T3> _td_T3, Dafny.TypeDescriptor<T4> _td_T4, Dafny.TypeDescriptor<T5> _td_T5, Dafny.TypeDescriptor<T6> _td_T6, Dafny.TypeDescriptor<T7> _td_T7, Dafny.TypeDescriptor<T8> _td_T8, Dafny.TypeDescriptor<T9> _td_T9, Dafny.TypeDescriptor<T10> _td_T10, Dafny.TypeDescriptor<T11> _td_T11, Dafny.TypeDescriptor<T12> _td_T12, Dafny.TypeDescriptor<T13> _td_T13, Dafny.TypeDescriptor<T14> _td_T14, Dafny.TypeDescriptor<T15> _td_T15, Dafny.TypeDescriptor<T16> _td_T16, Dafny.TypeDescriptor<T17> _td_T17, Dafny.TypeDescriptor<T18> _td_T18) {
      return new Dafny.TypeDescriptor<_System._ITuple19<T0, T1, T2, T3, T4, T5, T6, T7, T8, T9, T10, T11, T12, T13, T14, T15, T16, T17, T18>>(_System.Tuple19<T0, T1, T2, T3, T4, T5, T6, T7, T8, T9, T10, T11, T12, T13, T14, T15, T16, T17, T18>.Default(_td_T0.Default(), _td_T1.Default(), _td_T2.Default(), _td_T3.Default(), _td_T4.Default(), _td_T5.Default(), _td_T6.Default(), _td_T7.Default(), _td_T8.Default(), _td_T9.Default(), _td_T10.Default(), _td_T11.Default(), _td_T12.Default(), _td_T13.Default(), _td_T14.Default(), _td_T15.Default(), _td_T16.Default(), _td_T17.Default(), _td_T18.Default()));
    }
    public static _ITuple19<T0, T1, T2, T3, T4, T5, T6, T7, T8, T9, T10, T11, T12, T13, T14, T15, T16, T17, T18> create(T0 _0, T1 _1, T2 _2, T3 _3, T4 _4, T5 _5, T6 _6, T7 _7, T8 _8, T9 _9, T10 _10, T11 _11, T12 _12, T13 _13, T14 _14, T15 _15, T16 _16, T17 _17, T18 _18) {
      return new Tuple19<T0, T1, T2, T3, T4, T5, T6, T7, T8, T9, T10, T11, T12, T13, T14, T15, T16, T17, T18>(_0, _1, _2, _3, _4, _5, _6, _7, _8, _9, _10, _11, _12, _13, _14, _15, _16, _17, _18);
    }
    public static _ITuple19<T0, T1, T2, T3, T4, T5, T6, T7, T8, T9, T10, T11, T12, T13, T14, T15, T16, T17, T18> create____hMake19(T0 _0, T1 _1, T2 _2, T3 _3, T4 _4, T5 _5, T6 _6, T7 _7, T8 _8, T9 _9, T10 _10, T11 _11, T12 _12, T13 _13, T14 _14, T15 _15, T16 _16, T17 _17, T18 _18) {
      return create(_0, _1, _2, _3, _4, _5, _6, _7, _8, _9, _10, _11, _12, _13, _14, _15, _16, _17, _18);
    }
    public T0 dtor__0 {
      get {
        return this.__0;
      }
    }
    public T1 dtor__1 {
      get {
        return this.__1;
      }
    }
    public T2 dtor__2 {
      get {
        return this.__2;
      }
    }
    public T3 dtor__3 {
      get {
        return this.__3;
      }
    }
    public T4 dtor__4 {
      get {
        return this.__4;
      }
    }
    public T5 dtor__5 {
      get {
        return this.__5;
      }
    }
    public T6 dtor__6 {
      get {
        return this.__6;
      }
    }
    public T7 dtor__7 {
      get {
        return this.__7;
      }
    }
    public T8 dtor__8 {
      get {
        return this.__8;
      }
    }
    public T9 dtor__9 {
      get {
        return this.__9;
      }
    }
    public T10 dtor__10 {
      get {
        return this.__10;
      }
    }
    public T11 dtor__11 {
      get {
        return this.__11;
      }
    }
    public T12 dtor__12 {
      get {
        return this.__12;
      }
    }
    public T13 dtor__13 {
      get {
        return this.__13;
      }
    }
    public T14 dtor__14 {
      get {
        return this.__14;
      }
    }
    public T15 dtor__15 {
      get {
        return this.__15;
      }
    }
    public T16 dtor__16 {
      get {
        return this.__16;
      }
    }
    public T17 dtor__17 {
      get {
        return this.__17;
      }
    }
    public T18 dtor__18 {
      get {
        return this.__18;
      }
    }
  }

  public interface _ITuple20<out T0, out T1, out T2, out T3, out T4, out T5, out T6, out T7, out T8, out T9, out T10, out T11, out T12, out T13, out T14, out T15, out T16, out T17, out T18, out T19> {
    T0 dtor__0 { get; }
    T1 dtor__1 { get; }
    T2 dtor__2 { get; }
    T3 dtor__3 { get; }
    T4 dtor__4 { get; }
    T5 dtor__5 { get; }
    T6 dtor__6 { get; }
    T7 dtor__7 { get; }
    T8 dtor__8 { get; }
    T9 dtor__9 { get; }
    T10 dtor__10 { get; }
    T11 dtor__11 { get; }
    T12 dtor__12 { get; }
    T13 dtor__13 { get; }
    T14 dtor__14 { get; }
    T15 dtor__15 { get; }
    T16 dtor__16 { get; }
    T17 dtor__17 { get; }
    T18 dtor__18 { get; }
    T19 dtor__19 { get; }
    _ITuple20<__T0, __T1, __T2, __T3, __T4, __T5, __T6, __T7, __T8, __T9, __T10, __T11, __T12, __T13, __T14, __T15, __T16, __T17, __T18, __T19> DowncastClone<__T0, __T1, __T2, __T3, __T4, __T5, __T6, __T7, __T8, __T9, __T10, __T11, __T12, __T13, __T14, __T15, __T16, __T17, __T18, __T19>(Func<T0, __T0> converter0, Func<T1, __T1> converter1, Func<T2, __T2> converter2, Func<T3, __T3> converter3, Func<T4, __T4> converter4, Func<T5, __T5> converter5, Func<T6, __T6> converter6, Func<T7, __T7> converter7, Func<T8, __T8> converter8, Func<T9, __T9> converter9, Func<T10, __T10> converter10, Func<T11, __T11> converter11, Func<T12, __T12> converter12, Func<T13, __T13> converter13, Func<T14, __T14> converter14, Func<T15, __T15> converter15, Func<T16, __T16> converter16, Func<T17, __T17> converter17, Func<T18, __T18> converter18, Func<T19, __T19> converter19);
  }
  public class Tuple20<T0, T1, T2, T3, T4, T5, T6, T7, T8, T9, T10, T11, T12, T13, T14, T15, T16, T17, T18, T19> : _ITuple20<T0, T1, T2, T3, T4, T5, T6, T7, T8, T9, T10, T11, T12, T13, T14, T15, T16, T17, T18, T19> {
    public readonly T0 __0;
    public readonly T1 __1;
    public readonly T2 __2;
    public readonly T3 __3;
    public readonly T4 __4;
    public readonly T5 __5;
    public readonly T6 __6;
    public readonly T7 __7;
    public readonly T8 __8;
    public readonly T9 __9;
    public readonly T10 __10;
    public readonly T11 __11;
    public readonly T12 __12;
    public readonly T13 __13;
    public readonly T14 __14;
    public readonly T15 __15;
    public readonly T16 __16;
    public readonly T17 __17;
    public readonly T18 __18;
    public readonly T19 __19;
    public Tuple20(T0 _0, T1 _1, T2 _2, T3 _3, T4 _4, T5 _5, T6 _6, T7 _7, T8 _8, T9 _9, T10 _10, T11 _11, T12 _12, T13 _13, T14 _14, T15 _15, T16 _16, T17 _17, T18 _18, T19 _19) {
      this.__0 = _0;
      this.__1 = _1;
      this.__2 = _2;
      this.__3 = _3;
      this.__4 = _4;
      this.__5 = _5;
      this.__6 = _6;
      this.__7 = _7;
      this.__8 = _8;
      this.__9 = _9;
      this.__10 = _10;
      this.__11 = _11;
      this.__12 = _12;
      this.__13 = _13;
      this.__14 = _14;
      this.__15 = _15;
      this.__16 = _16;
      this.__17 = _17;
      this.__18 = _18;
      this.__19 = _19;
    }
    public _ITuple20<__T0, __T1, __T2, __T3, __T4, __T5, __T6, __T7, __T8, __T9, __T10, __T11, __T12, __T13, __T14, __T15, __T16, __T17, __T18, __T19> DowncastClone<__T0, __T1, __T2, __T3, __T4, __T5, __T6, __T7, __T8, __T9, __T10, __T11, __T12, __T13, __T14, __T15, __T16, __T17, __T18, __T19>(Func<T0, __T0> converter0, Func<T1, __T1> converter1, Func<T2, __T2> converter2, Func<T3, __T3> converter3, Func<T4, __T4> converter4, Func<T5, __T5> converter5, Func<T6, __T6> converter6, Func<T7, __T7> converter7, Func<T8, __T8> converter8, Func<T9, __T9> converter9, Func<T10, __T10> converter10, Func<T11, __T11> converter11, Func<T12, __T12> converter12, Func<T13, __T13> converter13, Func<T14, __T14> converter14, Func<T15, __T15> converter15, Func<T16, __T16> converter16, Func<T17, __T17> converter17, Func<T18, __T18> converter18, Func<T19, __T19> converter19) {
      if (this is _ITuple20<__T0, __T1, __T2, __T3, __T4, __T5, __T6, __T7, __T8, __T9, __T10, __T11, __T12, __T13, __T14, __T15, __T16, __T17, __T18, __T19> dt) { return dt; }
      return new Tuple20<__T0, __T1, __T2, __T3, __T4, __T5, __T6, __T7, __T8, __T9, __T10, __T11, __T12, __T13, __T14, __T15, __T16, __T17, __T18, __T19>(converter0(__0), converter1(__1), converter2(__2), converter3(__3), converter4(__4), converter5(__5), converter6(__6), converter7(__7), converter8(__8), converter9(__9), converter10(__10), converter11(__11), converter12(__12), converter13(__13), converter14(__14), converter15(__15), converter16(__16), converter17(__17), converter18(__18), converter19(__19));
    }
    public override bool Equals(object other) {
      var oth = other as _System.Tuple20<T0, T1, T2, T3, T4, T5, T6, T7, T8, T9, T10, T11, T12, T13, T14, T15, T16, T17, T18, T19>;
      return oth != null && object.Equals(this.__0, oth.__0) && object.Equals(this.__1, oth.__1) && object.Equals(this.__2, oth.__2) && object.Equals(this.__3, oth.__3) && object.Equals(this.__4, oth.__4) && object.Equals(this.__5, oth.__5) && object.Equals(this.__6, oth.__6) && object.Equals(this.__7, oth.__7) && object.Equals(this.__8, oth.__8) && object.Equals(this.__9, oth.__9) && object.Equals(this.__10, oth.__10) && object.Equals(this.__11, oth.__11) && object.Equals(this.__12, oth.__12) && object.Equals(this.__13, oth.__13) && object.Equals(this.__14, oth.__14) && object.Equals(this.__15, oth.__15) && object.Equals(this.__16, oth.__16) && object.Equals(this.__17, oth.__17) && object.Equals(this.__18, oth.__18) && object.Equals(this.__19, oth.__19);
    }
    public override int GetHashCode() {
      ulong hash = 5381;
      hash = ((hash << 5) + hash) + 0;
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this.__0));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this.__1));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this.__2));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this.__3));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this.__4));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this.__5));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this.__6));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this.__7));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this.__8));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this.__9));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this.__10));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this.__11));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this.__12));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this.__13));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this.__14));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this.__15));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this.__16));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this.__17));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this.__18));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this.__19));
      return (int) hash;
    }
    public override string ToString() {
      string s = "";
      s += "(";
      s += Dafny.Helpers.ToString(this.__0);
      s += ", ";
      s += Dafny.Helpers.ToString(this.__1);
      s += ", ";
      s += Dafny.Helpers.ToString(this.__2);
      s += ", ";
      s += Dafny.Helpers.ToString(this.__3);
      s += ", ";
      s += Dafny.Helpers.ToString(this.__4);
      s += ", ";
      s += Dafny.Helpers.ToString(this.__5);
      s += ", ";
      s += Dafny.Helpers.ToString(this.__6);
      s += ", ";
      s += Dafny.Helpers.ToString(this.__7);
      s += ", ";
      s += Dafny.Helpers.ToString(this.__8);
      s += ", ";
      s += Dafny.Helpers.ToString(this.__9);
      s += ", ";
      s += Dafny.Helpers.ToString(this.__10);
      s += ", ";
      s += Dafny.Helpers.ToString(this.__11);
      s += ", ";
      s += Dafny.Helpers.ToString(this.__12);
      s += ", ";
      s += Dafny.Helpers.ToString(this.__13);
      s += ", ";
      s += Dafny.Helpers.ToString(this.__14);
      s += ", ";
      s += Dafny.Helpers.ToString(this.__15);
      s += ", ";
      s += Dafny.Helpers.ToString(this.__16);
      s += ", ";
      s += Dafny.Helpers.ToString(this.__17);
      s += ", ";
      s += Dafny.Helpers.ToString(this.__18);
      s += ", ";
      s += Dafny.Helpers.ToString(this.__19);
      s += ")";
      return s;
    }
    public static _System._ITuple20<T0, T1, T2, T3, T4, T5, T6, T7, T8, T9, T10, T11, T12, T13, T14, T15, T16, T17, T18, T19> Default(T0 _default_T0, T1 _default_T1, T2 _default_T2, T3 _default_T3, T4 _default_T4, T5 _default_T5, T6 _default_T6, T7 _default_T7, T8 _default_T8, T9 _default_T9, T10 _default_T10, T11 _default_T11, T12 _default_T12, T13 _default_T13, T14 _default_T14, T15 _default_T15, T16 _default_T16, T17 _default_T17, T18 _default_T18, T19 _default_T19) {
      return create(_default_T0, _default_T1, _default_T2, _default_T3, _default_T4, _default_T5, _default_T6, _default_T7, _default_T8, _default_T9, _default_T10, _default_T11, _default_T12, _default_T13, _default_T14, _default_T15, _default_T16, _default_T17, _default_T18, _default_T19);
    }
    public static Dafny.TypeDescriptor<_System._ITuple20<T0, T1, T2, T3, T4, T5, T6, T7, T8, T9, T10, T11, T12, T13, T14, T15, T16, T17, T18, T19>> _TypeDescriptor(Dafny.TypeDescriptor<T0> _td_T0, Dafny.TypeDescriptor<T1> _td_T1, Dafny.TypeDescriptor<T2> _td_T2, Dafny.TypeDescriptor<T3> _td_T3, Dafny.TypeDescriptor<T4> _td_T4, Dafny.TypeDescriptor<T5> _td_T5, Dafny.TypeDescriptor<T6> _td_T6, Dafny.TypeDescriptor<T7> _td_T7, Dafny.TypeDescriptor<T8> _td_T8, Dafny.TypeDescriptor<T9> _td_T9, Dafny.TypeDescriptor<T10> _td_T10, Dafny.TypeDescriptor<T11> _td_T11, Dafny.TypeDescriptor<T12> _td_T12, Dafny.TypeDescriptor<T13> _td_T13, Dafny.TypeDescriptor<T14> _td_T14, Dafny.TypeDescriptor<T15> _td_T15, Dafny.TypeDescriptor<T16> _td_T16, Dafny.TypeDescriptor<T17> _td_T17, Dafny.TypeDescriptor<T18> _td_T18, Dafny.TypeDescriptor<T19> _td_T19) {
      return new Dafny.TypeDescriptor<_System._ITuple20<T0, T1, T2, T3, T4, T5, T6, T7, T8, T9, T10, T11, T12, T13, T14, T15, T16, T17, T18, T19>>(_System.Tuple20<T0, T1, T2, T3, T4, T5, T6, T7, T8, T9, T10, T11, T12, T13, T14, T15, T16, T17, T18, T19>.Default(_td_T0.Default(), _td_T1.Default(), _td_T2.Default(), _td_T3.Default(), _td_T4.Default(), _td_T5.Default(), _td_T6.Default(), _td_T7.Default(), _td_T8.Default(), _td_T9.Default(), _td_T10.Default(), _td_T11.Default(), _td_T12.Default(), _td_T13.Default(), _td_T14.Default(), _td_T15.Default(), _td_T16.Default(), _td_T17.Default(), _td_T18.Default(), _td_T19.Default()));
    }
    public static _ITuple20<T0, T1, T2, T3, T4, T5, T6, T7, T8, T9, T10, T11, T12, T13, T14, T15, T16, T17, T18, T19> create(T0 _0, T1 _1, T2 _2, T3 _3, T4 _4, T5 _5, T6 _6, T7 _7, T8 _8, T9 _9, T10 _10, T11 _11, T12 _12, T13 _13, T14 _14, T15 _15, T16 _16, T17 _17, T18 _18, T19 _19) {
      return new Tuple20<T0, T1, T2, T3, T4, T5, T6, T7, T8, T9, T10, T11, T12, T13, T14, T15, T16, T17, T18, T19>(_0, _1, _2, _3, _4, _5, _6, _7, _8, _9, _10, _11, _12, _13, _14, _15, _16, _17, _18, _19);
    }
    public static _ITuple20<T0, T1, T2, T3, T4, T5, T6, T7, T8, T9, T10, T11, T12, T13, T14, T15, T16, T17, T18, T19> create____hMake20(T0 _0, T1 _1, T2 _2, T3 _3, T4 _4, T5 _5, T6 _6, T7 _7, T8 _8, T9 _9, T10 _10, T11 _11, T12 _12, T13 _13, T14 _14, T15 _15, T16 _16, T17 _17, T18 _18, T19 _19) {
      return create(_0, _1, _2, _3, _4, _5, _6, _7, _8, _9, _10, _11, _12, _13, _14, _15, _16, _17, _18, _19);
    }
    public T0 dtor__0 {
      get {
        return this.__0;
      }
    }
    public T1 dtor__1 {
      get {
        return this.__1;
      }
    }
    public T2 dtor__2 {
      get {
        return this.__2;
      }
    }
    public T3 dtor__3 {
      get {
        return this.__3;
      }
    }
    public T4 dtor__4 {
      get {
        return this.__4;
      }
    }
    public T5 dtor__5 {
      get {
        return this.__5;
      }
    }
    public T6 dtor__6 {
      get {
        return this.__6;
      }
    }
    public T7 dtor__7 {
      get {
        return this.__7;
      }
    }
    public T8 dtor__8 {
      get {
        return this.__8;
      }
    }
    public T9 dtor__9 {
      get {
        return this.__9;
      }
    }
    public T10 dtor__10 {
      get {
        return this.__10;
      }
    }
    public T11 dtor__11 {
      get {
        return this.__11;
      }
    }
    public T12 dtor__12 {
      get {
        return this.__12;
      }
    }
    public T13 dtor__13 {
      get {
        return this.__13;
      }
    }
    public T14 dtor__14 {
      get {
        return this.__14;
      }
    }
    public T15 dtor__15 {
      get {
        return this.__15;
      }
    }
    public T16 dtor__16 {
      get {
        return this.__16;
      }
    }
    public T17 dtor__17 {
      get {
        return this.__17;
      }
    }
    public T18 dtor__18 {
      get {
        return this.__18;
      }
    }
    public T19 dtor__19 {
      get {
        return this.__19;
      }
    }
  }
} // end of namespace _System
namespace Std.Concurrent {
    using System.Collections.Concurrent;
    using Std.Wrappers;

    public class MutableMap<K, V> {

        private ConcurrentDictionary<K, V> map;

        public MutableMap() {
            map = new ConcurrentDictionary<K, V>();
        }

        public void __ctor() { }

        public Dafny.ISet<K> Keys() {
            return Dafny.Set<K>.FromCollection(map.Keys);
        }

        public bool HasKey(K k) {
            return map.ContainsKey(k);
        }

        public Dafny.ISet<V> Values() {
            return Dafny.Set<V>.FromCollection(map.Values);
        }
    
        public Dafny.ISet<_System._ITuple2<K, V>> Items() {
            System.Collections.Generic.IEnumerable<_System._ITuple2<K, V>> ToEnumerable(System.Collections.Generic.IEnumerator<System.Collections.Generic.KeyValuePair<K, V>> enumerator) {
                while (enumerator.MoveNext())
                    yield return  _System.Tuple2<K, V>.create(enumerator.Current.Key, enumerator.Current.Value);
            }

            return Dafny.Set<_System._ITuple2<K, V>>.FromCollection(ToEnumerable(map.GetEnumerator()));
        }

        public void Put(K k, V v) {
            map.AddOrUpdate(k, v, ((key, oldValue) => v));
        }

        public _IOption<V> Get(K k) {
            var v = map[k];
            if (v is null) {
                return Option<V>.create_None();
            } else {
                return Option<V>.create_Some(v);
            }
        }

        public void Remove(K k) {
            map.TryRemove(k, out _);
        }

        public System.Numerics.BigInteger Size() {
            return new System.Numerics.BigInteger(map.Count);
        }
    }

    public class AtomicBox<T> {

        private T val;
        private Lock l;

        public AtomicBox() {
            l = new Lock();
        }

        public void __ctor(T t) {
          val = t;
        }

        public void Put(T t) {
            l.__Lock();
            val = t;
            l.Unlock();
        }

        public T Get() {
            l.__Lock();
            var r = val;
            l.Unlock();
            return r;
        }
    }

    public class Lock {

        private static System.Threading.Mutex mut = new System.Threading.Mutex();

        public void __ctor() {
        }

        public void __Lock() {
            mut.WaitOne();
        }

        public void Unlock() {
            mut.ReleaseMutex();
        }
    }
}
/*******************************************************************************
*  Copyright by the contributors to the Dafny Project
*  SPDX-License-Identifier: MIT
*******************************************************************************/

namespace Std.FileIOInternalExterns {
  using System;
  using System.IO;

  using Dafny;

  public class __default {
    /// <summary>
    /// Attempts to read all bytes from the file at the given path, and outputs the following values:
    /// <list>
    ///   <item>
    ///     <term>isError</term>
    ///     <description>
    ///       true iff an exception was thrown during path string conversion or when reading the file
    ///     </description>
    ///   </item>
    ///   <item>
    ///     <term>bytesRead</term>
    ///     <description>
    ///       the sequence of bytes read from the file, or an empty sequence if <c>isError</c> is true
    ///     </description>
    ///   </item>
    ///   <item>
    ///     <term>errorMsg</term>
    ///     <description>
    ///       the error message of the thrown exception if <c>isError</c> is true, or an empty sequence otherwise
    ///     </description>
    ///   </item>
    /// </list>
    ///
    /// We output these values individually because Result is not defined in the runtime but instead in library code.
    /// It is the responsibility of library code to construct an equivalent Result value.
    /// </summary>
    public static void INTERNAL__ReadBytesFromFile(ISequence<Dafny.Rune> path, out bool isError, out ISequence<byte> bytesRead,
      out ISequence<Dafny.Rune> errorMsg) {
      isError = true;
      bytesRead = Sequence<byte>.Empty;
      errorMsg = Sequence<Rune>.Empty;
      try {
        bytesRead = Helpers.SeqFromArray(File.ReadAllBytes(path?.ToVerbatimString(false)));
        isError = false;
      } catch (Exception e) {
        errorMsg = Sequence<Rune>.UnicodeFromString(e.ToString());
      }
    }

    /// <summary>
    /// Attempts to write all given bytes to the file at the given path, creating nonexistent parent directories as necessary,
    /// and outputs the following values:
    /// <list>
    ///   <item>
    ///     <term>isError</term>
    ///     <description>
    ///       true iff an exception was thrown during path string conversion or when writing to the file
    ///     </description>
    ///   </item>
    ///   <item>
    ///     <term>errorMsg</term>
    ///     <description>
    ///       the error message of the thrown exception if <c>isError</c> is true, or an empty sequence otherwise
    ///     </description>
    ///   </item>
    /// </list>
    ///
    /// We output these values individually because Result is not defined in the runtime but instead in library code.
    /// It is the responsibility of library code to construct an equivalent Result value.
    /// </summary>
    public static void INTERNAL__WriteBytesToFile(ISequence<Dafny.Rune> path, ISequence<byte> bytes, out bool isError, out ISequence<Dafny.Rune> errorMsg) {
      isError = true;
      errorMsg = Sequence<Rune>.Empty;
      try {
        string pathStr = path?.ToVerbatimString(false);
        CreateParentDirs(pathStr);
        File.WriteAllBytes(pathStr, bytes.CloneAsArray());
        isError = false;
      } catch (Exception e) {
        errorMsg = Sequence<Rune>.UnicodeFromString(e.ToString());
      }
    }

    /// <summary>
    /// Creates the nonexistent parent directory(-ies) of the given path.
    /// </summary>
    private static void CreateParentDirs(string path) {
      string parentDir = Path.GetDirectoryName(Path.GetFullPath(path));
      Directory.CreateDirectory(parentDir);
    }
  }
}
namespace Dafny {
  internal class ArrayHelpers {
    public static T[] InitNewArray1<T>(T z, BigInteger size0) {
      int s0 = (int)size0;
      T[] a = new T[s0];
      for (int i0 = 0; i0 < s0; i0++) {
        a[i0] = z;
      }
      return a;
    }
  }
} // end of namespace Dafny
internal static class FuncExtensions {
  public static Func<U, UResult> DowncastClone<T, TResult, U, UResult>(this Func<T, TResult> F, Func<U, T> ArgConv, Func<TResult, UResult> ResConv) {
    return arg => ResConv(F(ArgConv(arg)));
  }
  public static Func<UResult> DowncastClone<TResult, UResult>(this Func<TResult> F, Func<TResult, UResult> ResConv) {
    return () => ResConv(F());
  }
  public static Func<U1, U2, UResult> DowncastClone<T1, T2, TResult, U1, U2, UResult>(this Func<T1, T2, TResult> F, Func<U1, T1> ArgConv1, Func<U2, T2> ArgConv2, Func<TResult, UResult> ResConv) {
    return (arg1, arg2) => ResConv(F(ArgConv1(arg1), ArgConv2(arg2)));
  }
  public static Func<U1, U2, U3, UResult> DowncastClone<T1, T2, T3, TResult, U1, U2, U3, UResult>(this Func<T1, T2, T3, TResult> F, Func<U1, T1> ArgConv1, Func<U2, T2> ArgConv2, Func<U3, T3> ArgConv3, Func<TResult, UResult> ResConv) {
    return (arg1, arg2, arg3) => ResConv(F(ArgConv1(arg1), ArgConv2(arg2), ArgConv3(arg3)));
  }
  public static Func<U1, U2, U3, U4, UResult> DowncastClone<T1, T2, T3, T4, TResult, U1, U2, U3, U4, UResult>(this Func<T1, T2, T3, T4, TResult> F, Func<U1, T1> ArgConv1, Func<U2, T2> ArgConv2, Func<U3, T3> ArgConv3, Func<U4, T4> ArgConv4, Func<TResult, UResult> ResConv) {
    return (arg1, arg2, arg3, arg4) => ResConv(F(ArgConv1(arg1), ArgConv2(arg2), ArgConv3(arg3), ArgConv4(arg4)));
  }
  public static Func<U1, U2, U3, U4, U5, UResult> DowncastClone<T1, T2, T3, T4, T5, TResult, U1, U2, U3, U4, U5, UResult>(this Func<T1, T2, T3, T4, T5, TResult> F, Func<U1, T1> ArgConv1, Func<U2, T2> ArgConv2, Func<U3, T3> ArgConv3, Func<U4, T4> ArgConv4, Func<U5, T5> ArgConv5, Func<TResult, UResult> ResConv) {
    return (arg1, arg2, arg3, arg4, arg5) => ResConv(F(ArgConv1(arg1), ArgConv2(arg2), ArgConv3(arg3), ArgConv4(arg4), ArgConv5(arg5)));
  }
  public static Func<U1, U2, U3, U4, U5, U6, U7, UResult> DowncastClone<T1, T2, T3, T4, T5, T6, T7, TResult, U1, U2, U3, U4, U5, U6, U7, UResult>(this Func<T1, T2, T3, T4, T5, T6, T7, TResult> F, Func<U1, T1> ArgConv1, Func<U2, T2> ArgConv2, Func<U3, T3> ArgConv3, Func<U4, T4> ArgConv4, Func<U5, T5> ArgConv5, Func<U6, T6> ArgConv6, Func<U7, T7> ArgConv7, Func<TResult, UResult> ResConv) {
    return (arg1, arg2, arg3, arg4, arg5, arg6, arg7) => ResConv(F(ArgConv1(arg1), ArgConv2(arg2), ArgConv3(arg3), ArgConv4(arg4), ArgConv5(arg5), ArgConv6(arg6), ArgConv7(arg7)));
  }
}
namespace Std.Wrappers {

  public partial class __default {
    public static Std.Wrappers._IOutcomeResult<__E> Need<__E>(bool condition, __E error)
    {
      if (condition) {
        return Std.Wrappers.OutcomeResult<__E>.create_Pass_k();
      } else {
        return Std.Wrappers.OutcomeResult<__E>.create_Fail_k(error);
      }
    }
  }

  public interface _IOption<out T> {
    bool is_None { get; }
    bool is_Some { get; }
    T dtor_value { get; }
    _IOption<__T> DowncastClone<__T>(Func<T, __T> converter0);
    bool IsFailure();
    Std.Wrappers._IOption<__U> PropagateFailure<__U>();
    T Extract();
    Std.Wrappers._IResult<T, __E> ToResult<__E>(__E error);
    Std.Wrappers._IOutcome<__E> ToOutcome<__E>(__E error);
  }
  public abstract class Option<T> : _IOption<T> {
    public Option() {
    }
    public static Std.Wrappers._IOption<T> Default() {
      return create_None();
    }
    public static Dafny.TypeDescriptor<Std.Wrappers._IOption<T>> _TypeDescriptor() {
      return new Dafny.TypeDescriptor<Std.Wrappers._IOption<T>>(Std.Wrappers.Option<T>.Default());
    }
    public static _IOption<T> create_None() {
      return new Option_None<T>();
    }
    public static _IOption<T> create_Some(T @value) {
      return new Option_Some<T>(@value);
    }
    public bool is_None { get { return this is Option_None<T>; } }
    public bool is_Some { get { return this is Option_Some<T>; } }
    public T dtor_value {
      get {
        var d = this;
        return ((Option_Some<T>)d)._value;
      }
    }
    public abstract _IOption<__T> DowncastClone<__T>(Func<T, __T> converter0);
    public bool IsFailure() {
      return (this).is_None;
    }
    public Std.Wrappers._IOption<__U> PropagateFailure<__U>() {
      return Std.Wrappers.Option<__U>.create_None();
    }
    public T Extract() {
      return (this).dtor_value;
    }
    public static T GetOr(Std.Wrappers._IOption<T> _this, T @default) {
      Std.Wrappers._IOption<T> _source0 = _this;
      {
        if (_source0.is_Some) {
          T _0_v = _source0.dtor_value;
          return _0_v;
        }
      }
      {
        return @default;
      }
    }
    public Std.Wrappers._IResult<T, __E> ToResult<__E>(__E error) {
      Std.Wrappers._IOption<T> _source0 = this;
      {
        if (_source0.is_Some) {
          T _0_v = _source0.dtor_value;
          return Std.Wrappers.Result<T, __E>.create_Success(_0_v);
        }
      }
      {
        return Std.Wrappers.Result<T, __E>.create_Failure(error);
      }
    }
    public Std.Wrappers._IOutcome<__E> ToOutcome<__E>(__E error) {
      Std.Wrappers._IOption<T> _source0 = this;
      {
        if (_source0.is_Some) {
          T _0_v = _source0.dtor_value;
          return Std.Wrappers.Outcome<__E>.create_Pass();
        }
      }
      {
        return Std.Wrappers.Outcome<__E>.create_Fail(error);
      }
    }
    public static __FC Map<__FC>(Std.Wrappers._IOption<T> _this, Func<Std.Wrappers._IOption<T>, __FC> rewrap) {
      return Dafny.Helpers.Id<Func<Std.Wrappers._IOption<T>, __FC>>(rewrap)(_this);
    }
  }
  public class Option_None<T> : Option<T> {
    public Option_None() : base() {
    }
    public override _IOption<__T> DowncastClone<__T>(Func<T, __T> converter0) {
      if (this is _IOption<__T> dt) { return dt; }
      return new Option_None<__T>();
    }
    public override bool Equals(object other) {
      var oth = other as Std.Wrappers.Option_None<T>;
      return oth != null;
    }
    public override int GetHashCode() {
      ulong hash = 5381;
      hash = ((hash << 5) + hash) + 0;
      return (int) hash;
    }
    public override string ToString() {
      string s = "Wrappers.Option.None";
      return s;
    }
  }
  public class Option_Some<T> : Option<T> {
    public readonly T _value;
    public Option_Some(T @value) : base() {
      this._value = @value;
    }
    public override _IOption<__T> DowncastClone<__T>(Func<T, __T> converter0) {
      if (this is _IOption<__T> dt) { return dt; }
      return new Option_Some<__T>(converter0(_value));
    }
    public override bool Equals(object other) {
      var oth = other as Std.Wrappers.Option_Some<T>;
      return oth != null && object.Equals(this._value, oth._value);
    }
    public override int GetHashCode() {
      ulong hash = 5381;
      hash = ((hash << 5) + hash) + 1;
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this._value));
      return (int) hash;
    }
    public override string ToString() {
      string s = "Wrappers.Option.Some";
      s += "(";
      s += Dafny.Helpers.ToString(this._value);
      s += ")";
      return s;
    }
  }

  public interface _IResult<out R, out E> {
    bool is_Success { get; }
    bool is_Failure { get; }
    R dtor_value { get; }
    E dtor_error { get; }
    _IResult<__R, __E> DowncastClone<__R, __E>(Func<R, __R> converter0, Func<E, __E> converter1);
    bool IsFailure();
    Std.Wrappers._IResult<__U, E> PropagateFailure<__U>();
    R Extract();
    Std.Wrappers._IOption<R> ToOption();
    Std.Wrappers._IOutcome<E> ToOutcome();
  }
  public abstract class Result<R, E> : _IResult<R, E> {
    public Result() {
    }
    public static Std.Wrappers._IResult<R, E> Default(R _default_R) {
      return create_Success(_default_R);
    }
    public static Dafny.TypeDescriptor<Std.Wrappers._IResult<R, E>> _TypeDescriptor(Dafny.TypeDescriptor<R> _td_R) {
      return new Dafny.TypeDescriptor<Std.Wrappers._IResult<R, E>>(Std.Wrappers.Result<R, E>.Default(_td_R.Default()));
    }
    public static _IResult<R, E> create_Success(R @value) {
      return new Result_Success<R, E>(@value);
    }
    public static _IResult<R, E> create_Failure(E error) {
      return new Result_Failure<R, E>(error);
    }
    public bool is_Success { get { return this is Result_Success<R, E>; } }
    public bool is_Failure { get { return this is Result_Failure<R, E>; } }
    public R dtor_value {
      get {
        var d = this;
        return ((Result_Success<R, E>)d)._value;
      }
    }
    public E dtor_error {
      get {
        var d = this;
        return ((Result_Failure<R, E>)d)._error;
      }
    }
    public abstract _IResult<__R, __E> DowncastClone<__R, __E>(Func<R, __R> converter0, Func<E, __E> converter1);
    public bool IsFailure() {
      return (this).is_Failure;
    }
    public Std.Wrappers._IResult<__U, E> PropagateFailure<__U>() {
      return Std.Wrappers.Result<__U, E>.create_Failure((this).dtor_error);
    }
    public R Extract() {
      return (this).dtor_value;
    }
    public static R GetOr(Std.Wrappers._IResult<R, E> _this, R @default) {
      Std.Wrappers._IResult<R, E> _source0 = _this;
      {
        if (_source0.is_Success) {
          R _0_s = _source0.dtor_value;
          return _0_s;
        }
      }
      {
        E _1_e = _source0.dtor_error;
        return @default;
      }
    }
    public Std.Wrappers._IOption<R> ToOption() {
      Std.Wrappers._IResult<R, E> _source0 = this;
      {
        if (_source0.is_Success) {
          R _0_s = _source0.dtor_value;
          return Std.Wrappers.Option<R>.create_Some(_0_s);
        }
      }
      {
        E _1_e = _source0.dtor_error;
        return Std.Wrappers.Option<R>.create_None();
      }
    }
    public Std.Wrappers._IOutcome<E> ToOutcome() {
      Std.Wrappers._IResult<R, E> _source0 = this;
      {
        if (_source0.is_Success) {
          R _0_s = _source0.dtor_value;
          return Std.Wrappers.Outcome<E>.create_Pass();
        }
      }
      {
        E _1_e = _source0.dtor_error;
        return Std.Wrappers.Outcome<E>.create_Fail(_1_e);
      }
    }
    public static __FC Map<__FC>(Std.Wrappers._IResult<R, E> _this, Func<Std.Wrappers._IResult<R, E>, __FC> rewrap) {
      return Dafny.Helpers.Id<Func<Std.Wrappers._IResult<R, E>, __FC>>(rewrap)(_this);
    }
    public static Std.Wrappers._IResult<R, __NewE> MapFailure<__NewE>(Std.Wrappers._IResult<R, E> _this, Func<E, __NewE> reWrap) {
      Std.Wrappers._IResult<R, E> _source0 = _this;
      {
        if (_source0.is_Success) {
          R _0_s = _source0.dtor_value;
          return Std.Wrappers.Result<R, __NewE>.create_Success(_0_s);
        }
      }
      {
        E _1_e = _source0.dtor_error;
        return Std.Wrappers.Result<R, __NewE>.create_Failure(Dafny.Helpers.Id<Func<E, __NewE>>(reWrap)(_1_e));
      }
    }
  }
  public class Result_Success<R, E> : Result<R, E> {
    public readonly R _value;
    public Result_Success(R @value) : base() {
      this._value = @value;
    }
    public override _IResult<__R, __E> DowncastClone<__R, __E>(Func<R, __R> converter0, Func<E, __E> converter1) {
      if (this is _IResult<__R, __E> dt) { return dt; }
      return new Result_Success<__R, __E>(converter0(_value));
    }
    public override bool Equals(object other) {
      var oth = other as Std.Wrappers.Result_Success<R, E>;
      return oth != null && object.Equals(this._value, oth._value);
    }
    public override int GetHashCode() {
      ulong hash = 5381;
      hash = ((hash << 5) + hash) + 0;
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this._value));
      return (int) hash;
    }
    public override string ToString() {
      string s = "Wrappers.Result.Success";
      s += "(";
      s += Dafny.Helpers.ToString(this._value);
      s += ")";
      return s;
    }
  }
  public class Result_Failure<R, E> : Result<R, E> {
    public readonly E _error;
    public Result_Failure(E error) : base() {
      this._error = error;
    }
    public override _IResult<__R, __E> DowncastClone<__R, __E>(Func<R, __R> converter0, Func<E, __E> converter1) {
      if (this is _IResult<__R, __E> dt) { return dt; }
      return new Result_Failure<__R, __E>(converter1(_error));
    }
    public override bool Equals(object other) {
      var oth = other as Std.Wrappers.Result_Failure<R, E>;
      return oth != null && object.Equals(this._error, oth._error);
    }
    public override int GetHashCode() {
      ulong hash = 5381;
      hash = ((hash << 5) + hash) + 1;
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this._error));
      return (int) hash;
    }
    public override string ToString() {
      string s = "Wrappers.Result.Failure";
      s += "(";
      s += Dafny.Helpers.ToString(this._error);
      s += ")";
      return s;
    }
  }

  public interface _IOutcome<out E> {
    bool is_Pass { get; }
    bool is_Fail { get; }
    E dtor_error { get; }
    _IOutcome<__E> DowncastClone<__E>(Func<E, __E> converter0);
    bool IsFailure();
    Std.Wrappers._IOutcome<E> PropagateFailure();
    Std.Wrappers._IOption<__R> ToOption<__R>(__R r);
    Std.Wrappers._IResult<__R, E> ToResult<__R>(__R r);
  }
  public abstract class Outcome<E> : _IOutcome<E> {
    public Outcome() {
    }
    public static Std.Wrappers._IOutcome<E> Default() {
      return create_Pass();
    }
    public static Dafny.TypeDescriptor<Std.Wrappers._IOutcome<E>> _TypeDescriptor() {
      return new Dafny.TypeDescriptor<Std.Wrappers._IOutcome<E>>(Std.Wrappers.Outcome<E>.Default());
    }
    public static _IOutcome<E> create_Pass() {
      return new Outcome_Pass<E>();
    }
    public static _IOutcome<E> create_Fail(E error) {
      return new Outcome_Fail<E>(error);
    }
    public bool is_Pass { get { return this is Outcome_Pass<E>; } }
    public bool is_Fail { get { return this is Outcome_Fail<E>; } }
    public E dtor_error {
      get {
        var d = this;
        return ((Outcome_Fail<E>)d)._error;
      }
    }
    public abstract _IOutcome<__E> DowncastClone<__E>(Func<E, __E> converter0);
    public bool IsFailure() {
      return (this).is_Fail;
    }
    public Std.Wrappers._IOutcome<E> PropagateFailure() {
      return this;
    }
    public Std.Wrappers._IOption<__R> ToOption<__R>(__R r) {
      Std.Wrappers._IOutcome<E> _source0 = this;
      {
        if (_source0.is_Pass) {
          return Std.Wrappers.Option<__R>.create_Some(r);
        }
      }
      {
        E _0_e = _source0.dtor_error;
        return Std.Wrappers.Option<__R>.create_None();
      }
    }
    public Std.Wrappers._IResult<__R, E> ToResult<__R>(__R r) {
      Std.Wrappers._IOutcome<E> _source0 = this;
      {
        if (_source0.is_Pass) {
          return Std.Wrappers.Result<__R, E>.create_Success(r);
        }
      }
      {
        E _0_e = _source0.dtor_error;
        return Std.Wrappers.Result<__R, E>.create_Failure(_0_e);
      }
    }
    public static __FC Map<__FC>(Std.Wrappers._IOutcome<E> _this, Func<Std.Wrappers._IOutcome<E>, __FC> rewrap) {
      return Dafny.Helpers.Id<Func<Std.Wrappers._IOutcome<E>, __FC>>(rewrap)(_this);
    }
    public static Std.Wrappers._IResult<__T, __NewE> MapFailure<__T, __NewE>(Std.Wrappers._IOutcome<E> _this, Func<E, __NewE> rewrap, __T @default)
    {
      Std.Wrappers._IOutcome<E> _source0 = _this;
      {
        if (_source0.is_Pass) {
          return Std.Wrappers.Result<__T, __NewE>.create_Success(@default);
        }
      }
      {
        E _0_e = _source0.dtor_error;
        return Std.Wrappers.Result<__T, __NewE>.create_Failure(Dafny.Helpers.Id<Func<E, __NewE>>(rewrap)(_0_e));
      }
    }
    public static Std.Wrappers._IOutcome<E> Need(bool condition, E error)
    {
      if (condition) {
        return Std.Wrappers.Outcome<E>.create_Pass();
      } else {
        return Std.Wrappers.Outcome<E>.create_Fail(error);
      }
    }
  }
  public class Outcome_Pass<E> : Outcome<E> {
    public Outcome_Pass() : base() {
    }
    public override _IOutcome<__E> DowncastClone<__E>(Func<E, __E> converter0) {
      if (this is _IOutcome<__E> dt) { return dt; }
      return new Outcome_Pass<__E>();
    }
    public override bool Equals(object other) {
      var oth = other as Std.Wrappers.Outcome_Pass<E>;
      return oth != null;
    }
    public override int GetHashCode() {
      ulong hash = 5381;
      hash = ((hash << 5) + hash) + 0;
      return (int) hash;
    }
    public override string ToString() {
      string s = "Wrappers.Outcome.Pass";
      return s;
    }
  }
  public class Outcome_Fail<E> : Outcome<E> {
    public readonly E _error;
    public Outcome_Fail(E error) : base() {
      this._error = error;
    }
    public override _IOutcome<__E> DowncastClone<__E>(Func<E, __E> converter0) {
      if (this is _IOutcome<__E> dt) { return dt; }
      return new Outcome_Fail<__E>(converter0(_error));
    }
    public override bool Equals(object other) {
      var oth = other as Std.Wrappers.Outcome_Fail<E>;
      return oth != null && object.Equals(this._error, oth._error);
    }
    public override int GetHashCode() {
      ulong hash = 5381;
      hash = ((hash << 5) + hash) + 1;
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this._error));
      return (int) hash;
    }
    public override string ToString() {
      string s = "Wrappers.Outcome.Fail";
      s += "(";
      s += Dafny.Helpers.ToString(this._error);
      s += ")";
      return s;
    }
  }

  public interface _IOutcomeResult<out E> {
    bool is_Pass_k { get; }
    bool is_Fail_k { get; }
    E dtor_error { get; }
    _IOutcomeResult<__E> DowncastClone<__E>(Func<E, __E> converter0);
    bool IsFailure();
    Std.Wrappers._IResult<__U, E> PropagateFailure<__U>();
  }
  public abstract class OutcomeResult<E> : _IOutcomeResult<E> {
    public OutcomeResult() {
    }
    public static Std.Wrappers._IOutcomeResult<E> Default() {
      return create_Pass_k();
    }
    public static Dafny.TypeDescriptor<Std.Wrappers._IOutcomeResult<E>> _TypeDescriptor() {
      return new Dafny.TypeDescriptor<Std.Wrappers._IOutcomeResult<E>>(Std.Wrappers.OutcomeResult<E>.Default());
    }
    public static _IOutcomeResult<E> create_Pass_k() {
      return new OutcomeResult_Pass_k<E>();
    }
    public static _IOutcomeResult<E> create_Fail_k(E error) {
      return new OutcomeResult_Fail_k<E>(error);
    }
    public bool is_Pass_k { get { return this is OutcomeResult_Pass_k<E>; } }
    public bool is_Fail_k { get { return this is OutcomeResult_Fail_k<E>; } }
    public E dtor_error {
      get {
        var d = this;
        return ((OutcomeResult_Fail_k<E>)d)._error;
      }
    }
    public abstract _IOutcomeResult<__E> DowncastClone<__E>(Func<E, __E> converter0);
    public bool IsFailure() {
      return (this).is_Fail_k;
    }
    public Std.Wrappers._IResult<__U, E> PropagateFailure<__U>() {
      return Std.Wrappers.Result<__U, E>.create_Failure((this).dtor_error);
    }
  }
  public class OutcomeResult_Pass_k<E> : OutcomeResult<E> {
    public OutcomeResult_Pass_k() : base() {
    }
    public override _IOutcomeResult<__E> DowncastClone<__E>(Func<E, __E> converter0) {
      if (this is _IOutcomeResult<__E> dt) { return dt; }
      return new OutcomeResult_Pass_k<__E>();
    }
    public override bool Equals(object other) {
      var oth = other as Std.Wrappers.OutcomeResult_Pass_k<E>;
      return oth != null;
    }
    public override int GetHashCode() {
      ulong hash = 5381;
      hash = ((hash << 5) + hash) + 0;
      return (int) hash;
    }
    public override string ToString() {
      string s = "Wrappers.OutcomeResult.Pass'";
      return s;
    }
  }
  public class OutcomeResult_Fail_k<E> : OutcomeResult<E> {
    public readonly E _error;
    public OutcomeResult_Fail_k(E error) : base() {
      this._error = error;
    }
    public override _IOutcomeResult<__E> DowncastClone<__E>(Func<E, __E> converter0) {
      if (this is _IOutcomeResult<__E> dt) { return dt; }
      return new OutcomeResult_Fail_k<__E>(converter0(_error));
    }
    public override bool Equals(object other) {
      var oth = other as Std.Wrappers.OutcomeResult_Fail_k<E>;
      return oth != null && object.Equals(this._error, oth._error);
    }
    public override int GetHashCode() {
      ulong hash = 5381;
      hash = ((hash << 5) + hash) + 1;
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this._error));
      return (int) hash;
    }
    public override string ToString() {
      string s = "Wrappers.OutcomeResult.Fail'";
      s += "(";
      s += Dafny.Helpers.ToString(this._error);
      s += ")";
      return s;
    }
  }
} // end of namespace Std.Wrappers
namespace Std.FileIOInternalExterns {

} // end of namespace Std.FileIOInternalExterns
namespace Std.FileIO {

  public partial class __default {
    public static Std.Wrappers._IResult<Dafny.ISequence<byte>, Dafny.ISequence<Dafny.Rune>> ReadBytesFromFile(Dafny.ISequence<Dafny.Rune> path)
    {
      Std.Wrappers._IResult<Dafny.ISequence<byte>, Dafny.ISequence<Dafny.Rune>> res = Std.Wrappers.Result<Dafny.ISequence<byte>, Dafny.ISequence<Dafny.Rune>>.Default(Dafny.Sequence<byte>.Empty);
      bool _0_isError;
      Dafny.ISequence<byte> _1_bytesRead;
      Dafny.ISequence<Dafny.Rune> _2_errorMsg;
      bool _out0;
      Dafny.ISequence<byte> _out1;
      Dafny.ISequence<Dafny.Rune> _out2;
      Std.FileIOInternalExterns.__default.INTERNAL__ReadBytesFromFile(path, out _out0, out _out1, out _out2);
      _0_isError = _out0;
      _1_bytesRead = _out1;
      _2_errorMsg = _out2;
      if (_0_isError) {
        res = Std.Wrappers.Result<Dafny.ISequence<byte>, Dafny.ISequence<Dafny.Rune>>.create_Failure(_2_errorMsg);
      } else {
        res = Std.Wrappers.Result<Dafny.ISequence<byte>, Dafny.ISequence<Dafny.Rune>>.create_Success(_1_bytesRead);
      }
      return res;
      return res;
    }
    public static Std.Wrappers._IResult<_System._ITuple0, Dafny.ISequence<Dafny.Rune>> WriteBytesToFile(Dafny.ISequence<Dafny.Rune> path, Dafny.ISequence<byte> bytes)
    {
      Std.Wrappers._IResult<_System._ITuple0, Dafny.ISequence<Dafny.Rune>> res = Std.Wrappers.Result<_System._ITuple0, Dafny.ISequence<Dafny.Rune>>.Default(_System.Tuple0.Default());
      bool _0_isError;
      Dafny.ISequence<Dafny.Rune> _1_errorMsg;
      bool _out0;
      Dafny.ISequence<Dafny.Rune> _out1;
      Std.FileIOInternalExterns.__default.INTERNAL__WriteBytesToFile(path, bytes, out _out0, out _out1);
      _0_isError = _out0;
      _1_errorMsg = _out1;
      if (_0_isError) {
        res = Std.Wrappers.Result<_System._ITuple0, Dafny.ISequence<Dafny.Rune>>.create_Failure(_1_errorMsg);
      } else {
        res = Std.Wrappers.Result<_System._ITuple0, Dafny.ISequence<Dafny.Rune>>.create_Success(_System.Tuple0.create());
      }
      return res;
      return res;
    }
  }
} // end of namespace Std.FileIO
namespace Std.BoundedInts {

  public partial class __default {
    public static BigInteger TWO__TO__THE__8 { get {
      return new BigInteger(256);
    } }
    public static byte UINT8__MAX { get {
      return (byte)(255);
    } }
    public static BigInteger TWO__TO__THE__16 { get {
      return new BigInteger(65536);
    } }
    public static ushort UINT16__MAX { get {
      return (ushort)(65535);
    } }
    public static BigInteger TWO__TO__THE__32 { get {
      return new BigInteger(4294967296L);
    } }
    public static uint UINT32__MAX { get {
      return 4294967295U;
    } }
    public static BigInteger TWO__TO__THE__64 { get {
      return BigInteger.Parse("18446744073709551616");
    } }
    public static ulong UINT64__MAX { get {
      return 18446744073709551615UL;
    } }
    public static BigInteger TWO__TO__THE__7 { get {
      return new BigInteger(128);
    } }
    public static sbyte INT8__MIN { get {
      return (sbyte)(-128);
    } }
    public static sbyte INT8__MAX { get {
      return (sbyte)(127);
    } }
    public static BigInteger TWO__TO__THE__15 { get {
      return new BigInteger(32768);
    } }
    public static short INT16__MIN { get {
      return (short)(-32768);
    } }
    public static short INT16__MAX { get {
      return (short)(32767);
    } }
    public static BigInteger TWO__TO__THE__31 { get {
      return new BigInteger(2147483648L);
    } }
    public static int INT32__MIN { get {
      return -2147483648;
    } }
    public static int INT32__MAX { get {
      return 2147483647;
    } }
    public static BigInteger TWO__TO__THE__63 { get {
      return new BigInteger(9223372036854775808UL);
    } }
    public static long INT64__MIN { get {
      return -9223372036854775808L;
    } }
    public static long INT64__MAX { get {
      return 9223372036854775807L;
    } }
    public static byte NAT8__MAX { get {
      return (byte)(127);
    } }
    public static ushort NAT16__MAX { get {
      return (ushort)(32767);
    } }
    public static uint NAT32__MAX { get {
      return 2147483647U;
    } }
    public static ulong NAT64__MAX { get {
      return 9223372036854775807UL;
    } }
    public static BigInteger TWO__TO__THE__128 { get {
      return BigInteger.Parse("340282366920938463463374607431768211456");
    } }
    public static BigInteger TWO__TO__THE__127 { get {
      return BigInteger.Parse("170141183460469231731687303715884105728");
    } }
    public static BigInteger TWO__TO__THE__0 { get {
      return BigInteger.One;
    } }
    public static BigInteger TWO__TO__THE__1 { get {
      return new BigInteger(2);
    } }
    public static BigInteger TWO__TO__THE__2 { get {
      return new BigInteger(4);
    } }
    public static BigInteger TWO__TO__THE__4 { get {
      return new BigInteger(16);
    } }
    public static BigInteger TWO__TO__THE__5 { get {
      return new BigInteger(32);
    } }
    public static BigInteger TWO__TO__THE__24 { get {
      return new BigInteger(16777216);
    } }
    public static BigInteger TWO__TO__THE__40 { get {
      return new BigInteger(1099511627776L);
    } }
    public static BigInteger TWO__TO__THE__48 { get {
      return new BigInteger(281474976710656L);
    } }
    public static BigInteger TWO__TO__THE__56 { get {
      return new BigInteger(72057594037927936L);
    } }
    public static BigInteger TWO__TO__THE__256 { get {
      return BigInteger.Parse("115792089237316195423570985008687907853269984665640564039457584007913129639936");
    } }
    public static BigInteger TWO__TO__THE__512 { get {
      return BigInteger.Parse("13407807929942597099574024998205846127479365820592393377723561443721764030073546976801874298166903427690031858186486050853753882811946569946433649006084096");
    } }
  }

  public partial class uint8 {
    public static System.Collections.Generic.IEnumerable<byte> IntegerRange(BigInteger lo, BigInteger hi) {
      for (var j = lo; j < hi; j++) { yield return (byte)j; }
    }
    private static readonly Dafny.TypeDescriptor<byte> _TYPE = new Dafny.TypeDescriptor<byte>(0);
    public static Dafny.TypeDescriptor<byte> _TypeDescriptor() {
      return _TYPE;
    }
    public static bool _Is(byte __source) {
      return true;
    }
  }

  public partial class uint16 {
    public static System.Collections.Generic.IEnumerable<ushort> IntegerRange(BigInteger lo, BigInteger hi) {
      for (var j = lo; j < hi; j++) { yield return (ushort)j; }
    }
    private static readonly Dafny.TypeDescriptor<ushort> _TYPE = new Dafny.TypeDescriptor<ushort>(0);
    public static Dafny.TypeDescriptor<ushort> _TypeDescriptor() {
      return _TYPE;
    }
    public static bool _Is(ushort __source) {
      return true;
    }
  }

  public partial class uint32 {
    public static System.Collections.Generic.IEnumerable<uint> IntegerRange(BigInteger lo, BigInteger hi) {
      for (var j = lo; j < hi; j++) { yield return (uint)j; }
    }
    private static readonly Dafny.TypeDescriptor<uint> _TYPE = new Dafny.TypeDescriptor<uint>(0);
    public static Dafny.TypeDescriptor<uint> _TypeDescriptor() {
      return _TYPE;
    }
    public static bool _Is(uint __source) {
      return true;
    }
  }

  public partial class uint64 {
    public static System.Collections.Generic.IEnumerable<ulong> IntegerRange(BigInteger lo, BigInteger hi) {
      for (var j = lo; j < hi; j++) { yield return (ulong)j; }
    }
    private static readonly Dafny.TypeDescriptor<ulong> _TYPE = new Dafny.TypeDescriptor<ulong>(0);
    public static Dafny.TypeDescriptor<ulong> _TypeDescriptor() {
      return _TYPE;
    }
    public static bool _Is(ulong __source) {
      return true;
    }
  }

  public partial class uint128 {
    private static readonly Dafny.TypeDescriptor<BigInteger> _TYPE = new Dafny.TypeDescriptor<BigInteger>(BigInteger.Zero);
    public static Dafny.TypeDescriptor<BigInteger> _TypeDescriptor() {
      return _TYPE;
    }
    public static bool _Is(BigInteger __source) {
      BigInteger _0_x = __source;
      return ((_0_x).Sign != -1) && ((_0_x) < (Std.BoundedInts.__default.TWO__TO__THE__128));
    }
  }

  public partial class int8 {
    public static System.Collections.Generic.IEnumerable<sbyte> IntegerRange(BigInteger lo, BigInteger hi) {
      for (var j = lo; j < hi; j++) { yield return (sbyte)j; }
    }
    private static readonly Dafny.TypeDescriptor<sbyte> _TYPE = new Dafny.TypeDescriptor<sbyte>(0);
    public static Dafny.TypeDescriptor<sbyte> _TypeDescriptor() {
      return _TYPE;
    }
    public static bool _Is(sbyte __source) {
      return true;
    }
  }

  public partial class int16 {
    public static System.Collections.Generic.IEnumerable<short> IntegerRange(BigInteger lo, BigInteger hi) {
      for (var j = lo; j < hi; j++) { yield return (short)j; }
    }
    private static readonly Dafny.TypeDescriptor<short> _TYPE = new Dafny.TypeDescriptor<short>(0);
    public static Dafny.TypeDescriptor<short> _TypeDescriptor() {
      return _TYPE;
    }
    public static bool _Is(short __source) {
      return true;
    }
  }

  public partial class int32 {
    public static System.Collections.Generic.IEnumerable<int> IntegerRange(BigInteger lo, BigInteger hi) {
      for (var j = lo; j < hi; j++) { yield return (int)j; }
    }
    private static readonly Dafny.TypeDescriptor<int> _TYPE = new Dafny.TypeDescriptor<int>(0);
    public static Dafny.TypeDescriptor<int> _TypeDescriptor() {
      return _TYPE;
    }
    public static bool _Is(int __source) {
      return true;
    }
  }

  public partial class int64 {
    public static System.Collections.Generic.IEnumerable<long> IntegerRange(BigInteger lo, BigInteger hi) {
      for (var j = lo; j < hi; j++) { yield return (long)j; }
    }
    private static readonly Dafny.TypeDescriptor<long> _TYPE = new Dafny.TypeDescriptor<long>(0);
    public static Dafny.TypeDescriptor<long> _TypeDescriptor() {
      return _TYPE;
    }
    public static bool _Is(long __source) {
      return true;
    }
  }

  public partial class int128 {
    private static readonly Dafny.TypeDescriptor<BigInteger> _TYPE = new Dafny.TypeDescriptor<BigInteger>(BigInteger.Zero);
    public static Dafny.TypeDescriptor<BigInteger> _TypeDescriptor() {
      return _TYPE;
    }
    public static bool _Is(BigInteger __source) {
      BigInteger _1_x = __source;
      return (((BigInteger.Zero) - (Std.BoundedInts.__default.TWO__TO__THE__127)) <= (_1_x)) && ((_1_x) < (Std.BoundedInts.__default.TWO__TO__THE__127));
    }
  }

  public partial class nat8 {
    public static System.Collections.Generic.IEnumerable<byte> IntegerRange(BigInteger lo, BigInteger hi) {
      for (var j = lo; j < hi; j++) { yield return (byte)j; }
    }
    private static readonly Dafny.TypeDescriptor<byte> _TYPE = new Dafny.TypeDescriptor<byte>(0);
    public static Dafny.TypeDescriptor<byte> _TypeDescriptor() {
      return _TYPE;
    }
    public static bool _Is(byte __source) {
      BigInteger _2_x = new BigInteger(__source);
      return ((_2_x).Sign != -1) && ((_2_x) < (Std.BoundedInts.__default.TWO__TO__THE__7));
    }
  }

  public partial class nat16 {
    public static System.Collections.Generic.IEnumerable<ushort> IntegerRange(BigInteger lo, BigInteger hi) {
      for (var j = lo; j < hi; j++) { yield return (ushort)j; }
    }
    private static readonly Dafny.TypeDescriptor<ushort> _TYPE = new Dafny.TypeDescriptor<ushort>(0);
    public static Dafny.TypeDescriptor<ushort> _TypeDescriptor() {
      return _TYPE;
    }
    public static bool _Is(ushort __source) {
      BigInteger _3_x = new BigInteger(__source);
      return ((_3_x).Sign != -1) && ((_3_x) < (Std.BoundedInts.__default.TWO__TO__THE__15));
    }
  }

  public partial class nat32 {
    public static System.Collections.Generic.IEnumerable<uint> IntegerRange(BigInteger lo, BigInteger hi) {
      for (var j = lo; j < hi; j++) { yield return (uint)j; }
    }
    private static readonly Dafny.TypeDescriptor<uint> _TYPE = new Dafny.TypeDescriptor<uint>(0);
    public static Dafny.TypeDescriptor<uint> _TypeDescriptor() {
      return _TYPE;
    }
    public static bool _Is(uint __source) {
      BigInteger _4_x = new BigInteger(__source);
      return ((_4_x).Sign != -1) && ((_4_x) < (Std.BoundedInts.__default.TWO__TO__THE__31));
    }
  }

  public partial class nat64 {
    public static System.Collections.Generic.IEnumerable<ulong> IntegerRange(BigInteger lo, BigInteger hi) {
      for (var j = lo; j < hi; j++) { yield return (ulong)j; }
    }
    private static readonly Dafny.TypeDescriptor<ulong> _TYPE = new Dafny.TypeDescriptor<ulong>(0);
    public static Dafny.TypeDescriptor<ulong> _TypeDescriptor() {
      return _TYPE;
    }
    public static bool _Is(ulong __source) {
      BigInteger _5_x = new BigInteger(__source);
      return ((_5_x).Sign != -1) && ((_5_x) < (Std.BoundedInts.__default.TWO__TO__THE__63));
    }
  }

  public partial class nat128 {
    private static readonly Dafny.TypeDescriptor<BigInteger> _TYPE = new Dafny.TypeDescriptor<BigInteger>(BigInteger.Zero);
    public static Dafny.TypeDescriptor<BigInteger> _TypeDescriptor() {
      return _TYPE;
    }
    public static bool _Is(BigInteger __source) {
      BigInteger _6_x = __source;
      return ((_6_x).Sign != -1) && ((_6_x) < (Std.BoundedInts.__default.TWO__TO__THE__127));
    }
  }

  public partial class opt__byte {
    public static System.Collections.Generic.IEnumerable<short> IntegerRange(BigInteger lo, BigInteger hi) {
      for (var j = lo; j < hi; j++) { yield return (short)j; }
    }
    private static readonly Dafny.TypeDescriptor<short> _TYPE = new Dafny.TypeDescriptor<short>(0);
    public static Dafny.TypeDescriptor<short> _TypeDescriptor() {
      return _TYPE;
    }
    public static bool _Is(short __source) {
      BigInteger _7_c = new BigInteger(__source);
      return ((new BigInteger(-1)) <= (_7_c)) && ((_7_c) < (Std.BoundedInts.__default.TWO__TO__THE__8));
    }
  }
} // end of namespace Std.BoundedInts
namespace Std.Base64 {

  public partial class __default {
    public static bool IsBase64Char(Dafny.Rune c) {
      return (((((c) == (new Dafny.Rune('+'))) || ((c) == (new Dafny.Rune('/')))) || (((new Dafny.Rune('0')) <= (c)) && ((c) <= (new Dafny.Rune('9'))))) || (((new Dafny.Rune('A')) <= (c)) && ((c) <= (new Dafny.Rune('Z'))))) || (((new Dafny.Rune('a')) <= (c)) && ((c) <= (new Dafny.Rune('z'))));
    }
    public static bool IsUnpaddedBase64String(Dafny.ISequence<Dafny.Rune> s) {
      return ((Dafny.Helpers.EuclideanModulus(new BigInteger((s).Count), new BigInteger(4))).Sign == 0) && (Dafny.Helpers.Id<Func<Dafny.ISequence<Dafny.Rune>, bool>>((_0_s) => Dafny.Helpers.Quantifier<Dafny.Rune>((_0_s).UniqueElements, true, (((_forall_var_0) => {
        Dafny.Rune _1_k = (Dafny.Rune)_forall_var_0;
        return !((_0_s).Contains(_1_k)) || (Std.Base64.__default.IsBase64Char(_1_k));
      }))))(s));
    }
    public static Dafny.Rune IndexToChar(byte i) {
      if ((i) == ((byte)(63))) {
        return new Dafny.Rune('/');
      } else if ((i) == ((byte)(62))) {
        return new Dafny.Rune('+');
      } else if ((((byte)(52)) <= (i)) && ((i) <= ((byte)(61)))) {
        return new Dafny.Rune((int)(new BigInteger(unchecked((byte)(((byte)((i) - ((byte)(4)))) & (byte)0x3F)))));
      } else if ((((byte)(26)) <= (i)) && ((i) <= ((byte)(51)))) {
        return Dafny.Helpers.AddRunes(new Dafny.Rune((int)(new BigInteger(i))), new Dafny.Rune((int)(new BigInteger(71))));
      } else {
        return Dafny.Helpers.AddRunes(new Dafny.Rune((int)(new BigInteger(i))), new Dafny.Rune((int)(new BigInteger(65))));
      }
    }
    public static byte CharToIndex(Dafny.Rune c) {
      if ((c) == (new Dafny.Rune('/'))) {
        return (byte)(63);
      } else if ((c) == (new Dafny.Rune('+'))) {
        return (byte)(62);
      } else if (((new Dafny.Rune('0')) <= (c)) && ((c) <= (new Dafny.Rune('9')))) {
        return (byte)(new BigInteger((Dafny.Helpers.AddRunes(c, new Dafny.Rune((int)(new BigInteger(4))))).Value));
      } else if (((new Dafny.Rune('a')) <= (c)) && ((c) <= (new Dafny.Rune('z')))) {
        return (byte)(new BigInteger((Dafny.Helpers.SubtractRunes(c, new Dafny.Rune((int)(new BigInteger(71))))).Value));
      } else {
        return (byte)(new BigInteger((Dafny.Helpers.SubtractRunes(c, new Dafny.Rune((int)(new BigInteger(65))))).Value));
      }
    }
    public static Dafny.ISequence<byte> BV24ToSeq(uint x) {
      byte _0_b0 = (byte)(((x) >> ((int)((byte)(16)))) & (255U));
      byte _1_b1 = (byte)(((x) >> ((int)((byte)(8)))) & (255U));
      byte _2_b2 = (byte)((x) & (255U));
      return Dafny.Sequence<byte>.FromElements(_0_b0, _1_b1, _2_b2);
    }
    public static uint SeqToBV24(Dafny.ISequence<byte> x) {
      return ((unchecked((uint)((((uint)((x).Select(BigInteger.Zero))) << ((int)((byte)(16)))) & (uint)0xFFFFFFU))) | (unchecked((uint)((((uint)((x).Select(BigInteger.One))) << ((int)((byte)(8)))) & (uint)0xFFFFFFU)))) | ((uint)((x).Select(new BigInteger(2))));
    }
    public static Dafny.ISequence<byte> BV24ToIndexSeq(uint x) {
      byte _0_b0 = (byte)(((x) >> ((int)((byte)(18)))) & (63U));
      byte _1_b1 = (byte)(((x) >> ((int)((byte)(12)))) & (63U));
      byte _2_b2 = (byte)(((x) >> ((int)((byte)(6)))) & (63U));
      byte _3_b3 = (byte)((x) & (63U));
      return Dafny.Sequence<byte>.FromElements(_0_b0, _1_b1, _2_b2, _3_b3);
    }
    public static uint IndexSeqToBV24(Dafny.ISequence<byte> x) {
      return (((unchecked((uint)((((uint)((x).Select(BigInteger.Zero))) << ((int)((byte)(18)))) & (uint)0xFFFFFFU))) | (unchecked((uint)((((uint)((x).Select(BigInteger.One))) << ((int)((byte)(12)))) & (uint)0xFFFFFFU)))) | (unchecked((uint)((((uint)((x).Select(new BigInteger(2)))) << ((int)((byte)(6)))) & (uint)0xFFFFFFU)))) | ((uint)((x).Select(new BigInteger(3))));
    }
    public static Dafny.ISequence<byte> DecodeBlock(Dafny.ISequence<byte> s) {
      return Std.Base64.__default.BV24ToSeq(Std.Base64.__default.IndexSeqToBV24(s));
    }
    public static Dafny.ISequence<byte> EncodeBlock(Dafny.ISequence<byte> s) {
      return Std.Base64.__default.BV24ToIndexSeq(Std.Base64.__default.SeqToBV24(s));
    }
    public static Dafny.ISequence<byte> DecodeRecursively(Dafny.ISequence<byte> s)
    {
      Dafny.ISequence<byte> b = Dafny.Sequence<byte>.Empty;
      BigInteger _0_resultLength;
      _0_resultLength = (Dafny.Helpers.EuclideanDivision(new BigInteger((s).Count), new BigInteger(4))) * (new BigInteger(3));
      byte[] _1_result;
      Func<BigInteger, byte> _init0 = ((System.Func<BigInteger, byte>)((_2_i) => {
        return (byte)(0);
      }));
      byte[] _nw0 = new byte[Dafny.Helpers.ToIntChecked(_0_resultLength, "array size exceeds memory limit")];
      for (var _i0_0 = 0; _i0_0 < new BigInteger(_nw0.Length); _i0_0++) {
        _nw0[(int)(_i0_0)] = _init0(_i0_0);
      }
      _1_result = _nw0;
      BigInteger _3_i;
      _3_i = new BigInteger((s).Count);
      BigInteger _4_j;
      _4_j = _0_resultLength;
      while ((_3_i).Sign == 1) {
        _3_i = (_3_i) - (new BigInteger(4));
        _4_j = (_4_j) - (new BigInteger(3));
        Dafny.ISequence<byte> _5_block;
        _5_block = Std.Base64.__default.DecodeBlock((s).Subsequence(_3_i, (_3_i) + (new BigInteger(4))));
        (_1_result)[(int)((_4_j))] = (_5_block).Select(BigInteger.Zero);
        BigInteger _index0 = (_4_j) + (BigInteger.One);
        (_1_result)[(int)(_index0)] = (_5_block).Select(BigInteger.One);
        BigInteger _index1 = (_4_j) + (new BigInteger(2));
        (_1_result)[(int)(_index1)] = (_5_block).Select(new BigInteger(2));
      }
      b = Dafny.Helpers.SeqFromArray(_1_result);
      return b;
    }
    public static Dafny.ISequence<byte> EncodeRecursively(Dafny.ISequence<byte> b)
    {
      Dafny.ISequence<byte> s = Dafny.Sequence<byte>.Empty;
      BigInteger _0_resultLength;
      _0_resultLength = (Dafny.Helpers.EuclideanDivision(new BigInteger((b).Count), new BigInteger(3))) * (new BigInteger(4));
      byte[] _1_result;
      Func<BigInteger, byte> _init0 = ((System.Func<BigInteger, byte>)((_2_i) => {
        return (byte)(0);
      }));
      byte[] _nw0 = new byte[Dafny.Helpers.ToIntChecked(_0_resultLength, "array size exceeds memory limit")];
      for (var _i0_0 = 0; _i0_0 < new BigInteger(_nw0.Length); _i0_0++) {
        _nw0[(int)(_i0_0)] = _init0(_i0_0);
      }
      _1_result = _nw0;
      BigInteger _3_i;
      _3_i = new BigInteger((b).Count);
      BigInteger _4_j;
      _4_j = _0_resultLength;
      while ((_3_i).Sign == 1) {
        _3_i = (_3_i) - (new BigInteger(3));
        _4_j = (_4_j) - (new BigInteger(4));
        Dafny.ISequence<byte> _5_block;
        _5_block = Std.Base64.__default.EncodeBlock((b).Subsequence(_3_i, (_3_i) + (new BigInteger(3))));
        (_1_result)[(int)((_4_j))] = (_5_block).Select(BigInteger.Zero);
        BigInteger _index0 = (_4_j) + (BigInteger.One);
        (_1_result)[(int)(_index0)] = (_5_block).Select(BigInteger.One);
        BigInteger _index1 = (_4_j) + (new BigInteger(2));
        (_1_result)[(int)(_index1)] = (_5_block).Select(new BigInteger(2));
        BigInteger _index2 = (_4_j) + (new BigInteger(3));
        (_1_result)[(int)(_index2)] = (_5_block).Select(new BigInteger(3));
      }
      s = Dafny.Helpers.SeqFromArray(_1_result);
      return s;
    }
    public static Dafny.ISequence<byte> FromCharsToIndices(Dafny.ISequence<Dafny.Rune> s) {
      return ((System.Func<Dafny.ISequence<byte>>) (() => {
        BigInteger dim0 = new BigInteger((s).Count);
        var arr0 = new byte[Dafny.Helpers.ToIntChecked(dim0, "array size exceeds memory limit")];
        for (int i0 = 0; i0 < dim0; i0++) {
          var _0_i = (BigInteger) i0;
          arr0[(int)(_0_i)] = Std.Base64.__default.CharToIndex((s).Select(_0_i));
        }
        return Dafny.Sequence<byte>.FromArray(arr0);
      }))();
    }
    public static Dafny.ISequence<Dafny.Rune> FromIndicesToChars(Dafny.ISequence<byte> b) {
      return ((System.Func<Dafny.ISequence<Dafny.Rune>>) (() => {
        BigInteger dim1 = new BigInteger((b).Count);
        var arr1 = new Dafny.Rune[Dafny.Helpers.ToIntChecked(dim1, "array size exceeds memory limit")];
        for (int i1 = 0; i1 < dim1; i1++) {
          var _0_i = (BigInteger) i1;
          arr1[(int)(_0_i)] = Std.Base64.__default.IndexToChar((b).Select(_0_i));
        }
        return Dafny.Sequence<Dafny.Rune>.FromArray(arr1);
      }))();
    }
    public static Dafny.ISequence<byte> DecodeUnpadded(Dafny.ISequence<Dafny.Rune> s) {
      return Std.Base64.__default.DecodeRecursively(Std.Base64.__default.FromCharsToIndices(s));
    }
    public static Dafny.ISequence<Dafny.Rune> EncodeUnpadded(Dafny.ISequence<byte> b) {
      return Std.Base64.__default.FromIndicesToChars(Std.Base64.__default.EncodeRecursively(b));
    }
    public static bool Is1Padding(Dafny.ISequence<Dafny.Rune> s) {
      return ((((((new BigInteger((s).Count)) == (new BigInteger(4))) && (Std.Base64.__default.IsBase64Char((s).Select(BigInteger.Zero)))) && (Std.Base64.__default.IsBase64Char((s).Select(BigInteger.One)))) && (Std.Base64.__default.IsBase64Char((s).Select(new BigInteger(2))))) && (((byte)((Std.Base64.__default.CharToIndex((s).Select(new BigInteger(2)))) & ((byte)(3)))) == ((byte)(0)))) && (((s).Select(new BigInteger(3))) == (new Dafny.Rune('=')));
    }
    public static Dafny.ISequence<byte> Decode1Padding(Dafny.ISequence<Dafny.Rune> s) {
      Dafny.ISequence<byte> _0_d = Std.Base64.__default.DecodeBlock(Dafny.Sequence<byte>.FromElements(Std.Base64.__default.CharToIndex((s).Select(BigInteger.Zero)), Std.Base64.__default.CharToIndex((s).Select(BigInteger.One)), Std.Base64.__default.CharToIndex((s).Select(new BigInteger(2))), (byte)(0)));
      return Dafny.Sequence<byte>.FromElements((_0_d).Select(BigInteger.Zero), (_0_d).Select(BigInteger.One));
    }
    public static Dafny.ISequence<Dafny.Rune> Encode1Padding(Dafny.ISequence<byte> b) {
      Dafny.ISequence<byte> _0_e = Std.Base64.__default.EncodeBlock(Dafny.Sequence<byte>.FromElements((b).Select(BigInteger.Zero), (b).Select(BigInteger.One), (byte)(0)));
      return Dafny.Sequence<Dafny.Rune>.FromElements(Std.Base64.__default.IndexToChar((_0_e).Select(BigInteger.Zero)), Std.Base64.__default.IndexToChar((_0_e).Select(BigInteger.One)), Std.Base64.__default.IndexToChar((_0_e).Select(new BigInteger(2))), new Dafny.Rune('='));
    }
    public static bool Is2Padding(Dafny.ISequence<Dafny.Rune> s) {
      return ((((((new BigInteger((s).Count)) == (new BigInteger(4))) && (Std.Base64.__default.IsBase64Char((s).Select(BigInteger.Zero)))) && (Std.Base64.__default.IsBase64Char((s).Select(BigInteger.One)))) && (((byte)((Std.Base64.__default.CharToIndex((s).Select(BigInteger.One))) % ((byte)(16)))) == ((byte)(0)))) && (((s).Select(new BigInteger(2))) == (new Dafny.Rune('=')))) && (((s).Select(new BigInteger(3))) == (new Dafny.Rune('=')));
    }
    public static Dafny.ISequence<byte> Decode2Padding(Dafny.ISequence<Dafny.Rune> s) {
      Dafny.ISequence<byte> _0_d = Std.Base64.__default.DecodeBlock(Dafny.Sequence<byte>.FromElements(Std.Base64.__default.CharToIndex((s).Select(BigInteger.Zero)), Std.Base64.__default.CharToIndex((s).Select(BigInteger.One)), (byte)(0), (byte)(0)));
      return Dafny.Sequence<byte>.FromElements((_0_d).Select(BigInteger.Zero));
    }
    public static Dafny.ISequence<Dafny.Rune> Encode2Padding(Dafny.ISequence<byte> b) {
      Dafny.ISequence<byte> _0_e = Std.Base64.__default.EncodeBlock(Dafny.Sequence<byte>.FromElements((b).Select(BigInteger.Zero), (byte)(0), (byte)(0)));
      return Dafny.Sequence<Dafny.Rune>.FromElements(Std.Base64.__default.IndexToChar((_0_e).Select(BigInteger.Zero)), Std.Base64.__default.IndexToChar((_0_e).Select(BigInteger.One)), new Dafny.Rune('='), new Dafny.Rune('='));
    }
    public static bool IsBase64String(Dafny.ISequence<Dafny.Rune> s) {
      BigInteger _0_finalBlockStart = (new BigInteger((s).Count)) - (new BigInteger(4));
      return ((Dafny.Helpers.EuclideanModulus(new BigInteger((s).Count), new BigInteger(4))).Sign == 0) && ((Std.Base64.__default.IsUnpaddedBase64String(s)) || ((Std.Base64.__default.IsUnpaddedBase64String((s).Take(_0_finalBlockStart))) && ((Std.Base64.__default.Is1Padding((s).Drop(_0_finalBlockStart))) || (Std.Base64.__default.Is2Padding((s).Drop(_0_finalBlockStart))))));
    }
    public static Dafny.ISequence<byte> DecodeValid(Dafny.ISequence<Dafny.Rune> s) {
      if ((s).Equals(Dafny.Sequence<Dafny.Rune>.FromElements())) {
        return Dafny.Sequence<byte>.FromElements();
      } else {
        BigInteger _0_finalBlockStart = (new BigInteger((s).Count)) - (new BigInteger(4));
        Dafny.ISequence<Dafny.Rune> _1_prefix = (s).Take(_0_finalBlockStart);
        Dafny.ISequence<Dafny.Rune> _2_suffix = (s).Drop(_0_finalBlockStart);
        if (Std.Base64.__default.Is1Padding(_2_suffix)) {
          return Dafny.Sequence<byte>.Concat(Std.Base64.__default.DecodeUnpadded(_1_prefix), Std.Base64.__default.Decode1Padding(_2_suffix));
        } else if (Std.Base64.__default.Is2Padding(_2_suffix)) {
          return Dafny.Sequence<byte>.Concat(Std.Base64.__default.DecodeUnpadded(_1_prefix), Std.Base64.__default.Decode2Padding(_2_suffix));
        } else {
          return Std.Base64.__default.DecodeUnpadded(s);
        }
      }
    }
    public static Std.Wrappers._IResult<Dafny.ISequence<byte>, Dafny.ISequence<Dafny.Rune>> DecodeBV(Dafny.ISequence<Dafny.Rune> s) {
      if (Std.Base64.__default.IsBase64String(s)) {
        return Std.Wrappers.Result<Dafny.ISequence<byte>, Dafny.ISequence<Dafny.Rune>>.create_Success(Std.Base64.__default.DecodeValid(s));
      } else {
        return Std.Wrappers.Result<Dafny.ISequence<byte>, Dafny.ISequence<Dafny.Rune>>.create_Failure(Dafny.Sequence<Dafny.Rune>.UnicodeFromString("The encoding is malformed"));
      }
    }
    public static Dafny.ISequence<Dafny.Rune> EncodeBV(Dafny.ISequence<byte> b) {
      if ((Dafny.Helpers.EuclideanModulus(new BigInteger((b).Count), new BigInteger(3))).Sign == 0) {
        return Std.Base64.__default.EncodeUnpadded(b);
      } else if ((Dafny.Helpers.EuclideanModulus(new BigInteger((b).Count), new BigInteger(3))) == (BigInteger.One)) {
        Dafny.ISequence<Dafny.Rune> _0_s1 = Std.Base64.__default.EncodeUnpadded((b).Take((new BigInteger((b).Count)) - (BigInteger.One)));
        Dafny.ISequence<Dafny.Rune> _1_s2 = Std.Base64.__default.Encode2Padding((b).Drop((new BigInteger((b).Count)) - (BigInteger.One)));
        return Dafny.Sequence<Dafny.Rune>.Concat(_0_s1, _1_s2);
      } else {
        Dafny.ISequence<Dafny.Rune> _2_s1 = Std.Base64.__default.EncodeUnpadded((b).Take((new BigInteger((b).Count)) - (new BigInteger(2))));
        Dafny.ISequence<Dafny.Rune> _3_s2 = Std.Base64.__default.Encode1Padding((b).Drop((new BigInteger((b).Count)) - (new BigInteger(2))));
        return Dafny.Sequence<Dafny.Rune>.Concat(_2_s1, _3_s2);
      }
    }
    public static Dafny.ISequence<byte> UInt8sToBVs(Dafny.ISequence<byte> u) {
      return ((System.Func<Dafny.ISequence<byte>>) (() => {
        BigInteger dim2 = new BigInteger((u).Count);
        var arr2 = new byte[Dafny.Helpers.ToIntChecked(dim2, "array size exceeds memory limit")];
        for (int i2 = 0; i2 < dim2; i2++) {
          var _0_i = (BigInteger) i2;
          arr2[(int)(_0_i)] = (byte)((u).Select(_0_i));
        }
        return Dafny.Sequence<byte>.FromArray(arr2);
      }))();
    }
    public static Dafny.ISequence<byte> BVsToUInt8s(Dafny.ISequence<byte> b) {
      return ((System.Func<Dafny.ISequence<byte>>) (() => {
        BigInteger dim3 = new BigInteger((b).Count);
        var arr3 = new byte[Dafny.Helpers.ToIntChecked(dim3, "array size exceeds memory limit")];
        for (int i3 = 0; i3 < dim3; i3++) {
          var _0_i = (BigInteger) i3;
          arr3[(int)(_0_i)] = (byte)((b).Select(_0_i));
        }
        return Dafny.Sequence<byte>.FromArray(arr3);
      }))();
    }
    public static Dafny.ISequence<Dafny.Rune> Encode(Dafny.ISequence<byte> u) {
      return Std.Base64.__default.EncodeBV(Std.Base64.__default.UInt8sToBVs(u));
    }
    public static Std.Wrappers._IResult<Dafny.ISequence<byte>, Dafny.ISequence<Dafny.Rune>> Decode(Dafny.ISequence<Dafny.Rune> s) {
      if (Std.Base64.__default.IsBase64String(s)) {
        Dafny.ISequence<byte> _0_b = Std.Base64.__default.DecodeValid(s);
        return Std.Wrappers.Result<Dafny.ISequence<byte>, Dafny.ISequence<Dafny.Rune>>.create_Success(Std.Base64.__default.BVsToUInt8s(_0_b));
      } else {
        return Std.Wrappers.Result<Dafny.ISequence<byte>, Dafny.ISequence<Dafny.Rune>>.create_Failure(Dafny.Sequence<Dafny.Rune>.UnicodeFromString("The encoding is malformed"));
      }
    }
  }
} // end of namespace Std.Base64
namespace Std.Relations {

} // end of namespace Std.Relations
namespace Std.Math {

  public partial class __default {
    public static BigInteger Min(BigInteger a, BigInteger b)
    {
      if ((a) < (b)) {
        return a;
      } else {
        return b;
      }
    }
    public static BigInteger Min3(BigInteger a, BigInteger b, BigInteger c)
    {
      return Std.Math.__default.Min(a, Std.Math.__default.Min(b, c));
    }
    public static BigInteger Max(BigInteger a, BigInteger b)
    {
      if ((a) < (b)) {
        return b;
      } else {
        return a;
      }
    }
    public static BigInteger Max3(BigInteger a, BigInteger b, BigInteger c)
    {
      return Std.Math.__default.Max(a, Std.Math.__default.Max(b, c));
    }
    public static BigInteger Abs(BigInteger a) {
      if ((a).Sign == -1) {
        return (BigInteger.Zero) - (a);
      } else {
        return a;
      }
    }
  }
} // end of namespace Std.Math
namespace Std.Collections.Seq {

  public partial class __default {
    public static __T First<__T>(Dafny.ISequence<__T> xs) {
      return (xs).Select(BigInteger.Zero);
    }
    public static Dafny.ISequence<__T> DropFirst<__T>(Dafny.ISequence<__T> xs) {
      return (xs).Drop(BigInteger.One);
    }
    public static __T Last<__T>(Dafny.ISequence<__T> xs) {
      return (xs).Select((new BigInteger((xs).Count)) - (BigInteger.One));
    }
    public static Dafny.ISequence<__T> DropLast<__T>(Dafny.ISequence<__T> xs) {
      return (xs).Take((new BigInteger((xs).Count)) - (BigInteger.One));
    }
    public static __T[] ToArray<__T>(Dafny.ISequence<__T> xs)
    {
      __T[] a = new __T[0];
      Func<BigInteger, __T> _init0 = Dafny.Helpers.Id<Func<Dafny.ISequence<__T>, Func<BigInteger, __T>>>((_0_xs) => ((System.Func<BigInteger, __T>)((_1_i) => {
        return (_0_xs).Select(_1_i);
      })))(xs);
      __T[] _nw0 = new __T[Dafny.Helpers.ToIntChecked(new BigInteger((xs).Count), "array size exceeds memory limit")];
      for (var _i0_0 = 0; _i0_0 < new BigInteger(_nw0.Length); _i0_0++) {
        _nw0[(int)(_i0_0)] = _init0(_i0_0);
      }
      a = _nw0;
      return a;
    }
    public static Dafny.ISet<__T> ToSet<__T>(Dafny.ISequence<__T> xs) {
      return Dafny.Helpers.Id<Func<Dafny.ISequence<__T>, Dafny.ISet<__T>>>((_0_xs) => ((System.Func<Dafny.ISet<__T>>)(() => {
        var _coll0 = new System.Collections.Generic.List<__T>();
        foreach (__T _compr_0 in (_0_xs).CloneAsArray()) {
          __T _1_x = (__T)_compr_0;
          if ((_0_xs).Contains(_1_x)) {
            _coll0.Add(_1_x);
          }
        }
        return Dafny.Set<__T>.FromCollection(_coll0);
      }))())(xs);
    }
    public static BigInteger IndexOf<__T>(Dafny.ISequence<__T> xs, __T v)
    {
      BigInteger _0___accumulator = BigInteger.Zero;
    TAIL_CALL_START: ;
      if (object.Equals((xs).Select(BigInteger.Zero), v)) {
        return (BigInteger.Zero) + (_0___accumulator);
      } else {
        _0___accumulator = (_0___accumulator) + (BigInteger.One);
        Dafny.ISequence<__T> _in0 = (xs).Drop(BigInteger.One);
        __T _in1 = v;
        xs = _in0;
        v = _in1;
        goto TAIL_CALL_START;
      }
    }
    public static Std.Wrappers._IOption<BigInteger> IndexOfOption<__T>(Dafny.ISequence<__T> xs, __T v)
    {
      return Std.Collections.Seq.__default.IndexByOption<__T>(xs, Dafny.Helpers.Id<Func<__T, Func<__T, bool>>>((_0_v) => ((System.Func<__T, bool>)((_1_x) => {
        return object.Equals(_1_x, _0_v);
      })))(v));
    }
    public static Std.Wrappers._IOption<BigInteger> IndexByOption<__T>(Dafny.ISequence<__T> xs, Func<__T, bool> p)
    {
      if ((new BigInteger((xs).Count)).Sign == 0) {
        return Std.Wrappers.Option<BigInteger>.create_None();
      } else if (Dafny.Helpers.Id<Func<__T, bool>>(p)((xs).Select(BigInteger.Zero))) {
        return Std.Wrappers.Option<BigInteger>.create_Some(BigInteger.Zero);
      } else {
        Std.Wrappers._IOption<BigInteger> _0_o_k = Std.Collections.Seq.__default.IndexByOption<__T>((xs).Drop(BigInteger.One), p);
        if ((_0_o_k).is_Some) {
          return Std.Wrappers.Option<BigInteger>.create_Some(((_0_o_k).dtor_value) + (BigInteger.One));
        } else {
          return Std.Wrappers.Option<BigInteger>.create_None();
        }
      }
    }
    public static BigInteger LastIndexOf<__T>(Dafny.ISequence<__T> xs, __T v)
    {
    TAIL_CALL_START: ;
      if (object.Equals((xs).Select((new BigInteger((xs).Count)) - (BigInteger.One)), v)) {
        return (new BigInteger((xs).Count)) - (BigInteger.One);
      } else {
        Dafny.ISequence<__T> _in0 = (xs).Take((new BigInteger((xs).Count)) - (BigInteger.One));
        __T _in1 = v;
        xs = _in0;
        v = _in1;
        goto TAIL_CALL_START;
      }
    }
    public static Std.Wrappers._IOption<BigInteger> LastIndexOfOption<__T>(Dafny.ISequence<__T> xs, __T v)
    {
      return Std.Collections.Seq.__default.LastIndexByOption<__T>(xs, Dafny.Helpers.Id<Func<__T, Func<__T, bool>>>((_0_v) => ((System.Func<__T, bool>)((_1_x) => {
        return object.Equals(_1_x, _0_v);
      })))(v));
    }
    public static Std.Wrappers._IOption<BigInteger> LastIndexByOption<__T>(Dafny.ISequence<__T> xs, Func<__T, bool> p)
    {
    TAIL_CALL_START: ;
      if ((new BigInteger((xs).Count)).Sign == 0) {
        return Std.Wrappers.Option<BigInteger>.create_None();
      } else if (Dafny.Helpers.Id<Func<__T, bool>>(p)((xs).Select((new BigInteger((xs).Count)) - (BigInteger.One)))) {
        return Std.Wrappers.Option<BigInteger>.create_Some((new BigInteger((xs).Count)) - (BigInteger.One));
      } else {
        Dafny.ISequence<__T> _in0 = (xs).Take((new BigInteger((xs).Count)) - (BigInteger.One));
        Func<__T, bool> _in1 = p;
        xs = _in0;
        p = _in1;
        goto TAIL_CALL_START;
      }
    }
    public static Dafny.ISequence<__T> Remove<__T>(Dafny.ISequence<__T> xs, BigInteger pos)
    {
      return Dafny.Sequence<__T>.Concat((xs).Take(pos), (xs).Drop((pos) + (BigInteger.One)));
    }
    public static Dafny.ISequence<__T> RemoveValue<__T>(Dafny.ISequence<__T> xs, __T v)
    {
      if (!(xs).Contains(v)) {
        return xs;
      } else {
        BigInteger _0_i = Std.Collections.Seq.__default.IndexOf<__T>(xs, v);
        return Dafny.Sequence<__T>.Concat((xs).Take(_0_i), (xs).Drop((_0_i) + (BigInteger.One)));
      }
    }
    public static Dafny.ISequence<__T> Insert<__T>(Dafny.ISequence<__T> xs, __T a, BigInteger pos)
    {
      return Dafny.Sequence<__T>.Concat(Dafny.Sequence<__T>.Concat((xs).Take(pos), Dafny.Sequence<__T>.FromElements(a)), (xs).Drop(pos));
    }
    public static Dafny.ISequence<__T> Reverse<__T>(Dafny.ISequence<__T> xs) {
      Dafny.ISequence<__T> _0___accumulator = Dafny.Sequence<__T>.FromElements();
    TAIL_CALL_START: ;
      if ((xs).Equals(Dafny.Sequence<__T>.FromElements())) {
        return Dafny.Sequence<__T>.Concat(_0___accumulator, Dafny.Sequence<__T>.FromElements());
      } else {
        _0___accumulator = Dafny.Sequence<__T>.Concat(_0___accumulator, Dafny.Sequence<__T>.FromElements((xs).Select((new BigInteger((xs).Count)) - (BigInteger.One))));
        Dafny.ISequence<__T> _in0 = (xs).Subsequence(BigInteger.Zero, (new BigInteger((xs).Count)) - (BigInteger.One));
        xs = _in0;
        goto TAIL_CALL_START;
      }
    }
    public static Dafny.ISequence<__T> Repeat<__T>(__T v, BigInteger length)
    {
      Dafny.ISequence<__T> _0___accumulator = Dafny.Sequence<__T>.FromElements();
    TAIL_CALL_START: ;
      if ((length).Sign == 0) {
        return Dafny.Sequence<__T>.Concat(_0___accumulator, Dafny.Sequence<__T>.FromElements());
      } else {
        _0___accumulator = Dafny.Sequence<__T>.Concat(_0___accumulator, Dafny.Sequence<__T>.FromElements(v));
        __T _in0 = v;
        BigInteger _in1 = (length) - (BigInteger.One);
        v = _in0;
        length = _in1;
        goto TAIL_CALL_START;
      }
    }
    public static _System._ITuple2<Dafny.ISequence<__A>, Dafny.ISequence<__B>> Unzip<__A, __B>(Dafny.ISequence<_System._ITuple2<__A, __B>> xs) {
      if ((new BigInteger((xs).Count)).Sign == 0) {
        return _System.Tuple2<Dafny.ISequence<__A>, Dafny.ISequence<__B>>.create(Dafny.Sequence<__A>.FromElements(), Dafny.Sequence<__B>.FromElements());
      } else {
        _System._ITuple2<Dafny.ISequence<__A>, Dafny.ISequence<__B>> _let_tmp_rhs0 = Std.Collections.Seq.__default.Unzip<__A, __B>(Std.Collections.Seq.__default.DropLast<_System._ITuple2<__A, __B>>(xs));
        Dafny.ISequence<__A> _0_a = _let_tmp_rhs0.dtor__0;
        Dafny.ISequence<__B> _1_b = _let_tmp_rhs0.dtor__1;
        return _System.Tuple2<Dafny.ISequence<__A>, Dafny.ISequence<__B>>.create(Dafny.Sequence<__A>.Concat(_0_a, Dafny.Sequence<__A>.FromElements((Std.Collections.Seq.__default.Last<_System._ITuple2<__A, __B>>(xs)).dtor__0)), Dafny.Sequence<__B>.Concat(_1_b, Dafny.Sequence<__B>.FromElements((Std.Collections.Seq.__default.Last<_System._ITuple2<__A, __B>>(xs)).dtor__1)));
      }
    }
    public static Dafny.ISequence<_System._ITuple2<__A, __B>> Zip<__A, __B>(Dafny.ISequence<__A> xs, Dafny.ISequence<__B> ys)
    {
      Dafny.ISequence<_System._ITuple2<__A, __B>> _0___accumulator = Dafny.Sequence<_System._ITuple2<__A, __B>>.FromElements();
    TAIL_CALL_START: ;
      if ((new BigInteger((xs).Count)).Sign == 0) {
        return Dafny.Sequence<_System._ITuple2<__A, __B>>.Concat(Dafny.Sequence<_System._ITuple2<__A, __B>>.FromElements(), _0___accumulator);
      } else {
        _0___accumulator = Dafny.Sequence<_System._ITuple2<__A, __B>>.Concat(Dafny.Sequence<_System._ITuple2<__A, __B>>.FromElements(_System.Tuple2<__A, __B>.create(Std.Collections.Seq.__default.Last<__A>(xs), Std.Collections.Seq.__default.Last<__B>(ys))), _0___accumulator);
        Dafny.ISequence<__A> _in0 = Std.Collections.Seq.__default.DropLast<__A>(xs);
        Dafny.ISequence<__B> _in1 = Std.Collections.Seq.__default.DropLast<__B>(ys);
        xs = _in0;
        ys = _in1;
        goto TAIL_CALL_START;
      }
    }
    public static BigInteger Max(Dafny.ISequence<BigInteger> xs) {
      if ((new BigInteger((xs).Count)) == (BigInteger.One)) {
        return (xs).Select(BigInteger.Zero);
      } else {
        return Std.Math.__default.Max((xs).Select(BigInteger.Zero), Std.Collections.Seq.__default.Max((xs).Drop(BigInteger.One)));
      }
    }
    public static BigInteger Min(Dafny.ISequence<BigInteger> xs) {
      if ((new BigInteger((xs).Count)) == (BigInteger.One)) {
        return (xs).Select(BigInteger.Zero);
      } else {
        return Std.Math.__default.Min((xs).Select(BigInteger.Zero), Std.Collections.Seq.__default.Min((xs).Drop(BigInteger.One)));
      }
    }
    public static Dafny.ISequence<__T> Flatten<__T>(Dafny.ISequence<Dafny.ISequence<__T>> xs) {
      Dafny.ISequence<__T> _0___accumulator = Dafny.Sequence<__T>.FromElements();
    TAIL_CALL_START: ;
      if ((new BigInteger((xs).Count)).Sign == 0) {
        return Dafny.Sequence<__T>.Concat(_0___accumulator, Dafny.Sequence<__T>.FromElements());
      } else {
        _0___accumulator = Dafny.Sequence<__T>.Concat(_0___accumulator, (xs).Select(BigInteger.Zero));
        Dafny.ISequence<Dafny.ISequence<__T>> _in0 = (xs).Drop(BigInteger.One);
        xs = _in0;
        goto TAIL_CALL_START;
      }
    }
    public static Dafny.ISequence<__T> FlattenReverse<__T>(Dafny.ISequence<Dafny.ISequence<__T>> xs) {
      Dafny.ISequence<__T> _0___accumulator = Dafny.Sequence<__T>.FromElements();
    TAIL_CALL_START: ;
      if ((new BigInteger((xs).Count)).Sign == 0) {
        return Dafny.Sequence<__T>.Concat(Dafny.Sequence<__T>.FromElements(), _0___accumulator);
      } else {
        _0___accumulator = Dafny.Sequence<__T>.Concat(Std.Collections.Seq.__default.Last<Dafny.ISequence<__T>>(xs), _0___accumulator);
        Dafny.ISequence<Dafny.ISequence<__T>> _in0 = Std.Collections.Seq.__default.DropLast<Dafny.ISequence<__T>>(xs);
        xs = _in0;
        goto TAIL_CALL_START;
      }
    }
    public static Dafny.ISequence<__T> Join<__T>(Dafny.ISequence<Dafny.ISequence<__T>> seqs, Dafny.ISequence<__T> separator)
    {
      Dafny.ISequence<__T> _0___accumulator = Dafny.Sequence<__T>.FromElements();
    TAIL_CALL_START: ;
      if ((new BigInteger((seqs).Count)).Sign == 0) {
        return Dafny.Sequence<__T>.Concat(_0___accumulator, Dafny.Sequence<__T>.FromElements());
      } else if ((new BigInteger((seqs).Count)) == (BigInteger.One)) {
        return Dafny.Sequence<__T>.Concat(_0___accumulator, (seqs).Select(BigInteger.Zero));
      } else {
        _0___accumulator = Dafny.Sequence<__T>.Concat(_0___accumulator, Dafny.Sequence<__T>.Concat((seqs).Select(BigInteger.Zero), separator));
        Dafny.ISequence<Dafny.ISequence<__T>> _in0 = (seqs).Drop(BigInteger.One);
        Dafny.ISequence<__T> _in1 = separator;
        seqs = _in0;
        separator = _in1;
        goto TAIL_CALL_START;
      }
    }
    public static Dafny.ISequence<Dafny.ISequence<__T>> Split<__T>(Dafny.ISequence<__T> s, __T delim)
    {
      Dafny.ISequence<Dafny.ISequence<__T>> _0___accumulator = Dafny.Sequence<Dafny.ISequence<__T>>.FromElements();
    TAIL_CALL_START: ;
      Std.Wrappers._IOption<BigInteger> _1_i = Std.Collections.Seq.__default.IndexOfOption<__T>(s, delim);
      if ((_1_i).is_Some) {
        _0___accumulator = Dafny.Sequence<Dafny.ISequence<__T>>.Concat(_0___accumulator, Dafny.Sequence<Dafny.ISequence<__T>>.FromElements((s).Take((_1_i).dtor_value)));
        Dafny.ISequence<__T> _in0 = (s).Drop(((_1_i).dtor_value) + (BigInteger.One));
        __T _in1 = delim;
        s = _in0;
        delim = _in1;
        goto TAIL_CALL_START;
      } else {
        return Dafny.Sequence<Dafny.ISequence<__T>>.Concat(_0___accumulator, Dafny.Sequence<Dafny.ISequence<__T>>.FromElements(s));
      }
    }
    public static _System._ITuple2<Dafny.ISequence<__T>, Dafny.ISequence<__T>> SplitOnce<__T>(Dafny.ISequence<__T> s, __T delim)
    {
      Std.Wrappers._IOption<BigInteger> _0_i = Std.Collections.Seq.__default.IndexOfOption<__T>(s, delim);
      return _System.Tuple2<Dafny.ISequence<__T>, Dafny.ISequence<__T>>.create((s).Take((_0_i).dtor_value), (s).Drop(((_0_i).dtor_value) + (BigInteger.One)));
    }
    public static Std.Wrappers._IOption<_System._ITuple2<Dafny.ISequence<__T>, Dafny.ISequence<__T>>> SplitOnceOption<__T>(Dafny.ISequence<__T> s, __T delim)
    {
      Std.Wrappers._IOption<BigInteger> _0_valueOrError0 = Std.Collections.Seq.__default.IndexOfOption<__T>(s, delim);
      if ((_0_valueOrError0).IsFailure()) {
        return (_0_valueOrError0).PropagateFailure<_System._ITuple2<Dafny.ISequence<__T>, Dafny.ISequence<__T>>>();
      } else {
        BigInteger _1_i = (_0_valueOrError0).Extract();
        return Std.Wrappers.Option<_System._ITuple2<Dafny.ISequence<__T>, Dafny.ISequence<__T>>>.create_Some(_System.Tuple2<Dafny.ISequence<__T>, Dafny.ISequence<__T>>.create((s).Take(_1_i), (s).Drop((_1_i) + (BigInteger.One))));
      }
    }
    public static Dafny.ISequence<__R> Map<__T, __R>(Func<__T, __R> f, Dafny.ISequence<__T> xs)
    {
      Dafny.ISequence<__R> _0___accumulator = Dafny.Sequence<__R>.FromElements();
    TAIL_CALL_START: ;
      if ((new BigInteger((xs).Count)).Sign == 0) {
        return Dafny.Sequence<__R>.Concat(_0___accumulator, Dafny.Sequence<__R>.FromElements());
      } else {
        _0___accumulator = Dafny.Sequence<__R>.Concat(_0___accumulator, Dafny.Sequence<__R>.FromElements(Dafny.Helpers.Id<Func<__T, __R>>(f)((xs).Select(BigInteger.Zero))));
        Func<__T, __R> _in0 = f;
        Dafny.ISequence<__T> _in1 = (xs).Drop(BigInteger.One);
        f = _in0;
        xs = _in1;
        goto TAIL_CALL_START;
      }
    }
    public static Std.Wrappers._IResult<Dafny.ISequence<__R>, __E> MapWithResult<__T, __R, __E>(Func<__T, Std.Wrappers._IResult<__R, __E>> f, Dafny.ISequence<__T> xs)
    {
      if ((new BigInteger((xs).Count)).Sign == 0) {
        return Std.Wrappers.Result<Dafny.ISequence<__R>, __E>.create_Success(Dafny.Sequence<__R>.FromElements());
      } else {
        Std.Wrappers._IResult<__R, __E> _0_valueOrError0 = Dafny.Helpers.Id<Func<__T, Std.Wrappers._IResult<__R, __E>>>(f)((xs).Select(BigInteger.Zero));
        if ((_0_valueOrError0).IsFailure()) {
          return (_0_valueOrError0).PropagateFailure<Dafny.ISequence<__R>>();
        } else {
          __R _1_head = (_0_valueOrError0).Extract();
          Std.Wrappers._IResult<Dafny.ISequence<__R>, __E> _2_valueOrError1 = Std.Collections.Seq.__default.MapWithResult<__T, __R, __E>(f, (xs).Drop(BigInteger.One));
          if ((_2_valueOrError1).IsFailure()) {
            return (_2_valueOrError1).PropagateFailure<Dafny.ISequence<__R>>();
          } else {
            Dafny.ISequence<__R> _3_tail = (_2_valueOrError1).Extract();
            return Std.Wrappers.Result<Dafny.ISequence<__R>, __E>.create_Success(Dafny.Sequence<__R>.Concat(Dafny.Sequence<__R>.FromElements(_1_head), _3_tail));
          }
        }
      }
    }
    public static Dafny.ISequence<__T> Filter<__T>(Func<__T, bool> f, Dafny.ISequence<__T> xs)
    {
      Dafny.ISequence<__T> _0___accumulator = Dafny.Sequence<__T>.FromElements();
    TAIL_CALL_START: ;
      if ((new BigInteger((xs).Count)).Sign == 0) {
        return Dafny.Sequence<__T>.Concat(_0___accumulator, Dafny.Sequence<__T>.FromElements());
      } else {
        _0___accumulator = Dafny.Sequence<__T>.Concat(_0___accumulator, ((Dafny.Helpers.Id<Func<__T, bool>>(f)((xs).Select(BigInteger.Zero))) ? (Dafny.Sequence<__T>.FromElements((xs).Select(BigInteger.Zero))) : (Dafny.Sequence<__T>.FromElements())));
        Func<__T, bool> _in0 = f;
        Dafny.ISequence<__T> _in1 = (xs).Drop(BigInteger.One);
        f = _in0;
        xs = _in1;
        goto TAIL_CALL_START;
      }
    }
    public static __A FoldLeft<__A, __T>(Func<__A, __T, __A> f, __A init, Dafny.ISequence<__T> xs)
    {
    TAIL_CALL_START: ;
      if ((new BigInteger((xs).Count)).Sign == 0) {
        return init;
      } else {
        Func<__A, __T, __A> _in0 = f;
        __A _in1 = Dafny.Helpers.Id<Func<__A, __T, __A>>(f)(init, (xs).Select(BigInteger.Zero));
        Dafny.ISequence<__T> _in2 = (xs).Drop(BigInteger.One);
        f = _in0;
        init = _in1;
        xs = _in2;
        goto TAIL_CALL_START;
      }
    }
    public static __A FoldRight<__A, __T>(Func<__T, __A, __A> f, Dafny.ISequence<__T> xs, __A init)
    {
      if ((new BigInteger((xs).Count)).Sign == 0) {
        return init;
      } else {
        return Dafny.Helpers.Id<Func<__T, __A, __A>>(f)((xs).Select(BigInteger.Zero), Std.Collections.Seq.__default.FoldRight<__A, __T>(f, (xs).Drop(BigInteger.One), init));
      }
    }
    public static Dafny.ISequence<__T> SetToSeq<__T>(Dafny.ISet<__T> s)
    {
      Dafny.ISequence<__T> xs = Dafny.Sequence<__T>.Empty;
      xs = Dafny.Sequence<__T>.FromElements();
      Dafny.ISet<__T> _0_left;
      _0_left = s;
      while (!(_0_left).Equals(Dafny.Set<__T>.FromElements())) {
        __T _1_x;
        foreach (__T _assign_such_that_0 in (_0_left).Elements) {
          _1_x = (__T)_assign_such_that_0;
          if ((_0_left).Contains(_1_x)) {
            goto after__ASSIGN_SUCH_THAT_0;
          }
        }
        throw new System.Exception("assign-such-that search produced no value");
      after__ASSIGN_SUCH_THAT_0: ;
        _0_left = Dafny.Set<__T>.Difference(_0_left, Dafny.Set<__T>.FromElements(_1_x));
        xs = Dafny.Sequence<__T>.Concat(xs, Dafny.Sequence<__T>.FromElements(_1_x));
      }
      return xs;
    }
    public static Dafny.ISequence<__T> SetToSortedSeq<__T>(Dafny.ISet<__T> s, Func<__T, __T, bool> R)
    {
      Dafny.ISequence<__T> xs = Dafny.Sequence<__T>.Empty;
      Dafny.ISequence<__T> _out0;
      _out0 = Std.Collections.Seq.__default.SetToSeq<__T>(s);
      xs = _out0;
      xs = Std.Collections.Seq.__default.MergeSortBy<__T>(R, xs);
      return xs;
    }
    public static Dafny.ISequence<__T> MergeSortBy<__T>(Func<__T, __T, bool> lessThanOrEq, Dafny.ISequence<__T> a)
    {
      if ((new BigInteger((a).Count)) <= (BigInteger.One)) {
        return a;
      } else {
        BigInteger _0_splitIndex = Dafny.Helpers.EuclideanDivision(new BigInteger((a).Count), new BigInteger(2));
        Dafny.ISequence<__T> _1_left = (a).Take(_0_splitIndex);
        Dafny.ISequence<__T> _2_right = (a).Drop(_0_splitIndex);
        Dafny.ISequence<__T> _3_leftSorted = Std.Collections.Seq.__default.MergeSortBy<__T>(lessThanOrEq, _1_left);
        Dafny.ISequence<__T> _4_rightSorted = Std.Collections.Seq.__default.MergeSortBy<__T>(lessThanOrEq, _2_right);
        return Std.Collections.Seq.__default.MergeSortedWith<__T>(_3_leftSorted, _4_rightSorted, lessThanOrEq);
      }
    }
    public static Dafny.ISequence<__T> MergeSortedWith<__T>(Dafny.ISequence<__T> left, Dafny.ISequence<__T> right, Func<__T, __T, bool> lessThanOrEq)
    {
      Dafny.ISequence<__T> _0___accumulator = Dafny.Sequence<__T>.FromElements();
    TAIL_CALL_START: ;
      if ((new BigInteger((left).Count)).Sign == 0) {
        return Dafny.Sequence<__T>.Concat(_0___accumulator, right);
      } else if ((new BigInteger((right).Count)).Sign == 0) {
        return Dafny.Sequence<__T>.Concat(_0___accumulator, left);
      } else if (Dafny.Helpers.Id<Func<__T, __T, bool>>(lessThanOrEq)((left).Select(BigInteger.Zero), (right).Select(BigInteger.Zero))) {
        _0___accumulator = Dafny.Sequence<__T>.Concat(_0___accumulator, Dafny.Sequence<__T>.FromElements((left).Select(BigInteger.Zero)));
        Dafny.ISequence<__T> _in0 = (left).Drop(BigInteger.One);
        Dafny.ISequence<__T> _in1 = right;
        Func<__T, __T, bool> _in2 = lessThanOrEq;
        left = _in0;
        right = _in1;
        lessThanOrEq = _in2;
        goto TAIL_CALL_START;
      } else {
        _0___accumulator = Dafny.Sequence<__T>.Concat(_0___accumulator, Dafny.Sequence<__T>.FromElements((right).Select(BigInteger.Zero)));
        Dafny.ISequence<__T> _in3 = left;
        Dafny.ISequence<__T> _in4 = (right).Drop(BigInteger.One);
        Func<__T, __T, bool> _in5 = lessThanOrEq;
        left = _in3;
        right = _in4;
        lessThanOrEq = _in5;
        goto TAIL_CALL_START;
      }
    }
  }
} // end of namespace Std.Collections.Seq
namespace Std.Collections.Array {

  public partial class __default {
    public static Std.Wrappers._IOption<BigInteger> BinarySearch<__T>(__T[] a, __T key, Func<__T, __T, bool> less)
    {
      Std.Wrappers._IOption<BigInteger> r = Std.Wrappers.Option<BigInteger>.Default();
      BigInteger _0_lo;
      BigInteger _1_hi;
      BigInteger _rhs0 = BigInteger.Zero;
      BigInteger _rhs1 = new BigInteger((a).Length);
      _0_lo = _rhs0;
      _1_hi = _rhs1;
      while ((_0_lo) < (_1_hi)) {
        BigInteger _2_mid;
        _2_mid = Dafny.Helpers.EuclideanDivision((_0_lo) + (_1_hi), new BigInteger(2));
        if (Dafny.Helpers.Id<Func<__T, __T, bool>>(less)(key, (a)[(int)(_2_mid)])) {
          _1_hi = _2_mid;
        } else if (Dafny.Helpers.Id<Func<__T, __T, bool>>(less)((a)[(int)(_2_mid)], key)) {
          _0_lo = (_2_mid) + (BigInteger.One);
        } else {
          r = Std.Wrappers.Option<BigInteger>.create_Some(_2_mid);
          return r;
        }
      }
      r = Std.Wrappers.Option<BigInteger>.create_None();
      return r;
      return r;
    }
  }
} // end of namespace Std.Collections.Array
namespace Std.Collections.Imap {

  public partial class __default {
    public static Std.Wrappers._IOption<__Y> Get<__X, __Y>(Dafny.IMap<__X,__Y> m, __X x)
    {
      if ((m).Contains(x)) {
        return Std.Wrappers.Option<__Y>.create_Some(Dafny.Map<__X, __Y>.Select(m,x));
      } else {
        return Std.Wrappers.Option<__Y>.create_None();
      }
    }
  }
} // end of namespace Std.Collections.Imap
namespace Std.Functions {

} // end of namespace Std.Functions
namespace Std.Collections.Iset {

} // end of namespace Std.Collections.Iset
namespace Std.Collections.Map {

  public partial class __default {
    public static Std.Wrappers._IOption<__Y> Get<__X, __Y>(Dafny.IMap<__X,__Y> m, __X x)
    {
      if ((m).Contains(x)) {
        return Std.Wrappers.Option<__Y>.create_Some(Dafny.Map<__X, __Y>.Select(m,x));
      } else {
        return Std.Wrappers.Option<__Y>.create_None();
      }
    }
    public static Dafny.IMap<__X,__Y> ToImap<__X, __Y>(Dafny.IMap<__X,__Y> m) {
      return Dafny.Helpers.Id<Func<Dafny.IMap<__X,__Y>, Dafny.IMap<__X,__Y>>>((_0_m) => ((System.Func<Dafny.IMap<__X,__Y>>)(() => {
        var _coll0 = new System.Collections.Generic.List<Dafny.Pair<__X,__Y>>();
        foreach (__X _compr_0 in (_0_m).Keys.Elements) {
          __X _1_x = (__X)_compr_0;
          if ((_0_m).Contains(_1_x)) {
            _coll0.Add(new Dafny.Pair<__X,__Y>(_1_x, Dafny.Map<__X, __Y>.Select(_0_m,_1_x)));
          }
        }
        return Dafny.Map<__X,__Y>.FromCollection(_coll0);
      }))())(m);
    }
    public static Dafny.IMap<__X,__Y> RemoveKeys<__X, __Y>(Dafny.IMap<__X,__Y> m, Dafny.ISet<__X> xs)
    {
      return Dafny.Map<__X, __Y>.Subtract(m, xs);
    }
    public static Dafny.IMap<__X,__Y> Remove<__X, __Y>(Dafny.IMap<__X,__Y> m, __X x)
    {
      Dafny.IMap<__X,__Y> _0_m_k = Dafny.Helpers.Id<Func<Dafny.IMap<__X,__Y>, __X, Dafny.IMap<__X,__Y>>>((_1_m, _2_x) => ((System.Func<Dafny.IMap<__X,__Y>>)(() => {
        var _coll0 = new System.Collections.Generic.List<Dafny.Pair<__X,__Y>>();
        foreach (__X _compr_0 in (_1_m).Keys.Elements) {
          __X _3_x_k = (__X)_compr_0;
          if (((_1_m).Contains(_3_x_k)) && (!object.Equals(_3_x_k, _2_x))) {
            _coll0.Add(new Dafny.Pair<__X,__Y>(_3_x_k, Dafny.Map<__X, __Y>.Select(_1_m,_3_x_k)));
          }
        }
        return Dafny.Map<__X,__Y>.FromCollection(_coll0);
      }))())(m, x);
      return _0_m_k;
    }
    public static Dafny.IMap<__X,__Y> Restrict<__X, __Y>(Dafny.IMap<__X,__Y> m, Dafny.ISet<__X> xs)
    {
      return Dafny.Helpers.Id<Func<Dafny.ISet<__X>, Dafny.IMap<__X,__Y>, Dafny.IMap<__X,__Y>>>((_0_xs, _1_m) => ((System.Func<Dafny.IMap<__X,__Y>>)(() => {
        var _coll0 = new System.Collections.Generic.List<Dafny.Pair<__X,__Y>>();
        foreach (__X _compr_0 in (_0_xs).Elements) {
          __X _2_x = (__X)_compr_0;
          if (((_0_xs).Contains(_2_x)) && ((_1_m).Contains(_2_x))) {
            _coll0.Add(new Dafny.Pair<__X,__Y>(_2_x, Dafny.Map<__X, __Y>.Select(_1_m,_2_x)));
          }
        }
        return Dafny.Map<__X,__Y>.FromCollection(_coll0);
      }))())(xs, m);
    }
    public static Dafny.IMap<__X,__Y> Union<__X, __Y>(Dafny.IMap<__X,__Y> m, Dafny.IMap<__X,__Y> m_k)
    {
      return Dafny.Map<__X, __Y>.Merge(m, m_k);
    }
  }
} // end of namespace Std.Collections.Map
namespace Std.Collections.Set {

  public partial class __default {
    public static __T ExtractFromSingleton<__T>(Dafny.ISet<__T> s) {
      return Dafny.Helpers.Let<int, __T>(0, _let_dummy_0 =>  {
        __T _0_x = default(__T);
        foreach (__T _assign_such_that_0 in (s).Elements) {
          _0_x = (__T)_assign_such_that_0;
          if ((s).Contains(_0_x)) {
            goto after__ASSIGN_SUCH_THAT_0;
          }
        }
        throw new System.Exception("assign-such-that search produced no value");
      after__ASSIGN_SUCH_THAT_0: ;
        return _0_x;
      }
      );
    }
    public static Dafny.ISet<__Y> Map<__X, __Y>(Func<__X, __Y> f, Dafny.ISet<__X> xs)
    {
      Dafny.ISet<__Y> _0_ys = Dafny.Helpers.Id<Func<Dafny.ISet<__X>, Func<__X, __Y>, Dafny.ISet<__Y>>>((_1_xs, _2_f) => ((System.Func<Dafny.ISet<__Y>>)(() => {
        var _coll0 = new System.Collections.Generic.List<__Y>();
        foreach (__X _compr_0 in (_1_xs).Elements) {
          __X _3_x = (__X)_compr_0;
          if ((_1_xs).Contains(_3_x)) {
            _coll0.Add(Dafny.Helpers.Id<Func<__X, __Y>>(_2_f)(_3_x));
          }
        }
        return Dafny.Set<__Y>.FromCollection(_coll0);
      }))())(xs, f);
      return _0_ys;
    }
    public static Dafny.ISet<__X> Filter<__X>(Func<__X, bool> f, Dafny.ISet<__X> xs)
    {
      Dafny.ISet<__X> _0_ys = Dafny.Helpers.Id<Func<Dafny.ISet<__X>, Func<__X, bool>, Dafny.ISet<__X>>>((_1_xs, _2_f) => ((System.Func<Dafny.ISet<__X>>)(() => {
        var _coll0 = new System.Collections.Generic.List<__X>();
        foreach (__X _compr_0 in (_1_xs).Elements) {
          __X _3_x = (__X)_compr_0;
          if (((_1_xs).Contains(_3_x)) && (Dafny.Helpers.Id<Func<__X, bool>>(_2_f)(_3_x))) {
            _coll0.Add(_3_x);
          }
        }
        return Dafny.Set<__X>.FromCollection(_coll0);
      }))())(xs, f);
      return _0_ys;
    }
    public static Dafny.ISet<BigInteger> SetRange(BigInteger a, BigInteger b)
    {
      Dafny.ISet<BigInteger> _0___accumulator = Dafny.Set<BigInteger>.FromElements();
    TAIL_CALL_START: ;
      if ((a) == (b)) {
        return Dafny.Set<BigInteger>.Union(Dafny.Set<BigInteger>.FromElements(), _0___accumulator);
      } else {
        _0___accumulator = Dafny.Set<BigInteger>.Union(_0___accumulator, Dafny.Set<BigInteger>.FromElements(a));
        BigInteger _in0 = (a) + (BigInteger.One);
        BigInteger _in1 = b;
        a = _in0;
        b = _in1;
        goto TAIL_CALL_START;
      }
    }
    public static Dafny.ISet<BigInteger> SetRangeZeroBound(BigInteger n) {
      return Std.Collections.Set.__default.SetRange(BigInteger.Zero, n);
    }
  }
} // end of namespace Std.Collections.Set
namespace Std.Collections {

} // end of namespace Std.Collections
namespace Std.DynamicArray {


  public partial class DynamicArray<A> {
    public DynamicArray() {
      this.size = BigInteger.Zero;
      this.capacity = BigInteger.Zero;
      this.data = new A[0];
    }
    public BigInteger size {get; set;}
    public BigInteger capacity {get; set;}
    public A[] data {get; set;}
    public void __ctor()
    {
      (this).size = BigInteger.Zero;
      (this).capacity = BigInteger.Zero;
      A[] _nw0 = new A[Dafny.Helpers.ToIntChecked(BigInteger.Zero, "array size exceeds memory limit")];
      (this).data = _nw0;
    }
    public A At(BigInteger index) {
      return (this.data)[(int)(index)];
    }
    public void Put(BigInteger index, A element)
    {
      A[] _arr0 = this.data;
      _arr0[(int)((index))] = element;
    }
    public void Ensure(BigInteger reserved, A defaultValue)
    {
      BigInteger _0_newCapacity;
      _0_newCapacity = this.capacity;
      while ((reserved) > ((_0_newCapacity) - (this.size))) {
        _0_newCapacity = (this).DefaultNewCapacity(_0_newCapacity);
      }
      if ((_0_newCapacity) > (this.capacity)) {
        (this).Realloc(defaultValue, _0_newCapacity);
      }
    }
    public void PopFast()
    {
      (this).size = (this.size) - (BigInteger.One);
    }
    public void PushFast(A element)
    {
      A[] _arr0 = this.data;
      BigInteger _index0 = this.size;
      _arr0[(int)(_index0)] = element;
      (this).size = (this.size) + (BigInteger.One);
    }
    public void Push(A element)
    {
      if ((this.size) == (this.capacity)) {
        (this).ReallocDefault(element);
      }
      (this).PushFast(element);
    }
    public void Realloc(A defaultValue, BigInteger newCapacity)
    {
      A[] _0_oldData;
      BigInteger _1_oldCapacity;
      A[] _rhs0 = this.data;
      BigInteger _rhs1 = this.capacity;
      _0_oldData = _rhs0;
      _1_oldCapacity = _rhs1;
      Func<BigInteger, A> _init0 = Dafny.Helpers.Id<Func<A, Func<BigInteger, A>>>((_2_defaultValue) => ((System.Func<BigInteger, A>)((_3___v0) => {
        return _2_defaultValue;
      })))(defaultValue);
      A[] _nw0 = new A[Dafny.Helpers.ToIntChecked(newCapacity, "array size exceeds memory limit")];
      for (var _i0_0 = 0; _i0_0 < new BigInteger(_nw0.Length); _i0_0++) {
        _nw0[(int)(_i0_0)] = _init0(_i0_0);
      }
      A[] _rhs2 = _nw0;
      BigInteger _rhs3 = newCapacity;
      Std.DynamicArray.DynamicArray<A> _lhs0 = this;
      Std.DynamicArray.DynamicArray<A> _lhs1 = this;
      _lhs0.data = _rhs2;
      _lhs1.capacity = _rhs3;
      (this).CopyFrom(_0_oldData, _1_oldCapacity);
    }
    public BigInteger DefaultNewCapacity(BigInteger capacity) {
      if ((capacity).Sign == 0) {
        return new BigInteger(8);
      } else {
        return (new BigInteger(2)) * (capacity);
      }
    }
    public void ReallocDefault(A defaultValue)
    {
      (this).Realloc(defaultValue, (this).DefaultNewCapacity(this.capacity));
    }
    public void CopyFrom(A[] newData, BigInteger count)
    {
      foreach (BigInteger _guard_loop_0 in Dafny.Helpers.IntegerRange(BigInteger.Zero, count)) {
        BigInteger _0_index = (BigInteger)_guard_loop_0;
        if ((true) && (((_0_index).Sign != -1) && ((_0_index) < (count)))) {
          A[] _arr0 = this.data;
          _arr0[(int)((_0_index))] = (newData)[(int)(_0_index)];
        }
      }
    }
  }
} // end of namespace Std.DynamicArray
namespace Std.Arithmetic.GeneralInternals {

} // end of namespace Std.Arithmetic.GeneralInternals
namespace Std.Arithmetic.MulInternalsNonlinear {

} // end of namespace Std.Arithmetic.MulInternalsNonlinear
namespace Std.Arithmetic.MulInternals {

  public partial class __default {
    public static BigInteger MulPos(BigInteger x, BigInteger y)
    {
      BigInteger _0___accumulator = BigInteger.Zero;
    TAIL_CALL_START: ;
      if ((x).Sign == 0) {
        return (BigInteger.Zero) + (_0___accumulator);
      } else {
        _0___accumulator = (_0___accumulator) + (y);
        BigInteger _in0 = (x) - (BigInteger.One);
        BigInteger _in1 = y;
        x = _in0;
        y = _in1;
        goto TAIL_CALL_START;
      }
    }
    public static BigInteger MulRecursive(BigInteger x, BigInteger y)
    {
      if ((x).Sign != -1) {
        return Std.Arithmetic.MulInternals.__default.MulPos(x, y);
      } else {
        return (new BigInteger(-1)) * (Std.Arithmetic.MulInternals.__default.MulPos((new BigInteger(-1)) * (x), y));
      }
    }
  }
} // end of namespace Std.Arithmetic.MulInternals
namespace Std.Arithmetic.Mul {

} // end of namespace Std.Arithmetic.Mul
namespace Std.Arithmetic.ModInternalsNonlinear {

} // end of namespace Std.Arithmetic.ModInternalsNonlinear
namespace Std.Arithmetic.DivInternalsNonlinear {

} // end of namespace Std.Arithmetic.DivInternalsNonlinear
namespace Std.Arithmetic.ModInternals {

  public partial class __default {
    public static BigInteger ModRecursive(BigInteger x, BigInteger d)
    {
    TAIL_CALL_START: ;
      if ((x).Sign == -1) {
        BigInteger _in0 = (d) + (x);
        BigInteger _in1 = d;
        x = _in0;
        d = _in1;
        goto TAIL_CALL_START;
      } else if ((x) < (d)) {
        return x;
      } else {
        BigInteger _in2 = (x) - (d);
        BigInteger _in3 = d;
        x = _in2;
        d = _in3;
        goto TAIL_CALL_START;
      }
    }
  }
} // end of namespace Std.Arithmetic.ModInternals
namespace Std.Arithmetic.DivInternals {

  public partial class __default {
    public static BigInteger DivPos(BigInteger x, BigInteger d)
    {
      BigInteger _0___accumulator = BigInteger.Zero;
    TAIL_CALL_START: ;
      if ((x).Sign == -1) {
        _0___accumulator = (_0___accumulator) + (new BigInteger(-1));
        BigInteger _in0 = (x) + (d);
        BigInteger _in1 = d;
        x = _in0;
        d = _in1;
        goto TAIL_CALL_START;
      } else if ((x) < (d)) {
        return (BigInteger.Zero) + (_0___accumulator);
      } else {
        _0___accumulator = (_0___accumulator) + (BigInteger.One);
        BigInteger _in2 = (x) - (d);
        BigInteger _in3 = d;
        x = _in2;
        d = _in3;
        goto TAIL_CALL_START;
      }
    }
    public static BigInteger DivRecursive(BigInteger x, BigInteger d)
    {
      if ((d).Sign == 1) {
        return Std.Arithmetic.DivInternals.__default.DivPos(x, d);
      } else {
        return (new BigInteger(-1)) * (Std.Arithmetic.DivInternals.__default.DivPos(x, (new BigInteger(-1)) * (d)));
      }
    }
  }
} // end of namespace Std.Arithmetic.DivInternals
namespace Std.Arithmetic.DivMod {

  public partial class __default {
    public static bool MultiplesVanish(BigInteger a, BigInteger b, BigInteger m)
    {
      return (Dafny.Helpers.EuclideanModulus(((m) * (a)) + (b), m)) == (Dafny.Helpers.EuclideanModulus(b, m));
    }
  }
} // end of namespace Std.Arithmetic.DivMod
namespace Std.Arithmetic.Power {

  public partial class __default {
    public static BigInteger Pow(BigInteger b, BigInteger e)
    {
      BigInteger _0___accumulator = BigInteger.One;
    TAIL_CALL_START: ;
      if ((e).Sign == 0) {
        return (BigInteger.One) * (_0___accumulator);
      } else {
        _0___accumulator = (_0___accumulator) * (b);
        BigInteger _in0 = b;
        BigInteger _in1 = (e) - (BigInteger.One);
        b = _in0;
        e = _in1;
        goto TAIL_CALL_START;
      }
    }
  }
} // end of namespace Std.Arithmetic.Power
namespace Std.Arithmetic.Logarithm {

  public partial class __default {
    public static BigInteger Log(BigInteger @base, BigInteger pow)
    {
      BigInteger _0___accumulator = BigInteger.Zero;
    TAIL_CALL_START: ;
      if ((pow) < (@base)) {
        return (BigInteger.Zero) + (_0___accumulator);
      } else {
        _0___accumulator = (_0___accumulator) + (BigInteger.One);
        BigInteger _in0 = @base;
        BigInteger _in1 = Dafny.Helpers.EuclideanDivision(pow, @base);
        @base = _in0;
        pow = _in1;
        goto TAIL_CALL_START;
      }
    }
  }
} // end of namespace Std.Arithmetic.Logarithm
namespace Std.Arithmetic.Power2 {

  public partial class __default {
    public static BigInteger Pow2(BigInteger e) {
      return Std.Arithmetic.Power.__default.Pow(new BigInteger(2), e);
    }
  }
} // end of namespace Std.Arithmetic.Power2
namespace Std.Arithmetic {

} // end of namespace Std.Arithmetic
namespace Std.Strings.HexConversion {

  public partial class __default {
    public static BigInteger BASE() {
      return Std.Strings.HexConversion.__default.@base;
    }
    public static bool IsDigitChar(Dafny.Rune c) {
      return (Std.Strings.HexConversion.__default.charToDigit).Contains(c);
    }
    public static Dafny.ISequence<Dafny.Rune> OfDigits(Dafny.ISequence<BigInteger> digits) {
      Dafny.ISequence<Dafny.Rune> _0___accumulator = Dafny.Sequence<Dafny.Rune>.FromElements();
    TAIL_CALL_START: ;
      if ((digits).Equals(Dafny.Sequence<BigInteger>.FromElements())) {
        return Dafny.Sequence<Dafny.Rune>.Concat(Dafny.Sequence<Dafny.Rune>.FromElements(), _0___accumulator);
      } else {
        _0___accumulator = Dafny.Sequence<Dafny.Rune>.Concat(Dafny.Sequence<Dafny.Rune>.FromElements((Std.Strings.HexConversion.__default.chars).Select((digits).Select(BigInteger.Zero))), _0___accumulator);
        Dafny.ISequence<BigInteger> _in0 = (digits).Drop(BigInteger.One);
        digits = _in0;
        goto TAIL_CALL_START;
      }
    }
    public static Dafny.ISequence<Dafny.Rune> OfNat(BigInteger n) {
      if ((n).Sign == 0) {
        return Dafny.Sequence<Dafny.Rune>.FromElements((Std.Strings.HexConversion.__default.chars).Select(BigInteger.Zero));
      } else {
        return Std.Strings.HexConversion.__default.OfDigits(Std.Strings.HexConversion.__default.FromNat(n));
      }
    }
    public static bool IsNumberStr(Dafny.ISequence<Dafny.Rune> str, Dafny.Rune minus)
    {
      return !(!(str).Equals(Dafny.Sequence<Dafny.Rune>.FromElements())) || (((((str).Select(BigInteger.Zero)) == (minus)) || ((Std.Strings.HexConversion.__default.charToDigit).Contains((str).Select(BigInteger.Zero)))) && (Dafny.Helpers.Id<Func<Dafny.ISequence<Dafny.Rune>, bool>>((_0_str) => Dafny.Helpers.Quantifier<Dafny.Rune>(((_0_str).Drop(BigInteger.One)).UniqueElements, true, (((_forall_var_0) => {
        Dafny.Rune _1_c = (Dafny.Rune)_forall_var_0;
        return !(((_0_str).Drop(BigInteger.One)).Contains(_1_c)) || (Std.Strings.HexConversion.__default.IsDigitChar(_1_c));
      }))))(str)));
    }
    public static Dafny.ISequence<Dafny.Rune> OfInt(BigInteger n, Dafny.Rune minus)
    {
      if ((n).Sign != -1) {
        return Std.Strings.HexConversion.__default.OfNat(n);
      } else {
        return Dafny.Sequence<Dafny.Rune>.Concat(Dafny.Sequence<Dafny.Rune>.FromElements(minus), Std.Strings.HexConversion.__default.OfNat((BigInteger.Zero) - (n)));
      }
    }
    public static BigInteger ToNat(Dafny.ISequence<Dafny.Rune> str) {
      if ((str).Equals(Dafny.Sequence<Dafny.Rune>.FromElements())) {
        return BigInteger.Zero;
      } else {
        Dafny.Rune _0_c = (str).Select((new BigInteger((str).Count)) - (BigInteger.One));
        return ((Std.Strings.HexConversion.__default.ToNat((str).Take((new BigInteger((str).Count)) - (BigInteger.One)))) * (Std.Strings.HexConversion.__default.@base)) + (Dafny.Map<Dafny.Rune, BigInteger>.Select(Std.Strings.HexConversion.__default.charToDigit,_0_c));
      }
    }
    public static BigInteger ToInt(Dafny.ISequence<Dafny.Rune> str, Dafny.Rune minus)
    {
      if (Dafny.Sequence<Dafny.Rune>.IsPrefixOf(Dafny.Sequence<Dafny.Rune>.FromElements(minus), str)) {
        return (BigInteger.Zero) - (Std.Strings.HexConversion.__default.ToNat((str).Drop(BigInteger.One)));
      } else {
        return Std.Strings.HexConversion.__default.ToNat(str);
      }
    }
    public static BigInteger ToNatRight(Dafny.ISequence<BigInteger> xs) {
      if ((new BigInteger((xs).Count)).Sign == 0) {
        return BigInteger.Zero;
      } else {
        return ((Std.Strings.HexConversion.__default.ToNatRight(Std.Collections.Seq.__default.DropFirst<BigInteger>(xs))) * (Std.Strings.HexConversion.__default.BASE())) + (Std.Collections.Seq.__default.First<BigInteger>(xs));
      }
    }
    public static BigInteger ToNatLeft(Dafny.ISequence<BigInteger> xs) {
      BigInteger _0___accumulator = BigInteger.Zero;
    TAIL_CALL_START: ;
      if ((new BigInteger((xs).Count)).Sign == 0) {
        return (BigInteger.Zero) + (_0___accumulator);
      } else {
        _0___accumulator = ((Std.Collections.Seq.__default.Last<BigInteger>(xs)) * (Std.Arithmetic.Power.__default.Pow(Std.Strings.HexConversion.__default.BASE(), (new BigInteger((xs).Count)) - (BigInteger.One)))) + (_0___accumulator);
        Dafny.ISequence<BigInteger> _in0 = Std.Collections.Seq.__default.DropLast<BigInteger>(xs);
        xs = _in0;
        goto TAIL_CALL_START;
      }
    }
    public static Dafny.ISequence<BigInteger> FromNat(BigInteger n) {
      Dafny.ISequence<BigInteger> _0___accumulator = Dafny.Sequence<BigInteger>.FromElements();
    TAIL_CALL_START: ;
      if ((n).Sign == 0) {
        return Dafny.Sequence<BigInteger>.Concat(_0___accumulator, Dafny.Sequence<BigInteger>.FromElements());
      } else {
        _0___accumulator = Dafny.Sequence<BigInteger>.Concat(_0___accumulator, Dafny.Sequence<BigInteger>.FromElements(Dafny.Helpers.EuclideanModulus(n, Std.Strings.HexConversion.__default.BASE())));
        BigInteger _in0 = Dafny.Helpers.EuclideanDivision(n, Std.Strings.HexConversion.__default.BASE());
        n = _in0;
        goto TAIL_CALL_START;
      }
    }
    public static Dafny.ISequence<BigInteger> SeqExtend(Dafny.ISequence<BigInteger> xs, BigInteger n)
    {
    TAIL_CALL_START: ;
      if ((new BigInteger((xs).Count)) >= (n)) {
        return xs;
      } else {
        Dafny.ISequence<BigInteger> _in0 = Dafny.Sequence<BigInteger>.Concat(xs, Dafny.Sequence<BigInteger>.FromElements(BigInteger.Zero));
        BigInteger _in1 = n;
        xs = _in0;
        n = _in1;
        goto TAIL_CALL_START;
      }
    }
    public static Dafny.ISequence<BigInteger> SeqExtendMultiple(Dafny.ISequence<BigInteger> xs, BigInteger n)
    {
      BigInteger _0_newLen = ((new BigInteger((xs).Count)) + (n)) - (Dafny.Helpers.EuclideanModulus(new BigInteger((xs).Count), n));
      return Std.Strings.HexConversion.__default.SeqExtend(xs, _0_newLen);
    }
    public static Dafny.ISequence<BigInteger> FromNatWithLen(BigInteger n, BigInteger len)
    {
      return Std.Strings.HexConversion.__default.SeqExtend(Std.Strings.HexConversion.__default.FromNat(n), len);
    }
    public static Dafny.ISequence<BigInteger> SeqZero(BigInteger len) {
      Dafny.ISequence<BigInteger> _0_xs = Std.Strings.HexConversion.__default.FromNatWithLen(BigInteger.Zero, len);
      return _0_xs;
    }
    public static _System._ITuple2<Dafny.ISequence<BigInteger>, BigInteger> SeqAdd(Dafny.ISequence<BigInteger> xs, Dafny.ISequence<BigInteger> ys)
    {
      if ((new BigInteger((xs).Count)).Sign == 0) {
        return _System.Tuple2<Dafny.ISequence<BigInteger>, BigInteger>.create(Dafny.Sequence<BigInteger>.FromElements(), BigInteger.Zero);
      } else {
        _System._ITuple2<Dafny.ISequence<BigInteger>, BigInteger> _let_tmp_rhs0 = Std.Strings.HexConversion.__default.SeqAdd(Std.Collections.Seq.__default.DropLast<BigInteger>(xs), Std.Collections.Seq.__default.DropLast<BigInteger>(ys));
        Dafny.ISequence<BigInteger> _0_zs_k = _let_tmp_rhs0.dtor__0;
        BigInteger _1_cin = _let_tmp_rhs0.dtor__1;
        BigInteger _2_sum = ((Std.Collections.Seq.__default.Last<BigInteger>(xs)) + (Std.Collections.Seq.__default.Last<BigInteger>(ys))) + (_1_cin);
        _System._ITuple2<BigInteger, BigInteger> _let_tmp_rhs1 = (((_2_sum) < (Std.Strings.HexConversion.__default.BASE())) ? (_System.Tuple2<BigInteger, BigInteger>.create(_2_sum, BigInteger.Zero)) : (_System.Tuple2<BigInteger, BigInteger>.create((_2_sum) - (Std.Strings.HexConversion.__default.BASE()), BigInteger.One)));
        BigInteger _3_sum__out = _let_tmp_rhs1.dtor__0;
        BigInteger _4_cout = _let_tmp_rhs1.dtor__1;
        return _System.Tuple2<Dafny.ISequence<BigInteger>, BigInteger>.create(Dafny.Sequence<BigInteger>.Concat(_0_zs_k, Dafny.Sequence<BigInteger>.FromElements(_3_sum__out)), _4_cout);
      }
    }
    public static _System._ITuple2<Dafny.ISequence<BigInteger>, BigInteger> SeqSub(Dafny.ISequence<BigInteger> xs, Dafny.ISequence<BigInteger> ys)
    {
      if ((new BigInteger((xs).Count)).Sign == 0) {
        return _System.Tuple2<Dafny.ISequence<BigInteger>, BigInteger>.create(Dafny.Sequence<BigInteger>.FromElements(), BigInteger.Zero);
      } else {
        _System._ITuple2<Dafny.ISequence<BigInteger>, BigInteger> _let_tmp_rhs0 = Std.Strings.HexConversion.__default.SeqSub(Std.Collections.Seq.__default.DropLast<BigInteger>(xs), Std.Collections.Seq.__default.DropLast<BigInteger>(ys));
        Dafny.ISequence<BigInteger> _0_zs = _let_tmp_rhs0.dtor__0;
        BigInteger _1_cin = _let_tmp_rhs0.dtor__1;
        _System._ITuple2<BigInteger, BigInteger> _let_tmp_rhs1 = (((Std.Collections.Seq.__default.Last<BigInteger>(xs)) >= ((Std.Collections.Seq.__default.Last<BigInteger>(ys)) + (_1_cin))) ? (_System.Tuple2<BigInteger, BigInteger>.create(((Std.Collections.Seq.__default.Last<BigInteger>(xs)) - (Std.Collections.Seq.__default.Last<BigInteger>(ys))) - (_1_cin), BigInteger.Zero)) : (_System.Tuple2<BigInteger, BigInteger>.create((((Std.Strings.HexConversion.__default.BASE()) + (Std.Collections.Seq.__default.Last<BigInteger>(xs))) - (Std.Collections.Seq.__default.Last<BigInteger>(ys))) - (_1_cin), BigInteger.One)));
        BigInteger _2_diff__out = _let_tmp_rhs1.dtor__0;
        BigInteger _3_cout = _let_tmp_rhs1.dtor__1;
        return _System.Tuple2<Dafny.ISequence<BigInteger>, BigInteger>.create(Dafny.Sequence<BigInteger>.Concat(_0_zs, Dafny.Sequence<BigInteger>.FromElements(_2_diff__out)), _3_cout);
      }
    }
    public static Dafny.ISequence<Dafny.Rune> HEX__DIGITS { get {
      return Dafny.Sequence<Dafny.Rune>.UnicodeFromString("0123456789ABCDEF");
    } }
    public static Dafny.ISequence<Dafny.Rune> chars { get {
      return Std.Strings.HexConversion.__default.HEX__DIGITS;
    } }
    public static BigInteger @base { get {
      return new BigInteger((Std.Strings.HexConversion.__default.chars).Count);
    } }
    public static Dafny.IMap<Dafny.Rune,BigInteger> charToDigit { get {
      return Dafny.Map<Dafny.Rune, BigInteger>.FromElements(new Dafny.Pair<Dafny.Rune, BigInteger>(new Dafny.Rune('0'), BigInteger.Zero), new Dafny.Pair<Dafny.Rune, BigInteger>(new Dafny.Rune('1'), BigInteger.One), new Dafny.Pair<Dafny.Rune, BigInteger>(new Dafny.Rune('2'), new BigInteger(2)), new Dafny.Pair<Dafny.Rune, BigInteger>(new Dafny.Rune('3'), new BigInteger(3)), new Dafny.Pair<Dafny.Rune, BigInteger>(new Dafny.Rune('4'), new BigInteger(4)), new Dafny.Pair<Dafny.Rune, BigInteger>(new Dafny.Rune('5'), new BigInteger(5)), new Dafny.Pair<Dafny.Rune, BigInteger>(new Dafny.Rune('6'), new BigInteger(6)), new Dafny.Pair<Dafny.Rune, BigInteger>(new Dafny.Rune('7'), new BigInteger(7)), new Dafny.Pair<Dafny.Rune, BigInteger>(new Dafny.Rune('8'), new BigInteger(8)), new Dafny.Pair<Dafny.Rune, BigInteger>(new Dafny.Rune('9'), new BigInteger(9)), new Dafny.Pair<Dafny.Rune, BigInteger>(new Dafny.Rune('a'), new BigInteger(10)), new Dafny.Pair<Dafny.Rune, BigInteger>(new Dafny.Rune('b'), new BigInteger(11)), new Dafny.Pair<Dafny.Rune, BigInteger>(new Dafny.Rune('c'), new BigInteger(12)), new Dafny.Pair<Dafny.Rune, BigInteger>(new Dafny.Rune('d'), new BigInteger(13)), new Dafny.Pair<Dafny.Rune, BigInteger>(new Dafny.Rune('e'), new BigInteger(14)), new Dafny.Pair<Dafny.Rune, BigInteger>(new Dafny.Rune('f'), new BigInteger(15)), new Dafny.Pair<Dafny.Rune, BigInteger>(new Dafny.Rune('A'), new BigInteger(10)), new Dafny.Pair<Dafny.Rune, BigInteger>(new Dafny.Rune('B'), new BigInteger(11)), new Dafny.Pair<Dafny.Rune, BigInteger>(new Dafny.Rune('C'), new BigInteger(12)), new Dafny.Pair<Dafny.Rune, BigInteger>(new Dafny.Rune('D'), new BigInteger(13)), new Dafny.Pair<Dafny.Rune, BigInteger>(new Dafny.Rune('E'), new BigInteger(14)), new Dafny.Pair<Dafny.Rune, BigInteger>(new Dafny.Rune('F'), new BigInteger(15)));
    } }
  }

  public partial class CharSeq {
    private static readonly Dafny.TypeDescriptor<Dafny.ISequence<Dafny.Rune>> _TYPE = new Dafny.TypeDescriptor<Dafny.ISequence<Dafny.Rune>>(Dafny.Sequence<Dafny.Rune>.Empty);
    public static Dafny.TypeDescriptor<Dafny.ISequence<Dafny.Rune>> _TypeDescriptor() {
      return _TYPE;
    }
    public static bool _Is(Dafny.ISequence<Dafny.Rune> __source) {
      Dafny.ISequence<Dafny.Rune> _0_chars = __source;
      return (new BigInteger((_0_chars).Count)) > (BigInteger.One);
    }
  }

  public partial class digit {
    private static readonly Dafny.TypeDescriptor<BigInteger> _TYPE = new Dafny.TypeDescriptor<BigInteger>(BigInteger.Zero);
    public static Dafny.TypeDescriptor<BigInteger> _TypeDescriptor() {
      return _TYPE;
    }
    public static bool _Is(BigInteger __source) {
      BigInteger _1_i = __source;
      if (_System.nat._Is(_1_i)) {
        return ((_1_i).Sign != -1) && ((_1_i) < (Std.Strings.HexConversion.__default.BASE()));
      }
      return false;
    }
  }
} // end of namespace Std.Strings.HexConversion
namespace Std.Strings.DecimalConversion {

  public partial class __default {
    public static BigInteger BASE() {
      return Std.Strings.DecimalConversion.__default.@base;
    }
    public static bool IsDigitChar(Dafny.Rune c) {
      return (Std.Strings.DecimalConversion.__default.charToDigit).Contains(c);
    }
    public static Dafny.ISequence<Dafny.Rune> OfDigits(Dafny.ISequence<BigInteger> digits) {
      Dafny.ISequence<Dafny.Rune> _0___accumulator = Dafny.Sequence<Dafny.Rune>.FromElements();
    TAIL_CALL_START: ;
      if ((digits).Equals(Dafny.Sequence<BigInteger>.FromElements())) {
        return Dafny.Sequence<Dafny.Rune>.Concat(Dafny.Sequence<Dafny.Rune>.FromElements(), _0___accumulator);
      } else {
        _0___accumulator = Dafny.Sequence<Dafny.Rune>.Concat(Dafny.Sequence<Dafny.Rune>.FromElements((Std.Strings.DecimalConversion.__default.chars).Select((digits).Select(BigInteger.Zero))), _0___accumulator);
        Dafny.ISequence<BigInteger> _in0 = (digits).Drop(BigInteger.One);
        digits = _in0;
        goto TAIL_CALL_START;
      }
    }
    public static Dafny.ISequence<Dafny.Rune> OfNat(BigInteger n) {
      if ((n).Sign == 0) {
        return Dafny.Sequence<Dafny.Rune>.FromElements((Std.Strings.DecimalConversion.__default.chars).Select(BigInteger.Zero));
      } else {
        return Std.Strings.DecimalConversion.__default.OfDigits(Std.Strings.DecimalConversion.__default.FromNat(n));
      }
    }
    public static bool IsNumberStr(Dafny.ISequence<Dafny.Rune> str, Dafny.Rune minus)
    {
      return !(!(str).Equals(Dafny.Sequence<Dafny.Rune>.FromElements())) || (((((str).Select(BigInteger.Zero)) == (minus)) || ((Std.Strings.DecimalConversion.__default.charToDigit).Contains((str).Select(BigInteger.Zero)))) && (Dafny.Helpers.Id<Func<Dafny.ISequence<Dafny.Rune>, bool>>((_0_str) => Dafny.Helpers.Quantifier<Dafny.Rune>(((_0_str).Drop(BigInteger.One)).UniqueElements, true, (((_forall_var_0) => {
        Dafny.Rune _1_c = (Dafny.Rune)_forall_var_0;
        return !(((_0_str).Drop(BigInteger.One)).Contains(_1_c)) || (Std.Strings.DecimalConversion.__default.IsDigitChar(_1_c));
      }))))(str)));
    }
    public static Dafny.ISequence<Dafny.Rune> OfInt(BigInteger n, Dafny.Rune minus)
    {
      if ((n).Sign != -1) {
        return Std.Strings.DecimalConversion.__default.OfNat(n);
      } else {
        return Dafny.Sequence<Dafny.Rune>.Concat(Dafny.Sequence<Dafny.Rune>.FromElements(minus), Std.Strings.DecimalConversion.__default.OfNat((BigInteger.Zero) - (n)));
      }
    }
    public static BigInteger ToNat(Dafny.ISequence<Dafny.Rune> str) {
      if ((str).Equals(Dafny.Sequence<Dafny.Rune>.FromElements())) {
        return BigInteger.Zero;
      } else {
        Dafny.Rune _0_c = (str).Select((new BigInteger((str).Count)) - (BigInteger.One));
        return ((Std.Strings.DecimalConversion.__default.ToNat((str).Take((new BigInteger((str).Count)) - (BigInteger.One)))) * (Std.Strings.DecimalConversion.__default.@base)) + (Dafny.Map<Dafny.Rune, BigInteger>.Select(Std.Strings.DecimalConversion.__default.charToDigit,_0_c));
      }
    }
    public static BigInteger ToInt(Dafny.ISequence<Dafny.Rune> str, Dafny.Rune minus)
    {
      if (Dafny.Sequence<Dafny.Rune>.IsPrefixOf(Dafny.Sequence<Dafny.Rune>.FromElements(minus), str)) {
        return (BigInteger.Zero) - (Std.Strings.DecimalConversion.__default.ToNat((str).Drop(BigInteger.One)));
      } else {
        return Std.Strings.DecimalConversion.__default.ToNat(str);
      }
    }
    public static BigInteger ToNatRight(Dafny.ISequence<BigInteger> xs) {
      if ((new BigInteger((xs).Count)).Sign == 0) {
        return BigInteger.Zero;
      } else {
        return ((Std.Strings.DecimalConversion.__default.ToNatRight(Std.Collections.Seq.__default.DropFirst<BigInteger>(xs))) * (Std.Strings.DecimalConversion.__default.BASE())) + (Std.Collections.Seq.__default.First<BigInteger>(xs));
      }
    }
    public static BigInteger ToNatLeft(Dafny.ISequence<BigInteger> xs) {
      BigInteger _0___accumulator = BigInteger.Zero;
    TAIL_CALL_START: ;
      if ((new BigInteger((xs).Count)).Sign == 0) {
        return (BigInteger.Zero) + (_0___accumulator);
      } else {
        _0___accumulator = ((Std.Collections.Seq.__default.Last<BigInteger>(xs)) * (Std.Arithmetic.Power.__default.Pow(Std.Strings.DecimalConversion.__default.BASE(), (new BigInteger((xs).Count)) - (BigInteger.One)))) + (_0___accumulator);
        Dafny.ISequence<BigInteger> _in0 = Std.Collections.Seq.__default.DropLast<BigInteger>(xs);
        xs = _in0;
        goto TAIL_CALL_START;
      }
    }
    public static Dafny.ISequence<BigInteger> FromNat(BigInteger n) {
      Dafny.ISequence<BigInteger> _0___accumulator = Dafny.Sequence<BigInteger>.FromElements();
    TAIL_CALL_START: ;
      if ((n).Sign == 0) {
        return Dafny.Sequence<BigInteger>.Concat(_0___accumulator, Dafny.Sequence<BigInteger>.FromElements());
      } else {
        _0___accumulator = Dafny.Sequence<BigInteger>.Concat(_0___accumulator, Dafny.Sequence<BigInteger>.FromElements(Dafny.Helpers.EuclideanModulus(n, Std.Strings.DecimalConversion.__default.BASE())));
        BigInteger _in0 = Dafny.Helpers.EuclideanDivision(n, Std.Strings.DecimalConversion.__default.BASE());
        n = _in0;
        goto TAIL_CALL_START;
      }
    }
    public static Dafny.ISequence<BigInteger> SeqExtend(Dafny.ISequence<BigInteger> xs, BigInteger n)
    {
    TAIL_CALL_START: ;
      if ((new BigInteger((xs).Count)) >= (n)) {
        return xs;
      } else {
        Dafny.ISequence<BigInteger> _in0 = Dafny.Sequence<BigInteger>.Concat(xs, Dafny.Sequence<BigInteger>.FromElements(BigInteger.Zero));
        BigInteger _in1 = n;
        xs = _in0;
        n = _in1;
        goto TAIL_CALL_START;
      }
    }
    public static Dafny.ISequence<BigInteger> SeqExtendMultiple(Dafny.ISequence<BigInteger> xs, BigInteger n)
    {
      BigInteger _0_newLen = ((new BigInteger((xs).Count)) + (n)) - (Dafny.Helpers.EuclideanModulus(new BigInteger((xs).Count), n));
      return Std.Strings.DecimalConversion.__default.SeqExtend(xs, _0_newLen);
    }
    public static Dafny.ISequence<BigInteger> FromNatWithLen(BigInteger n, BigInteger len)
    {
      return Std.Strings.DecimalConversion.__default.SeqExtend(Std.Strings.DecimalConversion.__default.FromNat(n), len);
    }
    public static Dafny.ISequence<BigInteger> SeqZero(BigInteger len) {
      Dafny.ISequence<BigInteger> _0_xs = Std.Strings.DecimalConversion.__default.FromNatWithLen(BigInteger.Zero, len);
      return _0_xs;
    }
    public static _System._ITuple2<Dafny.ISequence<BigInteger>, BigInteger> SeqAdd(Dafny.ISequence<BigInteger> xs, Dafny.ISequence<BigInteger> ys)
    {
      if ((new BigInteger((xs).Count)).Sign == 0) {
        return _System.Tuple2<Dafny.ISequence<BigInteger>, BigInteger>.create(Dafny.Sequence<BigInteger>.FromElements(), BigInteger.Zero);
      } else {
        _System._ITuple2<Dafny.ISequence<BigInteger>, BigInteger> _let_tmp_rhs0 = Std.Strings.DecimalConversion.__default.SeqAdd(Std.Collections.Seq.__default.DropLast<BigInteger>(xs), Std.Collections.Seq.__default.DropLast<BigInteger>(ys));
        Dafny.ISequence<BigInteger> _0_zs_k = _let_tmp_rhs0.dtor__0;
        BigInteger _1_cin = _let_tmp_rhs0.dtor__1;
        BigInteger _2_sum = ((Std.Collections.Seq.__default.Last<BigInteger>(xs)) + (Std.Collections.Seq.__default.Last<BigInteger>(ys))) + (_1_cin);
        _System._ITuple2<BigInteger, BigInteger> _let_tmp_rhs1 = (((_2_sum) < (Std.Strings.DecimalConversion.__default.BASE())) ? (_System.Tuple2<BigInteger, BigInteger>.create(_2_sum, BigInteger.Zero)) : (_System.Tuple2<BigInteger, BigInteger>.create((_2_sum) - (Std.Strings.DecimalConversion.__default.BASE()), BigInteger.One)));
        BigInteger _3_sum__out = _let_tmp_rhs1.dtor__0;
        BigInteger _4_cout = _let_tmp_rhs1.dtor__1;
        return _System.Tuple2<Dafny.ISequence<BigInteger>, BigInteger>.create(Dafny.Sequence<BigInteger>.Concat(_0_zs_k, Dafny.Sequence<BigInteger>.FromElements(_3_sum__out)), _4_cout);
      }
    }
    public static _System._ITuple2<Dafny.ISequence<BigInteger>, BigInteger> SeqSub(Dafny.ISequence<BigInteger> xs, Dafny.ISequence<BigInteger> ys)
    {
      if ((new BigInteger((xs).Count)).Sign == 0) {
        return _System.Tuple2<Dafny.ISequence<BigInteger>, BigInteger>.create(Dafny.Sequence<BigInteger>.FromElements(), BigInteger.Zero);
      } else {
        _System._ITuple2<Dafny.ISequence<BigInteger>, BigInteger> _let_tmp_rhs0 = Std.Strings.DecimalConversion.__default.SeqSub(Std.Collections.Seq.__default.DropLast<BigInteger>(xs), Std.Collections.Seq.__default.DropLast<BigInteger>(ys));
        Dafny.ISequence<BigInteger> _0_zs = _let_tmp_rhs0.dtor__0;
        BigInteger _1_cin = _let_tmp_rhs0.dtor__1;
        _System._ITuple2<BigInteger, BigInteger> _let_tmp_rhs1 = (((Std.Collections.Seq.__default.Last<BigInteger>(xs)) >= ((Std.Collections.Seq.__default.Last<BigInteger>(ys)) + (_1_cin))) ? (_System.Tuple2<BigInteger, BigInteger>.create(((Std.Collections.Seq.__default.Last<BigInteger>(xs)) - (Std.Collections.Seq.__default.Last<BigInteger>(ys))) - (_1_cin), BigInteger.Zero)) : (_System.Tuple2<BigInteger, BigInteger>.create((((Std.Strings.DecimalConversion.__default.BASE()) + (Std.Collections.Seq.__default.Last<BigInteger>(xs))) - (Std.Collections.Seq.__default.Last<BigInteger>(ys))) - (_1_cin), BigInteger.One)));
        BigInteger _2_diff__out = _let_tmp_rhs1.dtor__0;
        BigInteger _3_cout = _let_tmp_rhs1.dtor__1;
        return _System.Tuple2<Dafny.ISequence<BigInteger>, BigInteger>.create(Dafny.Sequence<BigInteger>.Concat(_0_zs, Dafny.Sequence<BigInteger>.FromElements(_2_diff__out)), _3_cout);
      }
    }
    public static Dafny.ISequence<Dafny.Rune> DIGITS { get {
      return Dafny.Sequence<Dafny.Rune>.UnicodeFromString("0123456789");
    } }
    public static Dafny.ISequence<Dafny.Rune> chars { get {
      return Std.Strings.DecimalConversion.__default.DIGITS;
    } }
    public static BigInteger @base { get {
      return new BigInteger((Std.Strings.DecimalConversion.__default.chars).Count);
    } }
    public static Dafny.IMap<Dafny.Rune,BigInteger> charToDigit { get {
      return Dafny.Map<Dafny.Rune, BigInteger>.FromElements(new Dafny.Pair<Dafny.Rune, BigInteger>(new Dafny.Rune('0'), BigInteger.Zero), new Dafny.Pair<Dafny.Rune, BigInteger>(new Dafny.Rune('1'), BigInteger.One), new Dafny.Pair<Dafny.Rune, BigInteger>(new Dafny.Rune('2'), new BigInteger(2)), new Dafny.Pair<Dafny.Rune, BigInteger>(new Dafny.Rune('3'), new BigInteger(3)), new Dafny.Pair<Dafny.Rune, BigInteger>(new Dafny.Rune('4'), new BigInteger(4)), new Dafny.Pair<Dafny.Rune, BigInteger>(new Dafny.Rune('5'), new BigInteger(5)), new Dafny.Pair<Dafny.Rune, BigInteger>(new Dafny.Rune('6'), new BigInteger(6)), new Dafny.Pair<Dafny.Rune, BigInteger>(new Dafny.Rune('7'), new BigInteger(7)), new Dafny.Pair<Dafny.Rune, BigInteger>(new Dafny.Rune('8'), new BigInteger(8)), new Dafny.Pair<Dafny.Rune, BigInteger>(new Dafny.Rune('9'), new BigInteger(9)));
    } }
  }

  public partial class CharSeq {
    private static readonly Dafny.TypeDescriptor<Dafny.ISequence<Dafny.Rune>> _TYPE = new Dafny.TypeDescriptor<Dafny.ISequence<Dafny.Rune>>(Dafny.Sequence<Dafny.Rune>.Empty);
    public static Dafny.TypeDescriptor<Dafny.ISequence<Dafny.Rune>> _TypeDescriptor() {
      return _TYPE;
    }
    public static bool _Is(Dafny.ISequence<Dafny.Rune> __source) {
      Dafny.ISequence<Dafny.Rune> _0_chars = __source;
      return (new BigInteger((_0_chars).Count)) > (BigInteger.One);
    }
  }

  public partial class digit {
    private static readonly Dafny.TypeDescriptor<BigInteger> _TYPE = new Dafny.TypeDescriptor<BigInteger>(BigInteger.Zero);
    public static Dafny.TypeDescriptor<BigInteger> _TypeDescriptor() {
      return _TYPE;
    }
    public static bool _Is(BigInteger __source) {
      BigInteger _1_i = __source;
      if (_System.nat._Is(_1_i)) {
        return ((_1_i).Sign != -1) && ((_1_i) < (Std.Strings.DecimalConversion.__default.BASE()));
      }
      return false;
    }
  }
} // end of namespace Std.Strings.DecimalConversion
namespace Std.Strings.CharStrEscaping {

  public partial class __default {
    public static Dafny.ISequence<Dafny.Rune> Escape(Dafny.ISequence<Dafny.Rune> str, Dafny.ISet<Dafny.Rune> mustEscape, Dafny.Rune escape)
    {
      Dafny.ISequence<Dafny.Rune> _0___accumulator = Dafny.Sequence<Dafny.Rune>.FromElements();
    TAIL_CALL_START: ;
      if ((str).Equals(Dafny.Sequence<Dafny.Rune>.FromElements())) {
        return Dafny.Sequence<Dafny.Rune>.Concat(_0___accumulator, str);
      } else if ((mustEscape).Contains((str).Select(BigInteger.Zero))) {
        _0___accumulator = Dafny.Sequence<Dafny.Rune>.Concat(_0___accumulator, Dafny.Sequence<Dafny.Rune>.FromElements(escape, (str).Select(BigInteger.Zero)));
        Dafny.ISequence<Dafny.Rune> _in0 = (str).Drop(BigInteger.One);
        Dafny.ISet<Dafny.Rune> _in1 = mustEscape;
        Dafny.Rune _in2 = escape;
        str = _in0;
        mustEscape = _in1;
        escape = _in2;
        goto TAIL_CALL_START;
      } else {
        _0___accumulator = Dafny.Sequence<Dafny.Rune>.Concat(_0___accumulator, Dafny.Sequence<Dafny.Rune>.FromElements((str).Select(BigInteger.Zero)));
        Dafny.ISequence<Dafny.Rune> _in3 = (str).Drop(BigInteger.One);
        Dafny.ISet<Dafny.Rune> _in4 = mustEscape;
        Dafny.Rune _in5 = escape;
        str = _in3;
        mustEscape = _in4;
        escape = _in5;
        goto TAIL_CALL_START;
      }
    }
    public static Std.Wrappers._IOption<Dafny.ISequence<Dafny.Rune>> Unescape(Dafny.ISequence<Dafny.Rune> str, Dafny.Rune escape)
    {
      if ((str).Equals(Dafny.Sequence<Dafny.Rune>.FromElements())) {
        return Std.Wrappers.Option<Dafny.ISequence<Dafny.Rune>>.create_Some(str);
      } else if (((str).Select(BigInteger.Zero)) == (escape)) {
        if ((new BigInteger((str).Count)) > (BigInteger.One)) {
          Std.Wrappers._IOption<Dafny.ISequence<Dafny.Rune>> _0_valueOrError0 = Std.Strings.CharStrEscaping.__default.Unescape((str).Drop(new BigInteger(2)), escape);
          if ((_0_valueOrError0).IsFailure()) {
            return (_0_valueOrError0).PropagateFailure<Dafny.ISequence<Dafny.Rune>>();
          } else {
            Dafny.ISequence<Dafny.Rune> _1_tl = (_0_valueOrError0).Extract();
            return Std.Wrappers.Option<Dafny.ISequence<Dafny.Rune>>.create_Some(Dafny.Sequence<Dafny.Rune>.Concat(Dafny.Sequence<Dafny.Rune>.FromElements((str).Select(BigInteger.One)), _1_tl));
          }
        } else {
          return Std.Wrappers.Option<Dafny.ISequence<Dafny.Rune>>.create_None();
        }
      } else {
        Std.Wrappers._IOption<Dafny.ISequence<Dafny.Rune>> _2_valueOrError1 = Std.Strings.CharStrEscaping.__default.Unescape((str).Drop(BigInteger.One), escape);
        if ((_2_valueOrError1).IsFailure()) {
          return (_2_valueOrError1).PropagateFailure<Dafny.ISequence<Dafny.Rune>>();
        } else {
          Dafny.ISequence<Dafny.Rune> _3_tl = (_2_valueOrError1).Extract();
          return Std.Wrappers.Option<Dafny.ISequence<Dafny.Rune>>.create_Some(Dafny.Sequence<Dafny.Rune>.Concat(Dafny.Sequence<Dafny.Rune>.FromElements((str).Select(BigInteger.Zero)), _3_tl));
        }
      }
    }
  }
} // end of namespace Std.Strings.CharStrEscaping
namespace Std.Strings {

  public partial class __default {
    public static Dafny.ISequence<Dafny.Rune> OfNat(BigInteger n) {
      return Std.Strings.DecimalConversion.__default.OfNat(n);
    }
    public static Dafny.ISequence<Dafny.Rune> OfInt(BigInteger n) {
      return Std.Strings.DecimalConversion.__default.OfInt(n, new Dafny.Rune('-'));
    }
    public static BigInteger ToNat(Dafny.ISequence<Dafny.Rune> str) {
      return Std.Strings.DecimalConversion.__default.ToNat(str);
    }
    public static BigInteger ToInt(Dafny.ISequence<Dafny.Rune> str) {
      return Std.Strings.DecimalConversion.__default.ToInt(str, new Dafny.Rune('-'));
    }
    public static Dafny.ISequence<Dafny.Rune> EscapeQuotes(Dafny.ISequence<Dafny.Rune> str) {
      return Std.Strings.CharStrEscaping.__default.Escape(str, Dafny.Set<Dafny.Rune>.FromElements(new Dafny.Rune('\"'), new Dafny.Rune('\'')), new Dafny.Rune('\\'));
    }
    public static Std.Wrappers._IOption<Dafny.ISequence<Dafny.Rune>> UnescapeQuotes(Dafny.ISequence<Dafny.Rune> str) {
      return Std.Strings.CharStrEscaping.__default.Unescape(str, new Dafny.Rune('\\'));
    }
    public static Dafny.ISequence<Dafny.Rune> OfBool(bool b) {
      if (b) {
        return Dafny.Sequence<Dafny.Rune>.UnicodeFromString("true");
      } else {
        return Dafny.Sequence<Dafny.Rune>.UnicodeFromString("false");
      }
    }
    public static Dafny.ISequence<Dafny.Rune> OfChar(Dafny.Rune c) {
      return Dafny.Sequence<Dafny.Rune>.FromElements(c);
    }
  }
} // end of namespace Std.Strings
namespace Std.Unicode.Base {

  public partial class __default {
    public static bool IsInAssignedPlane(uint i) {
      byte _0_plane = (byte)((i) >> ((int)((byte)(16))));
      return (Std.Unicode.Base.__default.ASSIGNED__PLANES).Contains(_0_plane);
    }
    public static uint HIGH__SURROGATE__MIN { get {
      return 55296U;
    } }
    public static uint HIGH__SURROGATE__MAX { get {
      return 56319U;
    } }
    public static uint LOW__SURROGATE__MIN { get {
      return 56320U;
    } }
    public static uint LOW__SURROGATE__MAX { get {
      return 57343U;
    } }
    public static Dafny.ISet<byte> ASSIGNED__PLANES { get {
      return Dafny.Set<byte>.FromElements((byte)(0), (byte)(1), (byte)(2), (byte)(3), (byte)(14), (byte)(15), (byte)(16));
    } }
  }

  public partial class CodePoint {
    private static readonly Dafny.TypeDescriptor<uint> _TYPE = new Dafny.TypeDescriptor<uint>(0);
    public static Dafny.TypeDescriptor<uint> _TypeDescriptor() {
      return _TYPE;
    }
    public static bool _Is(uint __source) {
      uint _0_i = (uint)(__source);
      return ((0U) <= (_0_i)) && ((_0_i) <= (1114111U));
    }
  }

  public partial class HighSurrogateCodePoint {
    private static readonly uint Witness = Std.Unicode.Base.__default.HIGH__SURROGATE__MIN;
    public static uint Default() {
      return Witness;
    }
    private static readonly Dafny.TypeDescriptor<uint> _TYPE = new Dafny.TypeDescriptor<uint>(Std.Unicode.Base.HighSurrogateCodePoint.Default());
    public static Dafny.TypeDescriptor<uint> _TypeDescriptor() {
      return _TYPE;
    }
    public static bool _Is(uint __source) {
      uint _1_p = (uint)(__source);
      if (Std.Unicode.Base.CodePoint._Is(_1_p)) {
        return ((Std.Unicode.Base.__default.HIGH__SURROGATE__MIN) <= (_1_p)) && ((_1_p) <= (Std.Unicode.Base.__default.HIGH__SURROGATE__MAX));
      }
      return false;
    }
  }

  public partial class LowSurrogateCodePoint {
    private static readonly uint Witness = Std.Unicode.Base.__default.LOW__SURROGATE__MIN;
    public static uint Default() {
      return Witness;
    }
    private static readonly Dafny.TypeDescriptor<uint> _TYPE = new Dafny.TypeDescriptor<uint>(Std.Unicode.Base.LowSurrogateCodePoint.Default());
    public static Dafny.TypeDescriptor<uint> _TypeDescriptor() {
      return _TYPE;
    }
    public static bool _Is(uint __source) {
      uint _2_p = (uint)(__source);
      if (Std.Unicode.Base.CodePoint._Is(_2_p)) {
        return ((Std.Unicode.Base.__default.LOW__SURROGATE__MIN) <= (_2_p)) && ((_2_p) <= (Std.Unicode.Base.__default.LOW__SURROGATE__MAX));
      }
      return false;
    }
  }

  public partial class ScalarValue {
    private static readonly Dafny.TypeDescriptor<uint> _TYPE = new Dafny.TypeDescriptor<uint>(0);
    public static Dafny.TypeDescriptor<uint> _TypeDescriptor() {
      return _TYPE;
    }
    public static bool _Is(uint __source) {
      uint _3_p = (uint)(__source);
      if (Std.Unicode.Base.CodePoint._Is(_3_p)) {
        return (((_3_p) < (Std.Unicode.Base.__default.HIGH__SURROGATE__MIN)) || ((_3_p) > (Std.Unicode.Base.__default.HIGH__SURROGATE__MAX))) && (((_3_p) < (Std.Unicode.Base.__default.LOW__SURROGATE__MIN)) || ((_3_p) > (Std.Unicode.Base.__default.LOW__SURROGATE__MAX)));
      }
      return false;
    }
  }

  public partial class AssignedCodePoint {
    private static readonly Dafny.TypeDescriptor<uint> _TYPE = new Dafny.TypeDescriptor<uint>(0);
    public static Dafny.TypeDescriptor<uint> _TypeDescriptor() {
      return _TYPE;
    }
    public static bool _Is(uint __source) {
      uint _4_p = (uint)(__source);
      if (Std.Unicode.Base.CodePoint._Is(_4_p)) {
        return Std.Unicode.Base.__default.IsInAssignedPlane(_4_p);
      }
      return false;
    }
  }
} // end of namespace Std.Unicode.Base
namespace Std.Unicode.Utf8EncodingForm {

  public partial class __default {
    public static bool IsMinimalWellFormedCodeUnitSubsequence(Dafny.ISequence<byte> s) {
      if ((new BigInteger((s).Count)) == (BigInteger.One)) {
        bool _0_b = Std.Unicode.Utf8EncodingForm.__default.IsWellFormedSingleCodeUnitSequence(s);
        return _0_b;
      } else if ((new BigInteger((s).Count)) == (new BigInteger(2))) {
        bool _1_b = Std.Unicode.Utf8EncodingForm.__default.IsWellFormedDoubleCodeUnitSequence(s);
        return _1_b;
      } else if ((new BigInteger((s).Count)) == (new BigInteger(3))) {
        bool _2_b = Std.Unicode.Utf8EncodingForm.__default.IsWellFormedTripleCodeUnitSequence(s);
        return _2_b;
      } else if ((new BigInteger((s).Count)) == (new BigInteger(4))) {
        bool _3_b = Std.Unicode.Utf8EncodingForm.__default.IsWellFormedQuadrupleCodeUnitSequence(s);
        return _3_b;
      } else {
        return false;
      }
    }
    public static bool IsWellFormedSingleCodeUnitSequence(Dafny.ISequence<byte> s) {
      byte _0_firstByte = (s).Select(BigInteger.Zero);
      return (true) && ((((byte)(0)) <= (_0_firstByte)) && ((_0_firstByte) <= ((byte)(127))));
    }
    public static bool IsWellFormedDoubleCodeUnitSequence(Dafny.ISequence<byte> s) {
      byte _0_firstByte = (s).Select(BigInteger.Zero);
      byte _1_secondByte = (s).Select(BigInteger.One);
      return ((((byte)(194)) <= (_0_firstByte)) && ((_0_firstByte) <= ((byte)(223)))) && ((((byte)(128)) <= (_1_secondByte)) && ((_1_secondByte) <= ((byte)(191))));
    }
    public static bool IsWellFormedTripleCodeUnitSequence(Dafny.ISequence<byte> s) {
      byte _0_firstByte = (s).Select(BigInteger.Zero);
      byte _1_secondByte = (s).Select(BigInteger.One);
      byte _2_thirdByte = (s).Select(new BigInteger(2));
      return ((((((_0_firstByte) == ((byte)(224))) && ((((byte)(160)) <= (_1_secondByte)) && ((_1_secondByte) <= ((byte)(191))))) || (((((byte)(225)) <= (_0_firstByte)) && ((_0_firstByte) <= ((byte)(236)))) && ((((byte)(128)) <= (_1_secondByte)) && ((_1_secondByte) <= ((byte)(191)))))) || (((_0_firstByte) == ((byte)(237))) && ((((byte)(128)) <= (_1_secondByte)) && ((_1_secondByte) <= ((byte)(159)))))) || (((((byte)(238)) <= (_0_firstByte)) && ((_0_firstByte) <= ((byte)(239)))) && ((((byte)(128)) <= (_1_secondByte)) && ((_1_secondByte) <= ((byte)(191)))))) && ((((byte)(128)) <= (_2_thirdByte)) && ((_2_thirdByte) <= ((byte)(191))));
    }
    public static bool IsWellFormedQuadrupleCodeUnitSequence(Dafny.ISequence<byte> s) {
      byte _0_firstByte = (s).Select(BigInteger.Zero);
      byte _1_secondByte = (s).Select(BigInteger.One);
      byte _2_thirdByte = (s).Select(new BigInteger(2));
      byte _3_fourthByte = (s).Select(new BigInteger(3));
      return ((((((_0_firstByte) == ((byte)(240))) && ((((byte)(144)) <= (_1_secondByte)) && ((_1_secondByte) <= ((byte)(191))))) || (((((byte)(241)) <= (_0_firstByte)) && ((_0_firstByte) <= ((byte)(243)))) && ((((byte)(128)) <= (_1_secondByte)) && ((_1_secondByte) <= ((byte)(191)))))) || (((_0_firstByte) == ((byte)(244))) && ((((byte)(128)) <= (_1_secondByte)) && ((_1_secondByte) <= ((byte)(143)))))) && ((((byte)(128)) <= (_2_thirdByte)) && ((_2_thirdByte) <= ((byte)(191))))) && ((((byte)(128)) <= (_3_fourthByte)) && ((_3_fourthByte) <= ((byte)(191))));
    }
    public static Std.Wrappers._IOption<Dafny.ISequence<byte>> SplitPrefixMinimalWellFormedCodeUnitSubsequence(Dafny.ISequence<byte> s) {
      if (((new BigInteger((s).Count)) >= (BigInteger.One)) && (Std.Unicode.Utf8EncodingForm.__default.IsWellFormedSingleCodeUnitSequence((s).Take(BigInteger.One)))) {
        return Std.Wrappers.Option<Dafny.ISequence<byte>>.create_Some((s).Take(BigInteger.One));
      } else if (((new BigInteger((s).Count)) >= (new BigInteger(2))) && (Std.Unicode.Utf8EncodingForm.__default.IsWellFormedDoubleCodeUnitSequence((s).Take(new BigInteger(2))))) {
        return Std.Wrappers.Option<Dafny.ISequence<byte>>.create_Some((s).Take(new BigInteger(2)));
      } else if (((new BigInteger((s).Count)) >= (new BigInteger(3))) && (Std.Unicode.Utf8EncodingForm.__default.IsWellFormedTripleCodeUnitSequence((s).Take(new BigInteger(3))))) {
        return Std.Wrappers.Option<Dafny.ISequence<byte>>.create_Some((s).Take(new BigInteger(3)));
      } else if (((new BigInteger((s).Count)) >= (new BigInteger(4))) && (Std.Unicode.Utf8EncodingForm.__default.IsWellFormedQuadrupleCodeUnitSequence((s).Take(new BigInteger(4))))) {
        return Std.Wrappers.Option<Dafny.ISequence<byte>>.create_Some((s).Take(new BigInteger(4)));
      } else {
        return Std.Wrappers.Option<Dafny.ISequence<byte>>.create_None();
      }
    }
    public static Dafny.ISequence<byte> EncodeScalarValue(uint v) {
      if ((v) <= (127U)) {
        return Std.Unicode.Utf8EncodingForm.__default.EncodeScalarValueSingleByte(v);
      } else if ((v) <= (2047U)) {
        return Std.Unicode.Utf8EncodingForm.__default.EncodeScalarValueDoubleByte(v);
      } else if ((v) <= (65535U)) {
        return Std.Unicode.Utf8EncodingForm.__default.EncodeScalarValueTripleByte(v);
      } else {
        return Std.Unicode.Utf8EncodingForm.__default.EncodeScalarValueQuadrupleByte(v);
      }
    }
    public static Dafny.ISequence<byte> EncodeScalarValueSingleByte(uint v) {
      byte _0_x = (byte)((v) & (127U));
      byte _1_firstByte = (byte)(_0_x);
      return Dafny.Sequence<byte>.FromElements(_1_firstByte);
    }
    public static Dafny.ISequence<byte> EncodeScalarValueDoubleByte(uint v) {
      byte _0_x = (byte)((v) & (63U));
      byte _1_y = (byte)(((v) & (1984U)) >> ((int)((byte)(6))));
      byte _2_firstByte = (byte)(((byte)(192)) | ((byte)(_1_y)));
      byte _3_secondByte = (byte)(((byte)(128)) | ((byte)(_0_x)));
      return Dafny.Sequence<byte>.FromElements(_2_firstByte, _3_secondByte);
    }
    public static Dafny.ISequence<byte> EncodeScalarValueTripleByte(uint v) {
      byte _0_x = (byte)((v) & (63U));
      byte _1_y = (byte)(((v) & (4032U)) >> ((int)((byte)(6))));
      byte _2_z = (byte)(((v) & (61440U)) >> ((int)((byte)(12))));
      byte _3_firstByte = (byte)(((byte)(224)) | ((byte)(_2_z)));
      byte _4_secondByte = (byte)(((byte)(128)) | ((byte)(_1_y)));
      byte _5_thirdByte = (byte)(((byte)(128)) | ((byte)(_0_x)));
      return Dafny.Sequence<byte>.FromElements(_3_firstByte, _4_secondByte, _5_thirdByte);
    }
    public static Dafny.ISequence<byte> EncodeScalarValueQuadrupleByte(uint v) {
      byte _0_x = (byte)((v) & (63U));
      byte _1_y = (byte)(((v) & (4032U)) >> ((int)((byte)(6))));
      byte _2_z = (byte)(((v) & (61440U)) >> ((int)((byte)(12))));
      byte _3_u2 = (byte)(((v) & (196608U)) >> ((int)((byte)(16))));
      byte _4_u1 = (byte)(((v) & (1835008U)) >> ((int)((byte)(18))));
      byte _5_firstByte = (byte)(((byte)(240)) | ((byte)(_4_u1)));
      byte _6_secondByte = (byte)(((byte)(((byte)(128)) | (unchecked((byte)(((byte)(((byte)(_3_u2)) << ((int)((byte)(4)))))))))) | ((byte)(_2_z)));
      byte _7_thirdByte = (byte)(((byte)(128)) | ((byte)(_1_y)));
      byte _8_fourthByte = (byte)(((byte)(128)) | ((byte)(_0_x)));
      return Dafny.Sequence<byte>.FromElements(_5_firstByte, _6_secondByte, _7_thirdByte, _8_fourthByte);
    }
    public static uint DecodeMinimalWellFormedCodeUnitSubsequence(Dafny.ISequence<byte> m) {
      if ((new BigInteger((m).Count)) == (BigInteger.One)) {
        return Std.Unicode.Utf8EncodingForm.__default.DecodeMinimalWellFormedCodeUnitSubsequenceSingleByte(m);
      } else if ((new BigInteger((m).Count)) == (new BigInteger(2))) {
        return Std.Unicode.Utf8EncodingForm.__default.DecodeMinimalWellFormedCodeUnitSubsequenceDoubleByte(m);
      } else if ((new BigInteger((m).Count)) == (new BigInteger(3))) {
        return Std.Unicode.Utf8EncodingForm.__default.DecodeMinimalWellFormedCodeUnitSubsequenceTripleByte(m);
      } else {
        return Std.Unicode.Utf8EncodingForm.__default.DecodeMinimalWellFormedCodeUnitSubsequenceQuadrupleByte(m);
      }
    }
    public static uint DecodeMinimalWellFormedCodeUnitSubsequenceSingleByte(Dafny.ISequence<byte> m) {
      byte _0_firstByte = (m).Select(BigInteger.Zero);
      byte _1_x = (byte)(_0_firstByte);
      return (uint)(_1_x);
    }
    public static uint DecodeMinimalWellFormedCodeUnitSubsequenceDoubleByte(Dafny.ISequence<byte> m) {
      byte _0_firstByte = (m).Select(BigInteger.Zero);
      byte _1_secondByte = (m).Select(BigInteger.One);
      uint _2_y = (uint)((byte)((_0_firstByte) & ((byte)(31))));
      uint _3_x = (uint)((byte)((_1_secondByte) & ((byte)(63))));
      return (unchecked((uint)(((_2_y) << ((int)((byte)(6)))) & (uint)0xFFFFFFU))) | ((uint)(_3_x));
    }
    public static uint DecodeMinimalWellFormedCodeUnitSubsequenceTripleByte(Dafny.ISequence<byte> m) {
      byte _0_firstByte = (m).Select(BigInteger.Zero);
      byte _1_secondByte = (m).Select(BigInteger.One);
      byte _2_thirdByte = (m).Select(new BigInteger(2));
      uint _3_z = (uint)((byte)((_0_firstByte) & ((byte)(15))));
      uint _4_y = (uint)((byte)((_1_secondByte) & ((byte)(63))));
      uint _5_x = (uint)((byte)((_2_thirdByte) & ((byte)(63))));
      return ((unchecked((uint)(((_3_z) << ((int)((byte)(12)))) & (uint)0xFFFFFFU))) | (unchecked((uint)(((_4_y) << ((int)((byte)(6)))) & (uint)0xFFFFFFU)))) | ((uint)(_5_x));
    }
    public static uint DecodeMinimalWellFormedCodeUnitSubsequenceQuadrupleByte(Dafny.ISequence<byte> m) {
      byte _0_firstByte = (m).Select(BigInteger.Zero);
      byte _1_secondByte = (m).Select(BigInteger.One);
      byte _2_thirdByte = (m).Select(new BigInteger(2));
      byte _3_fourthByte = (m).Select(new BigInteger(3));
      uint _4_u1 = (uint)((byte)((_0_firstByte) & ((byte)(7))));
      uint _5_u2 = (uint)((byte)(((byte)((_1_secondByte) & ((byte)(48)))) >> ((int)((byte)(4)))));
      uint _6_z = (uint)((byte)((_1_secondByte) & ((byte)(15))));
      uint _7_y = (uint)((byte)((_2_thirdByte) & ((byte)(63))));
      uint _8_x = (uint)((byte)((_3_fourthByte) & ((byte)(63))));
      uint _9_r = ((((unchecked((uint)(((_4_u1) << ((int)((byte)(18)))) & (uint)0xFFFFFFU))) | (unchecked((uint)(((_5_u2) << ((int)((byte)(16)))) & (uint)0xFFFFFFU)))) | (unchecked((uint)(((_6_z) << ((int)((byte)(12)))) & (uint)0xFFFFFFU)))) | (unchecked((uint)(((_7_y) << ((int)((byte)(6)))) & (uint)0xFFFFFFU)))) | ((uint)(_8_x));
      return _9_r;
    }
    public static Std.Wrappers._IOption<Dafny.ISequence<Dafny.ISequence<byte>>> PartitionCodeUnitSequenceChecked(Dafny.ISequence<byte> s)
    {
      Std.Wrappers._IOption<Dafny.ISequence<Dafny.ISequence<byte>>> maybeParts = Std.Wrappers.Option<Dafny.ISequence<Dafny.ISequence<byte>>>.Default();
      if ((s).Equals(Dafny.Sequence<byte>.FromElements())) {
        maybeParts = Std.Wrappers.Option<Dafny.ISequence<Dafny.ISequence<byte>>>.create_Some(Dafny.Sequence<Dafny.ISequence<byte>>.FromElements());
        return maybeParts;
      }
      Dafny.ISequence<Dafny.ISequence<byte>> _0_result;
      _0_result = Dafny.Sequence<Dafny.ISequence<byte>>.FromElements();
      Dafny.ISequence<byte> _1_rest;
      _1_rest = s;
      while ((new BigInteger((_1_rest).Count)).Sign == 1) {
        Std.Wrappers._IOption<Dafny.ISequence<byte>> _2_valueOrError0 = Std.Wrappers.Option<Dafny.ISequence<byte>>.Default();
        _2_valueOrError0 = Std.Unicode.Utf8EncodingForm.__default.SplitPrefixMinimalWellFormedCodeUnitSubsequence(_1_rest);
        if ((_2_valueOrError0).IsFailure()) {
          maybeParts = (_2_valueOrError0).PropagateFailure<Dafny.ISequence<Dafny.ISequence<byte>>>();
          return maybeParts;
        }
        Dafny.ISequence<byte> _3_prefix;
        _3_prefix = (_2_valueOrError0).Extract();
        _0_result = Dafny.Sequence<Dafny.ISequence<byte>>.Concat(_0_result, Dafny.Sequence<Dafny.ISequence<byte>>.FromElements(_3_prefix));
        _1_rest = (_1_rest).Drop(new BigInteger((_3_prefix).Count));
      }
      maybeParts = Std.Wrappers.Option<Dafny.ISequence<Dafny.ISequence<byte>>>.create_Some(_0_result);
      return maybeParts;
      return maybeParts;
    }
    public static Dafny.ISequence<Dafny.ISequence<byte>> PartitionCodeUnitSequence(Dafny.ISequence<byte> s) {
      return (Std.Unicode.Utf8EncodingForm.__default.PartitionCodeUnitSequenceChecked(s)).Extract();
    }
    public static bool IsWellFormedCodeUnitSequence(Dafny.ISequence<byte> s) {
      return (Std.Unicode.Utf8EncodingForm.__default.PartitionCodeUnitSequenceChecked(s)).is_Some;
    }
    public static Dafny.ISequence<byte> EncodeScalarSequence(Dafny.ISequence<uint> vs)
    {
      Dafny.ISequence<byte> s = Std.Unicode.Utf8EncodingForm.WellFormedCodeUnitSeq.Default();
      s = Dafny.Sequence<byte>.FromElements();
      BigInteger _lo0 = BigInteger.Zero;
      for (BigInteger _0_i = new BigInteger((vs).Count); _lo0 < _0_i; ) {
        _0_i--;
        Dafny.ISequence<byte> _1_next;
        _1_next = Std.Unicode.Utf8EncodingForm.__default.EncodeScalarValue((vs).Select(_0_i));
        s = Dafny.Sequence<byte>.Concat(_1_next, s);
      }
      return s;
    }
    public static Dafny.ISequence<uint> DecodeCodeUnitSequence(Dafny.ISequence<byte> s) {
      Dafny.ISequence<Dafny.ISequence<byte>> _0_parts = Std.Unicode.Utf8EncodingForm.__default.PartitionCodeUnitSequence(s);
      Dafny.ISequence<uint> _1_vs = Std.Collections.Seq.__default.Map<Dafny.ISequence<byte>, uint>(Std.Unicode.Utf8EncodingForm.__default.DecodeMinimalWellFormedCodeUnitSubsequence, _0_parts);
      return _1_vs;
    }
    public static Std.Wrappers._IOption<Dafny.ISequence<uint>> DecodeCodeUnitSequenceChecked(Dafny.ISequence<byte> s)
    {
      Std.Wrappers._IOption<Dafny.ISequence<uint>> maybeVs = Std.Wrappers.Option<Dafny.ISequence<uint>>.Default();
      Std.Wrappers._IOption<Dafny.ISequence<Dafny.ISequence<byte>>> _0_maybeParts;
      _0_maybeParts = Std.Unicode.Utf8EncodingForm.__default.PartitionCodeUnitSequenceChecked(s);
      if ((_0_maybeParts).is_None) {
        maybeVs = Std.Wrappers.Option<Dafny.ISequence<uint>>.create_None();
        return maybeVs;
      }
      Dafny.ISequence<Dafny.ISequence<byte>> _1_parts;
      _1_parts = (_0_maybeParts).dtor_value;
      Dafny.ISequence<uint> _2_vs;
      _2_vs = Std.Collections.Seq.__default.Map<Dafny.ISequence<byte>, uint>(Std.Unicode.Utf8EncodingForm.__default.DecodeMinimalWellFormedCodeUnitSubsequence, _1_parts);
      maybeVs = Std.Wrappers.Option<Dafny.ISequence<uint>>.create_Some(_2_vs);
      return maybeVs;
      return maybeVs;
    }
  }

  public partial class WellFormedCodeUnitSeq {
    private static readonly Dafny.ISequence<byte> Witness = Dafny.Sequence<byte>.FromElements();
    public static Dafny.ISequence<byte> Default() {
      return Witness;
    }
    private static readonly Dafny.TypeDescriptor<Dafny.ISequence<byte>> _TYPE = new Dafny.TypeDescriptor<Dafny.ISequence<byte>>(Std.Unicode.Utf8EncodingForm.WellFormedCodeUnitSeq.Default());
    public static Dafny.TypeDescriptor<Dafny.ISequence<byte>> _TypeDescriptor() {
      return _TYPE;
    }
    public static bool _Is(Dafny.ISequence<byte> __source) {
      Dafny.ISequence<byte> _3_s = __source;
      return Std.Unicode.Utf8EncodingForm.__default.IsWellFormedCodeUnitSequence(_3_s);
    }
  }

  public partial class MinimalWellFormedCodeUnitSeq {
    private static readonly Dafny.TypeDescriptor<Dafny.ISequence<byte>> _TYPE = new Dafny.TypeDescriptor<Dafny.ISequence<byte>>(Dafny.Sequence<byte>.Empty);
    public static Dafny.TypeDescriptor<Dafny.ISequence<byte>> _TypeDescriptor() {
      return _TYPE;
    }
    public static bool _Is(Dafny.ISequence<byte> __source) {
      Dafny.ISequence<byte> _4_s = __source;
      return Std.Unicode.Utf8EncodingForm.__default.IsMinimalWellFormedCodeUnitSubsequence(_4_s);
    }
  }
} // end of namespace Std.Unicode.Utf8EncodingForm
namespace Std.Unicode.Utf16EncodingForm {

  public partial class __default {
    public static bool IsMinimalWellFormedCodeUnitSubsequence(Dafny.ISequence<ushort> s) {
      if ((new BigInteger((s).Count)) == (BigInteger.One)) {
        return Std.Unicode.Utf16EncodingForm.__default.IsWellFormedSingleCodeUnitSequence(s);
      } else if ((new BigInteger((s).Count)) == (new BigInteger(2))) {
        bool _0_b = Std.Unicode.Utf16EncodingForm.__default.IsWellFormedDoubleCodeUnitSequence(s);
        return _0_b;
      } else {
        return false;
      }
    }
    public static bool IsWellFormedSingleCodeUnitSequence(Dafny.ISequence<ushort> s) {
      ushort _0_firstWord = (s).Select(BigInteger.Zero);
      return ((((ushort)(0)) <= (_0_firstWord)) && ((_0_firstWord) <= ((ushort)(55295)))) || ((((ushort)(57344)) <= (_0_firstWord)) && ((_0_firstWord) <= ((ushort)(65535))));
    }
    public static bool IsWellFormedDoubleCodeUnitSequence(Dafny.ISequence<ushort> s) {
      ushort _0_firstWord = (s).Select(BigInteger.Zero);
      ushort _1_secondWord = (s).Select(BigInteger.One);
      return ((((ushort)(55296)) <= (_0_firstWord)) && ((_0_firstWord) <= ((ushort)(56319)))) && ((((ushort)(56320)) <= (_1_secondWord)) && ((_1_secondWord) <= ((ushort)(57343))));
    }
    public static Std.Wrappers._IOption<Dafny.ISequence<ushort>> SplitPrefixMinimalWellFormedCodeUnitSubsequence(Dafny.ISequence<ushort> s) {
      if (((new BigInteger((s).Count)) >= (BigInteger.One)) && (Std.Unicode.Utf16EncodingForm.__default.IsWellFormedSingleCodeUnitSequence((s).Take(BigInteger.One)))) {
        return Std.Wrappers.Option<Dafny.ISequence<ushort>>.create_Some((s).Take(BigInteger.One));
      } else if (((new BigInteger((s).Count)) >= (new BigInteger(2))) && (Std.Unicode.Utf16EncodingForm.__default.IsWellFormedDoubleCodeUnitSequence((s).Take(new BigInteger(2))))) {
        return Std.Wrappers.Option<Dafny.ISequence<ushort>>.create_Some((s).Take(new BigInteger(2)));
      } else {
        return Std.Wrappers.Option<Dafny.ISequence<ushort>>.create_None();
      }
    }
    public static Dafny.ISequence<ushort> EncodeScalarValue(uint v) {
      if ((((0U) <= (v)) && ((v) <= (55295U))) || (((57344U) <= (v)) && ((v) <= (65535U)))) {
        return Std.Unicode.Utf16EncodingForm.__default.EncodeScalarValueSingleWord(v);
      } else {
        return Std.Unicode.Utf16EncodingForm.__default.EncodeScalarValueDoubleWord(v);
      }
    }
    public static Dafny.ISequence<ushort> EncodeScalarValueSingleWord(uint v) {
      ushort _0_firstWord = (ushort)(v);
      return Dafny.Sequence<ushort>.FromElements(_0_firstWord);
    }
    public static Dafny.ISequence<ushort> EncodeScalarValueDoubleWord(uint v) {
      ushort _0_x2 = (ushort)((v) & (1023U));
      byte _1_x1 = (byte)(((v) & (64512U)) >> ((int)((byte)(10))));
      byte _2_u = (byte)(((v) & (2031616U)) >> ((int)((byte)(16))));
      byte _3_w = (byte)(unchecked((byte)(((byte)((_2_u) - ((byte)(1)))) & (byte)0x1F)));
      ushort _4_firstWord = (ushort)(((ushort)(((ushort)(55296)) | (unchecked((ushort)(((ushort)(((ushort)(_3_w)) << ((int)((byte)(6)))))))))) | ((ushort)(_1_x1)));
      ushort _5_secondWord = (ushort)(((ushort)(56320)) | ((ushort)(_0_x2)));
      return Dafny.Sequence<ushort>.FromElements(_4_firstWord, _5_secondWord);
    }
    public static uint DecodeMinimalWellFormedCodeUnitSubsequence(Dafny.ISequence<ushort> m) {
      if ((new BigInteger((m).Count)) == (BigInteger.One)) {
        return Std.Unicode.Utf16EncodingForm.__default.DecodeMinimalWellFormedCodeUnitSubsequenceSingleWord(m);
      } else {
        return Std.Unicode.Utf16EncodingForm.__default.DecodeMinimalWellFormedCodeUnitSubsequenceDoubleWord(m);
      }
    }
    public static uint DecodeMinimalWellFormedCodeUnitSubsequenceSingleWord(Dafny.ISequence<ushort> m) {
      ushort _0_firstWord = (m).Select(BigInteger.Zero);
      ushort _1_x = _0_firstWord;
      return (uint)(_1_x);
    }
    public static uint DecodeMinimalWellFormedCodeUnitSubsequenceDoubleWord(Dafny.ISequence<ushort> m) {
      ushort _0_firstWord = (m).Select(BigInteger.Zero);
      ushort _1_secondWord = (m).Select(BigInteger.One);
      uint _2_x2 = (uint)((ushort)((_1_secondWord) & ((ushort)(1023))));
      uint _3_x1 = (uint)((ushort)((_0_firstWord) & ((ushort)(63))));
      uint _4_w = (uint)((ushort)(((ushort)((_0_firstWord) & ((ushort)(960)))) >> ((int)((byte)(6)))));
      uint _5_u = unchecked((uint)(((_4_w) + (1U)) & (uint)0xFFFFFFU));
      uint _6_v = ((unchecked((uint)(((_5_u) << ((int)((byte)(16)))) & (uint)0xFFFFFFU))) | (unchecked((uint)(((_3_x1) << ((int)((byte)(10)))) & (uint)0xFFFFFFU)))) | ((uint)(_2_x2));
      return _6_v;
    }
    public static Std.Wrappers._IOption<Dafny.ISequence<Dafny.ISequence<ushort>>> PartitionCodeUnitSequenceChecked(Dafny.ISequence<ushort> s)
    {
      Std.Wrappers._IOption<Dafny.ISequence<Dafny.ISequence<ushort>>> maybeParts = Std.Wrappers.Option<Dafny.ISequence<Dafny.ISequence<ushort>>>.Default();
      if ((s).Equals(Dafny.Sequence<ushort>.FromElements())) {
        maybeParts = Std.Wrappers.Option<Dafny.ISequence<Dafny.ISequence<ushort>>>.create_Some(Dafny.Sequence<Dafny.ISequence<ushort>>.FromElements());
        return maybeParts;
      }
      Dafny.ISequence<Dafny.ISequence<ushort>> _0_result;
      _0_result = Dafny.Sequence<Dafny.ISequence<ushort>>.FromElements();
      Dafny.ISequence<ushort> _1_rest;
      _1_rest = s;
      while ((new BigInteger((_1_rest).Count)).Sign == 1) {
        Std.Wrappers._IOption<Dafny.ISequence<ushort>> _2_valueOrError0 = Std.Wrappers.Option<Dafny.ISequence<ushort>>.Default();
        _2_valueOrError0 = Std.Unicode.Utf16EncodingForm.__default.SplitPrefixMinimalWellFormedCodeUnitSubsequence(_1_rest);
        if ((_2_valueOrError0).IsFailure()) {
          maybeParts = (_2_valueOrError0).PropagateFailure<Dafny.ISequence<Dafny.ISequence<ushort>>>();
          return maybeParts;
        }
        Dafny.ISequence<ushort> _3_prefix;
        _3_prefix = (_2_valueOrError0).Extract();
        _0_result = Dafny.Sequence<Dafny.ISequence<ushort>>.Concat(_0_result, Dafny.Sequence<Dafny.ISequence<ushort>>.FromElements(_3_prefix));
        _1_rest = (_1_rest).Drop(new BigInteger((_3_prefix).Count));
      }
      maybeParts = Std.Wrappers.Option<Dafny.ISequence<Dafny.ISequence<ushort>>>.create_Some(_0_result);
      return maybeParts;
      return maybeParts;
    }
    public static Dafny.ISequence<Dafny.ISequence<ushort>> PartitionCodeUnitSequence(Dafny.ISequence<ushort> s) {
      return (Std.Unicode.Utf16EncodingForm.__default.PartitionCodeUnitSequenceChecked(s)).Extract();
    }
    public static bool IsWellFormedCodeUnitSequence(Dafny.ISequence<ushort> s) {
      return (Std.Unicode.Utf16EncodingForm.__default.PartitionCodeUnitSequenceChecked(s)).is_Some;
    }
    public static Dafny.ISequence<ushort> EncodeScalarSequence(Dafny.ISequence<uint> vs)
    {
      Dafny.ISequence<ushort> s = Std.Unicode.Utf16EncodingForm.WellFormedCodeUnitSeq.Default();
      s = Dafny.Sequence<ushort>.FromElements();
      BigInteger _lo0 = BigInteger.Zero;
      for (BigInteger _0_i = new BigInteger((vs).Count); _lo0 < _0_i; ) {
        _0_i--;
        Dafny.ISequence<ushort> _1_next;
        _1_next = Std.Unicode.Utf16EncodingForm.__default.EncodeScalarValue((vs).Select(_0_i));
        s = Dafny.Sequence<ushort>.Concat(_1_next, s);
      }
      return s;
    }
    public static Dafny.ISequence<uint> DecodeCodeUnitSequence(Dafny.ISequence<ushort> s) {
      Dafny.ISequence<Dafny.ISequence<ushort>> _0_parts = Std.Unicode.Utf16EncodingForm.__default.PartitionCodeUnitSequence(s);
      Dafny.ISequence<uint> _1_vs = Std.Collections.Seq.__default.Map<Dafny.ISequence<ushort>, uint>(Std.Unicode.Utf16EncodingForm.__default.DecodeMinimalWellFormedCodeUnitSubsequence, _0_parts);
      return _1_vs;
    }
    public static Std.Wrappers._IOption<Dafny.ISequence<uint>> DecodeCodeUnitSequenceChecked(Dafny.ISequence<ushort> s)
    {
      Std.Wrappers._IOption<Dafny.ISequence<uint>> maybeVs = Std.Wrappers.Option<Dafny.ISequence<uint>>.Default();
      Std.Wrappers._IOption<Dafny.ISequence<Dafny.ISequence<ushort>>> _0_maybeParts;
      _0_maybeParts = Std.Unicode.Utf16EncodingForm.__default.PartitionCodeUnitSequenceChecked(s);
      if ((_0_maybeParts).is_None) {
        maybeVs = Std.Wrappers.Option<Dafny.ISequence<uint>>.create_None();
        return maybeVs;
      }
      Dafny.ISequence<Dafny.ISequence<ushort>> _1_parts;
      _1_parts = (_0_maybeParts).dtor_value;
      Dafny.ISequence<uint> _2_vs;
      _2_vs = Std.Collections.Seq.__default.Map<Dafny.ISequence<ushort>, uint>(Std.Unicode.Utf16EncodingForm.__default.DecodeMinimalWellFormedCodeUnitSubsequence, _1_parts);
      maybeVs = Std.Wrappers.Option<Dafny.ISequence<uint>>.create_Some(_2_vs);
      return maybeVs;
      return maybeVs;
    }
  }

  public partial class WellFormedCodeUnitSeq {
    private static readonly Dafny.ISequence<ushort> Witness = Dafny.Sequence<ushort>.FromElements();
    public static Dafny.ISequence<ushort> Default() {
      return Witness;
    }
    private static readonly Dafny.TypeDescriptor<Dafny.ISequence<ushort>> _TYPE = new Dafny.TypeDescriptor<Dafny.ISequence<ushort>>(Std.Unicode.Utf16EncodingForm.WellFormedCodeUnitSeq.Default());
    public static Dafny.TypeDescriptor<Dafny.ISequence<ushort>> _TypeDescriptor() {
      return _TYPE;
    }
    public static bool _Is(Dafny.ISequence<ushort> __source) {
      Dafny.ISequence<ushort> _3_s = __source;
      return Std.Unicode.Utf16EncodingForm.__default.IsWellFormedCodeUnitSequence(_3_s);
    }
  }

  public partial class MinimalWellFormedCodeUnitSeq {
    private static readonly Dafny.TypeDescriptor<Dafny.ISequence<ushort>> _TYPE = new Dafny.TypeDescriptor<Dafny.ISequence<ushort>>(Dafny.Sequence<ushort>.Empty);
    public static Dafny.TypeDescriptor<Dafny.ISequence<ushort>> _TypeDescriptor() {
      return _TYPE;
    }
    public static bool _Is(Dafny.ISequence<ushort> __source) {
      Dafny.ISequence<ushort> _4_s = __source;
      return Std.Unicode.Utf16EncodingForm.__default.IsMinimalWellFormedCodeUnitSubsequence(_4_s);
    }
  }
} // end of namespace Std.Unicode.Utf16EncodingForm
namespace Std.Unicode.UnicodeStringsWithUnicodeChar {

  public partial class __default {
    public static uint CharAsUnicodeScalarValue(Dafny.Rune c) {
      return (uint)(new BigInteger((c).Value));
    }
    public static Dafny.Rune CharFromUnicodeScalarValue(uint sv) {
      return new Dafny.Rune((int)(new BigInteger(sv)));
    }
    public static Std.Wrappers._IOption<Dafny.ISequence<byte>> ToUTF8Checked(Dafny.ISequence<Dafny.Rune> s) {
      Dafny.ISequence<uint> _0_asCodeUnits = Std.Collections.Seq.__default.Map<Dafny.Rune, uint>(Std.Unicode.UnicodeStringsWithUnicodeChar.__default.CharAsUnicodeScalarValue, s);
      Dafny.ISequence<byte> _1_asUtf8CodeUnits = Std.Unicode.Utf8EncodingForm.__default.EncodeScalarSequence(_0_asCodeUnits);
      Dafny.ISequence<byte> _2_asBytes = Std.Collections.Seq.__default.Map<byte, byte>(((System.Func<byte, byte>)((_3_cu) => {
        return (byte)(_3_cu);
      })), _1_asUtf8CodeUnits);
      return Std.Wrappers.Option<Dafny.ISequence<byte>>.create_Some(_2_asBytes);
    }
    public static Std.Wrappers._IOption<Dafny.ISequence<Dafny.Rune>> FromUTF8Checked(Dafny.ISequence<byte> bs) {
      Dafny.ISequence<byte> _0_asCodeUnits = Std.Collections.Seq.__default.Map<byte, byte>(((System.Func<byte, byte>)((_1_c) => {
        return (byte)(_1_c);
      })), bs);
      Std.Wrappers._IOption<Dafny.ISequence<uint>> _2_valueOrError0 = Std.Unicode.Utf8EncodingForm.__default.DecodeCodeUnitSequenceChecked(_0_asCodeUnits);
      if ((_2_valueOrError0).IsFailure()) {
        return (_2_valueOrError0).PropagateFailure<Dafny.ISequence<Dafny.Rune>>();
      } else {
        Dafny.ISequence<uint> _3_utf32 = (_2_valueOrError0).Extract();
        Dafny.ISequence<Dafny.Rune> _4_asChars = Std.Collections.Seq.__default.Map<uint, Dafny.Rune>(Std.Unicode.UnicodeStringsWithUnicodeChar.__default.CharFromUnicodeScalarValue, _3_utf32);
        return Std.Wrappers.Option<Dafny.ISequence<Dafny.Rune>>.create_Some(_4_asChars);
      }
    }
    public static Std.Wrappers._IOption<Dafny.ISequence<ushort>> ToUTF16Checked(Dafny.ISequence<Dafny.Rune> s) {
      Dafny.ISequence<uint> _0_asCodeUnits = Std.Collections.Seq.__default.Map<Dafny.Rune, uint>(Std.Unicode.UnicodeStringsWithUnicodeChar.__default.CharAsUnicodeScalarValue, s);
      Dafny.ISequence<ushort> _1_asUtf16CodeUnits = Std.Unicode.Utf16EncodingForm.__default.EncodeScalarSequence(_0_asCodeUnits);
      Dafny.ISequence<ushort> _2_asBytes = Std.Collections.Seq.__default.Map<ushort, ushort>(((System.Func<ushort, ushort>)((_3_cu) => {
        return (ushort)(_3_cu);
      })), _1_asUtf16CodeUnits);
      return Std.Wrappers.Option<Dafny.ISequence<ushort>>.create_Some(_2_asBytes);
    }
    public static Std.Wrappers._IOption<Dafny.ISequence<Dafny.Rune>> FromUTF16Checked(Dafny.ISequence<ushort> bs) {
      Dafny.ISequence<ushort> _0_asCodeUnits = Std.Collections.Seq.__default.Map<ushort, ushort>(((System.Func<ushort, ushort>)((_1_c) => {
        return (ushort)(_1_c);
      })), bs);
      Std.Wrappers._IOption<Dafny.ISequence<uint>> _2_valueOrError0 = Std.Unicode.Utf16EncodingForm.__default.DecodeCodeUnitSequenceChecked(_0_asCodeUnits);
      if ((_2_valueOrError0).IsFailure()) {
        return (_2_valueOrError0).PropagateFailure<Dafny.ISequence<Dafny.Rune>>();
      } else {
        Dafny.ISequence<uint> _3_utf32 = (_2_valueOrError0).Extract();
        Dafny.ISequence<Dafny.Rune> _4_asChars = Std.Collections.Seq.__default.Map<uint, Dafny.Rune>(Std.Unicode.UnicodeStringsWithUnicodeChar.__default.CharFromUnicodeScalarValue, _3_utf32);
        return Std.Wrappers.Option<Dafny.ISequence<Dafny.Rune>>.create_Some(_4_asChars);
      }
    }
    public static Dafny.ISequence<byte> ASCIIToUTF8(Dafny.ISequence<Dafny.Rune> s) {
      return Std.Collections.Seq.__default.Map<Dafny.Rune, byte>(((System.Func<Dafny.Rune, byte>)((_0_c) => {
        return (byte)((_0_c).Value);
      })), s);
    }
    public static Dafny.ISequence<ushort> ASCIIToUTF16(Dafny.ISequence<Dafny.Rune> s) {
      return Std.Collections.Seq.__default.Map<Dafny.Rune, ushort>(((System.Func<Dafny.Rune, ushort>)((_0_c) => {
        return (ushort)((_0_c).Value);
      })), s);
    }
  }
} // end of namespace Std.Unicode.UnicodeStringsWithUnicodeChar
namespace Std.Unicode.Utf8EncodingScheme {

  public partial class __default {
    public static Dafny.ISequence<byte> Serialize(Dafny.ISequence<byte> s) {
      return Std.Collections.Seq.__default.Map<byte, byte>(((System.Func<byte, byte>)((_0_c) => {
        return (byte)(_0_c);
      })), s);
    }
    public static Dafny.ISequence<byte> Deserialize(Dafny.ISequence<byte> b) {
      return Std.Collections.Seq.__default.Map<byte, byte>(((System.Func<byte, byte>)((_0_b) => {
        return (byte)(_0_b);
      })), b);
    }
  }
} // end of namespace Std.Unicode.Utf8EncodingScheme
namespace Std.Unicode {

} // end of namespace Std.Unicode
namespace Std.JSON.Values {

  public partial class __default {
    public static Std.JSON.Values._IDecimal Int(BigInteger n) {
      return Std.JSON.Values.Decimal.create(n, BigInteger.Zero);
    }
  }

  public interface _IDecimal {
    bool is_Decimal { get; }
    BigInteger dtor_n { get; }
    BigInteger dtor_e10 { get; }
    _IDecimal DowncastClone();
  }
  public class Decimal : _IDecimal {
    public readonly BigInteger _n;
    public readonly BigInteger _e10;
    public Decimal(BigInteger n, BigInteger e10) {
      this._n = n;
      this._e10 = e10;
    }
    public _IDecimal DowncastClone() {
      if (this is _IDecimal dt) { return dt; }
      return new Decimal(_n, _e10);
    }
    public override bool Equals(object other) {
      var oth = other as Std.JSON.Values.Decimal;
      return oth != null && this._n == oth._n && this._e10 == oth._e10;
    }
    public override int GetHashCode() {
      ulong hash = 5381;
      hash = ((hash << 5) + hash) + 0;
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this._n));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this._e10));
      return (int) hash;
    }
    public override string ToString() {
      string s = "Values.Decimal.Decimal";
      s += "(";
      s += Dafny.Helpers.ToString(this._n);
      s += ", ";
      s += Dafny.Helpers.ToString(this._e10);
      s += ")";
      return s;
    }
    private static readonly Std.JSON.Values._IDecimal theDefault = create(BigInteger.Zero, BigInteger.Zero);
    public static Std.JSON.Values._IDecimal Default() {
      return theDefault;
    }
    private static readonly Dafny.TypeDescriptor<Std.JSON.Values._IDecimal> _TYPE = new Dafny.TypeDescriptor<Std.JSON.Values._IDecimal>(Std.JSON.Values.Decimal.Default());
    public static Dafny.TypeDescriptor<Std.JSON.Values._IDecimal> _TypeDescriptor() {
      return _TYPE;
    }
    public static _IDecimal create(BigInteger n, BigInteger e10) {
      return new Decimal(n, e10);
    }
    public static _IDecimal create_Decimal(BigInteger n, BigInteger e10) {
      return create(n, e10);
    }
    public bool is_Decimal { get { return true; } }
    public BigInteger dtor_n {
      get {
        return this._n;
      }
    }
    public BigInteger dtor_e10 {
      get {
        return this._e10;
      }
    }
  }

  public interface _IJSON {
    bool is_Null { get; }
    bool is_Bool { get; }
    bool is_String { get; }
    bool is_Number { get; }
    bool is_Object { get; }
    bool is_Array { get; }
    bool dtor_b { get; }
    Dafny.ISequence<Dafny.Rune> dtor_str { get; }
    Std.JSON.Values._IDecimal dtor_num { get; }
    Dafny.ISequence<_System._ITuple2<Dafny.ISequence<Dafny.Rune>, Std.JSON.Values._IJSON>> dtor_obj { get; }
    Dafny.ISequence<Std.JSON.Values._IJSON> dtor_arr { get; }
    _IJSON DowncastClone();
  }
  public abstract class JSON : _IJSON {
    public JSON() {
    }
    private static readonly Std.JSON.Values._IJSON theDefault = create_Null();
    public static Std.JSON.Values._IJSON Default() {
      return theDefault;
    }
    private static readonly Dafny.TypeDescriptor<Std.JSON.Values._IJSON> _TYPE = new Dafny.TypeDescriptor<Std.JSON.Values._IJSON>(Std.JSON.Values.JSON.Default());
    public static Dafny.TypeDescriptor<Std.JSON.Values._IJSON> _TypeDescriptor() {
      return _TYPE;
    }
    public static _IJSON create_Null() {
      return new JSON_Null();
    }
    public static _IJSON create_Bool(bool b) {
      return new JSON_Bool(b);
    }
    public static _IJSON create_String(Dafny.ISequence<Dafny.Rune> str) {
      return new JSON_String(str);
    }
    public static _IJSON create_Number(Std.JSON.Values._IDecimal num) {
      return new JSON_Number(num);
    }
    public static _IJSON create_Object(Dafny.ISequence<_System._ITuple2<Dafny.ISequence<Dafny.Rune>, Std.JSON.Values._IJSON>> obj) {
      return new JSON_Object(obj);
    }
    public static _IJSON create_Array(Dafny.ISequence<Std.JSON.Values._IJSON> arr) {
      return new JSON_Array(arr);
    }
    public bool is_Null { get { return this is JSON_Null; } }
    public bool is_Bool { get { return this is JSON_Bool; } }
    public bool is_String { get { return this is JSON_String; } }
    public bool is_Number { get { return this is JSON_Number; } }
    public bool is_Object { get { return this is JSON_Object; } }
    public bool is_Array { get { return this is JSON_Array; } }
    public bool dtor_b {
      get {
        var d = this;
        return ((JSON_Bool)d)._b;
      }
    }
    public Dafny.ISequence<Dafny.Rune> dtor_str {
      get {
        var d = this;
        return ((JSON_String)d)._str;
      }
    }
    public Std.JSON.Values._IDecimal dtor_num {
      get {
        var d = this;
        return ((JSON_Number)d)._num;
      }
    }
    public Dafny.ISequence<_System._ITuple2<Dafny.ISequence<Dafny.Rune>, Std.JSON.Values._IJSON>> dtor_obj {
      get {
        var d = this;
        return ((JSON_Object)d)._obj;
      }
    }
    public Dafny.ISequence<Std.JSON.Values._IJSON> dtor_arr {
      get {
        var d = this;
        return ((JSON_Array)d)._arr;
      }
    }
    public abstract _IJSON DowncastClone();
  }
  public class JSON_Null : JSON {
    public JSON_Null() : base() {
    }
    public override _IJSON DowncastClone() {
      if (this is _IJSON dt) { return dt; }
      return new JSON_Null();
    }
    public override bool Equals(object other) {
      var oth = other as Std.JSON.Values.JSON_Null;
      return oth != null;
    }
    public override int GetHashCode() {
      ulong hash = 5381;
      hash = ((hash << 5) + hash) + 0;
      return (int) hash;
    }
    public override string ToString() {
      string s = "Values.JSON.Null";
      return s;
    }
  }
  public class JSON_Bool : JSON {
    public readonly bool _b;
    public JSON_Bool(bool b) : base() {
      this._b = b;
    }
    public override _IJSON DowncastClone() {
      if (this is _IJSON dt) { return dt; }
      return new JSON_Bool(_b);
    }
    public override bool Equals(object other) {
      var oth = other as Std.JSON.Values.JSON_Bool;
      return oth != null && this._b == oth._b;
    }
    public override int GetHashCode() {
      ulong hash = 5381;
      hash = ((hash << 5) + hash) + 1;
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this._b));
      return (int) hash;
    }
    public override string ToString() {
      string s = "Values.JSON.Bool";
      s += "(";
      s += Dafny.Helpers.ToString(this._b);
      s += ")";
      return s;
    }
  }
  public class JSON_String : JSON {
    public readonly Dafny.ISequence<Dafny.Rune> _str;
    public JSON_String(Dafny.ISequence<Dafny.Rune> str) : base() {
      this._str = str;
    }
    public override _IJSON DowncastClone() {
      if (this is _IJSON dt) { return dt; }
      return new JSON_String(_str);
    }
    public override bool Equals(object other) {
      var oth = other as Std.JSON.Values.JSON_String;
      return oth != null && object.Equals(this._str, oth._str);
    }
    public override int GetHashCode() {
      ulong hash = 5381;
      hash = ((hash << 5) + hash) + 2;
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this._str));
      return (int) hash;
    }
    public override string ToString() {
      string s = "Values.JSON.String";
      s += "(";
      s += this._str.ToVerbatimString(true);
      s += ")";
      return s;
    }
  }
  public class JSON_Number : JSON {
    public readonly Std.JSON.Values._IDecimal _num;
    public JSON_Number(Std.JSON.Values._IDecimal num) : base() {
      this._num = num;
    }
    public override _IJSON DowncastClone() {
      if (this is _IJSON dt) { return dt; }
      return new JSON_Number(_num);
    }
    public override bool Equals(object other) {
      var oth = other as Std.JSON.Values.JSON_Number;
      return oth != null && object.Equals(this._num, oth._num);
    }
    public override int GetHashCode() {
      ulong hash = 5381;
      hash = ((hash << 5) + hash) + 3;
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this._num));
      return (int) hash;
    }
    public override string ToString() {
      string s = "Values.JSON.Number";
      s += "(";
      s += Dafny.Helpers.ToString(this._num);
      s += ")";
      return s;
    }
  }
  public class JSON_Object : JSON {
    public readonly Dafny.ISequence<_System._ITuple2<Dafny.ISequence<Dafny.Rune>, Std.JSON.Values._IJSON>> _obj;
    public JSON_Object(Dafny.ISequence<_System._ITuple2<Dafny.ISequence<Dafny.Rune>, Std.JSON.Values._IJSON>> obj) : base() {
      this._obj = obj;
    }
    public override _IJSON DowncastClone() {
      if (this is _IJSON dt) { return dt; }
      return new JSON_Object(_obj);
    }
    public override bool Equals(object other) {
      var oth = other as Std.JSON.Values.JSON_Object;
      return oth != null && object.Equals(this._obj, oth._obj);
    }
    public override int GetHashCode() {
      ulong hash = 5381;
      hash = ((hash << 5) + hash) + 4;
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this._obj));
      return (int) hash;
    }
    public override string ToString() {
      string s = "Values.JSON.Object";
      s += "(";
      s += Dafny.Helpers.ToString(this._obj);
      s += ")";
      return s;
    }
  }
  public class JSON_Array : JSON {
    public readonly Dafny.ISequence<Std.JSON.Values._IJSON> _arr;
    public JSON_Array(Dafny.ISequence<Std.JSON.Values._IJSON> arr) : base() {
      this._arr = arr;
    }
    public override _IJSON DowncastClone() {
      if (this is _IJSON dt) { return dt; }
      return new JSON_Array(_arr);
    }
    public override bool Equals(object other) {
      var oth = other as Std.JSON.Values.JSON_Array;
      return oth != null && object.Equals(this._arr, oth._arr);
    }
    public override int GetHashCode() {
      ulong hash = 5381;
      hash = ((hash << 5) + hash) + 5;
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this._arr));
      return (int) hash;
    }
    public override string ToString() {
      string s = "Values.JSON.Array";
      s += "(";
      s += Dafny.Helpers.ToString(this._arr);
      s += ")";
      return s;
    }
  }
} // end of namespace Std.JSON.Values
namespace Std.JSON.Errors {


  public interface _IDeserializationError {
    bool is_UnterminatedSequence { get; }
    bool is_UnsupportedEscape { get; }
    bool is_EscapeAtEOS { get; }
    bool is_EmptyNumber { get; }
    bool is_ExpectingEOF { get; }
    bool is_IntOverflow { get; }
    bool is_ReachedEOF { get; }
    bool is_ExpectingByte { get; }
    bool is_ExpectingAnyByte { get; }
    bool is_InvalidUnicode { get; }
    Dafny.ISequence<Dafny.Rune> dtor_str { get; }
    byte dtor_expected { get; }
    short dtor_b { get; }
    Dafny.ISequence<byte> dtor_expected__sq { get; }
    _IDeserializationError DowncastClone();
    Dafny.ISequence<Dafny.Rune> _ToString();
  }
  public abstract class DeserializationError : _IDeserializationError {
    public DeserializationError() {
    }
    private static readonly Std.JSON.Errors._IDeserializationError theDefault = create_UnterminatedSequence();
    public static Std.JSON.Errors._IDeserializationError Default() {
      return theDefault;
    }
    private static readonly Dafny.TypeDescriptor<Std.JSON.Errors._IDeserializationError> _TYPE = new Dafny.TypeDescriptor<Std.JSON.Errors._IDeserializationError>(Std.JSON.Errors.DeserializationError.Default());
    public static Dafny.TypeDescriptor<Std.JSON.Errors._IDeserializationError> _TypeDescriptor() {
      return _TYPE;
    }
    public static _IDeserializationError create_UnterminatedSequence() {
      return new DeserializationError_UnterminatedSequence();
    }
    public static _IDeserializationError create_UnsupportedEscape(Dafny.ISequence<Dafny.Rune> str) {
      return new DeserializationError_UnsupportedEscape(str);
    }
    public static _IDeserializationError create_EscapeAtEOS() {
      return new DeserializationError_EscapeAtEOS();
    }
    public static _IDeserializationError create_EmptyNumber() {
      return new DeserializationError_EmptyNumber();
    }
    public static _IDeserializationError create_ExpectingEOF() {
      return new DeserializationError_ExpectingEOF();
    }
    public static _IDeserializationError create_IntOverflow() {
      return new DeserializationError_IntOverflow();
    }
    public static _IDeserializationError create_ReachedEOF() {
      return new DeserializationError_ReachedEOF();
    }
    public static _IDeserializationError create_ExpectingByte(byte expected, short b) {
      return new DeserializationError_ExpectingByte(expected, b);
    }
    public static _IDeserializationError create_ExpectingAnyByte(Dafny.ISequence<byte> expected__sq, short b) {
      return new DeserializationError_ExpectingAnyByte(expected__sq, b);
    }
    public static _IDeserializationError create_InvalidUnicode() {
      return new DeserializationError_InvalidUnicode();
    }
    public bool is_UnterminatedSequence { get { return this is DeserializationError_UnterminatedSequence; } }
    public bool is_UnsupportedEscape { get { return this is DeserializationError_UnsupportedEscape; } }
    public bool is_EscapeAtEOS { get { return this is DeserializationError_EscapeAtEOS; } }
    public bool is_EmptyNumber { get { return this is DeserializationError_EmptyNumber; } }
    public bool is_ExpectingEOF { get { return this is DeserializationError_ExpectingEOF; } }
    public bool is_IntOverflow { get { return this is DeserializationError_IntOverflow; } }
    public bool is_ReachedEOF { get { return this is DeserializationError_ReachedEOF; } }
    public bool is_ExpectingByte { get { return this is DeserializationError_ExpectingByte; } }
    public bool is_ExpectingAnyByte { get { return this is DeserializationError_ExpectingAnyByte; } }
    public bool is_InvalidUnicode { get { return this is DeserializationError_InvalidUnicode; } }
    public Dafny.ISequence<Dafny.Rune> dtor_str {
      get {
        var d = this;
        return ((DeserializationError_UnsupportedEscape)d)._str;
      }
    }
    public byte dtor_expected {
      get {
        var d = this;
        return ((DeserializationError_ExpectingByte)d)._expected;
      }
    }
    public short dtor_b {
      get {
        var d = this;
        if (d is DeserializationError_ExpectingByte) { return ((DeserializationError_ExpectingByte)d)._b; }
        return ((DeserializationError_ExpectingAnyByte)d)._b;
      }
    }
    public Dafny.ISequence<byte> dtor_expected__sq {
      get {
        var d = this;
        return ((DeserializationError_ExpectingAnyByte)d)._expected__sq;
      }
    }
    public abstract _IDeserializationError DowncastClone();
    public Dafny.ISequence<Dafny.Rune> _ToString() {
      Std.JSON.Errors._IDeserializationError _source0 = this;
      {
        if (_source0.is_UnterminatedSequence) {
          return Dafny.Sequence<Dafny.Rune>.UnicodeFromString("Unterminated sequence");
        }
      }
      {
        if (_source0.is_UnsupportedEscape) {
          Dafny.ISequence<Dafny.Rune> _0_str = _source0.dtor_str;
          return Dafny.Sequence<Dafny.Rune>.Concat(Dafny.Sequence<Dafny.Rune>.UnicodeFromString("Unsupported escape sequence: "), _0_str);
        }
      }
      {
        if (_source0.is_EscapeAtEOS) {
          return Dafny.Sequence<Dafny.Rune>.UnicodeFromString("Escape character at end of string");
        }
      }
      {
        if (_source0.is_EmptyNumber) {
          return Dafny.Sequence<Dafny.Rune>.UnicodeFromString("Number must contain at least one digit");
        }
      }
      {
        if (_source0.is_ExpectingEOF) {
          return Dafny.Sequence<Dafny.Rune>.UnicodeFromString("Expecting EOF");
        }
      }
      {
        if (_source0.is_IntOverflow) {
          return Dafny.Sequence<Dafny.Rune>.UnicodeFromString("Input length does not fit in a 32-bit counter");
        }
      }
      {
        if (_source0.is_ReachedEOF) {
          return Dafny.Sequence<Dafny.Rune>.UnicodeFromString("Reached EOF");
        }
      }
      {
        if (_source0.is_ExpectingByte) {
          byte _1_b0 = _source0.dtor_expected;
          short _2_b = _source0.dtor_b;
          Dafny.ISequence<Dafny.Rune> _3_c = (((_2_b) > ((short)(0))) ? (Dafny.Sequence<Dafny.Rune>.Concat(Dafny.Sequence<Dafny.Rune>.Concat(Dafny.Sequence<Dafny.Rune>.UnicodeFromString("'"), Dafny.Sequence<Dafny.Rune>.FromElements(new Dafny.Rune((int)(_2_b)))), Dafny.Sequence<Dafny.Rune>.UnicodeFromString("'"))) : (Dafny.Sequence<Dafny.Rune>.UnicodeFromString("EOF")));
          return Dafny.Sequence<Dafny.Rune>.Concat(Dafny.Sequence<Dafny.Rune>.Concat(Dafny.Sequence<Dafny.Rune>.Concat(Dafny.Sequence<Dafny.Rune>.UnicodeFromString("Expecting '"), Dafny.Sequence<Dafny.Rune>.FromElements(new Dafny.Rune((int)(_1_b0)))), Dafny.Sequence<Dafny.Rune>.UnicodeFromString("', read ")), _3_c);
        }
      }
      {
        if (_source0.is_ExpectingAnyByte) {
          Dafny.ISequence<byte> _4_bs0 = _source0.dtor_expected__sq;
          short _5_b = _source0.dtor_b;
          Dafny.ISequence<Dafny.Rune> _6_c = (((_5_b) > ((short)(0))) ? (Dafny.Sequence<Dafny.Rune>.Concat(Dafny.Sequence<Dafny.Rune>.Concat(Dafny.Sequence<Dafny.Rune>.UnicodeFromString("'"), Dafny.Sequence<Dafny.Rune>.FromElements(new Dafny.Rune((int)(_5_b)))), Dafny.Sequence<Dafny.Rune>.UnicodeFromString("'"))) : (Dafny.Sequence<Dafny.Rune>.UnicodeFromString("EOF")));
          Dafny.ISequence<Dafny.Rune> _7_c0s = ((System.Func<Dafny.ISequence<Dafny.Rune>>) (() => {
            BigInteger dim4 = new BigInteger((_4_bs0).Count);
            var arr4 = new Dafny.Rune[Dafny.Helpers.ToIntChecked(dim4, "array size exceeds memory limit")];
            for (int i4 = 0; i4 < dim4; i4++) {
              var _8_idx = (BigInteger) i4;
              arr4[(int)(_8_idx)] = new Dafny.Rune((int)((_4_bs0).Select(_8_idx)));
            }
            return Dafny.Sequence<Dafny.Rune>.FromArray(arr4);
          }))();
          return Dafny.Sequence<Dafny.Rune>.Concat(Dafny.Sequence<Dafny.Rune>.Concat(Dafny.Sequence<Dafny.Rune>.Concat(Dafny.Sequence<Dafny.Rune>.UnicodeFromString("Expecting one of '"), _7_c0s), Dafny.Sequence<Dafny.Rune>.UnicodeFromString("', read ")), _6_c);
        }
      }
      {
        return Dafny.Sequence<Dafny.Rune>.UnicodeFromString("Invalid Unicode sequence");
      }
    }
  }
  public class DeserializationError_UnterminatedSequence : DeserializationError {
    public DeserializationError_UnterminatedSequence() : base() {
    }
    public override _IDeserializationError DowncastClone() {
      if (this is _IDeserializationError dt) { return dt; }
      return new DeserializationError_UnterminatedSequence();
    }
    public override bool Equals(object other) {
      var oth = other as Std.JSON.Errors.DeserializationError_UnterminatedSequence;
      return oth != null;
    }
    public override int GetHashCode() {
      ulong hash = 5381;
      hash = ((hash << 5) + hash) + 0;
      return (int) hash;
    }
    public override string ToString() {
      string s = "Errors.DeserializationError.UnterminatedSequence";
      return s;
    }
  }
  public class DeserializationError_UnsupportedEscape : DeserializationError {
    public readonly Dafny.ISequence<Dafny.Rune> _str;
    public DeserializationError_UnsupportedEscape(Dafny.ISequence<Dafny.Rune> str) : base() {
      this._str = str;
    }
    public override _IDeserializationError DowncastClone() {
      if (this is _IDeserializationError dt) { return dt; }
      return new DeserializationError_UnsupportedEscape(_str);
    }
    public override bool Equals(object other) {
      var oth = other as Std.JSON.Errors.DeserializationError_UnsupportedEscape;
      return oth != null && object.Equals(this._str, oth._str);
    }
    public override int GetHashCode() {
      ulong hash = 5381;
      hash = ((hash << 5) + hash) + 1;
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this._str));
      return (int) hash;
    }
    public override string ToString() {
      string s = "Errors.DeserializationError.UnsupportedEscape";
      s += "(";
      s += this._str.ToVerbatimString(true);
      s += ")";
      return s;
    }
  }
  public class DeserializationError_EscapeAtEOS : DeserializationError {
    public DeserializationError_EscapeAtEOS() : base() {
    }
    public override _IDeserializationError DowncastClone() {
      if (this is _IDeserializationError dt) { return dt; }
      return new DeserializationError_EscapeAtEOS();
    }
    public override bool Equals(object other) {
      var oth = other as Std.JSON.Errors.DeserializationError_EscapeAtEOS;
      return oth != null;
    }
    public override int GetHashCode() {
      ulong hash = 5381;
      hash = ((hash << 5) + hash) + 2;
      return (int) hash;
    }
    public override string ToString() {
      string s = "Errors.DeserializationError.EscapeAtEOS";
      return s;
    }
  }
  public class DeserializationError_EmptyNumber : DeserializationError {
    public DeserializationError_EmptyNumber() : base() {
    }
    public override _IDeserializationError DowncastClone() {
      if (this is _IDeserializationError dt) { return dt; }
      return new DeserializationError_EmptyNumber();
    }
    public override bool Equals(object other) {
      var oth = other as Std.JSON.Errors.DeserializationError_EmptyNumber;
      return oth != null;
    }
    public override int GetHashCode() {
      ulong hash = 5381;
      hash = ((hash << 5) + hash) + 3;
      return (int) hash;
    }
    public override string ToString() {
      string s = "Errors.DeserializationError.EmptyNumber";
      return s;
    }
  }
  public class DeserializationError_ExpectingEOF : DeserializationError {
    public DeserializationError_ExpectingEOF() : base() {
    }
    public override _IDeserializationError DowncastClone() {
      if (this is _IDeserializationError dt) { return dt; }
      return new DeserializationError_ExpectingEOF();
    }
    public override bool Equals(object other) {
      var oth = other as Std.JSON.Errors.DeserializationError_ExpectingEOF;
      return oth != null;
    }
    public override int GetHashCode() {
      ulong hash = 5381;
      hash = ((hash << 5) + hash) + 4;
      return (int) hash;
    }
    public override string ToString() {
      string s = "Errors.DeserializationError.ExpectingEOF";
      return s;
    }
  }
  public class DeserializationError_IntOverflow : DeserializationError {
    public DeserializationError_IntOverflow() : base() {
    }
    public override _IDeserializationError DowncastClone() {
      if (this is _IDeserializationError dt) { return dt; }
      return new DeserializationError_IntOverflow();
    }
    public override bool Equals(object other) {
      var oth = other as Std.JSON.Errors.DeserializationError_IntOverflow;
      return oth != null;
    }
    public override int GetHashCode() {
      ulong hash = 5381;
      hash = ((hash << 5) + hash) + 5;
      return (int) hash;
    }
    public override string ToString() {
      string s = "Errors.DeserializationError.IntOverflow";
      return s;
    }
  }
  public class DeserializationError_ReachedEOF : DeserializationError {
    public DeserializationError_ReachedEOF() : base() {
    }
    public override _IDeserializationError DowncastClone() {
      if (this is _IDeserializationError dt) { return dt; }
      return new DeserializationError_ReachedEOF();
    }
    public override bool Equals(object other) {
      var oth = other as Std.JSON.Errors.DeserializationError_ReachedEOF;
      return oth != null;
    }
    public override int GetHashCode() {
      ulong hash = 5381;
      hash = ((hash << 5) + hash) + 6;
      return (int) hash;
    }
    public override string ToString() {
      string s = "Errors.DeserializationError.ReachedEOF";
      return s;
    }
  }
  public class DeserializationError_ExpectingByte : DeserializationError {
    public readonly byte _expected;
    public readonly short _b;
    public DeserializationError_ExpectingByte(byte expected, short b) : base() {
      this._expected = expected;
      this._b = b;
    }
    public override _IDeserializationError DowncastClone() {
      if (this is _IDeserializationError dt) { return dt; }
      return new DeserializationError_ExpectingByte(_expected, _b);
    }
    public override bool Equals(object other) {
      var oth = other as Std.JSON.Errors.DeserializationError_ExpectingByte;
      return oth != null && this._expected == oth._expected && this._b == oth._b;
    }
    public override int GetHashCode() {
      ulong hash = 5381;
      hash = ((hash << 5) + hash) + 7;
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this._expected));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this._b));
      return (int) hash;
    }
    public override string ToString() {
      string s = "Errors.DeserializationError.ExpectingByte";
      s += "(";
      s += Dafny.Helpers.ToString(this._expected);
      s += ", ";
      s += Dafny.Helpers.ToString(this._b);
      s += ")";
      return s;
    }
  }
  public class DeserializationError_ExpectingAnyByte : DeserializationError {
    public readonly Dafny.ISequence<byte> _expected__sq;
    public readonly short _b;
    public DeserializationError_ExpectingAnyByte(Dafny.ISequence<byte> expected__sq, short b) : base() {
      this._expected__sq = expected__sq;
      this._b = b;
    }
    public override _IDeserializationError DowncastClone() {
      if (this is _IDeserializationError dt) { return dt; }
      return new DeserializationError_ExpectingAnyByte(_expected__sq, _b);
    }
    public override bool Equals(object other) {
      var oth = other as Std.JSON.Errors.DeserializationError_ExpectingAnyByte;
      return oth != null && object.Equals(this._expected__sq, oth._expected__sq) && this._b == oth._b;
    }
    public override int GetHashCode() {
      ulong hash = 5381;
      hash = ((hash << 5) + hash) + 8;
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this._expected__sq));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this._b));
      return (int) hash;
    }
    public override string ToString() {
      string s = "Errors.DeserializationError.ExpectingAnyByte";
      s += "(";
      s += Dafny.Helpers.ToString(this._expected__sq);
      s += ", ";
      s += Dafny.Helpers.ToString(this._b);
      s += ")";
      return s;
    }
  }
  public class DeserializationError_InvalidUnicode : DeserializationError {
    public DeserializationError_InvalidUnicode() : base() {
    }
    public override _IDeserializationError DowncastClone() {
      if (this is _IDeserializationError dt) { return dt; }
      return new DeserializationError_InvalidUnicode();
    }
    public override bool Equals(object other) {
      var oth = other as Std.JSON.Errors.DeserializationError_InvalidUnicode;
      return oth != null;
    }
    public override int GetHashCode() {
      ulong hash = 5381;
      hash = ((hash << 5) + hash) + 9;
      return (int) hash;
    }
    public override string ToString() {
      string s = "Errors.DeserializationError.InvalidUnicode";
      return s;
    }
  }

  public interface _ISerializationError {
    bool is_OutOfMemory { get; }
    bool is_IntTooLarge { get; }
    bool is_StringTooLong { get; }
    bool is_InvalidUnicode { get; }
    BigInteger dtor_i { get; }
    Dafny.ISequence<Dafny.Rune> dtor_s { get; }
    _ISerializationError DowncastClone();
    Dafny.ISequence<Dafny.Rune> _ToString();
  }
  public abstract class SerializationError : _ISerializationError {
    public SerializationError() {
    }
    private static readonly Std.JSON.Errors._ISerializationError theDefault = create_OutOfMemory();
    public static Std.JSON.Errors._ISerializationError Default() {
      return theDefault;
    }
    private static readonly Dafny.TypeDescriptor<Std.JSON.Errors._ISerializationError> _TYPE = new Dafny.TypeDescriptor<Std.JSON.Errors._ISerializationError>(Std.JSON.Errors.SerializationError.Default());
    public static Dafny.TypeDescriptor<Std.JSON.Errors._ISerializationError> _TypeDescriptor() {
      return _TYPE;
    }
    public static _ISerializationError create_OutOfMemory() {
      return new SerializationError_OutOfMemory();
    }
    public static _ISerializationError create_IntTooLarge(BigInteger i) {
      return new SerializationError_IntTooLarge(i);
    }
    public static _ISerializationError create_StringTooLong(Dafny.ISequence<Dafny.Rune> s) {
      return new SerializationError_StringTooLong(s);
    }
    public static _ISerializationError create_InvalidUnicode() {
      return new SerializationError_InvalidUnicode();
    }
    public bool is_OutOfMemory { get { return this is SerializationError_OutOfMemory; } }
    public bool is_IntTooLarge { get { return this is SerializationError_IntTooLarge; } }
    public bool is_StringTooLong { get { return this is SerializationError_StringTooLong; } }
    public bool is_InvalidUnicode { get { return this is SerializationError_InvalidUnicode; } }
    public BigInteger dtor_i {
      get {
        var d = this;
        return ((SerializationError_IntTooLarge)d)._i;
      }
    }
    public Dafny.ISequence<Dafny.Rune> dtor_s {
      get {
        var d = this;
        return ((SerializationError_StringTooLong)d)._s;
      }
    }
    public abstract _ISerializationError DowncastClone();
    public Dafny.ISequence<Dafny.Rune> _ToString() {
      Std.JSON.Errors._ISerializationError _source0 = this;
      {
        if (_source0.is_OutOfMemory) {
          return Dafny.Sequence<Dafny.Rune>.UnicodeFromString("Out of memory");
        }
      }
      {
        if (_source0.is_IntTooLarge) {
          BigInteger _0_i = _source0.dtor_i;
          return Dafny.Sequence<Dafny.Rune>.Concat(Dafny.Sequence<Dafny.Rune>.UnicodeFromString("Integer too large: "), Std.Strings.__default.OfInt(_0_i));
        }
      }
      {
        if (_source0.is_StringTooLong) {
          Dafny.ISequence<Dafny.Rune> _1_s = _source0.dtor_s;
          return Dafny.Sequence<Dafny.Rune>.Concat(Dafny.Sequence<Dafny.Rune>.UnicodeFromString("String too long: "), _1_s);
        }
      }
      {
        return Dafny.Sequence<Dafny.Rune>.UnicodeFromString("Invalid Unicode sequence");
      }
    }
  }
  public class SerializationError_OutOfMemory : SerializationError {
    public SerializationError_OutOfMemory() : base() {
    }
    public override _ISerializationError DowncastClone() {
      if (this is _ISerializationError dt) { return dt; }
      return new SerializationError_OutOfMemory();
    }
    public override bool Equals(object other) {
      var oth = other as Std.JSON.Errors.SerializationError_OutOfMemory;
      return oth != null;
    }
    public override int GetHashCode() {
      ulong hash = 5381;
      hash = ((hash << 5) + hash) + 0;
      return (int) hash;
    }
    public override string ToString() {
      string s = "Errors.SerializationError.OutOfMemory";
      return s;
    }
  }
  public class SerializationError_IntTooLarge : SerializationError {
    public readonly BigInteger _i;
    public SerializationError_IntTooLarge(BigInteger i) : base() {
      this._i = i;
    }
    public override _ISerializationError DowncastClone() {
      if (this is _ISerializationError dt) { return dt; }
      return new SerializationError_IntTooLarge(_i);
    }
    public override bool Equals(object other) {
      var oth = other as Std.JSON.Errors.SerializationError_IntTooLarge;
      return oth != null && this._i == oth._i;
    }
    public override int GetHashCode() {
      ulong hash = 5381;
      hash = ((hash << 5) + hash) + 1;
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this._i));
      return (int) hash;
    }
    public override string ToString() {
      string s = "Errors.SerializationError.IntTooLarge";
      s += "(";
      s += Dafny.Helpers.ToString(this._i);
      s += ")";
      return s;
    }
  }
  public class SerializationError_StringTooLong : SerializationError {
    public readonly Dafny.ISequence<Dafny.Rune> _s;
    public SerializationError_StringTooLong(Dafny.ISequence<Dafny.Rune> s) : base() {
      this._s = s;
    }
    public override _ISerializationError DowncastClone() {
      if (this is _ISerializationError dt) { return dt; }
      return new SerializationError_StringTooLong(_s);
    }
    public override bool Equals(object other) {
      var oth = other as Std.JSON.Errors.SerializationError_StringTooLong;
      return oth != null && object.Equals(this._s, oth._s);
    }
    public override int GetHashCode() {
      ulong hash = 5381;
      hash = ((hash << 5) + hash) + 2;
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this._s));
      return (int) hash;
    }
    public override string ToString() {
      string ss = "Errors.SerializationError.StringTooLong";
      ss += "(";
      ss += this._s.ToVerbatimString(true);
      ss += ")";
      return ss;
    }
  }
  public class SerializationError_InvalidUnicode : SerializationError {
    public SerializationError_InvalidUnicode() : base() {
    }
    public override _ISerializationError DowncastClone() {
      if (this is _ISerializationError dt) { return dt; }
      return new SerializationError_InvalidUnicode();
    }
    public override bool Equals(object other) {
      var oth = other as Std.JSON.Errors.SerializationError_InvalidUnicode;
      return oth != null;
    }
    public override int GetHashCode() {
      ulong hash = 5381;
      hash = ((hash << 5) + hash) + 3;
      return (int) hash;
    }
    public override string ToString() {
      string s = "Errors.SerializationError.InvalidUnicode";
      return s;
    }
  }
} // end of namespace Std.JSON.Errors
namespace Std.JSON.Spec {

  public partial class __default {
    public static Dafny.ISequence<ushort> EscapeUnicode(ushort c) {
      Dafny.ISequence<Dafny.Rune> _0_sStr = Std.Strings.HexConversion.__default.OfNat(new BigInteger(c));
      Dafny.ISequence<ushort> _1_s = Std.Unicode.UnicodeStringsWithUnicodeChar.__default.ASCIIToUTF16(_0_sStr);
      return Dafny.Sequence<ushort>.Concat(_1_s, ((System.Func<Dafny.ISequence<ushort>>) (() => {
        BigInteger dim5 = (new BigInteger(4)) - (new BigInteger((_1_s).Count));
        var arr5 = new ushort[Dafny.Helpers.ToIntChecked(dim5, "array size exceeds memory limit")];
        for (int i5 = 0; i5 < dim5; i5++) {
          var _2___v8 = (BigInteger) i5;
          arr5[(int)(_2___v8)] = (ushort)((new Dafny.Rune(' ')).Value);
        }
        return Dafny.Sequence<ushort>.FromArray(arr5);
      }))());
    }
    public static Dafny.ISequence<ushort> Escape(Dafny.ISequence<ushort> str, BigInteger start)
    {
      Dafny.ISequence<ushort> _0___accumulator = Dafny.Sequence<ushort>.FromElements();
    TAIL_CALL_START: ;
      if ((start) >= (new BigInteger((str).Count))) {
        return Dafny.Sequence<ushort>.Concat(_0___accumulator, Dafny.Sequence<ushort>.FromElements());
      } else {
        _0___accumulator = Dafny.Sequence<ushort>.Concat(_0___accumulator, ((System.Func<Dafny.ISequence<ushort>>)(() => {
          ushort _source0 = (str).Select(start);
          {
            if ((_source0) == ((ushort)(34))) {
              return Std.Unicode.UnicodeStringsWithUnicodeChar.__default.ASCIIToUTF16(Dafny.Sequence<Dafny.Rune>.UnicodeFromString("\\\""));
            }
          }
          {
            if ((_source0) == ((ushort)(92))) {
              return Std.Unicode.UnicodeStringsWithUnicodeChar.__default.ASCIIToUTF16(Dafny.Sequence<Dafny.Rune>.UnicodeFromString("\\\\"));
            }
          }
          {
            if ((_source0) == ((ushort)(8))) {
              return Std.Unicode.UnicodeStringsWithUnicodeChar.__default.ASCIIToUTF16(Dafny.Sequence<Dafny.Rune>.UnicodeFromString("\\b"));
            }
          }
          {
            if ((_source0) == ((ushort)(12))) {
              return Std.Unicode.UnicodeStringsWithUnicodeChar.__default.ASCIIToUTF16(Dafny.Sequence<Dafny.Rune>.UnicodeFromString("\\f"));
            }
          }
          {
            if ((_source0) == ((ushort)(10))) {
              return Std.Unicode.UnicodeStringsWithUnicodeChar.__default.ASCIIToUTF16(Dafny.Sequence<Dafny.Rune>.UnicodeFromString("\\n"));
            }
          }
          {
            if ((_source0) == ((ushort)(13))) {
              return Std.Unicode.UnicodeStringsWithUnicodeChar.__default.ASCIIToUTF16(Dafny.Sequence<Dafny.Rune>.UnicodeFromString("\\r"));
            }
          }
          {
            if ((_source0) == ((ushort)(9))) {
              return Std.Unicode.UnicodeStringsWithUnicodeChar.__default.ASCIIToUTF16(Dafny.Sequence<Dafny.Rune>.UnicodeFromString("\\t"));
            }
          }
          {
            ushort _1_c = _source0;
            if ((_1_c) < ((ushort)(31))) {
              return Dafny.Sequence<ushort>.Concat(Std.Unicode.UnicodeStringsWithUnicodeChar.__default.ASCIIToUTF16(Dafny.Sequence<Dafny.Rune>.UnicodeFromString("\\u")), Std.JSON.Spec.__default.EscapeUnicode(_1_c));
            } else {
              return Dafny.Sequence<ushort>.FromElements((str).Select(start));
            }
          }
        }))());
        Dafny.ISequence<ushort> _in0 = str;
        BigInteger _in1 = (start) + (BigInteger.One);
        str = _in0;
        start = _in1;
        goto TAIL_CALL_START;
      }
    }
    public static Std.Wrappers._IResult<Dafny.ISequence<byte>, Std.JSON.Errors._ISerializationError> EscapeToUTF8(Dafny.ISequence<Dafny.Rune> str, BigInteger start)
    {
      Std.Wrappers._IResult<Dafny.ISequence<ushort>, Std.JSON.Errors._ISerializationError> _0_valueOrError0 = (Std.Unicode.UnicodeStringsWithUnicodeChar.__default.ToUTF16Checked(str)).ToResult<Std.JSON.Errors._ISerializationError>(Std.JSON.Errors.SerializationError.create_InvalidUnicode());
      if ((_0_valueOrError0).IsFailure()) {
        return (_0_valueOrError0).PropagateFailure<Dafny.ISequence<byte>>();
      } else {
        Dafny.ISequence<ushort> _1_utf16 = (_0_valueOrError0).Extract();
        Dafny.ISequence<ushort> _2_escaped = Std.JSON.Spec.__default.Escape(_1_utf16, BigInteger.Zero);
        Std.Wrappers._IResult<Dafny.ISequence<Dafny.Rune>, Std.JSON.Errors._ISerializationError> _3_valueOrError1 = (Std.Unicode.UnicodeStringsWithUnicodeChar.__default.FromUTF16Checked(_2_escaped)).ToResult<Std.JSON.Errors._ISerializationError>(Std.JSON.Errors.SerializationError.create_InvalidUnicode());
        if ((_3_valueOrError1).IsFailure()) {
          return (_3_valueOrError1).PropagateFailure<Dafny.ISequence<byte>>();
        } else {
          Dafny.ISequence<Dafny.Rune> _4_utf32 = (_3_valueOrError1).Extract();
          return (Std.Unicode.UnicodeStringsWithUnicodeChar.__default.ToUTF8Checked(_4_utf32)).ToResult<Std.JSON.Errors._ISerializationError>(Std.JSON.Errors.SerializationError.create_InvalidUnicode());
        }
      }
    }
    public static Std.Wrappers._IResult<Dafny.ISequence<byte>, Std.JSON.Errors._ISerializationError> String(Dafny.ISequence<Dafny.Rune> str) {
      Std.Wrappers._IResult<Dafny.ISequence<byte>, Std.JSON.Errors._ISerializationError> _0_valueOrError0 = Std.JSON.Spec.__default.EscapeToUTF8(str, BigInteger.Zero);
      if ((_0_valueOrError0).IsFailure()) {
        return (_0_valueOrError0).PropagateFailure<Dafny.ISequence<byte>>();
      } else {
        Dafny.ISequence<byte> _1_inBytes = (_0_valueOrError0).Extract();
        return Std.Wrappers.Result<Dafny.ISequence<byte>, Std.JSON.Errors._ISerializationError>.create_Success(Dafny.Sequence<byte>.Concat(Dafny.Sequence<byte>.Concat(Std.Unicode.UnicodeStringsWithUnicodeChar.__default.ASCIIToUTF8(Dafny.Sequence<Dafny.Rune>.UnicodeFromString("\"")), _1_inBytes), Std.Unicode.UnicodeStringsWithUnicodeChar.__default.ASCIIToUTF8(Dafny.Sequence<Dafny.Rune>.UnicodeFromString("\""))));
      }
    }
    public static Dafny.ISequence<byte> IntToBytes(BigInteger n) {
      Dafny.ISequence<Dafny.Rune> _0_s = Std.Strings.__default.OfInt(n);
      return Std.Unicode.UnicodeStringsWithUnicodeChar.__default.ASCIIToUTF8(_0_s);
    }
    public static Std.Wrappers._IResult<Dafny.ISequence<byte>, Std.JSON.Errors._ISerializationError> Number(Std.JSON.Values._IDecimal dec) {
      return Std.Wrappers.Result<Dafny.ISequence<byte>, Std.JSON.Errors._ISerializationError>.create_Success(Dafny.Sequence<byte>.Concat(Std.JSON.Spec.__default.IntToBytes((dec).dtor_n), ((((dec).dtor_e10).Sign == 0) ? (Dafny.Sequence<byte>.FromElements()) : (Dafny.Sequence<byte>.Concat(Std.Unicode.UnicodeStringsWithUnicodeChar.__default.ASCIIToUTF8(Dafny.Sequence<Dafny.Rune>.UnicodeFromString("e")), Std.JSON.Spec.__default.IntToBytes((dec).dtor_e10))))));
    }
    public static Std.Wrappers._IResult<Dafny.ISequence<byte>, Std.JSON.Errors._ISerializationError> KeyValue(_System._ITuple2<Dafny.ISequence<Dafny.Rune>, Std.JSON.Values._IJSON> kv) {
      Std.Wrappers._IResult<Dafny.ISequence<byte>, Std.JSON.Errors._ISerializationError> _0_valueOrError0 = Std.JSON.Spec.__default.String((kv).dtor__0);
      if ((_0_valueOrError0).IsFailure()) {
        return (_0_valueOrError0).PropagateFailure<Dafny.ISequence<byte>>();
      } else {
        Dafny.ISequence<byte> _1_key = (_0_valueOrError0).Extract();
        Std.Wrappers._IResult<Dafny.ISequence<byte>, Std.JSON.Errors._ISerializationError> _2_valueOrError1 = Std.JSON.Spec.__default.JSON((kv).dtor__1);
        if ((_2_valueOrError1).IsFailure()) {
          return (_2_valueOrError1).PropagateFailure<Dafny.ISequence<byte>>();
        } else {
          Dafny.ISequence<byte> _3_value = (_2_valueOrError1).Extract();
          return Std.Wrappers.Result<Dafny.ISequence<byte>, Std.JSON.Errors._ISerializationError>.create_Success(Dafny.Sequence<byte>.Concat(Dafny.Sequence<byte>.Concat(_1_key, Std.Unicode.UnicodeStringsWithUnicodeChar.__default.ASCIIToUTF8(Dafny.Sequence<Dafny.Rune>.UnicodeFromString(":"))), _3_value));
        }
      }
    }
    public static Std.Wrappers._IResult<Dafny.ISequence<byte>, Std.JSON.Errors._ISerializationError> Join(Dafny.ISequence<byte> sep, Dafny.ISequence<Std.Wrappers._IResult<Dafny.ISequence<byte>, Std.JSON.Errors._ISerializationError>> items)
    {
      if ((new BigInteger((items).Count)).Sign == 0) {
        return Std.Wrappers.Result<Dafny.ISequence<byte>, Std.JSON.Errors._ISerializationError>.create_Success(Dafny.Sequence<byte>.FromElements());
      } else {
        Std.Wrappers._IResult<Dafny.ISequence<byte>, Std.JSON.Errors._ISerializationError> _0_valueOrError0 = (items).Select(BigInteger.Zero);
        if ((_0_valueOrError0).IsFailure()) {
          return (_0_valueOrError0).PropagateFailure<Dafny.ISequence<byte>>();
        } else {
          Dafny.ISequence<byte> _1_first = (_0_valueOrError0).Extract();
          if ((new BigInteger((items).Count)) == (BigInteger.One)) {
            return Std.Wrappers.Result<Dafny.ISequence<byte>, Std.JSON.Errors._ISerializationError>.create_Success(_1_first);
          } else {
            Std.Wrappers._IResult<Dafny.ISequence<byte>, Std.JSON.Errors._ISerializationError> _2_valueOrError1 = Std.JSON.Spec.__default.Join(sep, (items).Drop(BigInteger.One));
            if ((_2_valueOrError1).IsFailure()) {
              return (_2_valueOrError1).PropagateFailure<Dafny.ISequence<byte>>();
            } else {
              Dafny.ISequence<byte> _3_rest = (_2_valueOrError1).Extract();
              return Std.Wrappers.Result<Dafny.ISequence<byte>, Std.JSON.Errors._ISerializationError>.create_Success(Dafny.Sequence<byte>.Concat(Dafny.Sequence<byte>.Concat(_1_first, sep), _3_rest));
            }
          }
        }
      }
    }
    public static Std.Wrappers._IResult<Dafny.ISequence<byte>, Std.JSON.Errors._ISerializationError> Object(Dafny.ISequence<_System._ITuple2<Dafny.ISequence<Dafny.Rune>, Std.JSON.Values._IJSON>> obj) {
      Std.Wrappers._IResult<Dafny.ISequence<byte>, Std.JSON.Errors._ISerializationError> _0_valueOrError0 = Std.JSON.Spec.__default.Join(Std.Unicode.UnicodeStringsWithUnicodeChar.__default.ASCIIToUTF8(Dafny.Sequence<Dafny.Rune>.UnicodeFromString(",")), ((System.Func<Dafny.ISequence<Std.Wrappers._IResult<Dafny.ISequence<byte>, Std.JSON.Errors._ISerializationError>>>) (() => {
        BigInteger dim6 = new BigInteger((obj).Count);
        var arr6 = new Std.Wrappers._IResult<Dafny.ISequence<byte>, Std.JSON.Errors._ISerializationError>[Dafny.Helpers.ToIntChecked(dim6, "array size exceeds memory limit")];
        for (int i6 = 0; i6 < dim6; i6++) {
          var _1_i = (BigInteger) i6;
          arr6[(int)(_1_i)] = Std.JSON.Spec.__default.KeyValue((obj).Select(_1_i));
        }
        return Dafny.Sequence<Std.Wrappers._IResult<Dafny.ISequence<byte>, Std.JSON.Errors._ISerializationError>>.FromArray(arr6);
      }))());
      if ((_0_valueOrError0).IsFailure()) {
        return (_0_valueOrError0).PropagateFailure<Dafny.ISequence<byte>>();
      } else {
        Dafny.ISequence<byte> _2_middle = (_0_valueOrError0).Extract();
        return Std.Wrappers.Result<Dafny.ISequence<byte>, Std.JSON.Errors._ISerializationError>.create_Success(Dafny.Sequence<byte>.Concat(Dafny.Sequence<byte>.Concat(Std.Unicode.UnicodeStringsWithUnicodeChar.__default.ASCIIToUTF8(Dafny.Sequence<Dafny.Rune>.UnicodeFromString("{")), _2_middle), Std.Unicode.UnicodeStringsWithUnicodeChar.__default.ASCIIToUTF8(Dafny.Sequence<Dafny.Rune>.UnicodeFromString("}"))));
      }
    }
    public static Std.Wrappers._IResult<Dafny.ISequence<byte>, Std.JSON.Errors._ISerializationError> Array(Dafny.ISequence<Std.JSON.Values._IJSON> arr) {
      Std.Wrappers._IResult<Dafny.ISequence<byte>, Std.JSON.Errors._ISerializationError> _0_valueOrError0 = Std.JSON.Spec.__default.Join(Std.Unicode.UnicodeStringsWithUnicodeChar.__default.ASCIIToUTF8(Dafny.Sequence<Dafny.Rune>.UnicodeFromString(",")), ((System.Func<Dafny.ISequence<Std.Wrappers._IResult<Dafny.ISequence<byte>, Std.JSON.Errors._ISerializationError>>>) (() => {
        BigInteger dim7 = new BigInteger((arr).Count);
        var arr7 = new Std.Wrappers._IResult<Dafny.ISequence<byte>, Std.JSON.Errors._ISerializationError>[Dafny.Helpers.ToIntChecked(dim7, "array size exceeds memory limit")];
        for (int i7 = 0; i7 < dim7; i7++) {
          var _1_i = (BigInteger) i7;
          arr7[(int)(_1_i)] = Std.JSON.Spec.__default.JSON((arr).Select(_1_i));
        }
        return Dafny.Sequence<Std.Wrappers._IResult<Dafny.ISequence<byte>, Std.JSON.Errors._ISerializationError>>.FromArray(arr7);
      }))());
      if ((_0_valueOrError0).IsFailure()) {
        return (_0_valueOrError0).PropagateFailure<Dafny.ISequence<byte>>();
      } else {
        Dafny.ISequence<byte> _2_middle = (_0_valueOrError0).Extract();
        return Std.Wrappers.Result<Dafny.ISequence<byte>, Std.JSON.Errors._ISerializationError>.create_Success(Dafny.Sequence<byte>.Concat(Dafny.Sequence<byte>.Concat(Std.Unicode.UnicodeStringsWithUnicodeChar.__default.ASCIIToUTF8(Dafny.Sequence<Dafny.Rune>.UnicodeFromString("[")), _2_middle), Std.Unicode.UnicodeStringsWithUnicodeChar.__default.ASCIIToUTF8(Dafny.Sequence<Dafny.Rune>.UnicodeFromString("]"))));
      }
    }
    public static Std.Wrappers._IResult<Dafny.ISequence<byte>, Std.JSON.Errors._ISerializationError> JSON(Std.JSON.Values._IJSON js) {
      Std.JSON.Values._IJSON _source0 = js;
      {
        if (_source0.is_Null) {
          return Std.Wrappers.Result<Dafny.ISequence<byte>, Std.JSON.Errors._ISerializationError>.create_Success(Std.Unicode.UnicodeStringsWithUnicodeChar.__default.ASCIIToUTF8(Dafny.Sequence<Dafny.Rune>.UnicodeFromString("null")));
        }
      }
      {
        if (_source0.is_Bool) {
          bool _0_b = _source0.dtor_b;
          return Std.Wrappers.Result<Dafny.ISequence<byte>, Std.JSON.Errors._ISerializationError>.create_Success(((_0_b) ? (Std.Unicode.UnicodeStringsWithUnicodeChar.__default.ASCIIToUTF8(Dafny.Sequence<Dafny.Rune>.UnicodeFromString("true"))) : (Std.Unicode.UnicodeStringsWithUnicodeChar.__default.ASCIIToUTF8(Dafny.Sequence<Dafny.Rune>.UnicodeFromString("false")))));
        }
      }
      {
        if (_source0.is_String) {
          Dafny.ISequence<Dafny.Rune> _1_str = _source0.dtor_str;
          return Std.JSON.Spec.__default.String(_1_str);
        }
      }
      {
        if (_source0.is_Number) {
          Std.JSON.Values._IDecimal _2_dec = _source0.dtor_num;
          return Std.JSON.Spec.__default.Number(_2_dec);
        }
      }
      {
        if (_source0.is_Object) {
          Dafny.ISequence<_System._ITuple2<Dafny.ISequence<Dafny.Rune>, Std.JSON.Values._IJSON>> _3_obj = _source0.dtor_obj;
          return Std.JSON.Spec.__default.Object(_3_obj);
        }
      }
      {
        Dafny.ISequence<Std.JSON.Values._IJSON> _4_arr = _source0.dtor_arr;
        return Std.JSON.Spec.__default.Array(_4_arr);
      }
    }
  }
} // end of namespace Std.JSON.Spec
namespace Std.JSON.Utils.Views.Core {

  public partial class __default {
    public static bool Adjacent(Std.JSON.Utils.Views.Core._IView__ lv, Std.JSON.Utils.Views.Core._IView__ rv)
    {
      return (((lv).dtor_end) == ((rv).dtor_beg)) && (((lv).dtor_s).Equals((rv).dtor_s));
    }
    public static Std.JSON.Utils.Views.Core._IView__ Merge(Std.JSON.Utils.Views.Core._IView__ lv, Std.JSON.Utils.Views.Core._IView__ rv)
    {
      Std.JSON.Utils.Views.Core._IView__ _0_dt__update__tmp_h0 = lv;
      uint _1_dt__update_hend_h0 = (rv).dtor_end;
      return Std.JSON.Utils.Views.Core.View__.create((_0_dt__update__tmp_h0).dtor_s, (_0_dt__update__tmp_h0).dtor_beg, _1_dt__update_hend_h0);
    }
  }

  public partial class View {
    private static readonly Std.JSON.Utils.Views.Core._IView__ Witness = Std.JSON.Utils.Views.Core.View__.create(Dafny.Sequence<byte>.FromElements(), 0U, 0U);
    public static Std.JSON.Utils.Views.Core._IView__ Default() {
      return Witness;
    }
    private static readonly Dafny.TypeDescriptor<Std.JSON.Utils.Views.Core._IView__> _TYPE = new Dafny.TypeDescriptor<Std.JSON.Utils.Views.Core._IView__>(Std.JSON.Utils.Views.Core.View.Default());
    public static Dafny.TypeDescriptor<Std.JSON.Utils.Views.Core._IView__> _TypeDescriptor() {
      return _TYPE;
    }
  }

  public interface _IView__ {
    bool is_View { get; }
    Dafny.ISequence<byte> dtor_s { get; }
    uint dtor_beg { get; }
    uint dtor_end { get; }
    _IView__ DowncastClone();
    bool Empty_q { get; }
    uint Length();
    Dafny.ISequence<byte> Bytes();
    bool Byte_q(byte c);
    bool Char_q(Dafny.Rune c);
    byte At(uint idx);
    short Peek();
    void CopyTo(byte[] dest, uint start);
  }
  public class View__ : _IView__ {
    public readonly Dafny.ISequence<byte> _s;
    public readonly uint _beg;
    public readonly uint _end;
    public View__(Dafny.ISequence<byte> s, uint beg, uint end) {
      this._s = s;
      this._beg = beg;
      this._end = end;
    }
    public _IView__ DowncastClone() {
      if (this is _IView__ dt) { return dt; }
      return new View__(_s, _beg, _end);
    }
    public override bool Equals(object other) {
      var oth = other as Std.JSON.Utils.Views.Core.View__;
      return oth != null && object.Equals(this._s, oth._s) && this._beg == oth._beg && this._end == oth._end;
    }
    public override int GetHashCode() {
      ulong hash = 5381;
      hash = ((hash << 5) + hash) + 0;
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this._s));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this._beg));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this._end));
      return (int) hash;
    }
    public override string ToString() {
      string ss = "Core.View_.View";
      ss += "(";
      ss += Dafny.Helpers.ToString(this._s);
      ss += ", ";
      ss += Dafny.Helpers.ToString(this._beg);
      ss += ", ";
      ss += Dafny.Helpers.ToString(this._end);
      ss += ")";
      return ss;
    }
    private static readonly Std.JSON.Utils.Views.Core._IView__ theDefault = create(Dafny.Sequence<byte>.Empty, 0, 0);
    public static Std.JSON.Utils.Views.Core._IView__ Default() {
      return theDefault;
    }
    private static readonly Dafny.TypeDescriptor<Std.JSON.Utils.Views.Core._IView__> _TYPE = new Dafny.TypeDescriptor<Std.JSON.Utils.Views.Core._IView__>(Std.JSON.Utils.Views.Core.View__.Default());
    public static Dafny.TypeDescriptor<Std.JSON.Utils.Views.Core._IView__> _TypeDescriptor() {
      return _TYPE;
    }
    public static _IView__ create(Dafny.ISequence<byte> s, uint beg, uint end) {
      return new View__(s, beg, end);
    }
    public static _IView__ create_View(Dafny.ISequence<byte> s, uint beg, uint end) {
      return create(s, beg, end);
    }
    public bool is_View { get { return true; } }
    public Dafny.ISequence<byte> dtor_s {
      get {
        return this._s;
      }
    }
    public uint dtor_beg {
      get {
        return this._beg;
      }
    }
    public uint dtor_end {
      get {
        return this._end;
      }
    }
    public uint Length() {
      return ((this).dtor_end) - ((this).dtor_beg);
    }
    public Dafny.ISequence<byte> Bytes() {
      return ((this).dtor_s).Subsequence((this).dtor_beg, (this).dtor_end);
    }
    public static Std.JSON.Utils.Views.Core._IView__ OfBytes(Dafny.ISequence<byte> bs) {
      return Std.JSON.Utils.Views.Core.View__.create(bs, (uint)(0U), (uint)(bs).LongCount);
    }
    public static Dafny.ISequence<byte> OfString(Dafny.ISequence<Dafny.Rune> s) {
      return ((System.Func<Dafny.ISequence<byte>>) (() => {
        BigInteger dim8 = new BigInteger((s).Count);
        var arr8 = new byte[Dafny.Helpers.ToIntChecked(dim8, "array size exceeds memory limit")];
        for (int i8 = 0; i8 < dim8; i8++) {
          var _0_i = (BigInteger) i8;
          arr8[(int)(_0_i)] = (byte)(((s).Select(_0_i)).Value);
        }
        return Dafny.Sequence<byte>.FromArray(arr8);
      }))();
    }
    public bool Byte_q(byte c)
    {
      bool _hresult = false;
      _hresult = (((this).Length()) == (1U)) && (((this).At(0U)) == (c));
      return _hresult;
      return _hresult;
    }
    public bool Char_q(Dafny.Rune c) {
      return (this).Byte_q((byte)((c).Value));
    }
    public byte At(uint idx) {
      return ((this).dtor_s).Select(((this).dtor_beg) + (idx));
    }
    public short Peek() {
      if ((this).Empty_q) {
        return (short)(-1);
      } else {
        return (short)((this).At(0U));
      }
    }
    public void CopyTo(byte[] dest, uint start)
    {
      uint _hi0 = (this).Length();
      for (uint _0_idx = 0U; _0_idx < _hi0; _0_idx++) {
        uint _index0 = (start) + (_0_idx);
        (dest)[(int)(_index0)] = ((this).dtor_s).Select(((this).dtor_beg) + (_0_idx));
      }
    }
    public static Std.JSON.Utils.Views.Core._IView__ Empty { get {
      return Std.JSON.Utils.Views.Core.View__.create(Dafny.Sequence<byte>.FromElements(), 0U, 0U);
    } }
    public bool Empty_q { get {
      return ((this).dtor_beg) == ((this).dtor_end);
    } }
  }
} // end of namespace Std.JSON.Utils.Views.Core
namespace Std.JSON.Utils.Views.Writers {


  public interface _IChain {
    bool is_Empty { get; }
    bool is_Chain { get; }
    Std.JSON.Utils.Views.Writers._IChain dtor_previous { get; }
    Std.JSON.Utils.Views.Core._IView__ dtor_v { get; }
    _IChain DowncastClone();
    BigInteger Length();
    BigInteger Count();
    Dafny.ISequence<byte> Bytes();
    Std.JSON.Utils.Views.Writers._IChain Append(Std.JSON.Utils.Views.Core._IView__ v_k);
    void CopyTo(byte[] dest, uint end);
  }
  public abstract class Chain : _IChain {
    public Chain() {
    }
    private static readonly Std.JSON.Utils.Views.Writers._IChain theDefault = create_Empty();
    public static Std.JSON.Utils.Views.Writers._IChain Default() {
      return theDefault;
    }
    private static readonly Dafny.TypeDescriptor<Std.JSON.Utils.Views.Writers._IChain> _TYPE = new Dafny.TypeDescriptor<Std.JSON.Utils.Views.Writers._IChain>(Std.JSON.Utils.Views.Writers.Chain.Default());
    public static Dafny.TypeDescriptor<Std.JSON.Utils.Views.Writers._IChain> _TypeDescriptor() {
      return _TYPE;
    }
    public static _IChain create_Empty() {
      return new Chain_Empty();
    }
    public static _IChain create_Chain(Std.JSON.Utils.Views.Writers._IChain previous, Std.JSON.Utils.Views.Core._IView__ v) {
      return new Chain_Chain(previous, v);
    }
    public bool is_Empty { get { return this is Chain_Empty; } }
    public bool is_Chain { get { return this is Chain_Chain; } }
    public Std.JSON.Utils.Views.Writers._IChain dtor_previous {
      get {
        var d = this;
        return ((Chain_Chain)d)._previous;
      }
    }
    public Std.JSON.Utils.Views.Core._IView__ dtor_v {
      get {
        var d = this;
        return ((Chain_Chain)d)._v;
      }
    }
    public abstract _IChain DowncastClone();
    public BigInteger Length() {
      BigInteger _0___accumulator = BigInteger.Zero;
      _IChain _this = this;
    TAIL_CALL_START: ;
      if ((_this).is_Empty) {
        return (BigInteger.Zero) + (_0___accumulator);
      } else {
        _0___accumulator = (new BigInteger(((_this).dtor_v).Length())) + (_0___accumulator);
        Std.JSON.Utils.Views.Writers._IChain _in0 = (_this).dtor_previous;
        _this = _in0;
        ;
        goto TAIL_CALL_START;
      }
    }
    public BigInteger Count() {
      BigInteger _0___accumulator = BigInteger.Zero;
      _IChain _this = this;
    TAIL_CALL_START: ;
      if ((_this).is_Empty) {
        return (BigInteger.Zero) + (_0___accumulator);
      } else {
        _0___accumulator = (BigInteger.One) + (_0___accumulator);
        Std.JSON.Utils.Views.Writers._IChain _in0 = (_this).dtor_previous;
        _this = _in0;
        ;
        goto TAIL_CALL_START;
      }
    }
    public Dafny.ISequence<byte> Bytes() {
      Dafny.ISequence<byte> _0___accumulator = Dafny.Sequence<byte>.FromElements();
      _IChain _this = this;
    TAIL_CALL_START: ;
      if ((_this).is_Empty) {
        return Dafny.Sequence<byte>.Concat(Dafny.Sequence<byte>.FromElements(), _0___accumulator);
      } else {
        _0___accumulator = Dafny.Sequence<byte>.Concat(((_this).dtor_v).Bytes(), _0___accumulator);
        Std.JSON.Utils.Views.Writers._IChain _in0 = (_this).dtor_previous;
        _this = _in0;
        ;
        goto TAIL_CALL_START;
      }
    }
    public Std.JSON.Utils.Views.Writers._IChain Append(Std.JSON.Utils.Views.Core._IView__ v_k) {
      if (((this).is_Chain) && (Std.JSON.Utils.Views.Core.__default.Adjacent((this).dtor_v, v_k))) {
        return Std.JSON.Utils.Views.Writers.Chain.create_Chain((this).dtor_previous, Std.JSON.Utils.Views.Core.__default.Merge((this).dtor_v, v_k));
      } else {
        return Std.JSON.Utils.Views.Writers.Chain.create_Chain(this, v_k);
      }
    }
    public void CopyTo(byte[] dest, uint end)
    {
      _IChain _this = this;
    TAIL_CALL_START: ;
      if ((_this).is_Chain) {
        uint _0_end;
        _0_end = (end) - (((_this).dtor_v).Length());
        ((_this).dtor_v).CopyTo(dest, _0_end);
        Std.JSON.Utils.Views.Writers._IChain _in0 = (_this).dtor_previous;
        byte[] _in1 = dest;
        uint _in2 = _0_end;
        _this = _in0;
        ;
        dest = _in1;
        end = _in2;
        goto TAIL_CALL_START;
      }
    }
  }
  public class Chain_Empty : Chain {
    public Chain_Empty() : base() {
    }
    public override _IChain DowncastClone() {
      if (this is _IChain dt) { return dt; }
      return new Chain_Empty();
    }
    public override bool Equals(object other) {
      var oth = other as Std.JSON.Utils.Views.Writers.Chain_Empty;
      return oth != null;
    }
    public override int GetHashCode() {
      ulong hash = 5381;
      hash = ((hash << 5) + hash) + 0;
      return (int) hash;
    }
    public override string ToString() {
      string s = "Writers.Chain.Empty";
      return s;
    }
  }
  public class Chain_Chain : Chain {
    public readonly Std.JSON.Utils.Views.Writers._IChain _previous;
    public readonly Std.JSON.Utils.Views.Core._IView__ _v;
    public Chain_Chain(Std.JSON.Utils.Views.Writers._IChain previous, Std.JSON.Utils.Views.Core._IView__ v) : base() {
      this._previous = previous;
      this._v = v;
    }
    public override _IChain DowncastClone() {
      if (this is _IChain dt) { return dt; }
      return new Chain_Chain(_previous, _v);
    }
    public override bool Equals(object other) {
      var oth = other as Std.JSON.Utils.Views.Writers.Chain_Chain;
      return oth != null && object.Equals(this._previous, oth._previous) && object.Equals(this._v, oth._v);
    }
    public override int GetHashCode() {
      ulong hash = 5381;
      hash = ((hash << 5) + hash) + 1;
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this._previous));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this._v));
      return (int) hash;
    }
    public override string ToString() {
      string s = "Writers.Chain.Chain";
      s += "(";
      s += Dafny.Helpers.ToString(this._previous);
      s += ", ";
      s += Dafny.Helpers.ToString(this._v);
      s += ")";
      return s;
    }
  }

  public partial class Writer {
    private static readonly Std.JSON.Utils.Views.Writers._IWriter__ Witness = Std.JSON.Utils.Views.Writers.Writer__.create(0U, Std.JSON.Utils.Views.Writers.Chain.create_Empty());
    public static Std.JSON.Utils.Views.Writers._IWriter__ Default() {
      return Witness;
    }
    private static readonly Dafny.TypeDescriptor<Std.JSON.Utils.Views.Writers._IWriter__> _TYPE = new Dafny.TypeDescriptor<Std.JSON.Utils.Views.Writers._IWriter__>(Std.JSON.Utils.Views.Writers.Writer.Default());
    public static Dafny.TypeDescriptor<Std.JSON.Utils.Views.Writers._IWriter__> _TypeDescriptor() {
      return _TYPE;
    }
  }

  public interface _IWriter__ {
    bool is_Writer { get; }
    uint dtor_length { get; }
    Std.JSON.Utils.Views.Writers._IChain dtor_chain { get; }
    _IWriter__ DowncastClone();
    bool Empty_q { get; }
    bool Unsaturated_q { get; }
    Dafny.ISequence<byte> Bytes();
    Std.JSON.Utils.Views.Writers._IWriter__ Append(Std.JSON.Utils.Views.Core._IView__ v_k);
    Std.JSON.Utils.Views.Writers._IWriter__ Then(Func<Std.JSON.Utils.Views.Writers._IWriter__, Std.JSON.Utils.Views.Writers._IWriter__> fn);
    void CopyTo(byte[] dest);
    byte[] ToArray();
  }
  public class Writer__ : _IWriter__ {
    public readonly uint _length;
    public readonly Std.JSON.Utils.Views.Writers._IChain _chain;
    public Writer__(uint length, Std.JSON.Utils.Views.Writers._IChain chain) {
      this._length = length;
      this._chain = chain;
    }
    public _IWriter__ DowncastClone() {
      if (this is _IWriter__ dt) { return dt; }
      return new Writer__(_length, _chain);
    }
    public override bool Equals(object other) {
      var oth = other as Std.JSON.Utils.Views.Writers.Writer__;
      return oth != null && this._length == oth._length && object.Equals(this._chain, oth._chain);
    }
    public override int GetHashCode() {
      ulong hash = 5381;
      hash = ((hash << 5) + hash) + 0;
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this._length));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this._chain));
      return (int) hash;
    }
    public override string ToString() {
      string s = "Writers.Writer_.Writer";
      s += "(";
      s += Dafny.Helpers.ToString(this._length);
      s += ", ";
      s += Dafny.Helpers.ToString(this._chain);
      s += ")";
      return s;
    }
    private static readonly Std.JSON.Utils.Views.Writers._IWriter__ theDefault = create(0, Std.JSON.Utils.Views.Writers.Chain.Default());
    public static Std.JSON.Utils.Views.Writers._IWriter__ Default() {
      return theDefault;
    }
    private static readonly Dafny.TypeDescriptor<Std.JSON.Utils.Views.Writers._IWriter__> _TYPE = new Dafny.TypeDescriptor<Std.JSON.Utils.Views.Writers._IWriter__>(Std.JSON.Utils.Views.Writers.Writer__.Default());
    public static Dafny.TypeDescriptor<Std.JSON.Utils.Views.Writers._IWriter__> _TypeDescriptor() {
      return _TYPE;
    }
    public static _IWriter__ create(uint length, Std.JSON.Utils.Views.Writers._IChain chain) {
      return new Writer__(length, chain);
    }
    public static _IWriter__ create_Writer(uint length, Std.JSON.Utils.Views.Writers._IChain chain) {
      return create(length, chain);
    }
    public bool is_Writer { get { return true; } }
    public uint dtor_length {
      get {
        return this._length;
      }
    }
    public Std.JSON.Utils.Views.Writers._IChain dtor_chain {
      get {
        return this._chain;
      }
    }
    public Dafny.ISequence<byte> Bytes() {
      return ((this).dtor_chain).Bytes();
    }
    public static uint SaturatedAddU32(uint a, uint b)
    {
      if ((a) <= ((Std.BoundedInts.__default.UINT32__MAX) - (b))) {
        return (a) + (b);
      } else {
        return Std.BoundedInts.__default.UINT32__MAX;
      }
    }
    public Std.JSON.Utils.Views.Writers._IWriter__ Append(Std.JSON.Utils.Views.Core._IView__ v_k) {
      return Std.JSON.Utils.Views.Writers.Writer__.create(Std.JSON.Utils.Views.Writers.Writer__.SaturatedAddU32((this).dtor_length, (v_k).Length()), ((this).dtor_chain).Append(v_k));
    }
    public Std.JSON.Utils.Views.Writers._IWriter__ Then(Func<Std.JSON.Utils.Views.Writers._IWriter__, Std.JSON.Utils.Views.Writers._IWriter__> fn) {
      return Dafny.Helpers.Id<Func<Std.JSON.Utils.Views.Writers._IWriter__, Std.JSON.Utils.Views.Writers._IWriter__>>(fn)(this);
    }
    public void CopyTo(byte[] dest)
    {
      ((this).dtor_chain).CopyTo(dest, (this).dtor_length);
    }
    public byte[] ToArray()
    {
      byte[] bs = new byte[0];
      Func<BigInteger, byte> _init0 = ((System.Func<BigInteger, byte>)((_0_i) => {
        return (byte)(0);
      }));
      byte[] _nw0 = new byte[Dafny.Helpers.ToIntChecked((this).dtor_length, "array size exceeds memory limit")];
      for (var _i0_0 = 0; _i0_0 < new BigInteger(_nw0.Length); _i0_0++) {
        _nw0[(int)(_i0_0)] = _init0(_i0_0);
      }
      bs = _nw0;
      (this).CopyTo(bs);
      return bs;
    }
    public static Std.JSON.Utils.Views.Writers._IWriter__ Empty { get {
      return Std.JSON.Utils.Views.Writers.Writer__.create(0U, Std.JSON.Utils.Views.Writers.Chain.create_Empty());
    } }
    public bool Unsaturated_q { get {
      return ((this).dtor_length) != (Std.BoundedInts.__default.UINT32__MAX);
    } }
    public bool Empty_q { get {
      return ((this).dtor_chain).is_Empty;
    } }
  }
} // end of namespace Std.JSON.Utils.Views.Writers
namespace Std.JSON.Utils.Views {

} // end of namespace Std.JSON.Utils.Views
namespace Std.JSON.Utils.Lexers.Core {


  public interface _ILexerResult<out T, out R> {
    bool is_Accept { get; }
    bool is_Reject { get; }
    bool is_Partial { get; }
    R dtor_err { get; }
    T dtor_st { get; }
    _ILexerResult<__T, __R> DowncastClone<__T, __R>(Func<T, __T> converter0, Func<R, __R> converter1);
  }
  public abstract class LexerResult<T, R> : _ILexerResult<T, R> {
    public LexerResult() {
    }
    public static Std.JSON.Utils.Lexers.Core._ILexerResult<T, R> Default() {
      return create_Accept();
    }
    public static Dafny.TypeDescriptor<Std.JSON.Utils.Lexers.Core._ILexerResult<T, R>> _TypeDescriptor() {
      return new Dafny.TypeDescriptor<Std.JSON.Utils.Lexers.Core._ILexerResult<T, R>>(Std.JSON.Utils.Lexers.Core.LexerResult<T, R>.Default());
    }
    public static _ILexerResult<T, R> create_Accept() {
      return new LexerResult_Accept<T, R>();
    }
    public static _ILexerResult<T, R> create_Reject(R err) {
      return new LexerResult_Reject<T, R>(err);
    }
    public static _ILexerResult<T, R> create_Partial(T st) {
      return new LexerResult_Partial<T, R>(st);
    }
    public bool is_Accept { get { return this is LexerResult_Accept<T, R>; } }
    public bool is_Reject { get { return this is LexerResult_Reject<T, R>; } }
    public bool is_Partial { get { return this is LexerResult_Partial<T, R>; } }
    public R dtor_err {
      get {
        var d = this;
        return ((LexerResult_Reject<T, R>)d)._err;
      }
    }
    public T dtor_st {
      get {
        var d = this;
        return ((LexerResult_Partial<T, R>)d)._st;
      }
    }
    public abstract _ILexerResult<__T, __R> DowncastClone<__T, __R>(Func<T, __T> converter0, Func<R, __R> converter1);
  }
  public class LexerResult_Accept<T, R> : LexerResult<T, R> {
    public LexerResult_Accept() : base() {
    }
    public override _ILexerResult<__T, __R> DowncastClone<__T, __R>(Func<T, __T> converter0, Func<R, __R> converter1) {
      if (this is _ILexerResult<__T, __R> dt) { return dt; }
      return new LexerResult_Accept<__T, __R>();
    }
    public override bool Equals(object other) {
      var oth = other as Std.JSON.Utils.Lexers.Core.LexerResult_Accept<T, R>;
      return oth != null;
    }
    public override int GetHashCode() {
      ulong hash = 5381;
      hash = ((hash << 5) + hash) + 0;
      return (int) hash;
    }
    public override string ToString() {
      string s = "Core.LexerResult.Accept";
      return s;
    }
  }
  public class LexerResult_Reject<T, R> : LexerResult<T, R> {
    public readonly R _err;
    public LexerResult_Reject(R err) : base() {
      this._err = err;
    }
    public override _ILexerResult<__T, __R> DowncastClone<__T, __R>(Func<T, __T> converter0, Func<R, __R> converter1) {
      if (this is _ILexerResult<__T, __R> dt) { return dt; }
      return new LexerResult_Reject<__T, __R>(converter1(_err));
    }
    public override bool Equals(object other) {
      var oth = other as Std.JSON.Utils.Lexers.Core.LexerResult_Reject<T, R>;
      return oth != null && object.Equals(this._err, oth._err);
    }
    public override int GetHashCode() {
      ulong hash = 5381;
      hash = ((hash << 5) + hash) + 1;
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this._err));
      return (int) hash;
    }
    public override string ToString() {
      string s = "Core.LexerResult.Reject";
      s += "(";
      s += Dafny.Helpers.ToString(this._err);
      s += ")";
      return s;
    }
  }
  public class LexerResult_Partial<T, R> : LexerResult<T, R> {
    public readonly T _st;
    public LexerResult_Partial(T st) : base() {
      this._st = st;
    }
    public override _ILexerResult<__T, __R> DowncastClone<__T, __R>(Func<T, __T> converter0, Func<R, __R> converter1) {
      if (this is _ILexerResult<__T, __R> dt) { return dt; }
      return new LexerResult_Partial<__T, __R>(converter0(_st));
    }
    public override bool Equals(object other) {
      var oth = other as Std.JSON.Utils.Lexers.Core.LexerResult_Partial<T, R>;
      return oth != null && object.Equals(this._st, oth._st);
    }
    public override int GetHashCode() {
      ulong hash = 5381;
      hash = ((hash << 5) + hash) + 2;
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this._st));
      return (int) hash;
    }
    public override string ToString() {
      string s = "Core.LexerResult.Partial";
      s += "(";
      s += Dafny.Helpers.ToString(this._st);
      s += ")";
      return s;
    }
  }
} // end of namespace Std.JSON.Utils.Lexers.Core
namespace Std.JSON.Utils.Lexers.Strings {

  public partial class __default {
    public static Std.JSON.Utils.Lexers.Core._ILexerResult<bool, __R> StringBody<__R>(bool escaped, short @byte)
    {
      if ((@byte) == ((short)((new Dafny.Rune('\\')).Value))) {
        return Std.JSON.Utils.Lexers.Core.LexerResult<bool, __R>.create_Partial(!(escaped));
      } else if (((@byte) == ((short)((new Dafny.Rune('\"')).Value))) && (!(escaped))) {
        return Std.JSON.Utils.Lexers.Core.LexerResult<bool, __R>.create_Accept();
      } else {
        return Std.JSON.Utils.Lexers.Core.LexerResult<bool, __R>.create_Partial(false);
      }
    }
    public static Std.JSON.Utils.Lexers.Core._ILexerResult<Std.JSON.Utils.Lexers.Strings._IStringLexerState, Dafny.ISequence<Dafny.Rune>> String(Std.JSON.Utils.Lexers.Strings._IStringLexerState st, short @byte)
    {
      Std.JSON.Utils.Lexers.Strings._IStringLexerState _source0 = st;
      {
        if (_source0.is_Start) {
          if ((@byte) == ((short)((new Dafny.Rune('\"')).Value))) {
            return Std.JSON.Utils.Lexers.Core.LexerResult<Std.JSON.Utils.Lexers.Strings._IStringLexerState, Dafny.ISequence<Dafny.Rune>>.create_Partial(Std.JSON.Utils.Lexers.Strings.StringLexerState.create_Body(false));
          } else {
            return Std.JSON.Utils.Lexers.Core.LexerResult<Std.JSON.Utils.Lexers.Strings._IStringLexerState, Dafny.ISequence<Dafny.Rune>>.create_Reject(Dafny.Sequence<Dafny.Rune>.UnicodeFromString("String must start with double quote"));
          }
        }
      }
      {
        if (_source0.is_End) {
          return Std.JSON.Utils.Lexers.Core.LexerResult<Std.JSON.Utils.Lexers.Strings._IStringLexerState, Dafny.ISequence<Dafny.Rune>>.create_Accept();
        }
      }
      {
        bool _0_escaped = _source0.dtor_escaped;
        if ((@byte) == ((short)((new Dafny.Rune('\\')).Value))) {
          return Std.JSON.Utils.Lexers.Core.LexerResult<Std.JSON.Utils.Lexers.Strings._IStringLexerState, Dafny.ISequence<Dafny.Rune>>.create_Partial(Std.JSON.Utils.Lexers.Strings.StringLexerState.create_Body(!(_0_escaped)));
        } else if (((@byte) == ((short)((new Dafny.Rune('\"')).Value))) && (!(_0_escaped))) {
          return Std.JSON.Utils.Lexers.Core.LexerResult<Std.JSON.Utils.Lexers.Strings._IStringLexerState, Dafny.ISequence<Dafny.Rune>>.create_Partial(Std.JSON.Utils.Lexers.Strings.StringLexerState.create_End());
        } else {
          return Std.JSON.Utils.Lexers.Core.LexerResult<Std.JSON.Utils.Lexers.Strings._IStringLexerState, Dafny.ISequence<Dafny.Rune>>.create_Partial(Std.JSON.Utils.Lexers.Strings.StringLexerState.create_Body(false));
        }
      }
    }
    public static bool StringBodyLexerStart { get {
      return false;
    } }
    public static Std.JSON.Utils.Lexers.Strings._IStringLexerState StringLexerStart { get {
      return Std.JSON.Utils.Lexers.Strings.StringLexerState.create_Start();
    } }
  }

  public interface _IStringLexerState {
    bool is_Start { get; }
    bool is_Body { get; }
    bool is_End { get; }
    bool dtor_escaped { get; }
    _IStringLexerState DowncastClone();
  }
  public abstract class StringLexerState : _IStringLexerState {
    public StringLexerState() {
    }
    private static readonly Std.JSON.Utils.Lexers.Strings._IStringLexerState theDefault = create_Start();
    public static Std.JSON.Utils.Lexers.Strings._IStringLexerState Default() {
      return theDefault;
    }
    private static readonly Dafny.TypeDescriptor<Std.JSON.Utils.Lexers.Strings._IStringLexerState> _TYPE = new Dafny.TypeDescriptor<Std.JSON.Utils.Lexers.Strings._IStringLexerState>(Std.JSON.Utils.Lexers.Strings.StringLexerState.Default());
    public static Dafny.TypeDescriptor<Std.JSON.Utils.Lexers.Strings._IStringLexerState> _TypeDescriptor() {
      return _TYPE;
    }
    public static _IStringLexerState create_Start() {
      return new StringLexerState_Start();
    }
    public static _IStringLexerState create_Body(bool escaped) {
      return new StringLexerState_Body(escaped);
    }
    public static _IStringLexerState create_End() {
      return new StringLexerState_End();
    }
    public bool is_Start { get { return this is StringLexerState_Start; } }
    public bool is_Body { get { return this is StringLexerState_Body; } }
    public bool is_End { get { return this is StringLexerState_End; } }
    public bool dtor_escaped {
      get {
        var d = this;
        return ((StringLexerState_Body)d)._escaped;
      }
    }
    public abstract _IStringLexerState DowncastClone();
  }
  public class StringLexerState_Start : StringLexerState {
    public StringLexerState_Start() : base() {
    }
    public override _IStringLexerState DowncastClone() {
      if (this is _IStringLexerState dt) { return dt; }
      return new StringLexerState_Start();
    }
    public override bool Equals(object other) {
      var oth = other as Std.JSON.Utils.Lexers.Strings.StringLexerState_Start;
      return oth != null;
    }
    public override int GetHashCode() {
      ulong hash = 5381;
      hash = ((hash << 5) + hash) + 0;
      return (int) hash;
    }
    public override string ToString() {
      string s = "Strings.StringLexerState.Start";
      return s;
    }
  }
  public class StringLexerState_Body : StringLexerState {
    public readonly bool _escaped;
    public StringLexerState_Body(bool escaped) : base() {
      this._escaped = escaped;
    }
    public override _IStringLexerState DowncastClone() {
      if (this is _IStringLexerState dt) { return dt; }
      return new StringLexerState_Body(_escaped);
    }
    public override bool Equals(object other) {
      var oth = other as Std.JSON.Utils.Lexers.Strings.StringLexerState_Body;
      return oth != null && this._escaped == oth._escaped;
    }
    public override int GetHashCode() {
      ulong hash = 5381;
      hash = ((hash << 5) + hash) + 1;
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this._escaped));
      return (int) hash;
    }
    public override string ToString() {
      string s = "Strings.StringLexerState.Body";
      s += "(";
      s += Dafny.Helpers.ToString(this._escaped);
      s += ")";
      return s;
    }
  }
  public class StringLexerState_End : StringLexerState {
    public StringLexerState_End() : base() {
    }
    public override _IStringLexerState DowncastClone() {
      if (this is _IStringLexerState dt) { return dt; }
      return new StringLexerState_End();
    }
    public override bool Equals(object other) {
      var oth = other as Std.JSON.Utils.Lexers.Strings.StringLexerState_End;
      return oth != null;
    }
    public override int GetHashCode() {
      ulong hash = 5381;
      hash = ((hash << 5) + hash) + 2;
      return (int) hash;
    }
    public override string ToString() {
      string s = "Strings.StringLexerState.End";
      return s;
    }
  }
} // end of namespace Std.JSON.Utils.Lexers.Strings
namespace Std.JSON.Utils.Lexers {

} // end of namespace Std.JSON.Utils.Lexers
namespace Std.JSON.Utils.Cursors {


  public interface _ISplit<out T> {
    bool is_SP { get; }
    T dtor_t { get; }
    Std.JSON.Utils.Cursors._ICursor__ dtor_cs { get; }
    _ISplit<__T> DowncastClone<__T>(Func<T, __T> converter0);
  }
  public class Split<T> : _ISplit<T> {
    public readonly T _t;
    public readonly Std.JSON.Utils.Cursors._ICursor__ _cs;
    public Split(T t, Std.JSON.Utils.Cursors._ICursor__ cs) {
      this._t = t;
      this._cs = cs;
    }
    public _ISplit<__T> DowncastClone<__T>(Func<T, __T> converter0) {
      if (this is _ISplit<__T> dt) { return dt; }
      return new Split<__T>(converter0(_t), _cs);
    }
    public override bool Equals(object other) {
      var oth = other as Std.JSON.Utils.Cursors.Split<T>;
      return oth != null && object.Equals(this._t, oth._t) && object.Equals(this._cs, oth._cs);
    }
    public override int GetHashCode() {
      ulong hash = 5381;
      hash = ((hash << 5) + hash) + 0;
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this._t));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this._cs));
      return (int) hash;
    }
    public override string ToString() {
      string s = "Cursors.Split.SP";
      s += "(";
      s += Dafny.Helpers.ToString(this._t);
      s += ", ";
      s += Dafny.Helpers.ToString(this._cs);
      s += ")";
      return s;
    }
    public static Std.JSON.Utils.Cursors._ISplit<T> Default(T _default_T) {
      return create(_default_T, Std.JSON.Utils.Cursors.FreshCursor.Default());
    }
    public static Dafny.TypeDescriptor<Std.JSON.Utils.Cursors._ISplit<T>> _TypeDescriptor(Dafny.TypeDescriptor<T> _td_T) {
      return new Dafny.TypeDescriptor<Std.JSON.Utils.Cursors._ISplit<T>>(Std.JSON.Utils.Cursors.Split<T>.Default(_td_T.Default()));
    }
    public static _ISplit<T> create(T t, Std.JSON.Utils.Cursors._ICursor__ cs) {
      return new Split<T>(t, cs);
    }
    public static _ISplit<T> create_SP(T t, Std.JSON.Utils.Cursors._ICursor__ cs) {
      return create(t, cs);
    }
    public bool is_SP { get { return true; } }
    public T dtor_t {
      get {
        return this._t;
      }
    }
    public Std.JSON.Utils.Cursors._ICursor__ dtor_cs {
      get {
        return this._cs;
      }
    }
  }

  public partial class Cursor {
    private static readonly Std.JSON.Utils.Cursors._ICursor__ Witness = Std.JSON.Utils.Cursors.Cursor__.create(Dafny.Sequence<byte>.FromElements(), 0U, 0U, 0U);
    public static Std.JSON.Utils.Cursors._ICursor__ Default() {
      return Witness;
    }
    private static readonly Dafny.TypeDescriptor<Std.JSON.Utils.Cursors._ICursor__> _TYPE = new Dafny.TypeDescriptor<Std.JSON.Utils.Cursors._ICursor__>(Std.JSON.Utils.Cursors.Cursor.Default());
    public static Dafny.TypeDescriptor<Std.JSON.Utils.Cursors._ICursor__> _TypeDescriptor() {
      return _TYPE;
    }
  }

  public partial class FreshCursor {
    private static readonly Std.JSON.Utils.Cursors._ICursor__ Witness = Std.JSON.Utils.Cursors.Cursor__.create(Dafny.Sequence<byte>.FromElements(), 0U, 0U, 0U);
    public static Std.JSON.Utils.Cursors._ICursor__ Default() {
      return Witness;
    }
    private static readonly Dafny.TypeDescriptor<Std.JSON.Utils.Cursors._ICursor__> _TYPE = new Dafny.TypeDescriptor<Std.JSON.Utils.Cursors._ICursor__>(Std.JSON.Utils.Cursors.FreshCursor.Default());
    public static Dafny.TypeDescriptor<Std.JSON.Utils.Cursors._ICursor__> _TypeDescriptor() {
      return _TYPE;
    }
  }

  public interface _ICursorError<out R> {
    bool is_EOF { get; }
    bool is_ExpectingByte { get; }
    bool is_ExpectingAnyByte { get; }
    bool is_OtherError { get; }
    byte dtor_expected { get; }
    short dtor_b { get; }
    Dafny.ISequence<byte> dtor_expected__sq { get; }
    R dtor_err { get; }
    _ICursorError<__R> DowncastClone<__R>(Func<R, __R> converter0);
  }
  public abstract class CursorError<R> : _ICursorError<R> {
    public CursorError() {
    }
    public static Std.JSON.Utils.Cursors._ICursorError<R> Default() {
      return create_EOF();
    }
    public static Dafny.TypeDescriptor<Std.JSON.Utils.Cursors._ICursorError<R>> _TypeDescriptor() {
      return new Dafny.TypeDescriptor<Std.JSON.Utils.Cursors._ICursorError<R>>(Std.JSON.Utils.Cursors.CursorError<R>.Default());
    }
    public static _ICursorError<R> create_EOF() {
      return new CursorError_EOF<R>();
    }
    public static _ICursorError<R> create_ExpectingByte(byte expected, short b) {
      return new CursorError_ExpectingByte<R>(expected, b);
    }
    public static _ICursorError<R> create_ExpectingAnyByte(Dafny.ISequence<byte> expected__sq, short b) {
      return new CursorError_ExpectingAnyByte<R>(expected__sq, b);
    }
    public static _ICursorError<R> create_OtherError(R err) {
      return new CursorError_OtherError<R>(err);
    }
    public bool is_EOF { get { return this is CursorError_EOF<R>; } }
    public bool is_ExpectingByte { get { return this is CursorError_ExpectingByte<R>; } }
    public bool is_ExpectingAnyByte { get { return this is CursorError_ExpectingAnyByte<R>; } }
    public bool is_OtherError { get { return this is CursorError_OtherError<R>; } }
    public byte dtor_expected {
      get {
        var d = this;
        return ((CursorError_ExpectingByte<R>)d)._expected;
      }
    }
    public short dtor_b {
      get {
        var d = this;
        if (d is CursorError_ExpectingByte<R>) { return ((CursorError_ExpectingByte<R>)d)._b; }
        return ((CursorError_ExpectingAnyByte<R>)d)._b;
      }
    }
    public Dafny.ISequence<byte> dtor_expected__sq {
      get {
        var d = this;
        return ((CursorError_ExpectingAnyByte<R>)d)._expected__sq;
      }
    }
    public R dtor_err {
      get {
        var d = this;
        return ((CursorError_OtherError<R>)d)._err;
      }
    }
    public abstract _ICursorError<__R> DowncastClone<__R>(Func<R, __R> converter0);
    public static Dafny.ISequence<Dafny.Rune> _ToString(Std.JSON.Utils.Cursors._ICursorError<R> _this, Func<R, Dafny.ISequence<Dafny.Rune>> pr) {
      Std.JSON.Utils.Cursors._ICursorError<R> _source0 = _this;
      {
        if (_source0.is_EOF) {
          return Dafny.Sequence<Dafny.Rune>.UnicodeFromString("Reached EOF");
        }
      }
      {
        if (_source0.is_ExpectingByte) {
          byte _0_b0 = _source0.dtor_expected;
          short _1_b = _source0.dtor_b;
          Dafny.ISequence<Dafny.Rune> _2_c = (((_1_b) > ((short)(0))) ? (Dafny.Sequence<Dafny.Rune>.Concat(Dafny.Sequence<Dafny.Rune>.Concat(Dafny.Sequence<Dafny.Rune>.UnicodeFromString("'"), Dafny.Sequence<Dafny.Rune>.FromElements(new Dafny.Rune((int)(_1_b)))), Dafny.Sequence<Dafny.Rune>.UnicodeFromString("'"))) : (Dafny.Sequence<Dafny.Rune>.UnicodeFromString("EOF")));
          return Dafny.Sequence<Dafny.Rune>.Concat(Dafny.Sequence<Dafny.Rune>.Concat(Dafny.Sequence<Dafny.Rune>.Concat(Dafny.Sequence<Dafny.Rune>.UnicodeFromString("Expecting '"), Dafny.Sequence<Dafny.Rune>.FromElements(new Dafny.Rune((int)(_0_b0)))), Dafny.Sequence<Dafny.Rune>.UnicodeFromString("', read ")), _2_c);
        }
      }
      {
        if (_source0.is_ExpectingAnyByte) {
          Dafny.ISequence<byte> _3_bs0 = _source0.dtor_expected__sq;
          short _4_b = _source0.dtor_b;
          Dafny.ISequence<Dafny.Rune> _5_c = (((_4_b) > ((short)(0))) ? (Dafny.Sequence<Dafny.Rune>.Concat(Dafny.Sequence<Dafny.Rune>.Concat(Dafny.Sequence<Dafny.Rune>.UnicodeFromString("'"), Dafny.Sequence<Dafny.Rune>.FromElements(new Dafny.Rune((int)(_4_b)))), Dafny.Sequence<Dafny.Rune>.UnicodeFromString("'"))) : (Dafny.Sequence<Dafny.Rune>.UnicodeFromString("EOF")));
          Dafny.ISequence<Dafny.Rune> _6_c0s = ((System.Func<Dafny.ISequence<Dafny.Rune>>) (() => {
            BigInteger dim9 = new BigInteger((_3_bs0).Count);
            var arr9 = new Dafny.Rune[Dafny.Helpers.ToIntChecked(dim9, "array size exceeds memory limit")];
            for (int i9 = 0; i9 < dim9; i9++) {
              var _7_idx = (BigInteger) i9;
              arr9[(int)(_7_idx)] = new Dafny.Rune((int)((_3_bs0).Select(_7_idx)));
            }
            return Dafny.Sequence<Dafny.Rune>.FromArray(arr9);
          }))();
          return Dafny.Sequence<Dafny.Rune>.Concat(Dafny.Sequence<Dafny.Rune>.Concat(Dafny.Sequence<Dafny.Rune>.Concat(Dafny.Sequence<Dafny.Rune>.UnicodeFromString("Expecting one of '"), _6_c0s), Dafny.Sequence<Dafny.Rune>.UnicodeFromString("', read ")), _5_c);
        }
      }
      {
        R _8_err = _source0.dtor_err;
        return Dafny.Helpers.Id<Func<R, Dafny.ISequence<Dafny.Rune>>>(pr)(_8_err);
      }
    }
  }
  public class CursorError_EOF<R> : CursorError<R> {
    public CursorError_EOF() : base() {
    }
    public override _ICursorError<__R> DowncastClone<__R>(Func<R, __R> converter0) {
      if (this is _ICursorError<__R> dt) { return dt; }
      return new CursorError_EOF<__R>();
    }
    public override bool Equals(object other) {
      var oth = other as Std.JSON.Utils.Cursors.CursorError_EOF<R>;
      return oth != null;
    }
    public override int GetHashCode() {
      ulong hash = 5381;
      hash = ((hash << 5) + hash) + 0;
      return (int) hash;
    }
    public override string ToString() {
      string s = "Cursors.CursorError.EOF";
      return s;
    }
  }
  public class CursorError_ExpectingByte<R> : CursorError<R> {
    public readonly byte _expected;
    public readonly short _b;
    public CursorError_ExpectingByte(byte expected, short b) : base() {
      this._expected = expected;
      this._b = b;
    }
    public override _ICursorError<__R> DowncastClone<__R>(Func<R, __R> converter0) {
      if (this is _ICursorError<__R> dt) { return dt; }
      return new CursorError_ExpectingByte<__R>(_expected, _b);
    }
    public override bool Equals(object other) {
      var oth = other as Std.JSON.Utils.Cursors.CursorError_ExpectingByte<R>;
      return oth != null && this._expected == oth._expected && this._b == oth._b;
    }
    public override int GetHashCode() {
      ulong hash = 5381;
      hash = ((hash << 5) + hash) + 1;
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this._expected));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this._b));
      return (int) hash;
    }
    public override string ToString() {
      string s = "Cursors.CursorError.ExpectingByte";
      s += "(";
      s += Dafny.Helpers.ToString(this._expected);
      s += ", ";
      s += Dafny.Helpers.ToString(this._b);
      s += ")";
      return s;
    }
  }
  public class CursorError_ExpectingAnyByte<R> : CursorError<R> {
    public readonly Dafny.ISequence<byte> _expected__sq;
    public readonly short _b;
    public CursorError_ExpectingAnyByte(Dafny.ISequence<byte> expected__sq, short b) : base() {
      this._expected__sq = expected__sq;
      this._b = b;
    }
    public override _ICursorError<__R> DowncastClone<__R>(Func<R, __R> converter0) {
      if (this is _ICursorError<__R> dt) { return dt; }
      return new CursorError_ExpectingAnyByte<__R>(_expected__sq, _b);
    }
    public override bool Equals(object other) {
      var oth = other as Std.JSON.Utils.Cursors.CursorError_ExpectingAnyByte<R>;
      return oth != null && object.Equals(this._expected__sq, oth._expected__sq) && this._b == oth._b;
    }
    public override int GetHashCode() {
      ulong hash = 5381;
      hash = ((hash << 5) + hash) + 2;
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this._expected__sq));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this._b));
      return (int) hash;
    }
    public override string ToString() {
      string s = "Cursors.CursorError.ExpectingAnyByte";
      s += "(";
      s += Dafny.Helpers.ToString(this._expected__sq);
      s += ", ";
      s += Dafny.Helpers.ToString(this._b);
      s += ")";
      return s;
    }
  }
  public class CursorError_OtherError<R> : CursorError<R> {
    public readonly R _err;
    public CursorError_OtherError(R err) : base() {
      this._err = err;
    }
    public override _ICursorError<__R> DowncastClone<__R>(Func<R, __R> converter0) {
      if (this is _ICursorError<__R> dt) { return dt; }
      return new CursorError_OtherError<__R>(converter0(_err));
    }
    public override bool Equals(object other) {
      var oth = other as Std.JSON.Utils.Cursors.CursorError_OtherError<R>;
      return oth != null && object.Equals(this._err, oth._err);
    }
    public override int GetHashCode() {
      ulong hash = 5381;
      hash = ((hash << 5) + hash) + 3;
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this._err));
      return (int) hash;
    }
    public override string ToString() {
      string s = "Cursors.CursorError.OtherError";
      s += "(";
      s += Dafny.Helpers.ToString(this._err);
      s += ")";
      return s;
    }
  }

  public interface _ICursor__ {
    bool is_Cursor { get; }
    Dafny.ISequence<byte> dtor_s { get; }
    uint dtor_beg { get; }
    uint dtor_point { get; }
    uint dtor_end { get; }
    _ICursor__ DowncastClone();
    bool BOF_q { get; }
    bool EOF_q { get; }
    Dafny.ISequence<byte> Bytes();
    Std.JSON.Utils.Views.Core._IView__ Prefix();
    Std.JSON.Utils.Cursors._ICursor__ Suffix();
    Std.JSON.Utils.Cursors._ISplit<Std.JSON.Utils.Views.Core._IView__> Split();
    uint PrefixLength();
    uint SuffixLength();
    uint Length();
    byte At(uint idx);
    byte SuffixAt(uint idx);
    short Peek();
    bool LookingAt(Dafny.Rune c);
    Std.JSON.Utils.Cursors._ICursor__ Skip(uint n);
    Std.JSON.Utils.Cursors._ICursor__ Unskip(uint n);
    Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ICursor__, Std.JSON.Utils.Cursors._ICursorError<__R>> Get<__R>(__R err);
    Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ICursor__, Std.JSON.Utils.Cursors._ICursorError<__R>> AssertByte<__R>(byte b);
    Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ICursor__, Std.JSON.Utils.Cursors._ICursorError<__R>> AssertBytes<__R>(Dafny.ISequence<byte> bs, uint offset);
    Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ICursor__, Std.JSON.Utils.Cursors._ICursorError<__R>> AssertChar<__R>(Dafny.Rune c0);
    Std.JSON.Utils.Cursors._ICursor__ SkipByte();
    Std.JSON.Utils.Cursors._ICursor__ SkipIf(Func<byte, bool> p);
    Std.JSON.Utils.Cursors._ICursor__ SkipWhile(Func<byte, bool> p);
    Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ICursor__, Std.JSON.Utils.Cursors._ICursorError<__R>> SkipWhileLexer<__A, __R>(Func<__A, short, Std.JSON.Utils.Lexers.Core._ILexerResult<__A, __R>> step, __A st);
  }
  public class Cursor__ : _ICursor__ {
    public readonly Dafny.ISequence<byte> _s;
    public readonly uint _beg;
    public readonly uint _point;
    public readonly uint _end;
    public Cursor__(Dafny.ISequence<byte> s, uint beg, uint point, uint end) {
      this._s = s;
      this._beg = beg;
      this._point = point;
      this._end = end;
    }
    public _ICursor__ DowncastClone() {
      if (this is _ICursor__ dt) { return dt; }
      return new Cursor__(_s, _beg, _point, _end);
    }
    public override bool Equals(object other) {
      var oth = other as Std.JSON.Utils.Cursors.Cursor__;
      return oth != null && object.Equals(this._s, oth._s) && this._beg == oth._beg && this._point == oth._point && this._end == oth._end;
    }
    public override int GetHashCode() {
      ulong hash = 5381;
      hash = ((hash << 5) + hash) + 0;
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this._s));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this._beg));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this._point));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this._end));
      return (int) hash;
    }
    public override string ToString() {
      string ss = "Cursors.Cursor_.Cursor";
      ss += "(";
      ss += Dafny.Helpers.ToString(this._s);
      ss += ", ";
      ss += Dafny.Helpers.ToString(this._beg);
      ss += ", ";
      ss += Dafny.Helpers.ToString(this._point);
      ss += ", ";
      ss += Dafny.Helpers.ToString(this._end);
      ss += ")";
      return ss;
    }
    private static readonly Std.JSON.Utils.Cursors._ICursor__ theDefault = create(Dafny.Sequence<byte>.Empty, 0, 0, 0);
    public static Std.JSON.Utils.Cursors._ICursor__ Default() {
      return theDefault;
    }
    private static readonly Dafny.TypeDescriptor<Std.JSON.Utils.Cursors._ICursor__> _TYPE = new Dafny.TypeDescriptor<Std.JSON.Utils.Cursors._ICursor__>(Std.JSON.Utils.Cursors.Cursor__.Default());
    public static Dafny.TypeDescriptor<Std.JSON.Utils.Cursors._ICursor__> _TypeDescriptor() {
      return _TYPE;
    }
    public static _ICursor__ create(Dafny.ISequence<byte> s, uint beg, uint point, uint end) {
      return new Cursor__(s, beg, point, end);
    }
    public static _ICursor__ create_Cursor(Dafny.ISequence<byte> s, uint beg, uint point, uint end) {
      return create(s, beg, point, end);
    }
    public bool is_Cursor { get { return true; } }
    public Dafny.ISequence<byte> dtor_s {
      get {
        return this._s;
      }
    }
    public uint dtor_beg {
      get {
        return this._beg;
      }
    }
    public uint dtor_point {
      get {
        return this._point;
      }
    }
    public uint dtor_end {
      get {
        return this._end;
      }
    }
    public static Std.JSON.Utils.Cursors._ICursor__ OfView(Std.JSON.Utils.Views.Core._IView__ v) {
      return Std.JSON.Utils.Cursors.Cursor__.create((v).dtor_s, (v).dtor_beg, (v).dtor_beg, (v).dtor_end);
    }
    public static Std.JSON.Utils.Cursors._ICursor__ OfBytes(Dafny.ISequence<byte> bs) {
      return Std.JSON.Utils.Cursors.Cursor__.create(bs, 0U, 0U, (uint)(bs).LongCount);
    }
    public Dafny.ISequence<byte> Bytes() {
      return ((this).dtor_s).Subsequence((this).dtor_beg, (this).dtor_end);
    }
    public Std.JSON.Utils.Views.Core._IView__ Prefix() {
      return Std.JSON.Utils.Views.Core.View__.create((this).dtor_s, (this).dtor_beg, (this).dtor_point);
    }
    public Std.JSON.Utils.Cursors._ICursor__ Suffix() {
      Std.JSON.Utils.Cursors._ICursor__ _0_dt__update__tmp_h0 = this;
      uint _1_dt__update_hbeg_h0 = (this).dtor_point;
      return Std.JSON.Utils.Cursors.Cursor__.create((_0_dt__update__tmp_h0).dtor_s, _1_dt__update_hbeg_h0, (_0_dt__update__tmp_h0).dtor_point, (_0_dt__update__tmp_h0).dtor_end);
    }
    public Std.JSON.Utils.Cursors._ISplit<Std.JSON.Utils.Views.Core._IView__> Split() {
      return Std.JSON.Utils.Cursors.Split<Std.JSON.Utils.Views.Core._IView__>.create((this).Prefix(), (this).Suffix());
    }
    public uint PrefixLength() {
      return ((this).dtor_point) - ((this).dtor_beg);
    }
    public uint SuffixLength() {
      return ((this).dtor_end) - ((this).dtor_point);
    }
    public uint Length() {
      return ((this).dtor_end) - ((this).dtor_beg);
    }
    public byte At(uint idx) {
      return ((this).dtor_s).Select(((this).dtor_beg) + (idx));
    }
    public byte SuffixAt(uint idx) {
      return ((this).dtor_s).Select(((this).dtor_point) + (idx));
    }
    public short Peek() {
      if ((this).EOF_q) {
        return (short)(-1);
      } else {
        return (short)((this).SuffixAt(0U));
      }
    }
    public bool LookingAt(Dafny.Rune c) {
      return ((this).Peek()) == ((short)((c).Value));
    }
    public Std.JSON.Utils.Cursors._ICursor__ Skip(uint n) {
      Std.JSON.Utils.Cursors._ICursor__ _0_dt__update__tmp_h0 = this;
      uint _1_dt__update_hpoint_h0 = ((this).dtor_point) + (n);
      return Std.JSON.Utils.Cursors.Cursor__.create((_0_dt__update__tmp_h0).dtor_s, (_0_dt__update__tmp_h0).dtor_beg, _1_dt__update_hpoint_h0, (_0_dt__update__tmp_h0).dtor_end);
    }
    public Std.JSON.Utils.Cursors._ICursor__ Unskip(uint n) {
      Std.JSON.Utils.Cursors._ICursor__ _0_dt__update__tmp_h0 = this;
      uint _1_dt__update_hpoint_h0 = ((this).dtor_point) - (n);
      return Std.JSON.Utils.Cursors.Cursor__.create((_0_dt__update__tmp_h0).dtor_s, (_0_dt__update__tmp_h0).dtor_beg, _1_dt__update_hpoint_h0, (_0_dt__update__tmp_h0).dtor_end);
    }
    public Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ICursor__, Std.JSON.Utils.Cursors._ICursorError<__R>> Get<__R>(__R err) {
      if ((this).EOF_q) {
        return Std.Wrappers.Result<Std.JSON.Utils.Cursors._ICursor__, Std.JSON.Utils.Cursors._ICursorError<__R>>.create_Failure(Std.JSON.Utils.Cursors.CursorError<__R>.create_OtherError(err));
      } else {
        return Std.Wrappers.Result<Std.JSON.Utils.Cursors._ICursor__, Std.JSON.Utils.Cursors._ICursorError<__R>>.create_Success((this).Skip(1U));
      }
    }
    public Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ICursor__, Std.JSON.Utils.Cursors._ICursorError<__R>> AssertByte<__R>(byte b) {
      short _0_nxt = (this).Peek();
      if ((_0_nxt) == ((short)(b))) {
        return Std.Wrappers.Result<Std.JSON.Utils.Cursors._ICursor__, Std.JSON.Utils.Cursors._ICursorError<__R>>.create_Success((this).Skip(1U));
      } else {
        return Std.Wrappers.Result<Std.JSON.Utils.Cursors._ICursor__, Std.JSON.Utils.Cursors._ICursorError<__R>>.create_Failure(Std.JSON.Utils.Cursors.CursorError<__R>.create_ExpectingByte(b, _0_nxt));
      }
    }
    public Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ICursor__, Std.JSON.Utils.Cursors._ICursorError<__R>> AssertBytes<__R>(Dafny.ISequence<byte> bs, uint offset)
    {
      _ICursor__ _this = this;
    TAIL_CALL_START: ;
      if ((offset) == ((uint)(bs).LongCount)) {
        return Std.Wrappers.Result<Std.JSON.Utils.Cursors._ICursor__, Std.JSON.Utils.Cursors._ICursorError<__R>>.create_Success(_this);
      } else {
        Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ICursor__, Std.JSON.Utils.Cursors._ICursorError<__R>> _0_valueOrError0 = (_this).AssertByte<__R>((bs).Select(offset));
        if ((_0_valueOrError0).IsFailure()) {
          return (_0_valueOrError0).PropagateFailure<Std.JSON.Utils.Cursors._ICursor__>();
        } else {
          Std.JSON.Utils.Cursors._ICursor__ _1_ps = (_0_valueOrError0).Extract();
          Std.JSON.Utils.Cursors._ICursor__ _in0 = _1_ps;
          Dafny.ISequence<byte> _in1 = bs;
          uint _in2 = (offset) + (1U);
          _this = _in0;
          ;
          bs = _in1;
          offset = _in2;
          goto TAIL_CALL_START;
        }
      }
    }
    public Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ICursor__, Std.JSON.Utils.Cursors._ICursorError<__R>> AssertChar<__R>(Dafny.Rune c0) {
      return (this).AssertByte<__R>((byte)((c0).Value));
    }
    public Std.JSON.Utils.Cursors._ICursor__ SkipByte() {
      if ((this).EOF_q) {
        return this;
      } else {
        return (this).Skip(1U);
      }
    }
    public Std.JSON.Utils.Cursors._ICursor__ SkipIf(Func<byte, bool> p) {
      if (((this).EOF_q) || (!(Dafny.Helpers.Id<Func<byte, bool>>(p)((this).SuffixAt(0U))))) {
        return this;
      } else {
        return (this).Skip(1U);
      }
    }
    public Std.JSON.Utils.Cursors._ICursor__ SkipWhile(Func<byte, bool> p)
    {
      Std.JSON.Utils.Cursors._ICursor__ ps = Std.JSON.Utils.Cursors.Cursor.Default();
      uint _0_point_k;
      _0_point_k = (this).dtor_point;
      uint _1_end;
      _1_end = (this).dtor_end;
      while (((_0_point_k) < (_1_end)) && (Dafny.Helpers.Id<Func<byte, bool>>(p)(((this).dtor_s).Select(_0_point_k)))) {
        _0_point_k = (_0_point_k) + (1U);
      }
      ps = Std.JSON.Utils.Cursors.Cursor__.create((this).dtor_s, (this).dtor_beg, _0_point_k, (this).dtor_end);
      return ps;
      return ps;
    }
    public Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ICursor__, Std.JSON.Utils.Cursors._ICursorError<__R>> SkipWhileLexer<__A, __R>(Func<__A, short, Std.JSON.Utils.Lexers.Core._ILexerResult<__A, __R>> step, __A st)
    {
      Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ICursor__, Std.JSON.Utils.Cursors._ICursorError<__R>> pr = Std.Wrappers.Result<Std.JSON.Utils.Cursors._ICursor__, Std.JSON.Utils.Cursors._ICursorError<__R>>.Default(Std.JSON.Utils.Cursors.Cursor.Default());
      uint _0_point_k;
      _0_point_k = (this).dtor_point;
      uint _1_end;
      _1_end = (this).dtor_end;
      __A _2_st_k;
      _2_st_k = st;
      while (true) {
        bool _3_eof;
        _3_eof = (_0_point_k) == (_1_end);
        short _4_minusone;
        _4_minusone = (short)(-1);
        short _5_c;
        if (_3_eof) {
          _5_c = _4_minusone;
        } else {
          _5_c = (short)(((this).dtor_s).Select(_0_point_k));
        }
        Std.JSON.Utils.Lexers.Core._ILexerResult<__A, __R> _source0 = Dafny.Helpers.Id<Func<__A, short, Std.JSON.Utils.Lexers.Core._ILexerResult<__A, __R>>>(step)(_2_st_k, _5_c);
        {
          if (_source0.is_Accept) {
            pr = Std.Wrappers.Result<Std.JSON.Utils.Cursors._ICursor__, Std.JSON.Utils.Cursors._ICursorError<__R>>.create_Success(Std.JSON.Utils.Cursors.Cursor__.create((this).dtor_s, (this).dtor_beg, _0_point_k, (this).dtor_end));
            return pr;
            goto after_match0;
          }
        }
        {
          if (_source0.is_Reject) {
            __R _6_err = _source0.dtor_err;
            pr = Std.Wrappers.Result<Std.JSON.Utils.Cursors._ICursor__, Std.JSON.Utils.Cursors._ICursorError<__R>>.create_Failure(Std.JSON.Utils.Cursors.CursorError<__R>.create_OtherError(_6_err));
            return pr;
            goto after_match0;
          }
        }
        {
          __A _7_st_k_k = _source0.dtor_st;
          if (_3_eof) {
            pr = Std.Wrappers.Result<Std.JSON.Utils.Cursors._ICursor__, Std.JSON.Utils.Cursors._ICursorError<__R>>.create_Failure(Std.JSON.Utils.Cursors.CursorError<__R>.create_EOF());
            return pr;
          } else {
            _2_st_k = _7_st_k_k;
            _0_point_k = (_0_point_k) + (1U);
          }
        }
      after_match0: ;
      }
      return pr;
    }
    public bool BOF_q { get {
      return ((this).dtor_point) == ((this).dtor_beg);
    } }
    public bool EOF_q { get {
      return ((this).dtor_point) == ((this).dtor_end);
    } }
  }
} // end of namespace Std.JSON.Utils.Cursors
namespace Std.JSON.Utils.Parsers {

  public partial class __default {
    public static Func<Std.JSON.Utils.Cursors._ICursor__, Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<__T>, Std.JSON.Utils.Cursors._ICursorError<__R>>> ParserWitness<__T, __R>() {
      return ((System.Func<Std.JSON.Utils.Cursors._ICursor__, Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<__T>, Std.JSON.Utils.Cursors._ICursorError<__R>>>)((_0___v9) => {
        return Std.Wrappers.Result<Std.JSON.Utils.Cursors._ISplit<__T>, Std.JSON.Utils.Cursors._ICursorError<__R>>.create_Failure(Std.JSON.Utils.Cursors.CursorError<__R>.create_EOF());
      }));
    }
    public static Func<Std.JSON.Utils.Cursors._ICursor__, Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<__T>, Std.JSON.Utils.Cursors._ICursorError<__R>>> SubParserWitness<__T, __R>() {
      return ((System.Func<Std.JSON.Utils.Cursors._ICursor__, Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<__T>, Std.JSON.Utils.Cursors._ICursorError<__R>>>)((_0_cs) => {
        return Std.Wrappers.Result<Std.JSON.Utils.Cursors._ISplit<__T>, Std.JSON.Utils.Cursors._ICursorError<__R>>.create_Failure(Std.JSON.Utils.Cursors.CursorError<__R>.create_EOF());
      }));
    }
  }

  public partial class Parser<T, R> {
    public static Func<Std.JSON.Utils.Cursors._ICursor__, Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<T>, Std.JSON.Utils.Cursors._ICursorError<R>>> Default() {
      return Std.JSON.Utils.Parsers.__default.ParserWitness<T, R>();
    }
    public static Dafny.TypeDescriptor<Func<Std.JSON.Utils.Cursors._ICursor__, Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<T>, Std.JSON.Utils.Cursors._ICursorError<R>>>> _TypeDescriptor(Dafny.TypeDescriptor<T> _td_T, Dafny.TypeDescriptor<R> _td_R) {
      return new Dafny.TypeDescriptor<Func<Std.JSON.Utils.Cursors._ICursor__, Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<T>, Std.JSON.Utils.Cursors._ICursorError<R>>>>(Std.JSON.Utils.Parsers.Parser<T, R>.Default());
    }
  }

  public interface _IParser__<T, out R> {
    bool is_Parser { get; }
    Func<Std.JSON.Utils.Cursors._ICursor__, Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<T>, Std.JSON.Utils.Cursors._ICursorError<R>>> dtor_fn { get; }
  }
  public class Parser__<T, R> : _IParser__<T, R> {
    public readonly Func<Std.JSON.Utils.Cursors._ICursor__, Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<T>, Std.JSON.Utils.Cursors._ICursorError<R>>> _fn;
    public Parser__(Func<Std.JSON.Utils.Cursors._ICursor__, Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<T>, Std.JSON.Utils.Cursors._ICursorError<R>>> fn) {
      this._fn = fn;
    }
    public static Func<Std.JSON.Utils.Cursors._ICursor__, Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<__T>, Std.JSON.Utils.Cursors._ICursorError<__R>>> DowncastClone<__T, __R>(Func<Std.JSON.Utils.Cursors._ICursor__, Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<T>, Std.JSON.Utils.Cursors._ICursorError<R>>> _this, Func<T, __T> converter0, Func<R, __R> converter1) {
      return (_this).DowncastClone<Std.JSON.Utils.Cursors._ICursor__, Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<T>, Std.JSON.Utils.Cursors._ICursorError<R>>, Std.JSON.Utils.Cursors._ICursor__, Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<__T>, Std.JSON.Utils.Cursors._ICursorError<__R>>>(Dafny.Helpers.Id<Std.JSON.Utils.Cursors._ICursor__>, Dafny.Helpers.CastConverter<Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<T>, Std.JSON.Utils.Cursors._ICursorError<R>>, Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<__T>, Std.JSON.Utils.Cursors._ICursorError<__R>>>);
    }
    public override bool Equals(object other) {
      var oth = other as Std.JSON.Utils.Parsers.Parser__<T, R>;
      return oth != null && object.Equals(this._fn, oth._fn);
    }
    public override int GetHashCode() {
      ulong hash = 5381;
      hash = ((hash << 5) + hash) + 0;
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this._fn));
      return (int) hash;
    }
    public override string ToString() {
      string s = "Parsers.Parser_.Parser";
      s += "(";
      s += Dafny.Helpers.ToString(this._fn);
      s += ")";
      return s;
    }
    public static Func<Std.JSON.Utils.Cursors._ICursor__, Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<T>, Std.JSON.Utils.Cursors._ICursorError<R>>> Default(T _default_T) {
      return ((Std.JSON.Utils.Cursors._ICursor__ x0) => Std.Wrappers.Result<Std.JSON.Utils.Cursors._ISplit<T>, Std.JSON.Utils.Cursors._ICursorError<R>>.Default(Std.JSON.Utils.Cursors.Split<T>.Default(_default_T)));
    }
    public static Dafny.TypeDescriptor<Func<Std.JSON.Utils.Cursors._ICursor__, Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<T>, Std.JSON.Utils.Cursors._ICursorError<R>>>> _TypeDescriptor(Dafny.TypeDescriptor<T> _td_T) {
      return new Dafny.TypeDescriptor<Func<Std.JSON.Utils.Cursors._ICursor__, Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<T>, Std.JSON.Utils.Cursors._ICursorError<R>>>>(((Std.JSON.Utils.Cursors._ICursor__ x1) => Std.Wrappers.Result<Std.JSON.Utils.Cursors._ISplit<T>, Std.JSON.Utils.Cursors._ICursorError<R>>.Default(Std.JSON.Utils.Cursors.Split<T>.Default(_td_T.Default()))));
    }
    public static _IParser__<T, R> create(Func<Std.JSON.Utils.Cursors._ICursor__, Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<T>, Std.JSON.Utils.Cursors._ICursorError<R>>> fn) {
      return new Parser__<T, R>(fn);
    }
    public static _IParser__<T, R> create_Parser(Func<Std.JSON.Utils.Cursors._ICursor__, Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<T>, Std.JSON.Utils.Cursors._ICursorError<R>>> fn) {
      return create(fn);
    }
    public bool is_Parser { get { return true; } }
    public Func<Std.JSON.Utils.Cursors._ICursor__, Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<T>, Std.JSON.Utils.Cursors._ICursorError<R>>> dtor_fn {
      get {
        return this._fn;
      }
    }
  }

  public interface _ISubParser__<T, out R> {
    bool is_SubParser { get; }
    Func<Std.JSON.Utils.Cursors._ICursor__, Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<T>, Std.JSON.Utils.Cursors._ICursorError<R>>> dtor_fn { get; }
  }
  public class SubParser__<T, R> : _ISubParser__<T, R> {
    public readonly Func<Std.JSON.Utils.Cursors._ICursor__, Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<T>, Std.JSON.Utils.Cursors._ICursorError<R>>> _fn;
    public SubParser__(Func<Std.JSON.Utils.Cursors._ICursor__, Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<T>, Std.JSON.Utils.Cursors._ICursorError<R>>> fn) {
      this._fn = fn;
    }
    public static Func<Std.JSON.Utils.Cursors._ICursor__, Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<__T>, Std.JSON.Utils.Cursors._ICursorError<__R>>> DowncastClone<__T, __R>(Func<Std.JSON.Utils.Cursors._ICursor__, Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<T>, Std.JSON.Utils.Cursors._ICursorError<R>>> _this, Func<T, __T> converter0, Func<R, __R> converter1) {
      return (_this).DowncastClone<Std.JSON.Utils.Cursors._ICursor__, Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<T>, Std.JSON.Utils.Cursors._ICursorError<R>>, Std.JSON.Utils.Cursors._ICursor__, Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<__T>, Std.JSON.Utils.Cursors._ICursorError<__R>>>(Dafny.Helpers.Id<Std.JSON.Utils.Cursors._ICursor__>, Dafny.Helpers.CastConverter<Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<T>, Std.JSON.Utils.Cursors._ICursorError<R>>, Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<__T>, Std.JSON.Utils.Cursors._ICursorError<__R>>>);
    }
    public override bool Equals(object other) {
      var oth = other as Std.JSON.Utils.Parsers.SubParser__<T, R>;
      return oth != null && object.Equals(this._fn, oth._fn);
    }
    public override int GetHashCode() {
      ulong hash = 5381;
      hash = ((hash << 5) + hash) + 0;
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this._fn));
      return (int) hash;
    }
    public override string ToString() {
      string s = "Parsers.SubParser_.SubParser";
      s += "(";
      s += Dafny.Helpers.ToString(this._fn);
      s += ")";
      return s;
    }
    public static Func<Std.JSON.Utils.Cursors._ICursor__, Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<T>, Std.JSON.Utils.Cursors._ICursorError<R>>> Default() {
      return ((Func<Std.JSON.Utils.Cursors._ICursor__, Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<T>, Std.JSON.Utils.Cursors._ICursorError<R>>>)null);
    }
    public static Dafny.TypeDescriptor<Func<Std.JSON.Utils.Cursors._ICursor__, Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<T>, Std.JSON.Utils.Cursors._ICursorError<R>>>> _TypeDescriptor() {
      return new Dafny.TypeDescriptor<Func<Std.JSON.Utils.Cursors._ICursor__, Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<T>, Std.JSON.Utils.Cursors._ICursorError<R>>>>(((Func<Std.JSON.Utils.Cursors._ICursor__, Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<T>, Std.JSON.Utils.Cursors._ICursorError<R>>>)null));
    }
    public static _ISubParser__<T, R> create(Func<Std.JSON.Utils.Cursors._ICursor__, Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<T>, Std.JSON.Utils.Cursors._ICursorError<R>>> fn) {
      return new SubParser__<T, R>(fn);
    }
    public static _ISubParser__<T, R> create_SubParser(Func<Std.JSON.Utils.Cursors._ICursor__, Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<T>, Std.JSON.Utils.Cursors._ICursorError<R>>> fn) {
      return create(fn);
    }
    public bool is_SubParser { get { return true; } }
    public Func<Std.JSON.Utils.Cursors._ICursor__, Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<T>, Std.JSON.Utils.Cursors._ICursorError<R>>> dtor_fn {
      get {
        return this._fn;
      }
    }
  }

  public partial class SubParser<T, R> {
    public static Func<Std.JSON.Utils.Cursors._ICursor__, Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<T>, Std.JSON.Utils.Cursors._ICursorError<R>>> Default() {
      return Std.JSON.Utils.Parsers.__default.SubParserWitness<T, R>();
    }
    public static Dafny.TypeDescriptor<Func<Std.JSON.Utils.Cursors._ICursor__, Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<T>, Std.JSON.Utils.Cursors._ICursorError<R>>>> _TypeDescriptor(Dafny.TypeDescriptor<T> _td_T, Dafny.TypeDescriptor<R> _td_R) {
      return new Dafny.TypeDescriptor<Func<Std.JSON.Utils.Cursors._ICursor__, Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<T>, Std.JSON.Utils.Cursors._ICursorError<R>>>>(Std.JSON.Utils.Parsers.SubParser<T, R>.Default());
    }
  }
} // end of namespace Std.JSON.Utils.Parsers
namespace Std.JSON.Utils {

} // end of namespace Std.JSON.Utils
namespace Std.JSON.Grammar {

  public partial class __default {
    public static bool Blank_q(byte b) {
      return ((((b) == ((byte)(32))) || ((b) == ((byte)(9)))) || ((b) == ((byte)(10)))) || ((b) == ((byte)(13)));
    }
    public static bool Digit_q(byte b) {
      return (((byte)((new Dafny.Rune('0')).Value)) <= (b)) && ((b) <= ((byte)((new Dafny.Rune('9')).Value)));
    }
    public static Dafny.ISequence<byte> NULL { get {
      return Dafny.Sequence<byte>.FromElements((byte)((new Dafny.Rune('n')).Value), (byte)((new Dafny.Rune('u')).Value), (byte)((new Dafny.Rune('l')).Value), (byte)((new Dafny.Rune('l')).Value));
    } }
    public static Dafny.ISequence<byte> TRUE { get {
      return Dafny.Sequence<byte>.FromElements((byte)((new Dafny.Rune('t')).Value), (byte)((new Dafny.Rune('r')).Value), (byte)((new Dafny.Rune('u')).Value), (byte)((new Dafny.Rune('e')).Value));
    } }
    public static Dafny.ISequence<byte> FALSE { get {
      return Dafny.Sequence<byte>.FromElements((byte)((new Dafny.Rune('f')).Value), (byte)((new Dafny.Rune('a')).Value), (byte)((new Dafny.Rune('l')).Value), (byte)((new Dafny.Rune('s')).Value), (byte)((new Dafny.Rune('e')).Value));
    } }
    public static Std.JSON.Utils.Views.Core._IView__ DOUBLEQUOTE { get {
      return Std.JSON.Utils.Views.Core.View__.OfBytes(Dafny.Sequence<byte>.FromElements((byte)((new Dafny.Rune('\"')).Value)));
    } }
    public static Std.JSON.Utils.Views.Core._IView__ PERIOD { get {
      return Std.JSON.Utils.Views.Core.View__.OfBytes(Dafny.Sequence<byte>.FromElements((byte)((new Dafny.Rune('.')).Value)));
    } }
    public static Std.JSON.Utils.Views.Core._IView__ E { get {
      return Std.JSON.Utils.Views.Core.View__.OfBytes(Dafny.Sequence<byte>.FromElements((byte)((new Dafny.Rune('e')).Value)));
    } }
    public static Std.JSON.Utils.Views.Core._IView__ COLON { get {
      return Std.JSON.Utils.Views.Core.View__.OfBytes(Dafny.Sequence<byte>.FromElements((byte)((new Dafny.Rune(':')).Value)));
    } }
    public static Std.JSON.Utils.Views.Core._IView__ COMMA { get {
      return Std.JSON.Utils.Views.Core.View__.OfBytes(Dafny.Sequence<byte>.FromElements((byte)((new Dafny.Rune(',')).Value)));
    } }
    public static Std.JSON.Utils.Views.Core._IView__ LBRACE { get {
      return Std.JSON.Utils.Views.Core.View__.OfBytes(Dafny.Sequence<byte>.FromElements((byte)((new Dafny.Rune('{')).Value)));
    } }
    public static Std.JSON.Utils.Views.Core._IView__ RBRACE { get {
      return Std.JSON.Utils.Views.Core.View__.OfBytes(Dafny.Sequence<byte>.FromElements((byte)((new Dafny.Rune('}')).Value)));
    } }
    public static Std.JSON.Utils.Views.Core._IView__ LBRACKET { get {
      return Std.JSON.Utils.Views.Core.View__.OfBytes(Dafny.Sequence<byte>.FromElements((byte)((new Dafny.Rune('[')).Value)));
    } }
    public static Std.JSON.Utils.Views.Core._IView__ RBRACKET { get {
      return Std.JSON.Utils.Views.Core.View__.OfBytes(Dafny.Sequence<byte>.FromElements((byte)((new Dafny.Rune(']')).Value)));
    } }
    public static Std.JSON.Utils.Views.Core._IView__ MINUS { get {
      return Std.JSON.Utils.Views.Core.View__.OfBytes(Dafny.Sequence<byte>.FromElements((byte)((new Dafny.Rune('-')).Value)));
    } }
    public static Std.JSON.Utils.Views.Core._IView__ EMPTY { get {
      return Std.JSON.Utils.Views.Core.View__.OfBytes(Dafny.Sequence<byte>.FromElements());
    } }
  }

  public partial class jchar {
    private static readonly Std.JSON.Utils.Views.Core._IView__ Witness = Std.JSON.Utils.Views.Core.View__.OfBytes(Dafny.Sequence<byte>.FromElements((byte)((new Dafny.Rune('b')).Value)));
    public static Std.JSON.Utils.Views.Core._IView__ Default() {
      return Witness;
    }
    private static readonly Dafny.TypeDescriptor<Std.JSON.Utils.Views.Core._IView__> _TYPE = new Dafny.TypeDescriptor<Std.JSON.Utils.Views.Core._IView__>(Std.JSON.Grammar.jchar.Default());
    public static Dafny.TypeDescriptor<Std.JSON.Utils.Views.Core._IView__> _TypeDescriptor() {
      return _TYPE;
    }
  }

  public partial class jquote {
    private static readonly Std.JSON.Utils.Views.Core._IView__ Witness = Std.JSON.Grammar.__default.DOUBLEQUOTE;
    public static Std.JSON.Utils.Views.Core._IView__ Default() {
      return Witness;
    }
    private static readonly Dafny.TypeDescriptor<Std.JSON.Utils.Views.Core._IView__> _TYPE = new Dafny.TypeDescriptor<Std.JSON.Utils.Views.Core._IView__>(Std.JSON.Grammar.jquote.Default());
    public static Dafny.TypeDescriptor<Std.JSON.Utils.Views.Core._IView__> _TypeDescriptor() {
      return _TYPE;
    }
  }

  public partial class jperiod {
    private static readonly Std.JSON.Utils.Views.Core._IView__ Witness = Std.JSON.Grammar.__default.PERIOD;
    public static Std.JSON.Utils.Views.Core._IView__ Default() {
      return Witness;
    }
    private static readonly Dafny.TypeDescriptor<Std.JSON.Utils.Views.Core._IView__> _TYPE = new Dafny.TypeDescriptor<Std.JSON.Utils.Views.Core._IView__>(Std.JSON.Grammar.jperiod.Default());
    public static Dafny.TypeDescriptor<Std.JSON.Utils.Views.Core._IView__> _TypeDescriptor() {
      return _TYPE;
    }
  }

  public partial class je {
    private static readonly Std.JSON.Utils.Views.Core._IView__ Witness = Std.JSON.Grammar.__default.E;
    public static Std.JSON.Utils.Views.Core._IView__ Default() {
      return Witness;
    }
    private static readonly Dafny.TypeDescriptor<Std.JSON.Utils.Views.Core._IView__> _TYPE = new Dafny.TypeDescriptor<Std.JSON.Utils.Views.Core._IView__>(Std.JSON.Grammar.je.Default());
    public static Dafny.TypeDescriptor<Std.JSON.Utils.Views.Core._IView__> _TypeDescriptor() {
      return _TYPE;
    }
  }

  public partial class jcolon {
    private static readonly Std.JSON.Utils.Views.Core._IView__ Witness = Std.JSON.Grammar.__default.COLON;
    public static Std.JSON.Utils.Views.Core._IView__ Default() {
      return Witness;
    }
    private static readonly Dafny.TypeDescriptor<Std.JSON.Utils.Views.Core._IView__> _TYPE = new Dafny.TypeDescriptor<Std.JSON.Utils.Views.Core._IView__>(Std.JSON.Grammar.jcolon.Default());
    public static Dafny.TypeDescriptor<Std.JSON.Utils.Views.Core._IView__> _TypeDescriptor() {
      return _TYPE;
    }
  }

  public partial class jcomma {
    private static readonly Std.JSON.Utils.Views.Core._IView__ Witness = Std.JSON.Grammar.__default.COMMA;
    public static Std.JSON.Utils.Views.Core._IView__ Default() {
      return Witness;
    }
    private static readonly Dafny.TypeDescriptor<Std.JSON.Utils.Views.Core._IView__> _TYPE = new Dafny.TypeDescriptor<Std.JSON.Utils.Views.Core._IView__>(Std.JSON.Grammar.jcomma.Default());
    public static Dafny.TypeDescriptor<Std.JSON.Utils.Views.Core._IView__> _TypeDescriptor() {
      return _TYPE;
    }
  }

  public partial class jlbrace {
    private static readonly Std.JSON.Utils.Views.Core._IView__ Witness = Std.JSON.Grammar.__default.LBRACE;
    public static Std.JSON.Utils.Views.Core._IView__ Default() {
      return Witness;
    }
    private static readonly Dafny.TypeDescriptor<Std.JSON.Utils.Views.Core._IView__> _TYPE = new Dafny.TypeDescriptor<Std.JSON.Utils.Views.Core._IView__>(Std.JSON.Grammar.jlbrace.Default());
    public static Dafny.TypeDescriptor<Std.JSON.Utils.Views.Core._IView__> _TypeDescriptor() {
      return _TYPE;
    }
  }

  public partial class jrbrace {
    private static readonly Std.JSON.Utils.Views.Core._IView__ Witness = Std.JSON.Grammar.__default.RBRACE;
    public static Std.JSON.Utils.Views.Core._IView__ Default() {
      return Witness;
    }
    private static readonly Dafny.TypeDescriptor<Std.JSON.Utils.Views.Core._IView__> _TYPE = new Dafny.TypeDescriptor<Std.JSON.Utils.Views.Core._IView__>(Std.JSON.Grammar.jrbrace.Default());
    public static Dafny.TypeDescriptor<Std.JSON.Utils.Views.Core._IView__> _TypeDescriptor() {
      return _TYPE;
    }
  }

  public partial class jlbracket {
    private static readonly Std.JSON.Utils.Views.Core._IView__ Witness = Std.JSON.Grammar.__default.LBRACKET;
    public static Std.JSON.Utils.Views.Core._IView__ Default() {
      return Witness;
    }
    private static readonly Dafny.TypeDescriptor<Std.JSON.Utils.Views.Core._IView__> _TYPE = new Dafny.TypeDescriptor<Std.JSON.Utils.Views.Core._IView__>(Std.JSON.Grammar.jlbracket.Default());
    public static Dafny.TypeDescriptor<Std.JSON.Utils.Views.Core._IView__> _TypeDescriptor() {
      return _TYPE;
    }
  }

  public partial class jrbracket {
    private static readonly Std.JSON.Utils.Views.Core._IView__ Witness = Std.JSON.Grammar.__default.RBRACKET;
    public static Std.JSON.Utils.Views.Core._IView__ Default() {
      return Witness;
    }
    private static readonly Dafny.TypeDescriptor<Std.JSON.Utils.Views.Core._IView__> _TYPE = new Dafny.TypeDescriptor<Std.JSON.Utils.Views.Core._IView__>(Std.JSON.Grammar.jrbracket.Default());
    public static Dafny.TypeDescriptor<Std.JSON.Utils.Views.Core._IView__> _TypeDescriptor() {
      return _TYPE;
    }
  }

  public partial class jminus {
    private static readonly Std.JSON.Utils.Views.Core._IView__ Witness = Std.JSON.Grammar.__default.MINUS;
    public static Std.JSON.Utils.Views.Core._IView__ Default() {
      return Witness;
    }
    private static readonly Dafny.TypeDescriptor<Std.JSON.Utils.Views.Core._IView__> _TYPE = new Dafny.TypeDescriptor<Std.JSON.Utils.Views.Core._IView__>(Std.JSON.Grammar.jminus.Default());
    public static Dafny.TypeDescriptor<Std.JSON.Utils.Views.Core._IView__> _TypeDescriptor() {
      return _TYPE;
    }
  }

  public partial class jsign {
    private static readonly Std.JSON.Utils.Views.Core._IView__ Witness = Std.JSON.Grammar.__default.EMPTY;
    public static Std.JSON.Utils.Views.Core._IView__ Default() {
      return Witness;
    }
    private static readonly Dafny.TypeDescriptor<Std.JSON.Utils.Views.Core._IView__> _TYPE = new Dafny.TypeDescriptor<Std.JSON.Utils.Views.Core._IView__>(Std.JSON.Grammar.jsign.Default());
    public static Dafny.TypeDescriptor<Std.JSON.Utils.Views.Core._IView__> _TypeDescriptor() {
      return _TYPE;
    }
  }

  public partial class jblanks {
    private static readonly Std.JSON.Utils.Views.Core._IView__ Witness = Std.JSON.Utils.Views.Core.View__.OfBytes(Dafny.Sequence<byte>.FromElements());
    public static Std.JSON.Utils.Views.Core._IView__ Default() {
      return Witness;
    }
    private static readonly Dafny.TypeDescriptor<Std.JSON.Utils.Views.Core._IView__> _TYPE = new Dafny.TypeDescriptor<Std.JSON.Utils.Views.Core._IView__>(Std.JSON.Grammar.jblanks.Default());
    public static Dafny.TypeDescriptor<Std.JSON.Utils.Views.Core._IView__> _TypeDescriptor() {
      return _TYPE;
    }
  }

  public interface _IStructural<out T> {
    bool is_Structural { get; }
    Std.JSON.Utils.Views.Core._IView__ dtor_before { get; }
    T dtor_t { get; }
    Std.JSON.Utils.Views.Core._IView__ dtor_after { get; }
    _IStructural<__T> DowncastClone<__T>(Func<T, __T> converter0);
  }
  public class Structural<T> : _IStructural<T> {
    public readonly Std.JSON.Utils.Views.Core._IView__ _before;
    public readonly T _t;
    public readonly Std.JSON.Utils.Views.Core._IView__ _after;
    public Structural(Std.JSON.Utils.Views.Core._IView__ before, T t, Std.JSON.Utils.Views.Core._IView__ after) {
      this._before = before;
      this._t = t;
      this._after = after;
    }
    public _IStructural<__T> DowncastClone<__T>(Func<T, __T> converter0) {
      if (this is _IStructural<__T> dt) { return dt; }
      return new Structural<__T>(_before, converter0(_t), _after);
    }
    public override bool Equals(object other) {
      var oth = other as Std.JSON.Grammar.Structural<T>;
      return oth != null && object.Equals(this._before, oth._before) && object.Equals(this._t, oth._t) && object.Equals(this._after, oth._after);
    }
    public override int GetHashCode() {
      ulong hash = 5381;
      hash = ((hash << 5) + hash) + 0;
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this._before));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this._t));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this._after));
      return (int) hash;
    }
    public override string ToString() {
      string s = "Grammar.Structural.Structural";
      s += "(";
      s += Dafny.Helpers.ToString(this._before);
      s += ", ";
      s += Dafny.Helpers.ToString(this._t);
      s += ", ";
      s += Dafny.Helpers.ToString(this._after);
      s += ")";
      return s;
    }
    public static Std.JSON.Grammar._IStructural<T> Default(T _default_T) {
      return create(Std.JSON.Grammar.jblanks.Default(), _default_T, Std.JSON.Grammar.jblanks.Default());
    }
    public static Dafny.TypeDescriptor<Std.JSON.Grammar._IStructural<T>> _TypeDescriptor(Dafny.TypeDescriptor<T> _td_T) {
      return new Dafny.TypeDescriptor<Std.JSON.Grammar._IStructural<T>>(Std.JSON.Grammar.Structural<T>.Default(_td_T.Default()));
    }
    public static _IStructural<T> create(Std.JSON.Utils.Views.Core._IView__ before, T t, Std.JSON.Utils.Views.Core._IView__ after) {
      return new Structural<T>(before, t, after);
    }
    public static _IStructural<T> create_Structural(Std.JSON.Utils.Views.Core._IView__ before, T t, Std.JSON.Utils.Views.Core._IView__ after) {
      return create(before, t, after);
    }
    public bool is_Structural { get { return true; } }
    public Std.JSON.Utils.Views.Core._IView__ dtor_before {
      get {
        return this._before;
      }
    }
    public T dtor_t {
      get {
        return this._t;
      }
    }
    public Std.JSON.Utils.Views.Core._IView__ dtor_after {
      get {
        return this._after;
      }
    }
  }

  public interface _IMaybe<out T> {
    bool is_Empty { get; }
    bool is_NonEmpty { get; }
    T dtor_t { get; }
    _IMaybe<__T> DowncastClone<__T>(Func<T, __T> converter0);
  }
  public abstract class Maybe<T> : _IMaybe<T> {
    public Maybe() {
    }
    public static Std.JSON.Grammar._IMaybe<T> Default() {
      return create_Empty();
    }
    public static Dafny.TypeDescriptor<Std.JSON.Grammar._IMaybe<T>> _TypeDescriptor() {
      return new Dafny.TypeDescriptor<Std.JSON.Grammar._IMaybe<T>>(Std.JSON.Grammar.Maybe<T>.Default());
    }
    public static _IMaybe<T> create_Empty() {
      return new Maybe_Empty<T>();
    }
    public static _IMaybe<T> create_NonEmpty(T t) {
      return new Maybe_NonEmpty<T>(t);
    }
    public bool is_Empty { get { return this is Maybe_Empty<T>; } }
    public bool is_NonEmpty { get { return this is Maybe_NonEmpty<T>; } }
    public T dtor_t {
      get {
        var d = this;
        return ((Maybe_NonEmpty<T>)d)._t;
      }
    }
    public abstract _IMaybe<__T> DowncastClone<__T>(Func<T, __T> converter0);
  }
  public class Maybe_Empty<T> : Maybe<T> {
    public Maybe_Empty() : base() {
    }
    public override _IMaybe<__T> DowncastClone<__T>(Func<T, __T> converter0) {
      if (this is _IMaybe<__T> dt) { return dt; }
      return new Maybe_Empty<__T>();
    }
    public override bool Equals(object other) {
      var oth = other as Std.JSON.Grammar.Maybe_Empty<T>;
      return oth != null;
    }
    public override int GetHashCode() {
      ulong hash = 5381;
      hash = ((hash << 5) + hash) + 0;
      return (int) hash;
    }
    public override string ToString() {
      string s = "Grammar.Maybe.Empty";
      return s;
    }
  }
  public class Maybe_NonEmpty<T> : Maybe<T> {
    public readonly T _t;
    public Maybe_NonEmpty(T t) : base() {
      this._t = t;
    }
    public override _IMaybe<__T> DowncastClone<__T>(Func<T, __T> converter0) {
      if (this is _IMaybe<__T> dt) { return dt; }
      return new Maybe_NonEmpty<__T>(converter0(_t));
    }
    public override bool Equals(object other) {
      var oth = other as Std.JSON.Grammar.Maybe_NonEmpty<T>;
      return oth != null && object.Equals(this._t, oth._t);
    }
    public override int GetHashCode() {
      ulong hash = 5381;
      hash = ((hash << 5) + hash) + 1;
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this._t));
      return (int) hash;
    }
    public override string ToString() {
      string s = "Grammar.Maybe.NonEmpty";
      s += "(";
      s += Dafny.Helpers.ToString(this._t);
      s += ")";
      return s;
    }
  }

  public interface _ISuffixed<out T, out S> {
    bool is_Suffixed { get; }
    T dtor_t { get; }
    Std.JSON.Grammar._IMaybe<Std.JSON.Grammar._IStructural<S>> dtor_suffix { get; }
    _ISuffixed<__T, __S> DowncastClone<__T, __S>(Func<T, __T> converter0, Func<S, __S> converter1);
  }
  public class Suffixed<T, S> : _ISuffixed<T, S> {
    public readonly T _t;
    public readonly Std.JSON.Grammar._IMaybe<Std.JSON.Grammar._IStructural<S>> _suffix;
    public Suffixed(T t, Std.JSON.Grammar._IMaybe<Std.JSON.Grammar._IStructural<S>> suffix) {
      this._t = t;
      this._suffix = suffix;
    }
    public _ISuffixed<__T, __S> DowncastClone<__T, __S>(Func<T, __T> converter0, Func<S, __S> converter1) {
      if (this is _ISuffixed<__T, __S> dt) { return dt; }
      return new Suffixed<__T, __S>(converter0(_t), (_suffix).DowncastClone<Std.JSON.Grammar._IStructural<__S>>(Dafny.Helpers.CastConverter<Std.JSON.Grammar._IStructural<S>, Std.JSON.Grammar._IStructural<__S>>));
    }
    public override bool Equals(object other) {
      var oth = other as Std.JSON.Grammar.Suffixed<T, S>;
      return oth != null && object.Equals(this._t, oth._t) && object.Equals(this._suffix, oth._suffix);
    }
    public override int GetHashCode() {
      ulong hash = 5381;
      hash = ((hash << 5) + hash) + 0;
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this._t));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this._suffix));
      return (int) hash;
    }
    public override string ToString() {
      string s = "Grammar.Suffixed.Suffixed";
      s += "(";
      s += Dafny.Helpers.ToString(this._t);
      s += ", ";
      s += Dafny.Helpers.ToString(this._suffix);
      s += ")";
      return s;
    }
    public static Std.JSON.Grammar._ISuffixed<T, S> Default(T _default_T) {
      return create(_default_T, Std.JSON.Grammar.Maybe<Std.JSON.Grammar._IStructural<S>>.Default());
    }
    public static Dafny.TypeDescriptor<Std.JSON.Grammar._ISuffixed<T, S>> _TypeDescriptor(Dafny.TypeDescriptor<T> _td_T) {
      return new Dafny.TypeDescriptor<Std.JSON.Grammar._ISuffixed<T, S>>(Std.JSON.Grammar.Suffixed<T, S>.Default(_td_T.Default()));
    }
    public static _ISuffixed<T, S> create(T t, Std.JSON.Grammar._IMaybe<Std.JSON.Grammar._IStructural<S>> suffix) {
      return new Suffixed<T, S>(t, suffix);
    }
    public static _ISuffixed<T, S> create_Suffixed(T t, Std.JSON.Grammar._IMaybe<Std.JSON.Grammar._IStructural<S>> suffix) {
      return create(t, suffix);
    }
    public bool is_Suffixed { get { return true; } }
    public T dtor_t {
      get {
        return this._t;
      }
    }
    public Std.JSON.Grammar._IMaybe<Std.JSON.Grammar._IStructural<S>> dtor_suffix {
      get {
        return this._suffix;
      }
    }
  }

  public partial class SuffixedSequence<D, S> {
    public static Dafny.TypeDescriptor<Dafny.ISequence<Std.JSON.Grammar._ISuffixed<D, S>>> _TypeDescriptor(Dafny.TypeDescriptor<D> _td_D, Dafny.TypeDescriptor<S> _td_S) {
      return new Dafny.TypeDescriptor<Dafny.ISequence<Std.JSON.Grammar._ISuffixed<D, S>>>(Dafny.Sequence<Std.JSON.Grammar._ISuffixed<D, S>>.Empty);
    }
  }

  public interface _IBracketed<out L, out D, out S, out R> {
    bool is_Bracketed { get; }
    Std.JSON.Grammar._IStructural<L> dtor_l { get; }
    Dafny.ISequence<Std.JSON.Grammar._ISuffixed<D, S>> dtor_data { get; }
    Std.JSON.Grammar._IStructural<R> dtor_r { get; }
    _IBracketed<__L, __D, __S, __R> DowncastClone<__L, __D, __S, __R>(Func<L, __L> converter0, Func<D, __D> converter1, Func<S, __S> converter2, Func<R, __R> converter3);
  }
  public class Bracketed<L, D, S, R> : _IBracketed<L, D, S, R> {
    public readonly Std.JSON.Grammar._IStructural<L> _l;
    public readonly Dafny.ISequence<Std.JSON.Grammar._ISuffixed<D, S>> _data;
    public readonly Std.JSON.Grammar._IStructural<R> _r;
    public Bracketed(Std.JSON.Grammar._IStructural<L> l, Dafny.ISequence<Std.JSON.Grammar._ISuffixed<D, S>> data, Std.JSON.Grammar._IStructural<R> r) {
      this._l = l;
      this._data = data;
      this._r = r;
    }
    public _IBracketed<__L, __D, __S, __R> DowncastClone<__L, __D, __S, __R>(Func<L, __L> converter0, Func<D, __D> converter1, Func<S, __S> converter2, Func<R, __R> converter3) {
      if (this is _IBracketed<__L, __D, __S, __R> dt) { return dt; }
      return new Bracketed<__L, __D, __S, __R>((_l).DowncastClone<__L>(Dafny.Helpers.CastConverter<L, __L>), (_data).DowncastClone<Std.JSON.Grammar._ISuffixed<__D, __S>>(Dafny.Helpers.CastConverter<Std.JSON.Grammar._ISuffixed<D, S>, Std.JSON.Grammar._ISuffixed<__D, __S>>), (_r).DowncastClone<__R>(Dafny.Helpers.CastConverter<R, __R>));
    }
    public override bool Equals(object other) {
      var oth = other as Std.JSON.Grammar.Bracketed<L, D, S, R>;
      return oth != null && object.Equals(this._l, oth._l) && object.Equals(this._data, oth._data) && object.Equals(this._r, oth._r);
    }
    public override int GetHashCode() {
      ulong hash = 5381;
      hash = ((hash << 5) + hash) + 0;
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this._l));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this._data));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this._r));
      return (int) hash;
    }
    public override string ToString() {
      string s = "Grammar.Bracketed.Bracketed";
      s += "(";
      s += Dafny.Helpers.ToString(this._l);
      s += ", ";
      s += Dafny.Helpers.ToString(this._data);
      s += ", ";
      s += Dafny.Helpers.ToString(this._r);
      s += ")";
      return s;
    }
    public static Std.JSON.Grammar._IBracketed<L, D, S, R> Default(L _default_L, R _default_R) {
      return create(Std.JSON.Grammar.Structural<L>.Default(_default_L), Dafny.Sequence<Std.JSON.Grammar._ISuffixed<D, S>>.Empty, Std.JSON.Grammar.Structural<R>.Default(_default_R));
    }
    public static Dafny.TypeDescriptor<Std.JSON.Grammar._IBracketed<L, D, S, R>> _TypeDescriptor(Dafny.TypeDescriptor<L> _td_L, Dafny.TypeDescriptor<R> _td_R) {
      return new Dafny.TypeDescriptor<Std.JSON.Grammar._IBracketed<L, D, S, R>>(Std.JSON.Grammar.Bracketed<L, D, S, R>.Default(_td_L.Default(), _td_R.Default()));
    }
    public static _IBracketed<L, D, S, R> create(Std.JSON.Grammar._IStructural<L> l, Dafny.ISequence<Std.JSON.Grammar._ISuffixed<D, S>> data, Std.JSON.Grammar._IStructural<R> r) {
      return new Bracketed<L, D, S, R>(l, data, r);
    }
    public static _IBracketed<L, D, S, R> create_Bracketed(Std.JSON.Grammar._IStructural<L> l, Dafny.ISequence<Std.JSON.Grammar._ISuffixed<D, S>> data, Std.JSON.Grammar._IStructural<R> r) {
      return create(l, data, r);
    }
    public bool is_Bracketed { get { return true; } }
    public Std.JSON.Grammar._IStructural<L> dtor_l {
      get {
        return this._l;
      }
    }
    public Dafny.ISequence<Std.JSON.Grammar._ISuffixed<D, S>> dtor_data {
      get {
        return this._data;
      }
    }
    public Std.JSON.Grammar._IStructural<R> dtor_r {
      get {
        return this._r;
      }
    }
  }

  public partial class jnull {
    private static readonly Std.JSON.Utils.Views.Core._IView__ Witness = Std.JSON.Utils.Views.Core.View__.OfBytes(Std.JSON.Grammar.__default.NULL);
    public static Std.JSON.Utils.Views.Core._IView__ Default() {
      return Witness;
    }
    private static readonly Dafny.TypeDescriptor<Std.JSON.Utils.Views.Core._IView__> _TYPE = new Dafny.TypeDescriptor<Std.JSON.Utils.Views.Core._IView__>(Std.JSON.Grammar.jnull.Default());
    public static Dafny.TypeDescriptor<Std.JSON.Utils.Views.Core._IView__> _TypeDescriptor() {
      return _TYPE;
    }
  }

  public partial class jbool {
    private static readonly Std.JSON.Utils.Views.Core._IView__ Witness = Std.JSON.Utils.Views.Core.View__.OfBytes(Std.JSON.Grammar.__default.TRUE);
    public static Std.JSON.Utils.Views.Core._IView__ Default() {
      return Witness;
    }
    private static readonly Dafny.TypeDescriptor<Std.JSON.Utils.Views.Core._IView__> _TYPE = new Dafny.TypeDescriptor<Std.JSON.Utils.Views.Core._IView__>(Std.JSON.Grammar.jbool.Default());
    public static Dafny.TypeDescriptor<Std.JSON.Utils.Views.Core._IView__> _TypeDescriptor() {
      return _TYPE;
    }
  }

  public partial class jdigits {
    private static readonly Std.JSON.Utils.Views.Core._IView__ Witness = Std.JSON.Utils.Views.Core.View__.OfBytes(Dafny.Sequence<byte>.FromElements());
    public static Std.JSON.Utils.Views.Core._IView__ Default() {
      return Witness;
    }
    private static readonly Dafny.TypeDescriptor<Std.JSON.Utils.Views.Core._IView__> _TYPE = new Dafny.TypeDescriptor<Std.JSON.Utils.Views.Core._IView__>(Std.JSON.Grammar.jdigits.Default());
    public static Dafny.TypeDescriptor<Std.JSON.Utils.Views.Core._IView__> _TypeDescriptor() {
      return _TYPE;
    }
  }

  public partial class jnum {
    private static readonly Std.JSON.Utils.Views.Core._IView__ Witness = Std.JSON.Utils.Views.Core.View__.OfBytes(Dafny.Sequence<byte>.FromElements((byte)((new Dafny.Rune('0')).Value)));
    public static Std.JSON.Utils.Views.Core._IView__ Default() {
      return Witness;
    }
    private static readonly Dafny.TypeDescriptor<Std.JSON.Utils.Views.Core._IView__> _TYPE = new Dafny.TypeDescriptor<Std.JSON.Utils.Views.Core._IView__>(Std.JSON.Grammar.jnum.Default());
    public static Dafny.TypeDescriptor<Std.JSON.Utils.Views.Core._IView__> _TypeDescriptor() {
      return _TYPE;
    }
  }

  public partial class jint {
    private static readonly Std.JSON.Utils.Views.Core._IView__ Witness = Std.JSON.Utils.Views.Core.View__.OfBytes(Dafny.Sequence<byte>.FromElements((byte)((new Dafny.Rune('0')).Value)));
    public static Std.JSON.Utils.Views.Core._IView__ Default() {
      return Witness;
    }
    private static readonly Dafny.TypeDescriptor<Std.JSON.Utils.Views.Core._IView__> _TYPE = new Dafny.TypeDescriptor<Std.JSON.Utils.Views.Core._IView__>(Std.JSON.Grammar.jint.Default());
    public static Dafny.TypeDescriptor<Std.JSON.Utils.Views.Core._IView__> _TypeDescriptor() {
      return _TYPE;
    }
  }

  public partial class jstr {
    private static readonly Std.JSON.Utils.Views.Core._IView__ Witness = Std.JSON.Utils.Views.Core.View__.OfBytes(Dafny.Sequence<byte>.FromElements());
    public static Std.JSON.Utils.Views.Core._IView__ Default() {
      return Witness;
    }
    private static readonly Dafny.TypeDescriptor<Std.JSON.Utils.Views.Core._IView__> _TYPE = new Dafny.TypeDescriptor<Std.JSON.Utils.Views.Core._IView__>(Std.JSON.Grammar.jstr.Default());
    public static Dafny.TypeDescriptor<Std.JSON.Utils.Views.Core._IView__> _TypeDescriptor() {
      return _TYPE;
    }
  }

  public interface _Ijstring {
    bool is_JString { get; }
    Std.JSON.Utils.Views.Core._IView__ dtor_lq { get; }
    Std.JSON.Utils.Views.Core._IView__ dtor_contents { get; }
    Std.JSON.Utils.Views.Core._IView__ dtor_rq { get; }
    _Ijstring DowncastClone();
  }
  public class jstring : _Ijstring {
    public readonly Std.JSON.Utils.Views.Core._IView__ _lq;
    public readonly Std.JSON.Utils.Views.Core._IView__ _contents;
    public readonly Std.JSON.Utils.Views.Core._IView__ _rq;
    public jstring(Std.JSON.Utils.Views.Core._IView__ lq, Std.JSON.Utils.Views.Core._IView__ contents, Std.JSON.Utils.Views.Core._IView__ rq) {
      this._lq = lq;
      this._contents = contents;
      this._rq = rq;
    }
    public _Ijstring DowncastClone() {
      if (this is _Ijstring dt) { return dt; }
      return new jstring(_lq, _contents, _rq);
    }
    public override bool Equals(object other) {
      var oth = other as Std.JSON.Grammar.jstring;
      return oth != null && object.Equals(this._lq, oth._lq) && object.Equals(this._contents, oth._contents) && object.Equals(this._rq, oth._rq);
    }
    public override int GetHashCode() {
      ulong hash = 5381;
      hash = ((hash << 5) + hash) + 0;
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this._lq));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this._contents));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this._rq));
      return (int) hash;
    }
    public override string ToString() {
      string s = "Grammar.jstring.JString";
      s += "(";
      s += Dafny.Helpers.ToString(this._lq);
      s += ", ";
      s += Dafny.Helpers.ToString(this._contents);
      s += ", ";
      s += Dafny.Helpers.ToString(this._rq);
      s += ")";
      return s;
    }
    private static readonly Std.JSON.Grammar._Ijstring theDefault = create(Std.JSON.Grammar.jquote.Default(), Std.JSON.Grammar.jstr.Default(), Std.JSON.Grammar.jquote.Default());
    public static Std.JSON.Grammar._Ijstring Default() {
      return theDefault;
    }
    private static readonly Dafny.TypeDescriptor<Std.JSON.Grammar._Ijstring> _TYPE = new Dafny.TypeDescriptor<Std.JSON.Grammar._Ijstring>(Std.JSON.Grammar.jstring.Default());
    public static Dafny.TypeDescriptor<Std.JSON.Grammar._Ijstring> _TypeDescriptor() {
      return _TYPE;
    }
    public static _Ijstring create(Std.JSON.Utils.Views.Core._IView__ lq, Std.JSON.Utils.Views.Core._IView__ contents, Std.JSON.Utils.Views.Core._IView__ rq) {
      return new jstring(lq, contents, rq);
    }
    public static _Ijstring create_JString(Std.JSON.Utils.Views.Core._IView__ lq, Std.JSON.Utils.Views.Core._IView__ contents, Std.JSON.Utils.Views.Core._IView__ rq) {
      return create(lq, contents, rq);
    }
    public bool is_JString { get { return true; } }
    public Std.JSON.Utils.Views.Core._IView__ dtor_lq {
      get {
        return this._lq;
      }
    }
    public Std.JSON.Utils.Views.Core._IView__ dtor_contents {
      get {
        return this._contents;
      }
    }
    public Std.JSON.Utils.Views.Core._IView__ dtor_rq {
      get {
        return this._rq;
      }
    }
  }

  public interface _IjKeyValue {
    bool is_KeyValue { get; }
    Std.JSON.Grammar._Ijstring dtor_k { get; }
    Std.JSON.Grammar._IStructural<Std.JSON.Utils.Views.Core._IView__> dtor_colon { get; }
    Std.JSON.Grammar._IValue dtor_v { get; }
    _IjKeyValue DowncastClone();
  }
  public class jKeyValue : _IjKeyValue {
    public readonly Std.JSON.Grammar._Ijstring _k;
    public readonly Std.JSON.Grammar._IStructural<Std.JSON.Utils.Views.Core._IView__> _colon;
    public readonly Std.JSON.Grammar._IValue _v;
    public jKeyValue(Std.JSON.Grammar._Ijstring k, Std.JSON.Grammar._IStructural<Std.JSON.Utils.Views.Core._IView__> colon, Std.JSON.Grammar._IValue v) {
      this._k = k;
      this._colon = colon;
      this._v = v;
    }
    public _IjKeyValue DowncastClone() {
      if (this is _IjKeyValue dt) { return dt; }
      return new jKeyValue(_k, _colon, _v);
    }
    public override bool Equals(object other) {
      var oth = other as Std.JSON.Grammar.jKeyValue;
      return oth != null && object.Equals(this._k, oth._k) && object.Equals(this._colon, oth._colon) && object.Equals(this._v, oth._v);
    }
    public override int GetHashCode() {
      ulong hash = 5381;
      hash = ((hash << 5) + hash) + 0;
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this._k));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this._colon));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this._v));
      return (int) hash;
    }
    public override string ToString() {
      string s = "Grammar.jKeyValue.KeyValue";
      s += "(";
      s += Dafny.Helpers.ToString(this._k);
      s += ", ";
      s += Dafny.Helpers.ToString(this._colon);
      s += ", ";
      s += Dafny.Helpers.ToString(this._v);
      s += ")";
      return s;
    }
    private static readonly Std.JSON.Grammar._IjKeyValue theDefault = create(Std.JSON.Grammar.jstring.Default(), Std.JSON.Grammar.Structural<Std.JSON.Utils.Views.Core._IView__>.Default(Std.JSON.Grammar.jcolon.Default()), Std.JSON.Grammar.Value.Default());
    public static Std.JSON.Grammar._IjKeyValue Default() {
      return theDefault;
    }
    private static readonly Dafny.TypeDescriptor<Std.JSON.Grammar._IjKeyValue> _TYPE = new Dafny.TypeDescriptor<Std.JSON.Grammar._IjKeyValue>(Std.JSON.Grammar.jKeyValue.Default());
    public static Dafny.TypeDescriptor<Std.JSON.Grammar._IjKeyValue> _TypeDescriptor() {
      return _TYPE;
    }
    public static _IjKeyValue create(Std.JSON.Grammar._Ijstring k, Std.JSON.Grammar._IStructural<Std.JSON.Utils.Views.Core._IView__> colon, Std.JSON.Grammar._IValue v) {
      return new jKeyValue(k, colon, v);
    }
    public static _IjKeyValue create_KeyValue(Std.JSON.Grammar._Ijstring k, Std.JSON.Grammar._IStructural<Std.JSON.Utils.Views.Core._IView__> colon, Std.JSON.Grammar._IValue v) {
      return create(k, colon, v);
    }
    public bool is_KeyValue { get { return true; } }
    public Std.JSON.Grammar._Ijstring dtor_k {
      get {
        return this._k;
      }
    }
    public Std.JSON.Grammar._IStructural<Std.JSON.Utils.Views.Core._IView__> dtor_colon {
      get {
        return this._colon;
      }
    }
    public Std.JSON.Grammar._IValue dtor_v {
      get {
        return this._v;
      }
    }
  }

  public interface _Ijfrac {
    bool is_JFrac { get; }
    Std.JSON.Utils.Views.Core._IView__ dtor_period { get; }
    Std.JSON.Utils.Views.Core._IView__ dtor_num { get; }
    _Ijfrac DowncastClone();
  }
  public class jfrac : _Ijfrac {
    public readonly Std.JSON.Utils.Views.Core._IView__ _period;
    public readonly Std.JSON.Utils.Views.Core._IView__ _num;
    public jfrac(Std.JSON.Utils.Views.Core._IView__ period, Std.JSON.Utils.Views.Core._IView__ num) {
      this._period = period;
      this._num = num;
    }
    public _Ijfrac DowncastClone() {
      if (this is _Ijfrac dt) { return dt; }
      return new jfrac(_period, _num);
    }
    public override bool Equals(object other) {
      var oth = other as Std.JSON.Grammar.jfrac;
      return oth != null && object.Equals(this._period, oth._period) && object.Equals(this._num, oth._num);
    }
    public override int GetHashCode() {
      ulong hash = 5381;
      hash = ((hash << 5) + hash) + 0;
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this._period));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this._num));
      return (int) hash;
    }
    public override string ToString() {
      string s = "Grammar.jfrac.JFrac";
      s += "(";
      s += Dafny.Helpers.ToString(this._period);
      s += ", ";
      s += Dafny.Helpers.ToString(this._num);
      s += ")";
      return s;
    }
    private static readonly Std.JSON.Grammar._Ijfrac theDefault = create(Std.JSON.Grammar.jperiod.Default(), Std.JSON.Grammar.jnum.Default());
    public static Std.JSON.Grammar._Ijfrac Default() {
      return theDefault;
    }
    private static readonly Dafny.TypeDescriptor<Std.JSON.Grammar._Ijfrac> _TYPE = new Dafny.TypeDescriptor<Std.JSON.Grammar._Ijfrac>(Std.JSON.Grammar.jfrac.Default());
    public static Dafny.TypeDescriptor<Std.JSON.Grammar._Ijfrac> _TypeDescriptor() {
      return _TYPE;
    }
    public static _Ijfrac create(Std.JSON.Utils.Views.Core._IView__ period, Std.JSON.Utils.Views.Core._IView__ num) {
      return new jfrac(period, num);
    }
    public static _Ijfrac create_JFrac(Std.JSON.Utils.Views.Core._IView__ period, Std.JSON.Utils.Views.Core._IView__ num) {
      return create(period, num);
    }
    public bool is_JFrac { get { return true; } }
    public Std.JSON.Utils.Views.Core._IView__ dtor_period {
      get {
        return this._period;
      }
    }
    public Std.JSON.Utils.Views.Core._IView__ dtor_num {
      get {
        return this._num;
      }
    }
  }

  public interface _Ijexp {
    bool is_JExp { get; }
    Std.JSON.Utils.Views.Core._IView__ dtor_e { get; }
    Std.JSON.Utils.Views.Core._IView__ dtor_sign { get; }
    Std.JSON.Utils.Views.Core._IView__ dtor_num { get; }
    _Ijexp DowncastClone();
  }
  public class jexp : _Ijexp {
    public readonly Std.JSON.Utils.Views.Core._IView__ _e;
    public readonly Std.JSON.Utils.Views.Core._IView__ _sign;
    public readonly Std.JSON.Utils.Views.Core._IView__ _num;
    public jexp(Std.JSON.Utils.Views.Core._IView__ e, Std.JSON.Utils.Views.Core._IView__ sign, Std.JSON.Utils.Views.Core._IView__ num) {
      this._e = e;
      this._sign = sign;
      this._num = num;
    }
    public _Ijexp DowncastClone() {
      if (this is _Ijexp dt) { return dt; }
      return new jexp(_e, _sign, _num);
    }
    public override bool Equals(object other) {
      var oth = other as Std.JSON.Grammar.jexp;
      return oth != null && object.Equals(this._e, oth._e) && object.Equals(this._sign, oth._sign) && object.Equals(this._num, oth._num);
    }
    public override int GetHashCode() {
      ulong hash = 5381;
      hash = ((hash << 5) + hash) + 0;
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this._e));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this._sign));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this._num));
      return (int) hash;
    }
    public override string ToString() {
      string s = "Grammar.jexp.JExp";
      s += "(";
      s += Dafny.Helpers.ToString(this._e);
      s += ", ";
      s += Dafny.Helpers.ToString(this._sign);
      s += ", ";
      s += Dafny.Helpers.ToString(this._num);
      s += ")";
      return s;
    }
    private static readonly Std.JSON.Grammar._Ijexp theDefault = create(Std.JSON.Grammar.je.Default(), Std.JSON.Grammar.jsign.Default(), Std.JSON.Grammar.jnum.Default());
    public static Std.JSON.Grammar._Ijexp Default() {
      return theDefault;
    }
    private static readonly Dafny.TypeDescriptor<Std.JSON.Grammar._Ijexp> _TYPE = new Dafny.TypeDescriptor<Std.JSON.Grammar._Ijexp>(Std.JSON.Grammar.jexp.Default());
    public static Dafny.TypeDescriptor<Std.JSON.Grammar._Ijexp> _TypeDescriptor() {
      return _TYPE;
    }
    public static _Ijexp create(Std.JSON.Utils.Views.Core._IView__ e, Std.JSON.Utils.Views.Core._IView__ sign, Std.JSON.Utils.Views.Core._IView__ num) {
      return new jexp(e, sign, num);
    }
    public static _Ijexp create_JExp(Std.JSON.Utils.Views.Core._IView__ e, Std.JSON.Utils.Views.Core._IView__ sign, Std.JSON.Utils.Views.Core._IView__ num) {
      return create(e, sign, num);
    }
    public bool is_JExp { get { return true; } }
    public Std.JSON.Utils.Views.Core._IView__ dtor_e {
      get {
        return this._e;
      }
    }
    public Std.JSON.Utils.Views.Core._IView__ dtor_sign {
      get {
        return this._sign;
      }
    }
    public Std.JSON.Utils.Views.Core._IView__ dtor_num {
      get {
        return this._num;
      }
    }
  }

  public interface _Ijnumber {
    bool is_JNumber { get; }
    Std.JSON.Utils.Views.Core._IView__ dtor_minus { get; }
    Std.JSON.Utils.Views.Core._IView__ dtor_num { get; }
    Std.JSON.Grammar._IMaybe<Std.JSON.Grammar._Ijfrac> dtor_frac { get; }
    Std.JSON.Grammar._IMaybe<Std.JSON.Grammar._Ijexp> dtor_exp { get; }
    _Ijnumber DowncastClone();
  }
  public class jnumber : _Ijnumber {
    public readonly Std.JSON.Utils.Views.Core._IView__ _minus;
    public readonly Std.JSON.Utils.Views.Core._IView__ _num;
    public readonly Std.JSON.Grammar._IMaybe<Std.JSON.Grammar._Ijfrac> _frac;
    public readonly Std.JSON.Grammar._IMaybe<Std.JSON.Grammar._Ijexp> _exp;
    public jnumber(Std.JSON.Utils.Views.Core._IView__ minus, Std.JSON.Utils.Views.Core._IView__ num, Std.JSON.Grammar._IMaybe<Std.JSON.Grammar._Ijfrac> frac, Std.JSON.Grammar._IMaybe<Std.JSON.Grammar._Ijexp> exp) {
      this._minus = minus;
      this._num = num;
      this._frac = frac;
      this._exp = exp;
    }
    public _Ijnumber DowncastClone() {
      if (this is _Ijnumber dt) { return dt; }
      return new jnumber(_minus, _num, _frac, _exp);
    }
    public override bool Equals(object other) {
      var oth = other as Std.JSON.Grammar.jnumber;
      return oth != null && object.Equals(this._minus, oth._minus) && object.Equals(this._num, oth._num) && object.Equals(this._frac, oth._frac) && object.Equals(this._exp, oth._exp);
    }
    public override int GetHashCode() {
      ulong hash = 5381;
      hash = ((hash << 5) + hash) + 0;
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this._minus));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this._num));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this._frac));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this._exp));
      return (int) hash;
    }
    public override string ToString() {
      string s = "Grammar.jnumber.JNumber";
      s += "(";
      s += Dafny.Helpers.ToString(this._minus);
      s += ", ";
      s += Dafny.Helpers.ToString(this._num);
      s += ", ";
      s += Dafny.Helpers.ToString(this._frac);
      s += ", ";
      s += Dafny.Helpers.ToString(this._exp);
      s += ")";
      return s;
    }
    private static readonly Std.JSON.Grammar._Ijnumber theDefault = create(Std.JSON.Grammar.jminus.Default(), Std.JSON.Grammar.jnum.Default(), Std.JSON.Grammar.Maybe<Std.JSON.Grammar._Ijfrac>.Default(), Std.JSON.Grammar.Maybe<Std.JSON.Grammar._Ijexp>.Default());
    public static Std.JSON.Grammar._Ijnumber Default() {
      return theDefault;
    }
    private static readonly Dafny.TypeDescriptor<Std.JSON.Grammar._Ijnumber> _TYPE = new Dafny.TypeDescriptor<Std.JSON.Grammar._Ijnumber>(Std.JSON.Grammar.jnumber.Default());
    public static Dafny.TypeDescriptor<Std.JSON.Grammar._Ijnumber> _TypeDescriptor() {
      return _TYPE;
    }
    public static _Ijnumber create(Std.JSON.Utils.Views.Core._IView__ minus, Std.JSON.Utils.Views.Core._IView__ num, Std.JSON.Grammar._IMaybe<Std.JSON.Grammar._Ijfrac> frac, Std.JSON.Grammar._IMaybe<Std.JSON.Grammar._Ijexp> exp) {
      return new jnumber(minus, num, frac, exp);
    }
    public static _Ijnumber create_JNumber(Std.JSON.Utils.Views.Core._IView__ minus, Std.JSON.Utils.Views.Core._IView__ num, Std.JSON.Grammar._IMaybe<Std.JSON.Grammar._Ijfrac> frac, Std.JSON.Grammar._IMaybe<Std.JSON.Grammar._Ijexp> exp) {
      return create(minus, num, frac, exp);
    }
    public bool is_JNumber { get { return true; } }
    public Std.JSON.Utils.Views.Core._IView__ dtor_minus {
      get {
        return this._minus;
      }
    }
    public Std.JSON.Utils.Views.Core._IView__ dtor_num {
      get {
        return this._num;
      }
    }
    public Std.JSON.Grammar._IMaybe<Std.JSON.Grammar._Ijfrac> dtor_frac {
      get {
        return this._frac;
      }
    }
    public Std.JSON.Grammar._IMaybe<Std.JSON.Grammar._Ijexp> dtor_exp {
      get {
        return this._exp;
      }
    }
  }

  public interface _IValue {
    bool is_Null { get; }
    bool is_Bool { get; }
    bool is_String { get; }
    bool is_Number { get; }
    bool is_Object { get; }
    bool is_Array { get; }
    Std.JSON.Utils.Views.Core._IView__ dtor_n { get; }
    Std.JSON.Utils.Views.Core._IView__ dtor_b { get; }
    Std.JSON.Grammar._Ijstring dtor_str { get; }
    Std.JSON.Grammar._Ijnumber dtor_num { get; }
    Std.JSON.Grammar._IBracketed<Std.JSON.Utils.Views.Core._IView__, Std.JSON.Grammar._IjKeyValue, Std.JSON.Utils.Views.Core._IView__, Std.JSON.Utils.Views.Core._IView__> dtor_obj { get; }
    Std.JSON.Grammar._IBracketed<Std.JSON.Utils.Views.Core._IView__, Std.JSON.Grammar._IValue, Std.JSON.Utils.Views.Core._IView__, Std.JSON.Utils.Views.Core._IView__> dtor_arr { get; }
    _IValue DowncastClone();
  }
  public abstract class Value : _IValue {
    public Value() {
    }
    private static readonly Std.JSON.Grammar._IValue theDefault = create_Null(Std.JSON.Grammar.jnull.Default());
    public static Std.JSON.Grammar._IValue Default() {
      return theDefault;
    }
    private static readonly Dafny.TypeDescriptor<Std.JSON.Grammar._IValue> _TYPE = new Dafny.TypeDescriptor<Std.JSON.Grammar._IValue>(Std.JSON.Grammar.Value.Default());
    public static Dafny.TypeDescriptor<Std.JSON.Grammar._IValue> _TypeDescriptor() {
      return _TYPE;
    }
    public static _IValue create_Null(Std.JSON.Utils.Views.Core._IView__ n) {
      return new Value_Null(n);
    }
    public static _IValue create_Bool(Std.JSON.Utils.Views.Core._IView__ b) {
      return new Value_Bool(b);
    }
    public static _IValue create_String(Std.JSON.Grammar._Ijstring str) {
      return new Value_String(str);
    }
    public static _IValue create_Number(Std.JSON.Grammar._Ijnumber num) {
      return new Value_Number(num);
    }
    public static _IValue create_Object(Std.JSON.Grammar._IBracketed<Std.JSON.Utils.Views.Core._IView__, Std.JSON.Grammar._IjKeyValue, Std.JSON.Utils.Views.Core._IView__, Std.JSON.Utils.Views.Core._IView__> obj) {
      return new Value_Object(obj);
    }
    public static _IValue create_Array(Std.JSON.Grammar._IBracketed<Std.JSON.Utils.Views.Core._IView__, Std.JSON.Grammar._IValue, Std.JSON.Utils.Views.Core._IView__, Std.JSON.Utils.Views.Core._IView__> arr) {
      return new Value_Array(arr);
    }
    public bool is_Null { get { return this is Value_Null; } }
    public bool is_Bool { get { return this is Value_Bool; } }
    public bool is_String { get { return this is Value_String; } }
    public bool is_Number { get { return this is Value_Number; } }
    public bool is_Object { get { return this is Value_Object; } }
    public bool is_Array { get { return this is Value_Array; } }
    public Std.JSON.Utils.Views.Core._IView__ dtor_n {
      get {
        var d = this;
        return ((Value_Null)d)._n;
      }
    }
    public Std.JSON.Utils.Views.Core._IView__ dtor_b {
      get {
        var d = this;
        return ((Value_Bool)d)._b;
      }
    }
    public Std.JSON.Grammar._Ijstring dtor_str {
      get {
        var d = this;
        return ((Value_String)d)._str;
      }
    }
    public Std.JSON.Grammar._Ijnumber dtor_num {
      get {
        var d = this;
        return ((Value_Number)d)._num;
      }
    }
    public Std.JSON.Grammar._IBracketed<Std.JSON.Utils.Views.Core._IView__, Std.JSON.Grammar._IjKeyValue, Std.JSON.Utils.Views.Core._IView__, Std.JSON.Utils.Views.Core._IView__> dtor_obj {
      get {
        var d = this;
        return ((Value_Object)d)._obj;
      }
    }
    public Std.JSON.Grammar._IBracketed<Std.JSON.Utils.Views.Core._IView__, Std.JSON.Grammar._IValue, Std.JSON.Utils.Views.Core._IView__, Std.JSON.Utils.Views.Core._IView__> dtor_arr {
      get {
        var d = this;
        return ((Value_Array)d)._arr;
      }
    }
    public abstract _IValue DowncastClone();
  }
  public class Value_Null : Value {
    public readonly Std.JSON.Utils.Views.Core._IView__ _n;
    public Value_Null(Std.JSON.Utils.Views.Core._IView__ n) : base() {
      this._n = n;
    }
    public override _IValue DowncastClone() {
      if (this is _IValue dt) { return dt; }
      return new Value_Null(_n);
    }
    public override bool Equals(object other) {
      var oth = other as Std.JSON.Grammar.Value_Null;
      return oth != null && object.Equals(this._n, oth._n);
    }
    public override int GetHashCode() {
      ulong hash = 5381;
      hash = ((hash << 5) + hash) + 0;
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this._n));
      return (int) hash;
    }
    public override string ToString() {
      string s = "Grammar.Value.Null";
      s += "(";
      s += Dafny.Helpers.ToString(this._n);
      s += ")";
      return s;
    }
  }
  public class Value_Bool : Value {
    public readonly Std.JSON.Utils.Views.Core._IView__ _b;
    public Value_Bool(Std.JSON.Utils.Views.Core._IView__ b) : base() {
      this._b = b;
    }
    public override _IValue DowncastClone() {
      if (this is _IValue dt) { return dt; }
      return new Value_Bool(_b);
    }
    public override bool Equals(object other) {
      var oth = other as Std.JSON.Grammar.Value_Bool;
      return oth != null && object.Equals(this._b, oth._b);
    }
    public override int GetHashCode() {
      ulong hash = 5381;
      hash = ((hash << 5) + hash) + 1;
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this._b));
      return (int) hash;
    }
    public override string ToString() {
      string s = "Grammar.Value.Bool";
      s += "(";
      s += Dafny.Helpers.ToString(this._b);
      s += ")";
      return s;
    }
  }
  public class Value_String : Value {
    public readonly Std.JSON.Grammar._Ijstring _str;
    public Value_String(Std.JSON.Grammar._Ijstring str) : base() {
      this._str = str;
    }
    public override _IValue DowncastClone() {
      if (this is _IValue dt) { return dt; }
      return new Value_String(_str);
    }
    public override bool Equals(object other) {
      var oth = other as Std.JSON.Grammar.Value_String;
      return oth != null && object.Equals(this._str, oth._str);
    }
    public override int GetHashCode() {
      ulong hash = 5381;
      hash = ((hash << 5) + hash) + 2;
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this._str));
      return (int) hash;
    }
    public override string ToString() {
      string s = "Grammar.Value.String";
      s += "(";
      s += Dafny.Helpers.ToString(this._str);
      s += ")";
      return s;
    }
  }
  public class Value_Number : Value {
    public readonly Std.JSON.Grammar._Ijnumber _num;
    public Value_Number(Std.JSON.Grammar._Ijnumber num) : base() {
      this._num = num;
    }
    public override _IValue DowncastClone() {
      if (this is _IValue dt) { return dt; }
      return new Value_Number(_num);
    }
    public override bool Equals(object other) {
      var oth = other as Std.JSON.Grammar.Value_Number;
      return oth != null && object.Equals(this._num, oth._num);
    }
    public override int GetHashCode() {
      ulong hash = 5381;
      hash = ((hash << 5) + hash) + 3;
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this._num));
      return (int) hash;
    }
    public override string ToString() {
      string s = "Grammar.Value.Number";
      s += "(";
      s += Dafny.Helpers.ToString(this._num);
      s += ")";
      return s;
    }
  }
  public class Value_Object : Value {
    public readonly Std.JSON.Grammar._IBracketed<Std.JSON.Utils.Views.Core._IView__, Std.JSON.Grammar._IjKeyValue, Std.JSON.Utils.Views.Core._IView__, Std.JSON.Utils.Views.Core._IView__> _obj;
    public Value_Object(Std.JSON.Grammar._IBracketed<Std.JSON.Utils.Views.Core._IView__, Std.JSON.Grammar._IjKeyValue, Std.JSON.Utils.Views.Core._IView__, Std.JSON.Utils.Views.Core._IView__> obj) : base() {
      this._obj = obj;
    }
    public override _IValue DowncastClone() {
      if (this is _IValue dt) { return dt; }
      return new Value_Object(_obj);
    }
    public override bool Equals(object other) {
      var oth = other as Std.JSON.Grammar.Value_Object;
      return oth != null && object.Equals(this._obj, oth._obj);
    }
    public override int GetHashCode() {
      ulong hash = 5381;
      hash = ((hash << 5) + hash) + 4;
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this._obj));
      return (int) hash;
    }
    public override string ToString() {
      string s = "Grammar.Value.Object";
      s += "(";
      s += Dafny.Helpers.ToString(this._obj);
      s += ")";
      return s;
    }
  }
  public class Value_Array : Value {
    public readonly Std.JSON.Grammar._IBracketed<Std.JSON.Utils.Views.Core._IView__, Std.JSON.Grammar._IValue, Std.JSON.Utils.Views.Core._IView__, Std.JSON.Utils.Views.Core._IView__> _arr;
    public Value_Array(Std.JSON.Grammar._IBracketed<Std.JSON.Utils.Views.Core._IView__, Std.JSON.Grammar._IValue, Std.JSON.Utils.Views.Core._IView__, Std.JSON.Utils.Views.Core._IView__> arr) : base() {
      this._arr = arr;
    }
    public override _IValue DowncastClone() {
      if (this is _IValue dt) { return dt; }
      return new Value_Array(_arr);
    }
    public override bool Equals(object other) {
      var oth = other as Std.JSON.Grammar.Value_Array;
      return oth != null && object.Equals(this._arr, oth._arr);
    }
    public override int GetHashCode() {
      ulong hash = 5381;
      hash = ((hash << 5) + hash) + 5;
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this._arr));
      return (int) hash;
    }
    public override string ToString() {
      string s = "Grammar.Value.Array";
      s += "(";
      s += Dafny.Helpers.ToString(this._arr);
      s += ")";
      return s;
    }
  }
} // end of namespace Std.JSON.Grammar
namespace Std.JSON.ByteStrConversion {

  public partial class __default {
    public static BigInteger BASE() {
      return Std.JSON.ByteStrConversion.__default.@base;
    }
    public static bool IsDigitChar(byte c) {
      return (Std.JSON.ByteStrConversion.__default.charToDigit).Contains(c);
    }
    public static Dafny.ISequence<byte> OfDigits(Dafny.ISequence<BigInteger> digits) {
      Dafny.ISequence<byte> _0___accumulator = Dafny.Sequence<byte>.FromElements();
    TAIL_CALL_START: ;
      if ((digits).Equals(Dafny.Sequence<BigInteger>.FromElements())) {
        return Dafny.Sequence<byte>.Concat(Dafny.Sequence<byte>.FromElements(), _0___accumulator);
      } else {
        _0___accumulator = Dafny.Sequence<byte>.Concat(Dafny.Sequence<byte>.FromElements((Std.JSON.ByteStrConversion.__default.chars).Select((digits).Select(BigInteger.Zero))), _0___accumulator);
        Dafny.ISequence<BigInteger> _in0 = (digits).Drop(BigInteger.One);
        digits = _in0;
        goto TAIL_CALL_START;
      }
    }
    public static Dafny.ISequence<byte> OfNat(BigInteger n) {
      if ((n).Sign == 0) {
        return Dafny.Sequence<byte>.FromElements((Std.JSON.ByteStrConversion.__default.chars).Select(BigInteger.Zero));
      } else {
        return Std.JSON.ByteStrConversion.__default.OfDigits(Std.JSON.ByteStrConversion.__default.FromNat(n));
      }
    }
    public static bool IsNumberStr(Dafny.ISequence<byte> str, byte minus)
    {
      return !(!(str).Equals(Dafny.Sequence<byte>.FromElements())) || (((((str).Select(BigInteger.Zero)) == (minus)) || ((Std.JSON.ByteStrConversion.__default.charToDigit).Contains((str).Select(BigInteger.Zero)))) && (Dafny.Helpers.Id<Func<Dafny.ISequence<byte>, bool>>((_0_str) => Dafny.Helpers.Quantifier<byte>(((_0_str).Drop(BigInteger.One)).UniqueElements, true, (((_forall_var_0) => {
        byte _1_c = (byte)_forall_var_0;
        return !(((_0_str).Drop(BigInteger.One)).Contains(_1_c)) || (Std.JSON.ByteStrConversion.__default.IsDigitChar(_1_c));
      }))))(str)));
    }
    public static Dafny.ISequence<byte> OfInt(BigInteger n, byte minus)
    {
      if ((n).Sign != -1) {
        return Std.JSON.ByteStrConversion.__default.OfNat(n);
      } else {
        return Dafny.Sequence<byte>.Concat(Dafny.Sequence<byte>.FromElements(minus), Std.JSON.ByteStrConversion.__default.OfNat((BigInteger.Zero) - (n)));
      }
    }
    public static BigInteger ToNat(Dafny.ISequence<byte> str) {
      if ((str).Equals(Dafny.Sequence<byte>.FromElements())) {
        return BigInteger.Zero;
      } else {
        byte _0_c = (str).Select((new BigInteger((str).Count)) - (BigInteger.One));
        return ((Std.JSON.ByteStrConversion.__default.ToNat((str).Take((new BigInteger((str).Count)) - (BigInteger.One)))) * (Std.JSON.ByteStrConversion.__default.@base)) + (Dafny.Map<byte, BigInteger>.Select(Std.JSON.ByteStrConversion.__default.charToDigit,_0_c));
      }
    }
    public static BigInteger ToInt(Dafny.ISequence<byte> str, byte minus)
    {
      if (Dafny.Sequence<byte>.IsPrefixOf(Dafny.Sequence<byte>.FromElements(minus), str)) {
        return (BigInteger.Zero) - (Std.JSON.ByteStrConversion.__default.ToNat((str).Drop(BigInteger.One)));
      } else {
        return Std.JSON.ByteStrConversion.__default.ToNat(str);
      }
    }
    public static BigInteger ToNatRight(Dafny.ISequence<BigInteger> xs) {
      if ((new BigInteger((xs).Count)).Sign == 0) {
        return BigInteger.Zero;
      } else {
        return ((Std.JSON.ByteStrConversion.__default.ToNatRight(Std.Collections.Seq.__default.DropFirst<BigInteger>(xs))) * (Std.JSON.ByteStrConversion.__default.BASE())) + (Std.Collections.Seq.__default.First<BigInteger>(xs));
      }
    }
    public static BigInteger ToNatLeft(Dafny.ISequence<BigInteger> xs) {
      BigInteger _0___accumulator = BigInteger.Zero;
    TAIL_CALL_START: ;
      if ((new BigInteger((xs).Count)).Sign == 0) {
        return (BigInteger.Zero) + (_0___accumulator);
      } else {
        _0___accumulator = ((Std.Collections.Seq.__default.Last<BigInteger>(xs)) * (Std.Arithmetic.Power.__default.Pow(Std.JSON.ByteStrConversion.__default.BASE(), (new BigInteger((xs).Count)) - (BigInteger.One)))) + (_0___accumulator);
        Dafny.ISequence<BigInteger> _in0 = Std.Collections.Seq.__default.DropLast<BigInteger>(xs);
        xs = _in0;
        goto TAIL_CALL_START;
      }
    }
    public static Dafny.ISequence<BigInteger> FromNat(BigInteger n) {
      Dafny.ISequence<BigInteger> _0___accumulator = Dafny.Sequence<BigInteger>.FromElements();
    TAIL_CALL_START: ;
      if ((n).Sign == 0) {
        return Dafny.Sequence<BigInteger>.Concat(_0___accumulator, Dafny.Sequence<BigInteger>.FromElements());
      } else {
        _0___accumulator = Dafny.Sequence<BigInteger>.Concat(_0___accumulator, Dafny.Sequence<BigInteger>.FromElements(Dafny.Helpers.EuclideanModulus(n, Std.JSON.ByteStrConversion.__default.BASE())));
        BigInteger _in0 = Dafny.Helpers.EuclideanDivision(n, Std.JSON.ByteStrConversion.__default.BASE());
        n = _in0;
        goto TAIL_CALL_START;
      }
    }
    public static Dafny.ISequence<BigInteger> SeqExtend(Dafny.ISequence<BigInteger> xs, BigInteger n)
    {
    TAIL_CALL_START: ;
      if ((new BigInteger((xs).Count)) >= (n)) {
        return xs;
      } else {
        Dafny.ISequence<BigInteger> _in0 = Dafny.Sequence<BigInteger>.Concat(xs, Dafny.Sequence<BigInteger>.FromElements(BigInteger.Zero));
        BigInteger _in1 = n;
        xs = _in0;
        n = _in1;
        goto TAIL_CALL_START;
      }
    }
    public static Dafny.ISequence<BigInteger> SeqExtendMultiple(Dafny.ISequence<BigInteger> xs, BigInteger n)
    {
      BigInteger _0_newLen = ((new BigInteger((xs).Count)) + (n)) - (Dafny.Helpers.EuclideanModulus(new BigInteger((xs).Count), n));
      return Std.JSON.ByteStrConversion.__default.SeqExtend(xs, _0_newLen);
    }
    public static Dafny.ISequence<BigInteger> FromNatWithLen(BigInteger n, BigInteger len)
    {
      return Std.JSON.ByteStrConversion.__default.SeqExtend(Std.JSON.ByteStrConversion.__default.FromNat(n), len);
    }
    public static Dafny.ISequence<BigInteger> SeqZero(BigInteger len) {
      Dafny.ISequence<BigInteger> _0_xs = Std.JSON.ByteStrConversion.__default.FromNatWithLen(BigInteger.Zero, len);
      return _0_xs;
    }
    public static _System._ITuple2<Dafny.ISequence<BigInteger>, BigInteger> SeqAdd(Dafny.ISequence<BigInteger> xs, Dafny.ISequence<BigInteger> ys)
    {
      if ((new BigInteger((xs).Count)).Sign == 0) {
        return _System.Tuple2<Dafny.ISequence<BigInteger>, BigInteger>.create(Dafny.Sequence<BigInteger>.FromElements(), BigInteger.Zero);
      } else {
        _System._ITuple2<Dafny.ISequence<BigInteger>, BigInteger> _let_tmp_rhs0 = Std.JSON.ByteStrConversion.__default.SeqAdd(Std.Collections.Seq.__default.DropLast<BigInteger>(xs), Std.Collections.Seq.__default.DropLast<BigInteger>(ys));
        Dafny.ISequence<BigInteger> _0_zs_k = _let_tmp_rhs0.dtor__0;
        BigInteger _1_cin = _let_tmp_rhs0.dtor__1;
        BigInteger _2_sum = ((Std.Collections.Seq.__default.Last<BigInteger>(xs)) + (Std.Collections.Seq.__default.Last<BigInteger>(ys))) + (_1_cin);
        _System._ITuple2<BigInteger, BigInteger> _let_tmp_rhs1 = (((_2_sum) < (Std.JSON.ByteStrConversion.__default.BASE())) ? (_System.Tuple2<BigInteger, BigInteger>.create(_2_sum, BigInteger.Zero)) : (_System.Tuple2<BigInteger, BigInteger>.create((_2_sum) - (Std.JSON.ByteStrConversion.__default.BASE()), BigInteger.One)));
        BigInteger _3_sum__out = _let_tmp_rhs1.dtor__0;
        BigInteger _4_cout = _let_tmp_rhs1.dtor__1;
        return _System.Tuple2<Dafny.ISequence<BigInteger>, BigInteger>.create(Dafny.Sequence<BigInteger>.Concat(_0_zs_k, Dafny.Sequence<BigInteger>.FromElements(_3_sum__out)), _4_cout);
      }
    }
    public static _System._ITuple2<Dafny.ISequence<BigInteger>, BigInteger> SeqSub(Dafny.ISequence<BigInteger> xs, Dafny.ISequence<BigInteger> ys)
    {
      if ((new BigInteger((xs).Count)).Sign == 0) {
        return _System.Tuple2<Dafny.ISequence<BigInteger>, BigInteger>.create(Dafny.Sequence<BigInteger>.FromElements(), BigInteger.Zero);
      } else {
        _System._ITuple2<Dafny.ISequence<BigInteger>, BigInteger> _let_tmp_rhs0 = Std.JSON.ByteStrConversion.__default.SeqSub(Std.Collections.Seq.__default.DropLast<BigInteger>(xs), Std.Collections.Seq.__default.DropLast<BigInteger>(ys));
        Dafny.ISequence<BigInteger> _0_zs = _let_tmp_rhs0.dtor__0;
        BigInteger _1_cin = _let_tmp_rhs0.dtor__1;
        _System._ITuple2<BigInteger, BigInteger> _let_tmp_rhs1 = (((Std.Collections.Seq.__default.Last<BigInteger>(xs)) >= ((Std.Collections.Seq.__default.Last<BigInteger>(ys)) + (_1_cin))) ? (_System.Tuple2<BigInteger, BigInteger>.create(((Std.Collections.Seq.__default.Last<BigInteger>(xs)) - (Std.Collections.Seq.__default.Last<BigInteger>(ys))) - (_1_cin), BigInteger.Zero)) : (_System.Tuple2<BigInteger, BigInteger>.create((((Std.JSON.ByteStrConversion.__default.BASE()) + (Std.Collections.Seq.__default.Last<BigInteger>(xs))) - (Std.Collections.Seq.__default.Last<BigInteger>(ys))) - (_1_cin), BigInteger.One)));
        BigInteger _2_diff__out = _let_tmp_rhs1.dtor__0;
        BigInteger _3_cout = _let_tmp_rhs1.dtor__1;
        return _System.Tuple2<Dafny.ISequence<BigInteger>, BigInteger>.create(Dafny.Sequence<BigInteger>.Concat(_0_zs, Dafny.Sequence<BigInteger>.FromElements(_2_diff__out)), _3_cout);
      }
    }
    public static Dafny.ISequence<byte> chars { get {
      return Dafny.Sequence<byte>.FromElements((byte)((new Dafny.Rune('0')).Value), (byte)((new Dafny.Rune('1')).Value), (byte)((new Dafny.Rune('2')).Value), (byte)((new Dafny.Rune('3')).Value), (byte)((new Dafny.Rune('4')).Value), (byte)((new Dafny.Rune('5')).Value), (byte)((new Dafny.Rune('6')).Value), (byte)((new Dafny.Rune('7')).Value), (byte)((new Dafny.Rune('8')).Value), (byte)((new Dafny.Rune('9')).Value));
    } }
    public static BigInteger @base { get {
      return new BigInteger((Std.JSON.ByteStrConversion.__default.chars).Count);
    } }
    public static Dafny.IMap<byte,BigInteger> charToDigit { get {
      return Dafny.Map<byte, BigInteger>.FromElements(new Dafny.Pair<byte, BigInteger>((byte)((new Dafny.Rune('0')).Value), BigInteger.Zero), new Dafny.Pair<byte, BigInteger>((byte)((new Dafny.Rune('1')).Value), BigInteger.One), new Dafny.Pair<byte, BigInteger>((byte)((new Dafny.Rune('2')).Value), new BigInteger(2)), new Dafny.Pair<byte, BigInteger>((byte)((new Dafny.Rune('3')).Value), new BigInteger(3)), new Dafny.Pair<byte, BigInteger>((byte)((new Dafny.Rune('4')).Value), new BigInteger(4)), new Dafny.Pair<byte, BigInteger>((byte)((new Dafny.Rune('5')).Value), new BigInteger(5)), new Dafny.Pair<byte, BigInteger>((byte)((new Dafny.Rune('6')).Value), new BigInteger(6)), new Dafny.Pair<byte, BigInteger>((byte)((new Dafny.Rune('7')).Value), new BigInteger(7)), new Dafny.Pair<byte, BigInteger>((byte)((new Dafny.Rune('8')).Value), new BigInteger(8)), new Dafny.Pair<byte, BigInteger>((byte)((new Dafny.Rune('9')).Value), new BigInteger(9)));
    } }
  }

  public partial class CharSeq {
    private static readonly Dafny.TypeDescriptor<Dafny.ISequence<byte>> _TYPE = new Dafny.TypeDescriptor<Dafny.ISequence<byte>>(Dafny.Sequence<byte>.Empty);
    public static Dafny.TypeDescriptor<Dafny.ISequence<byte>> _TypeDescriptor() {
      return _TYPE;
    }
    public static bool _Is(Dafny.ISequence<byte> __source) {
      Dafny.ISequence<byte> _0_chars = __source;
      return (new BigInteger((_0_chars).Count)) > (BigInteger.One);
    }
  }

  public partial class digit {
    private static readonly Dafny.TypeDescriptor<BigInteger> _TYPE = new Dafny.TypeDescriptor<BigInteger>(BigInteger.Zero);
    public static Dafny.TypeDescriptor<BigInteger> _TypeDescriptor() {
      return _TYPE;
    }
    public static bool _Is(BigInteger __source) {
      BigInteger _1_i = __source;
      if (_System.nat._Is(_1_i)) {
        return ((_1_i).Sign != -1) && ((_1_i) < (Std.JSON.ByteStrConversion.__default.BASE()));
      }
      return false;
    }
  }
} // end of namespace Std.JSON.ByteStrConversion
namespace Std.JSON.Serializer {

  public partial class __default {
    public static Std.JSON.Utils.Views.Core._IView__ Bool(bool b) {
      return Std.JSON.Utils.Views.Core.View__.OfBytes(((b) ? (Std.JSON.Grammar.__default.TRUE) : (Std.JSON.Grammar.__default.FALSE)));
    }
    public static Std.Wrappers._IOutcome<Std.JSON.Errors._ISerializationError> CheckLength<__T>(Dafny.ISequence<__T> s, Std.JSON.Errors._ISerializationError err)
    {
      return Std.Wrappers.Outcome<Std.JSON.Errors._ISerializationError>.Need((new BigInteger((s).Count)) < (Std.BoundedInts.__default.TWO__TO__THE__32), err);
    }
    public static Std.Wrappers._IResult<Std.JSON.Grammar._Ijstring, Std.JSON.Errors._ISerializationError> String(Dafny.ISequence<Dafny.Rune> str) {
      Std.Wrappers._IResult<Dafny.ISequence<byte>, Std.JSON.Errors._ISerializationError> _0_valueOrError0 = Std.JSON.Spec.__default.EscapeToUTF8(str, BigInteger.Zero);
      if ((_0_valueOrError0).IsFailure()) {
        return (_0_valueOrError0).PropagateFailure<Std.JSON.Grammar._Ijstring>();
      } else {
        Dafny.ISequence<byte> _1_bs = (_0_valueOrError0).Extract();
        Std.Wrappers._IOutcome<Std.JSON.Errors._ISerializationError> _2_o = Std.JSON.Serializer.__default.CheckLength<byte>(_1_bs, Std.JSON.Errors.SerializationError.create_StringTooLong(str));
        if ((_2_o).is_Pass) {
          return Std.Wrappers.Result<Std.JSON.Grammar._Ijstring, Std.JSON.Errors._ISerializationError>.create_Success(Std.JSON.Grammar.jstring.create(Std.JSON.Grammar.__default.DOUBLEQUOTE, Std.JSON.Utils.Views.Core.View__.OfBytes(_1_bs), Std.JSON.Grammar.__default.DOUBLEQUOTE));
        } else {
          return Std.Wrappers.Result<Std.JSON.Grammar._Ijstring, Std.JSON.Errors._ISerializationError>.create_Failure((_2_o).dtor_error);
        }
      }
    }
    public static Std.JSON.Utils.Views.Core._IView__ Sign(BigInteger n) {
      return Std.JSON.Utils.Views.Core.View__.OfBytes((((n).Sign == -1) ? (Dafny.Sequence<byte>.FromElements((byte)((new Dafny.Rune('-')).Value))) : (Dafny.Sequence<byte>.FromElements())));
    }
    public static Dafny.ISequence<byte> Int_k(BigInteger n) {
      return Std.JSON.ByteStrConversion.__default.OfInt(n, Std.JSON.Serializer.__default.MINUS);
    }
    public static Std.Wrappers._IResult<Std.JSON.Utils.Views.Core._IView__, Std.JSON.Errors._ISerializationError> Int(BigInteger n) {
      Dafny.ISequence<byte> _0_bs = Std.JSON.Serializer.__default.Int_k(n);
      Std.Wrappers._IOutcome<Std.JSON.Errors._ISerializationError> _1_o = Std.JSON.Serializer.__default.CheckLength<byte>(_0_bs, Std.JSON.Errors.SerializationError.create_IntTooLarge(n));
      if ((_1_o).is_Pass) {
        return Std.Wrappers.Result<Std.JSON.Utils.Views.Core._IView__, Std.JSON.Errors._ISerializationError>.create_Success(Std.JSON.Utils.Views.Core.View__.OfBytes(_0_bs));
      } else {
        return Std.Wrappers.Result<Std.JSON.Utils.Views.Core._IView__, Std.JSON.Errors._ISerializationError>.create_Failure((_1_o).dtor_error);
      }
    }
    public static Std.Wrappers._IResult<Std.JSON.Grammar._Ijnumber, Std.JSON.Errors._ISerializationError> Number(Std.JSON.Values._IDecimal dec) {
      var _pat_let_tv0 = dec;
      var _pat_let_tv1 = dec;
      Std.JSON.Utils.Views.Core._IView__ _0_minus = Std.JSON.Serializer.__default.Sign((dec).dtor_n);
      Std.Wrappers._IResult<Std.JSON.Utils.Views.Core._IView__, Std.JSON.Errors._ISerializationError> _1_valueOrError0 = Std.JSON.Serializer.__default.Int(Std.Math.__default.Abs((dec).dtor_n));
      if ((_1_valueOrError0).IsFailure()) {
        return (_1_valueOrError0).PropagateFailure<Std.JSON.Grammar._Ijnumber>();
      } else {
        Std.JSON.Utils.Views.Core._IView__ _2_num = (_1_valueOrError0).Extract();
        Std.JSON.Grammar._IMaybe<Std.JSON.Grammar._Ijfrac> _3_frac = Std.JSON.Grammar.Maybe<Std.JSON.Grammar._Ijfrac>.create_Empty();
        Std.Wrappers._IResult<Std.JSON.Grammar._IMaybe<Std.JSON.Grammar._Ijexp>, Std.JSON.Errors._ISerializationError> _4_valueOrError1 = ((((dec).dtor_e10).Sign == 0) ? (Std.Wrappers.Result<Std.JSON.Grammar._IMaybe<Std.JSON.Grammar._Ijexp>, Std.JSON.Errors._ISerializationError>.create_Success(Std.JSON.Grammar.Maybe<Std.JSON.Grammar._Ijexp>.create_Empty())) : (Dafny.Helpers.Let<Std.JSON.Utils.Views.Core._IView__, Std.Wrappers._IResult<Std.JSON.Grammar._IMaybe<Std.JSON.Grammar._Ijexp>, Std.JSON.Errors._ISerializationError>>(Std.JSON.Utils.Views.Core.View__.OfBytes(Dafny.Sequence<byte>.FromElements((byte)((new Dafny.Rune('e')).Value))), _pat_let1_0 => Dafny.Helpers.Let<Std.JSON.Utils.Views.Core._IView__, Std.Wrappers._IResult<Std.JSON.Grammar._IMaybe<Std.JSON.Grammar._Ijexp>, Std.JSON.Errors._ISerializationError>>(_pat_let1_0, _5_e => Dafny.Helpers.Let<Std.JSON.Utils.Views.Core._IView__, Std.Wrappers._IResult<Std.JSON.Grammar._IMaybe<Std.JSON.Grammar._Ijexp>, Std.JSON.Errors._ISerializationError>>(Std.JSON.Serializer.__default.Sign((_pat_let_tv0).dtor_e10), _pat_let2_0 => Dafny.Helpers.Let<Std.JSON.Utils.Views.Core._IView__, Std.Wrappers._IResult<Std.JSON.Grammar._IMaybe<Std.JSON.Grammar._Ijexp>, Std.JSON.Errors._ISerializationError>>(_pat_let2_0, _6_sign => Dafny.Helpers.Let<Std.Wrappers._IResult<Std.JSON.Utils.Views.Core._IView__, Std.JSON.Errors._ISerializationError>, Std.Wrappers._IResult<Std.JSON.Grammar._IMaybe<Std.JSON.Grammar._Ijexp>, Std.JSON.Errors._ISerializationError>>(Std.JSON.Serializer.__default.Int(Std.Math.__default.Abs((_pat_let_tv1).dtor_e10)), _pat_let3_0 => Dafny.Helpers.Let<Std.Wrappers._IResult<Std.JSON.Utils.Views.Core._IView__, Std.JSON.Errors._ISerializationError>, Std.Wrappers._IResult<Std.JSON.Grammar._IMaybe<Std.JSON.Grammar._Ijexp>, Std.JSON.Errors._ISerializationError>>(_pat_let3_0, _7_valueOrError2 => (((_7_valueOrError2).IsFailure()) ? ((_7_valueOrError2).PropagateFailure<Std.JSON.Grammar._IMaybe<Std.JSON.Grammar._Ijexp>>()) : (Dafny.Helpers.Let<Std.JSON.Utils.Views.Core._IView__, Std.Wrappers._IResult<Std.JSON.Grammar._IMaybe<Std.JSON.Grammar._Ijexp>, Std.JSON.Errors._ISerializationError>>((_7_valueOrError2).Extract(), _pat_let4_0 => Dafny.Helpers.Let<Std.JSON.Utils.Views.Core._IView__, Std.Wrappers._IResult<Std.JSON.Grammar._IMaybe<Std.JSON.Grammar._Ijexp>, Std.JSON.Errors._ISerializationError>>(_pat_let4_0, _8_num => Std.Wrappers.Result<Std.JSON.Grammar._IMaybe<Std.JSON.Grammar._Ijexp>, Std.JSON.Errors._ISerializationError>.create_Success(Std.JSON.Grammar.Maybe<Std.JSON.Grammar._Ijexp>.create_NonEmpty(Std.JSON.Grammar.jexp.create(_5_e, _6_sign, _8_num)))))))))))))));
        if ((_4_valueOrError1).IsFailure()) {
          return (_4_valueOrError1).PropagateFailure<Std.JSON.Grammar._Ijnumber>();
        } else {
          Std.JSON.Grammar._IMaybe<Std.JSON.Grammar._Ijexp> _9_exp = (_4_valueOrError1).Extract();
          return Std.Wrappers.Result<Std.JSON.Grammar._Ijnumber, Std.JSON.Errors._ISerializationError>.create_Success(Std.JSON.Grammar.jnumber.create(_0_minus, _2_num, Std.JSON.Grammar.Maybe<Std.JSON.Grammar._Ijfrac>.create_Empty(), _9_exp));
        }
      }
    }
    public static Std.JSON.Grammar._IStructural<__T> MkStructural<__T>(__T v) {
      return Std.JSON.Grammar.Structural<__T>.create(Std.JSON.Grammar.__default.EMPTY, v, Std.JSON.Grammar.__default.EMPTY);
    }
    public static Std.Wrappers._IResult<Std.JSON.Grammar._IjKeyValue, Std.JSON.Errors._ISerializationError> KeyValue(_System._ITuple2<Dafny.ISequence<Dafny.Rune>, Std.JSON.Values._IJSON> kv) {
      Std.Wrappers._IResult<Std.JSON.Grammar._Ijstring, Std.JSON.Errors._ISerializationError> _0_valueOrError0 = Std.JSON.Serializer.__default.String((kv).dtor__0);
      if ((_0_valueOrError0).IsFailure()) {
        return (_0_valueOrError0).PropagateFailure<Std.JSON.Grammar._IjKeyValue>();
      } else {
        Std.JSON.Grammar._Ijstring _1_k = (_0_valueOrError0).Extract();
        Std.Wrappers._IResult<Std.JSON.Grammar._IValue, Std.JSON.Errors._ISerializationError> _2_valueOrError1 = Std.JSON.Serializer.__default.Value((kv).dtor__1);
        if ((_2_valueOrError1).IsFailure()) {
          return (_2_valueOrError1).PropagateFailure<Std.JSON.Grammar._IjKeyValue>();
        } else {
          Std.JSON.Grammar._IValue _3_v = (_2_valueOrError1).Extract();
          return Std.Wrappers.Result<Std.JSON.Grammar._IjKeyValue, Std.JSON.Errors._ISerializationError>.create_Success(Std.JSON.Grammar.jKeyValue.create(_1_k, Std.JSON.Serializer.__default.COLON, _3_v));
        }
      }
    }
    public static Dafny.ISequence<Std.JSON.Grammar._ISuffixed<__D, __S>> MkSuffixedSequence<__D, __S>(Dafny.ISequence<__D> ds, Std.JSON.Grammar._IStructural<__S> suffix, BigInteger start)
    {
      Dafny.ISequence<Std.JSON.Grammar._ISuffixed<__D, __S>> _0___accumulator = Dafny.Sequence<Std.JSON.Grammar._ISuffixed<__D, __S>>.FromElements();
    TAIL_CALL_START: ;
      if ((start) >= (new BigInteger((ds).Count))) {
        return Dafny.Sequence<Std.JSON.Grammar._ISuffixed<__D, __S>>.Concat(_0___accumulator, Dafny.Sequence<Std.JSON.Grammar._ISuffixed<__D, __S>>.FromElements());
      } else if ((start) == ((new BigInteger((ds).Count)) - (BigInteger.One))) {
        return Dafny.Sequence<Std.JSON.Grammar._ISuffixed<__D, __S>>.Concat(_0___accumulator, Dafny.Sequence<Std.JSON.Grammar._ISuffixed<__D, __S>>.FromElements(Std.JSON.Grammar.Suffixed<__D, __S>.create((ds).Select(start), Std.JSON.Grammar.Maybe<Std.JSON.Grammar._IStructural<__S>>.create_Empty())));
      } else {
        _0___accumulator = Dafny.Sequence<Std.JSON.Grammar._ISuffixed<__D, __S>>.Concat(_0___accumulator, Dafny.Sequence<Std.JSON.Grammar._ISuffixed<__D, __S>>.FromElements(Std.JSON.Grammar.Suffixed<__D, __S>.create((ds).Select(start), Std.JSON.Grammar.Maybe<Std.JSON.Grammar._IStructural<__S>>.create_NonEmpty(suffix))));
        Dafny.ISequence<__D> _in0 = ds;
        Std.JSON.Grammar._IStructural<__S> _in1 = suffix;
        BigInteger _in2 = (start) + (BigInteger.One);
        ds = _in0;
        suffix = _in1;
        start = _in2;
        goto TAIL_CALL_START;
      }
    }
    public static Std.Wrappers._IResult<Std.JSON.Grammar._IBracketed<Std.JSON.Utils.Views.Core._IView__, Std.JSON.Grammar._IjKeyValue, Std.JSON.Utils.Views.Core._IView__, Std.JSON.Utils.Views.Core._IView__>, Std.JSON.Errors._ISerializationError> Object(Dafny.ISequence<_System._ITuple2<Dafny.ISequence<Dafny.Rune>, Std.JSON.Values._IJSON>> obj) {
      Std.Wrappers._IResult<Dafny.ISequence<Std.JSON.Grammar._IjKeyValue>, Std.JSON.Errors._ISerializationError> _0_valueOrError0 = Std.Collections.Seq.__default.MapWithResult<_System._ITuple2<Dafny.ISequence<Dafny.Rune>, Std.JSON.Values._IJSON>, Std.JSON.Grammar._IjKeyValue, Std.JSON.Errors._ISerializationError>(Dafny.Helpers.Id<Func<Dafny.ISequence<_System._ITuple2<Dafny.ISequence<Dafny.Rune>, Std.JSON.Values._IJSON>>, Func<_System._ITuple2<Dafny.ISequence<Dafny.Rune>, Std.JSON.Values._IJSON>, Std.Wrappers._IResult<Std.JSON.Grammar._IjKeyValue, Std.JSON.Errors._ISerializationError>>>>((_1_obj) => ((System.Func<_System._ITuple2<Dafny.ISequence<Dafny.Rune>, Std.JSON.Values._IJSON>, Std.Wrappers._IResult<Std.JSON.Grammar._IjKeyValue, Std.JSON.Errors._ISerializationError>>)((_2_v) => {
        return Std.JSON.Serializer.__default.KeyValue(_2_v);
      })))(obj), obj);
      if ((_0_valueOrError0).IsFailure()) {
        return (_0_valueOrError0).PropagateFailure<Std.JSON.Grammar._IBracketed<Std.JSON.Utils.Views.Core._IView__, Std.JSON.Grammar._IjKeyValue, Std.JSON.Utils.Views.Core._IView__, Std.JSON.Utils.Views.Core._IView__>>();
      } else {
        Dafny.ISequence<Std.JSON.Grammar._IjKeyValue> _3_items = (_0_valueOrError0).Extract();
        return Std.Wrappers.Result<Std.JSON.Grammar._IBracketed<Std.JSON.Utils.Views.Core._IView__, Std.JSON.Grammar._IjKeyValue, Std.JSON.Utils.Views.Core._IView__, Std.JSON.Utils.Views.Core._IView__>, Std.JSON.Errors._ISerializationError>.create_Success(Std.JSON.Grammar.Bracketed<Std.JSON.Utils.Views.Core._IView__, Std.JSON.Grammar._IjKeyValue, Std.JSON.Utils.Views.Core._IView__, Std.JSON.Utils.Views.Core._IView__>.create(Std.JSON.Serializer.__default.MkStructural<Std.JSON.Utils.Views.Core._IView__>(Std.JSON.Grammar.__default.LBRACE), Std.JSON.Serializer.__default.MkSuffixedSequence<Std.JSON.Grammar._IjKeyValue, Std.JSON.Utils.Views.Core._IView__>(_3_items, Std.JSON.Serializer.__default.COMMA, BigInteger.Zero), Std.JSON.Serializer.__default.MkStructural<Std.JSON.Utils.Views.Core._IView__>(Std.JSON.Grammar.__default.RBRACE)));
      }
    }
    public static Std.Wrappers._IResult<Std.JSON.Grammar._IBracketed<Std.JSON.Utils.Views.Core._IView__, Std.JSON.Grammar._IValue, Std.JSON.Utils.Views.Core._IView__, Std.JSON.Utils.Views.Core._IView__>, Std.JSON.Errors._ISerializationError> Array(Dafny.ISequence<Std.JSON.Values._IJSON> arr) {
      Std.Wrappers._IResult<Dafny.ISequence<Std.JSON.Grammar._IValue>, Std.JSON.Errors._ISerializationError> _0_valueOrError0 = Std.Collections.Seq.__default.MapWithResult<Std.JSON.Values._IJSON, Std.JSON.Grammar._IValue, Std.JSON.Errors._ISerializationError>(Dafny.Helpers.Id<Func<Dafny.ISequence<Std.JSON.Values._IJSON>, Func<Std.JSON.Values._IJSON, Std.Wrappers._IResult<Std.JSON.Grammar._IValue, Std.JSON.Errors._ISerializationError>>>>((_1_arr) => ((System.Func<Std.JSON.Values._IJSON, Std.Wrappers._IResult<Std.JSON.Grammar._IValue, Std.JSON.Errors._ISerializationError>>)((_2_v) => {
        return Std.JSON.Serializer.__default.Value(_2_v);
      })))(arr), arr);
      if ((_0_valueOrError0).IsFailure()) {
        return (_0_valueOrError0).PropagateFailure<Std.JSON.Grammar._IBracketed<Std.JSON.Utils.Views.Core._IView__, Std.JSON.Grammar._IValue, Std.JSON.Utils.Views.Core._IView__, Std.JSON.Utils.Views.Core._IView__>>();
      } else {
        Dafny.ISequence<Std.JSON.Grammar._IValue> _3_items = (_0_valueOrError0).Extract();
        return Std.Wrappers.Result<Std.JSON.Grammar._IBracketed<Std.JSON.Utils.Views.Core._IView__, Std.JSON.Grammar._IValue, Std.JSON.Utils.Views.Core._IView__, Std.JSON.Utils.Views.Core._IView__>, Std.JSON.Errors._ISerializationError>.create_Success(Std.JSON.Grammar.Bracketed<Std.JSON.Utils.Views.Core._IView__, Std.JSON.Grammar._IValue, Std.JSON.Utils.Views.Core._IView__, Std.JSON.Utils.Views.Core._IView__>.create(Std.JSON.Serializer.__default.MkStructural<Std.JSON.Utils.Views.Core._IView__>(Std.JSON.Grammar.__default.LBRACKET), Std.JSON.Serializer.__default.MkSuffixedSequence<Std.JSON.Grammar._IValue, Std.JSON.Utils.Views.Core._IView__>(_3_items, Std.JSON.Serializer.__default.COMMA, BigInteger.Zero), Std.JSON.Serializer.__default.MkStructural<Std.JSON.Utils.Views.Core._IView__>(Std.JSON.Grammar.__default.RBRACKET)));
      }
    }
    public static Std.Wrappers._IResult<Std.JSON.Grammar._IValue, Std.JSON.Errors._ISerializationError> Value(Std.JSON.Values._IJSON js) {
      Std.JSON.Values._IJSON _source0 = js;
      {
        if (_source0.is_Null) {
          return Std.Wrappers.Result<Std.JSON.Grammar._IValue, Std.JSON.Errors._ISerializationError>.create_Success(Std.JSON.Grammar.Value.create_Null(Std.JSON.Utils.Views.Core.View__.OfBytes(Std.JSON.Grammar.__default.NULL)));
        }
      }
      {
        if (_source0.is_Bool) {
          bool _0_b = _source0.dtor_b;
          return Std.Wrappers.Result<Std.JSON.Grammar._IValue, Std.JSON.Errors._ISerializationError>.create_Success(Std.JSON.Grammar.Value.create_Bool(Std.JSON.Serializer.__default.Bool(_0_b)));
        }
      }
      {
        if (_source0.is_String) {
          Dafny.ISequence<Dafny.Rune> _1_str = _source0.dtor_str;
          Std.Wrappers._IResult<Std.JSON.Grammar._Ijstring, Std.JSON.Errors._ISerializationError> _2_valueOrError0 = Std.JSON.Serializer.__default.String(_1_str);
          if ((_2_valueOrError0).IsFailure()) {
            return (_2_valueOrError0).PropagateFailure<Std.JSON.Grammar._IValue>();
          } else {
            Std.JSON.Grammar._Ijstring _3_s = (_2_valueOrError0).Extract();
            return Std.Wrappers.Result<Std.JSON.Grammar._IValue, Std.JSON.Errors._ISerializationError>.create_Success(Std.JSON.Grammar.Value.create_String(_3_s));
          }
        }
      }
      {
        if (_source0.is_Number) {
          Std.JSON.Values._IDecimal _4_dec = _source0.dtor_num;
          Std.Wrappers._IResult<Std.JSON.Grammar._Ijnumber, Std.JSON.Errors._ISerializationError> _5_valueOrError1 = Std.JSON.Serializer.__default.Number(_4_dec);
          if ((_5_valueOrError1).IsFailure()) {
            return (_5_valueOrError1).PropagateFailure<Std.JSON.Grammar._IValue>();
          } else {
            Std.JSON.Grammar._Ijnumber _6_n = (_5_valueOrError1).Extract();
            return Std.Wrappers.Result<Std.JSON.Grammar._IValue, Std.JSON.Errors._ISerializationError>.create_Success(Std.JSON.Grammar.Value.create_Number(_6_n));
          }
        }
      }
      {
        if (_source0.is_Object) {
          Dafny.ISequence<_System._ITuple2<Dafny.ISequence<Dafny.Rune>, Std.JSON.Values._IJSON>> _7_obj = _source0.dtor_obj;
          Std.Wrappers._IResult<Std.JSON.Grammar._IBracketed<Std.JSON.Utils.Views.Core._IView__, Std.JSON.Grammar._IjKeyValue, Std.JSON.Utils.Views.Core._IView__, Std.JSON.Utils.Views.Core._IView__>, Std.JSON.Errors._ISerializationError> _8_valueOrError2 = Std.JSON.Serializer.__default.Object(_7_obj);
          if ((_8_valueOrError2).IsFailure()) {
            return (_8_valueOrError2).PropagateFailure<Std.JSON.Grammar._IValue>();
          } else {
            Std.JSON.Grammar._IBracketed<Std.JSON.Utils.Views.Core._IView__, Std.JSON.Grammar._IjKeyValue, Std.JSON.Utils.Views.Core._IView__, Std.JSON.Utils.Views.Core._IView__> _9_o = (_8_valueOrError2).Extract();
            return Std.Wrappers.Result<Std.JSON.Grammar._IValue, Std.JSON.Errors._ISerializationError>.create_Success(Std.JSON.Grammar.Value.create_Object(_9_o));
          }
        }
      }
      {
        Dafny.ISequence<Std.JSON.Values._IJSON> _10_arr = _source0.dtor_arr;
        Std.Wrappers._IResult<Std.JSON.Grammar._IBracketed<Std.JSON.Utils.Views.Core._IView__, Std.JSON.Grammar._IValue, Std.JSON.Utils.Views.Core._IView__, Std.JSON.Utils.Views.Core._IView__>, Std.JSON.Errors._ISerializationError> _11_valueOrError3 = Std.JSON.Serializer.__default.Array(_10_arr);
        if ((_11_valueOrError3).IsFailure()) {
          return (_11_valueOrError3).PropagateFailure<Std.JSON.Grammar._IValue>();
        } else {
          Std.JSON.Grammar._IBracketed<Std.JSON.Utils.Views.Core._IView__, Std.JSON.Grammar._IValue, Std.JSON.Utils.Views.Core._IView__, Std.JSON.Utils.Views.Core._IView__> _12_a = (_11_valueOrError3).Extract();
          return Std.Wrappers.Result<Std.JSON.Grammar._IValue, Std.JSON.Errors._ISerializationError>.create_Success(Std.JSON.Grammar.Value.create_Array(_12_a));
        }
      }
    }
    public static Std.Wrappers._IResult<Std.JSON.Grammar._IStructural<Std.JSON.Grammar._IValue>, Std.JSON.Errors._ISerializationError> JSON(Std.JSON.Values._IJSON js) {
      Std.Wrappers._IResult<Std.JSON.Grammar._IValue, Std.JSON.Errors._ISerializationError> _0_valueOrError0 = Std.JSON.Serializer.__default.Value(js);
      if ((_0_valueOrError0).IsFailure()) {
        return (_0_valueOrError0).PropagateFailure<Std.JSON.Grammar._IStructural<Std.JSON.Grammar._IValue>>();
      } else {
        Std.JSON.Grammar._IValue _1_val = (_0_valueOrError0).Extract();
        return Std.Wrappers.Result<Std.JSON.Grammar._IStructural<Std.JSON.Grammar._IValue>, Std.JSON.Errors._ISerializationError>.create_Success(Std.JSON.Serializer.__default.MkStructural<Std.JSON.Grammar._IValue>(_1_val));
      }
    }
    public static Dafny.ISequence<byte> DIGITS { get {
      return Std.JSON.ByteStrConversion.__default.chars;
    } }
    public static byte MINUS { get {
      return (byte)((new Dafny.Rune('-')).Value);
    } }
    public static Std.JSON.Grammar._IStructural<Std.JSON.Utils.Views.Core._IView__> COLON { get {
      return Std.JSON.Serializer.__default.MkStructural<Std.JSON.Utils.Views.Core._IView__>(Std.JSON.Grammar.__default.COLON);
    } }
    public static Std.JSON.Grammar._IStructural<Std.JSON.Utils.Views.Core._IView__> COMMA { get {
      return Std.JSON.Serializer.__default.MkStructural<Std.JSON.Utils.Views.Core._IView__>(Std.JSON.Grammar.__default.COMMA);
    } }
  }

  public partial class bytes32 {
    private static readonly Dafny.TypeDescriptor<Dafny.ISequence<byte>> _TYPE = new Dafny.TypeDescriptor<Dafny.ISequence<byte>>(Dafny.Sequence<byte>.Empty);
    public static Dafny.TypeDescriptor<Dafny.ISequence<byte>> _TypeDescriptor() {
      return _TYPE;
    }
    public static bool _Is(Dafny.ISequence<byte> __source) {
      Dafny.ISequence<byte> _0_bs = __source;
      return (new BigInteger((_0_bs).Count)) < (Std.BoundedInts.__default.TWO__TO__THE__32);
    }
  }

  public partial class string32 {
    private static readonly Dafny.TypeDescriptor<Dafny.ISequence<Dafny.Rune>> _TYPE = new Dafny.TypeDescriptor<Dafny.ISequence<Dafny.Rune>>(Dafny.Sequence<Dafny.Rune>.Empty);
    public static Dafny.TypeDescriptor<Dafny.ISequence<Dafny.Rune>> _TypeDescriptor() {
      return _TYPE;
    }
    public static bool _Is(Dafny.ISequence<Dafny.Rune> __source) {
      Dafny.ISequence<Dafny.Rune> _1_s = __source;
      return (new BigInteger((_1_s).Count)) < (Std.BoundedInts.__default.TWO__TO__THE__32);
    }
  }
} // end of namespace Std.JSON.Serializer
namespace Std.JSON.Deserializer.Uint16StrConversion {

  public partial class __default {
    public static BigInteger BASE() {
      return Std.JSON.Deserializer.Uint16StrConversion.__default.@base;
    }
    public static bool IsDigitChar(ushort c) {
      return (Std.JSON.Deserializer.Uint16StrConversion.__default.charToDigit).Contains(c);
    }
    public static Dafny.ISequence<ushort> OfDigits(Dafny.ISequence<BigInteger> digits) {
      Dafny.ISequence<ushort> _0___accumulator = Dafny.Sequence<ushort>.FromElements();
    TAIL_CALL_START: ;
      if ((digits).Equals(Dafny.Sequence<BigInteger>.FromElements())) {
        return Dafny.Sequence<ushort>.Concat(Dafny.Sequence<ushort>.FromElements(), _0___accumulator);
      } else {
        _0___accumulator = Dafny.Sequence<ushort>.Concat(Dafny.Sequence<ushort>.FromElements((Std.JSON.Deserializer.Uint16StrConversion.__default.chars).Select((digits).Select(BigInteger.Zero))), _0___accumulator);
        Dafny.ISequence<BigInteger> _in0 = (digits).Drop(BigInteger.One);
        digits = _in0;
        goto TAIL_CALL_START;
      }
    }
    public static Dafny.ISequence<ushort> OfNat(BigInteger n) {
      if ((n).Sign == 0) {
        return Dafny.Sequence<ushort>.FromElements((Std.JSON.Deserializer.Uint16StrConversion.__default.chars).Select(BigInteger.Zero));
      } else {
        return Std.JSON.Deserializer.Uint16StrConversion.__default.OfDigits(Std.JSON.Deserializer.Uint16StrConversion.__default.FromNat(n));
      }
    }
    public static bool IsNumberStr(Dafny.ISequence<ushort> str, ushort minus)
    {
      return !(!(str).Equals(Dafny.Sequence<ushort>.FromElements())) || (((((str).Select(BigInteger.Zero)) == (minus)) || ((Std.JSON.Deserializer.Uint16StrConversion.__default.charToDigit).Contains((str).Select(BigInteger.Zero)))) && (Dafny.Helpers.Id<Func<Dafny.ISequence<ushort>, bool>>((_0_str) => Dafny.Helpers.Quantifier<ushort>(((_0_str).Drop(BigInteger.One)).UniqueElements, true, (((_forall_var_0) => {
        ushort _1_c = (ushort)_forall_var_0;
        return !(((_0_str).Drop(BigInteger.One)).Contains(_1_c)) || (Std.JSON.Deserializer.Uint16StrConversion.__default.IsDigitChar(_1_c));
      }))))(str)));
    }
    public static Dafny.ISequence<ushort> OfInt(BigInteger n, ushort minus)
    {
      if ((n).Sign != -1) {
        return Std.JSON.Deserializer.Uint16StrConversion.__default.OfNat(n);
      } else {
        return Dafny.Sequence<ushort>.Concat(Dafny.Sequence<ushort>.FromElements(minus), Std.JSON.Deserializer.Uint16StrConversion.__default.OfNat((BigInteger.Zero) - (n)));
      }
    }
    public static BigInteger ToNat(Dafny.ISequence<ushort> str) {
      if ((str).Equals(Dafny.Sequence<ushort>.FromElements())) {
        return BigInteger.Zero;
      } else {
        ushort _0_c = (str).Select((new BigInteger((str).Count)) - (BigInteger.One));
        return ((Std.JSON.Deserializer.Uint16StrConversion.__default.ToNat((str).Take((new BigInteger((str).Count)) - (BigInteger.One)))) * (Std.JSON.Deserializer.Uint16StrConversion.__default.@base)) + (Dafny.Map<ushort, BigInteger>.Select(Std.JSON.Deserializer.Uint16StrConversion.__default.charToDigit,_0_c));
      }
    }
    public static BigInteger ToInt(Dafny.ISequence<ushort> str, ushort minus)
    {
      if (Dafny.Sequence<ushort>.IsPrefixOf(Dafny.Sequence<ushort>.FromElements(minus), str)) {
        return (BigInteger.Zero) - (Std.JSON.Deserializer.Uint16StrConversion.__default.ToNat((str).Drop(BigInteger.One)));
      } else {
        return Std.JSON.Deserializer.Uint16StrConversion.__default.ToNat(str);
      }
    }
    public static BigInteger ToNatRight(Dafny.ISequence<BigInteger> xs) {
      if ((new BigInteger((xs).Count)).Sign == 0) {
        return BigInteger.Zero;
      } else {
        return ((Std.JSON.Deserializer.Uint16StrConversion.__default.ToNatRight(Std.Collections.Seq.__default.DropFirst<BigInteger>(xs))) * (Std.JSON.Deserializer.Uint16StrConversion.__default.BASE())) + (Std.Collections.Seq.__default.First<BigInteger>(xs));
      }
    }
    public static BigInteger ToNatLeft(Dafny.ISequence<BigInteger> xs) {
      BigInteger _0___accumulator = BigInteger.Zero;
    TAIL_CALL_START: ;
      if ((new BigInteger((xs).Count)).Sign == 0) {
        return (BigInteger.Zero) + (_0___accumulator);
      } else {
        _0___accumulator = ((Std.Collections.Seq.__default.Last<BigInteger>(xs)) * (Std.Arithmetic.Power.__default.Pow(Std.JSON.Deserializer.Uint16StrConversion.__default.BASE(), (new BigInteger((xs).Count)) - (BigInteger.One)))) + (_0___accumulator);
        Dafny.ISequence<BigInteger> _in0 = Std.Collections.Seq.__default.DropLast<BigInteger>(xs);
        xs = _in0;
        goto TAIL_CALL_START;
      }
    }
    public static Dafny.ISequence<BigInteger> FromNat(BigInteger n) {
      Dafny.ISequence<BigInteger> _0___accumulator = Dafny.Sequence<BigInteger>.FromElements();
    TAIL_CALL_START: ;
      if ((n).Sign == 0) {
        return Dafny.Sequence<BigInteger>.Concat(_0___accumulator, Dafny.Sequence<BigInteger>.FromElements());
      } else {
        _0___accumulator = Dafny.Sequence<BigInteger>.Concat(_0___accumulator, Dafny.Sequence<BigInteger>.FromElements(Dafny.Helpers.EuclideanModulus(n, Std.JSON.Deserializer.Uint16StrConversion.__default.BASE())));
        BigInteger _in0 = Dafny.Helpers.EuclideanDivision(n, Std.JSON.Deserializer.Uint16StrConversion.__default.BASE());
        n = _in0;
        goto TAIL_CALL_START;
      }
    }
    public static Dafny.ISequence<BigInteger> SeqExtend(Dafny.ISequence<BigInteger> xs, BigInteger n)
    {
    TAIL_CALL_START: ;
      if ((new BigInteger((xs).Count)) >= (n)) {
        return xs;
      } else {
        Dafny.ISequence<BigInteger> _in0 = Dafny.Sequence<BigInteger>.Concat(xs, Dafny.Sequence<BigInteger>.FromElements(BigInteger.Zero));
        BigInteger _in1 = n;
        xs = _in0;
        n = _in1;
        goto TAIL_CALL_START;
      }
    }
    public static Dafny.ISequence<BigInteger> SeqExtendMultiple(Dafny.ISequence<BigInteger> xs, BigInteger n)
    {
      BigInteger _0_newLen = ((new BigInteger((xs).Count)) + (n)) - (Dafny.Helpers.EuclideanModulus(new BigInteger((xs).Count), n));
      return Std.JSON.Deserializer.Uint16StrConversion.__default.SeqExtend(xs, _0_newLen);
    }
    public static Dafny.ISequence<BigInteger> FromNatWithLen(BigInteger n, BigInteger len)
    {
      return Std.JSON.Deserializer.Uint16StrConversion.__default.SeqExtend(Std.JSON.Deserializer.Uint16StrConversion.__default.FromNat(n), len);
    }
    public static Dafny.ISequence<BigInteger> SeqZero(BigInteger len) {
      Dafny.ISequence<BigInteger> _0_xs = Std.JSON.Deserializer.Uint16StrConversion.__default.FromNatWithLen(BigInteger.Zero, len);
      return _0_xs;
    }
    public static _System._ITuple2<Dafny.ISequence<BigInteger>, BigInteger> SeqAdd(Dafny.ISequence<BigInteger> xs, Dafny.ISequence<BigInteger> ys)
    {
      if ((new BigInteger((xs).Count)).Sign == 0) {
        return _System.Tuple2<Dafny.ISequence<BigInteger>, BigInteger>.create(Dafny.Sequence<BigInteger>.FromElements(), BigInteger.Zero);
      } else {
        _System._ITuple2<Dafny.ISequence<BigInteger>, BigInteger> _let_tmp_rhs0 = Std.JSON.Deserializer.Uint16StrConversion.__default.SeqAdd(Std.Collections.Seq.__default.DropLast<BigInteger>(xs), Std.Collections.Seq.__default.DropLast<BigInteger>(ys));
        Dafny.ISequence<BigInteger> _0_zs_k = _let_tmp_rhs0.dtor__0;
        BigInteger _1_cin = _let_tmp_rhs0.dtor__1;
        BigInteger _2_sum = ((Std.Collections.Seq.__default.Last<BigInteger>(xs)) + (Std.Collections.Seq.__default.Last<BigInteger>(ys))) + (_1_cin);
        _System._ITuple2<BigInteger, BigInteger> _let_tmp_rhs1 = (((_2_sum) < (Std.JSON.Deserializer.Uint16StrConversion.__default.BASE())) ? (_System.Tuple2<BigInteger, BigInteger>.create(_2_sum, BigInteger.Zero)) : (_System.Tuple2<BigInteger, BigInteger>.create((_2_sum) - (Std.JSON.Deserializer.Uint16StrConversion.__default.BASE()), BigInteger.One)));
        BigInteger _3_sum__out = _let_tmp_rhs1.dtor__0;
        BigInteger _4_cout = _let_tmp_rhs1.dtor__1;
        return _System.Tuple2<Dafny.ISequence<BigInteger>, BigInteger>.create(Dafny.Sequence<BigInteger>.Concat(_0_zs_k, Dafny.Sequence<BigInteger>.FromElements(_3_sum__out)), _4_cout);
      }
    }
    public static _System._ITuple2<Dafny.ISequence<BigInteger>, BigInteger> SeqSub(Dafny.ISequence<BigInteger> xs, Dafny.ISequence<BigInteger> ys)
    {
      if ((new BigInteger((xs).Count)).Sign == 0) {
        return _System.Tuple2<Dafny.ISequence<BigInteger>, BigInteger>.create(Dafny.Sequence<BigInteger>.FromElements(), BigInteger.Zero);
      } else {
        _System._ITuple2<Dafny.ISequence<BigInteger>, BigInteger> _let_tmp_rhs0 = Std.JSON.Deserializer.Uint16StrConversion.__default.SeqSub(Std.Collections.Seq.__default.DropLast<BigInteger>(xs), Std.Collections.Seq.__default.DropLast<BigInteger>(ys));
        Dafny.ISequence<BigInteger> _0_zs = _let_tmp_rhs0.dtor__0;
        BigInteger _1_cin = _let_tmp_rhs0.dtor__1;
        _System._ITuple2<BigInteger, BigInteger> _let_tmp_rhs1 = (((Std.Collections.Seq.__default.Last<BigInteger>(xs)) >= ((Std.Collections.Seq.__default.Last<BigInteger>(ys)) + (_1_cin))) ? (_System.Tuple2<BigInteger, BigInteger>.create(((Std.Collections.Seq.__default.Last<BigInteger>(xs)) - (Std.Collections.Seq.__default.Last<BigInteger>(ys))) - (_1_cin), BigInteger.Zero)) : (_System.Tuple2<BigInteger, BigInteger>.create((((Std.JSON.Deserializer.Uint16StrConversion.__default.BASE()) + (Std.Collections.Seq.__default.Last<BigInteger>(xs))) - (Std.Collections.Seq.__default.Last<BigInteger>(ys))) - (_1_cin), BigInteger.One)));
        BigInteger _2_diff__out = _let_tmp_rhs1.dtor__0;
        BigInteger _3_cout = _let_tmp_rhs1.dtor__1;
        return _System.Tuple2<Dafny.ISequence<BigInteger>, BigInteger>.create(Dafny.Sequence<BigInteger>.Concat(_0_zs, Dafny.Sequence<BigInteger>.FromElements(_2_diff__out)), _3_cout);
      }
    }
    public static Dafny.ISequence<ushort> chars { get {
      return Dafny.Sequence<ushort>.FromElements((ushort)((new Dafny.Rune('0')).Value), (ushort)((new Dafny.Rune('1')).Value), (ushort)((new Dafny.Rune('2')).Value), (ushort)((new Dafny.Rune('3')).Value), (ushort)((new Dafny.Rune('4')).Value), (ushort)((new Dafny.Rune('5')).Value), (ushort)((new Dafny.Rune('6')).Value), (ushort)((new Dafny.Rune('7')).Value), (ushort)((new Dafny.Rune('8')).Value), (ushort)((new Dafny.Rune('9')).Value), (ushort)((new Dafny.Rune('a')).Value), (ushort)((new Dafny.Rune('b')).Value), (ushort)((new Dafny.Rune('c')).Value), (ushort)((new Dafny.Rune('d')).Value), (ushort)((new Dafny.Rune('e')).Value), (ushort)((new Dafny.Rune('f')).Value), (ushort)((new Dafny.Rune('A')).Value), (ushort)((new Dafny.Rune('B')).Value), (ushort)((new Dafny.Rune('C')).Value), (ushort)((new Dafny.Rune('D')).Value), (ushort)((new Dafny.Rune('E')).Value), (ushort)((new Dafny.Rune('F')).Value));
    } }
    public static BigInteger @base { get {
      return new BigInteger((Std.JSON.Deserializer.Uint16StrConversion.__default.chars).Count);
    } }
    public static Dafny.IMap<ushort,BigInteger> charToDigit { get {
      return Dafny.Map<ushort, BigInteger>.FromElements(new Dafny.Pair<ushort, BigInteger>((ushort)((new Dafny.Rune('0')).Value), BigInteger.Zero), new Dafny.Pair<ushort, BigInteger>((ushort)((new Dafny.Rune('1')).Value), BigInteger.One), new Dafny.Pair<ushort, BigInteger>((ushort)((new Dafny.Rune('2')).Value), new BigInteger(2)), new Dafny.Pair<ushort, BigInteger>((ushort)((new Dafny.Rune('3')).Value), new BigInteger(3)), new Dafny.Pair<ushort, BigInteger>((ushort)((new Dafny.Rune('4')).Value), new BigInteger(4)), new Dafny.Pair<ushort, BigInteger>((ushort)((new Dafny.Rune('5')).Value), new BigInteger(5)), new Dafny.Pair<ushort, BigInteger>((ushort)((new Dafny.Rune('6')).Value), new BigInteger(6)), new Dafny.Pair<ushort, BigInteger>((ushort)((new Dafny.Rune('7')).Value), new BigInteger(7)), new Dafny.Pair<ushort, BigInteger>((ushort)((new Dafny.Rune('8')).Value), new BigInteger(8)), new Dafny.Pair<ushort, BigInteger>((ushort)((new Dafny.Rune('9')).Value), new BigInteger(9)), new Dafny.Pair<ushort, BigInteger>((ushort)((new Dafny.Rune('a')).Value), new BigInteger(10)), new Dafny.Pair<ushort, BigInteger>((ushort)((new Dafny.Rune('b')).Value), new BigInteger(11)), new Dafny.Pair<ushort, BigInteger>((ushort)((new Dafny.Rune('c')).Value), new BigInteger(12)), new Dafny.Pair<ushort, BigInteger>((ushort)((new Dafny.Rune('d')).Value), new BigInteger(13)), new Dafny.Pair<ushort, BigInteger>((ushort)((new Dafny.Rune('e')).Value), new BigInteger(14)), new Dafny.Pair<ushort, BigInteger>((ushort)((new Dafny.Rune('f')).Value), new BigInteger(15)), new Dafny.Pair<ushort, BigInteger>((ushort)((new Dafny.Rune('A')).Value), new BigInteger(10)), new Dafny.Pair<ushort, BigInteger>((ushort)((new Dafny.Rune('B')).Value), new BigInteger(11)), new Dafny.Pair<ushort, BigInteger>((ushort)((new Dafny.Rune('C')).Value), new BigInteger(12)), new Dafny.Pair<ushort, BigInteger>((ushort)((new Dafny.Rune('D')).Value), new BigInteger(13)), new Dafny.Pair<ushort, BigInteger>((ushort)((new Dafny.Rune('E')).Value), new BigInteger(14)), new Dafny.Pair<ushort, BigInteger>((ushort)((new Dafny.Rune('F')).Value), new BigInteger(15)));
    } }
  }

  public partial class CharSeq {
    private static readonly Dafny.TypeDescriptor<Dafny.ISequence<ushort>> _TYPE = new Dafny.TypeDescriptor<Dafny.ISequence<ushort>>(Dafny.Sequence<ushort>.Empty);
    public static Dafny.TypeDescriptor<Dafny.ISequence<ushort>> _TypeDescriptor() {
      return _TYPE;
    }
    public static bool _Is(Dafny.ISequence<ushort> __source) {
      Dafny.ISequence<ushort> _0_chars = __source;
      return (new BigInteger((_0_chars).Count)) > (BigInteger.One);
    }
  }

  public partial class digit {
    private static readonly Dafny.TypeDescriptor<BigInteger> _TYPE = new Dafny.TypeDescriptor<BigInteger>(BigInteger.Zero);
    public static Dafny.TypeDescriptor<BigInteger> _TypeDescriptor() {
      return _TYPE;
    }
    public static bool _Is(BigInteger __source) {
      BigInteger _1_i = __source;
      if (_System.nat._Is(_1_i)) {
        return ((_1_i).Sign != -1) && ((_1_i) < (Std.JSON.Deserializer.Uint16StrConversion.__default.BASE()));
      }
      return false;
    }
  }
} // end of namespace Std.JSON.Deserializer.Uint16StrConversion
namespace Std.JSON.Deserializer {

  public partial class __default {
    public static bool Bool(Std.JSON.Utils.Views.Core._IView__ js) {
      return ((js).At(0U)) == ((byte)((new Dafny.Rune('t')).Value));
    }
    public static Std.JSON.Errors._IDeserializationError UnsupportedEscape16(Dafny.ISequence<ushort> code) {
      return Std.JSON.Errors.DeserializationError.create_UnsupportedEscape(Std.Wrappers.Option<Dafny.ISequence<Dafny.Rune>>.GetOr(Std.Unicode.UnicodeStringsWithUnicodeChar.__default.FromUTF16Checked(code), Dafny.Sequence<Dafny.Rune>.UnicodeFromString("Couldn't decode UTF-16")));
    }
    public static ushort ToNat16(Dafny.ISequence<ushort> str) {
      BigInteger _0_hd = Std.JSON.Deserializer.Uint16StrConversion.__default.ToNat(str);
      return (ushort)(_0_hd);
    }
    public static Std.Wrappers._IResult<Dafny.ISequence<ushort>, Std.JSON.Errors._IDeserializationError> Unescape(Dafny.ISequence<ushort> str, BigInteger start, Dafny.ISequence<ushort> prefix)
    {
    TAIL_CALL_START: ;
      if ((start) >= (new BigInteger((str).Count))) {
        return Std.Wrappers.Result<Dafny.ISequence<ushort>, Std.JSON.Errors._IDeserializationError>.create_Success(prefix);
      } else if (((str).Select(start)) == ((ushort)((new Dafny.Rune('\\')).Value))) {
        if ((new BigInteger((str).Count)) == ((start) + (BigInteger.One))) {
          return Std.Wrappers.Result<Dafny.ISequence<ushort>, Std.JSON.Errors._IDeserializationError>.create_Failure(Std.JSON.Errors.DeserializationError.create_EscapeAtEOS());
        } else {
          ushort _0_c = (str).Select((start) + (BigInteger.One));
          if ((_0_c) == ((ushort)((new Dafny.Rune('u')).Value))) {
            if ((new BigInteger((str).Count)) <= ((start) + (new BigInteger(6)))) {
              return Std.Wrappers.Result<Dafny.ISequence<ushort>, Std.JSON.Errors._IDeserializationError>.create_Failure(Std.JSON.Errors.DeserializationError.create_EscapeAtEOS());
            } else {
              Dafny.ISequence<ushort> _1_code = (str).Subsequence((start) + (new BigInteger(2)), (start) + (new BigInteger(6)));
              if (Dafny.Helpers.Id<Func<Dafny.ISequence<ushort>, bool>>((_2_code) => Dafny.Helpers.Quantifier<ushort>((_2_code).UniqueElements, false, (((_exists_var_0) => {
                ushort _3_c = (ushort)_exists_var_0;
                return ((_2_code).Contains(_3_c)) && (!(Std.JSON.Deserializer.__default.HEX__TABLE__16).Contains(_3_c));
              }))))(_1_code)) {
                return Std.Wrappers.Result<Dafny.ISequence<ushort>, Std.JSON.Errors._IDeserializationError>.create_Failure(Std.JSON.Deserializer.__default.UnsupportedEscape16(_1_code));
              } else {
                ushort _4_hd = Std.JSON.Deserializer.__default.ToNat16(_1_code);
                Dafny.ISequence<ushort> _in0 = str;
                BigInteger _in1 = (start) + (new BigInteger(6));
                Dafny.ISequence<ushort> _in2 = Dafny.Sequence<ushort>.Concat(prefix, Dafny.Sequence<ushort>.FromElements(_4_hd));
                str = _in0;
                start = _in1;
                prefix = _in2;
                goto TAIL_CALL_START;
              }
            }
          } else {
            ushort _5_unescaped = ((System.Func<ushort>)(() => {
              ushort _source0 = _0_c;
              {
                if ((_source0) == ((ushort)(34))) {
                  return (ushort)(34);
                }
              }
              {
                if ((_source0) == ((ushort)(92))) {
                  return (ushort)(92);
                }
              }
              {
                if ((_source0) == ((ushort)(98))) {
                  return (ushort)(8);
                }
              }
              {
                if ((_source0) == ((ushort)(102))) {
                  return (ushort)(12);
                }
              }
              {
                if ((_source0) == ((ushort)(110))) {
                  return (ushort)(10);
                }
              }
              {
                if ((_source0) == ((ushort)(114))) {
                  return (ushort)(13);
                }
              }
              {
                if ((_source0) == ((ushort)(116))) {
                  return (ushort)(9);
                }
              }
              {
                return (ushort)(0);
              }
            }))();
            if ((new BigInteger(_5_unescaped)).Sign == 0) {
              return Std.Wrappers.Result<Dafny.ISequence<ushort>, Std.JSON.Errors._IDeserializationError>.create_Failure(Std.JSON.Deserializer.__default.UnsupportedEscape16((str).Subsequence(start, (start) + (new BigInteger(2)))));
            } else {
              Dafny.ISequence<ushort> _in3 = str;
              BigInteger _in4 = (start) + (new BigInteger(2));
              Dafny.ISequence<ushort> _in5 = Dafny.Sequence<ushort>.Concat(prefix, Dafny.Sequence<ushort>.FromElements(_5_unescaped));
              str = _in3;
              start = _in4;
              prefix = _in5;
              goto TAIL_CALL_START;
            }
          }
        }
      } else {
        Dafny.ISequence<ushort> _in6 = str;
        BigInteger _in7 = (start) + (BigInteger.One);
        Dafny.ISequence<ushort> _in8 = Dafny.Sequence<ushort>.Concat(prefix, Dafny.Sequence<ushort>.FromElements((str).Select(start)));
        str = _in6;
        start = _in7;
        prefix = _in8;
        goto TAIL_CALL_START;
      }
    }
    public static Std.Wrappers._IResult<Dafny.ISequence<Dafny.Rune>, Std.JSON.Errors._IDeserializationError> String(Std.JSON.Grammar._Ijstring js) {
      Std.Wrappers._IResult<Dafny.ISequence<Dafny.Rune>, Std.JSON.Errors._IDeserializationError> _0_valueOrError0 = (Std.Unicode.UnicodeStringsWithUnicodeChar.__default.FromUTF8Checked(((js).dtor_contents).Bytes())).ToResult<Std.JSON.Errors._IDeserializationError>(Std.JSON.Errors.DeserializationError.create_InvalidUnicode());
      if ((_0_valueOrError0).IsFailure()) {
        return (_0_valueOrError0).PropagateFailure<Dafny.ISequence<Dafny.Rune>>();
      } else {
        Dafny.ISequence<Dafny.Rune> _1_asUtf32 = (_0_valueOrError0).Extract();
        Std.Wrappers._IResult<Dafny.ISequence<ushort>, Std.JSON.Errors._IDeserializationError> _2_valueOrError1 = (Std.Unicode.UnicodeStringsWithUnicodeChar.__default.ToUTF16Checked(_1_asUtf32)).ToResult<Std.JSON.Errors._IDeserializationError>(Std.JSON.Errors.DeserializationError.create_InvalidUnicode());
        if ((_2_valueOrError1).IsFailure()) {
          return (_2_valueOrError1).PropagateFailure<Dafny.ISequence<Dafny.Rune>>();
        } else {
          Dafny.ISequence<ushort> _3_asUint16 = (_2_valueOrError1).Extract();
          Std.Wrappers._IResult<Dafny.ISequence<ushort>, Std.JSON.Errors._IDeserializationError> _4_valueOrError2 = Std.JSON.Deserializer.__default.Unescape(_3_asUint16, BigInteger.Zero, Dafny.Sequence<ushort>.FromElements());
          if ((_4_valueOrError2).IsFailure()) {
            return (_4_valueOrError2).PropagateFailure<Dafny.ISequence<Dafny.Rune>>();
          } else {
            Dafny.ISequence<ushort> _5_unescaped = (_4_valueOrError2).Extract();
            return (Std.Unicode.UnicodeStringsWithUnicodeChar.__default.FromUTF16Checked(_5_unescaped)).ToResult<Std.JSON.Errors._IDeserializationError>(Std.JSON.Errors.DeserializationError.create_InvalidUnicode());
          }
        }
      }
    }
    public static Std.Wrappers._IResult<BigInteger, Std.JSON.Errors._IDeserializationError> ToInt(Std.JSON.Utils.Views.Core._IView__ sign, Std.JSON.Utils.Views.Core._IView__ n)
    {
      BigInteger _0_n = Std.JSON.ByteStrConversion.__default.ToNat((n).Bytes());
      return Std.Wrappers.Result<BigInteger, Std.JSON.Errors._IDeserializationError>.create_Success((((sign).Char_q(new Dafny.Rune('-'))) ? ((BigInteger.Zero) - (_0_n)) : (_0_n)));
    }
    public static Std.Wrappers._IResult<Std.JSON.Values._IDecimal, Std.JSON.Errors._IDeserializationError> Number(Std.JSON.Grammar._Ijnumber js) {
      Std.JSON.Grammar._Ijnumber _let_tmp_rhs0 = js;
      Std.JSON.Utils.Views.Core._IView__ _0_minus = _let_tmp_rhs0.dtor_minus;
      Std.JSON.Utils.Views.Core._IView__ _1_num = _let_tmp_rhs0.dtor_num;
      Std.JSON.Grammar._IMaybe<Std.JSON.Grammar._Ijfrac> _2_frac = _let_tmp_rhs0.dtor_frac;
      Std.JSON.Grammar._IMaybe<Std.JSON.Grammar._Ijexp> _3_exp = _let_tmp_rhs0.dtor_exp;
      Std.Wrappers._IResult<BigInteger, Std.JSON.Errors._IDeserializationError> _4_valueOrError0 = Std.JSON.Deserializer.__default.ToInt(_0_minus, _1_num);
      if ((_4_valueOrError0).IsFailure()) {
        return (_4_valueOrError0).PropagateFailure<Std.JSON.Values._IDecimal>();
      } else {
        BigInteger _5_n = (_4_valueOrError0).Extract();
        Std.Wrappers._IResult<BigInteger, Std.JSON.Errors._IDeserializationError> _6_valueOrError1 = ((System.Func<Std.Wrappers._IResult<BigInteger, Std.JSON.Errors._IDeserializationError>>)(() => {
          Std.JSON.Grammar._IMaybe<Std.JSON.Grammar._Ijexp> _source0 = _3_exp;
          {
            if (_source0.is_Empty) {
              return Std.Wrappers.Result<BigInteger, Std.JSON.Errors._IDeserializationError>.create_Success(BigInteger.Zero);
            }
          }
          {
            Std.JSON.Grammar._Ijexp t0 = _source0.dtor_t;
            Std.JSON.Utils.Views.Core._IView__ _7_sign = t0.dtor_sign;
            Std.JSON.Utils.Views.Core._IView__ _8_num = t0.dtor_num;
            return Std.JSON.Deserializer.__default.ToInt(_7_sign, _8_num);
          }
        }))();
        if ((_6_valueOrError1).IsFailure()) {
          return (_6_valueOrError1).PropagateFailure<Std.JSON.Values._IDecimal>();
        } else {
          BigInteger _9_e10 = (_6_valueOrError1).Extract();
          Std.JSON.Grammar._IMaybe<Std.JSON.Grammar._Ijfrac> _source1 = _2_frac;
          {
            if (_source1.is_Empty) {
              return Std.Wrappers.Result<Std.JSON.Values._IDecimal, Std.JSON.Errors._IDeserializationError>.create_Success(Std.JSON.Values.Decimal.create(_5_n, _9_e10));
            }
          }
          {
            Std.JSON.Grammar._Ijfrac t1 = _source1.dtor_t;
            Std.JSON.Utils.Views.Core._IView__ _10_num = t1.dtor_num;
            BigInteger _11_pow10 = new BigInteger((_10_num).Length());
            Std.Wrappers._IResult<BigInteger, Std.JSON.Errors._IDeserializationError> _12_valueOrError2 = Std.JSON.Deserializer.__default.ToInt(_0_minus, _10_num);
            if ((_12_valueOrError2).IsFailure()) {
              return (_12_valueOrError2).PropagateFailure<Std.JSON.Values._IDecimal>();
            } else {
              BigInteger _13_frac = (_12_valueOrError2).Extract();
              return Std.Wrappers.Result<Std.JSON.Values._IDecimal, Std.JSON.Errors._IDeserializationError>.create_Success(Std.JSON.Values.Decimal.create(((_5_n) * (Std.Arithmetic.Power.__default.Pow(new BigInteger(10), _11_pow10))) + (_13_frac), (_9_e10) - (_11_pow10)));
            }
          }
        }
      }
    }
    public static Std.Wrappers._IResult<_System._ITuple2<Dafny.ISequence<Dafny.Rune>, Std.JSON.Values._IJSON>, Std.JSON.Errors._IDeserializationError> KeyValue(Std.JSON.Grammar._IjKeyValue js) {
      Std.Wrappers._IResult<Dafny.ISequence<Dafny.Rune>, Std.JSON.Errors._IDeserializationError> _0_valueOrError0 = Std.JSON.Deserializer.__default.String((js).dtor_k);
      if ((_0_valueOrError0).IsFailure()) {
        return (_0_valueOrError0).PropagateFailure<_System._ITuple2<Dafny.ISequence<Dafny.Rune>, Std.JSON.Values._IJSON>>();
      } else {
        Dafny.ISequence<Dafny.Rune> _1_k = (_0_valueOrError0).Extract();
        Std.Wrappers._IResult<Std.JSON.Values._IJSON, Std.JSON.Errors._IDeserializationError> _2_valueOrError1 = Std.JSON.Deserializer.__default.Value((js).dtor_v);
        if ((_2_valueOrError1).IsFailure()) {
          return (_2_valueOrError1).PropagateFailure<_System._ITuple2<Dafny.ISequence<Dafny.Rune>, Std.JSON.Values._IJSON>>();
        } else {
          Std.JSON.Values._IJSON _3_v = (_2_valueOrError1).Extract();
          return Std.Wrappers.Result<_System._ITuple2<Dafny.ISequence<Dafny.Rune>, Std.JSON.Values._IJSON>, Std.JSON.Errors._IDeserializationError>.create_Success(_System.Tuple2<Dafny.ISequence<Dafny.Rune>, Std.JSON.Values._IJSON>.create(_1_k, _3_v));
        }
      }
    }
    public static Std.Wrappers._IResult<Dafny.ISequence<_System._ITuple2<Dafny.ISequence<Dafny.Rune>, Std.JSON.Values._IJSON>>, Std.JSON.Errors._IDeserializationError> Object(Std.JSON.Grammar._IBracketed<Std.JSON.Utils.Views.Core._IView__, Std.JSON.Grammar._IjKeyValue, Std.JSON.Utils.Views.Core._IView__, Std.JSON.Utils.Views.Core._IView__> js) {
      return Std.Collections.Seq.__default.MapWithResult<Std.JSON.Grammar._ISuffixed<Std.JSON.Grammar._IjKeyValue, Std.JSON.Utils.Views.Core._IView__>, _System._ITuple2<Dafny.ISequence<Dafny.Rune>, Std.JSON.Values._IJSON>, Std.JSON.Errors._IDeserializationError>(Dafny.Helpers.Id<Func<Std.JSON.Grammar._IBracketed<Std.JSON.Utils.Views.Core._IView__, Std.JSON.Grammar._IjKeyValue, Std.JSON.Utils.Views.Core._IView__, Std.JSON.Utils.Views.Core._IView__>, Func<Std.JSON.Grammar._ISuffixed<Std.JSON.Grammar._IjKeyValue, Std.JSON.Utils.Views.Core._IView__>, Std.Wrappers._IResult<_System._ITuple2<Dafny.ISequence<Dafny.Rune>, Std.JSON.Values._IJSON>, Std.JSON.Errors._IDeserializationError>>>>((_0_js) => ((System.Func<Std.JSON.Grammar._ISuffixed<Std.JSON.Grammar._IjKeyValue, Std.JSON.Utils.Views.Core._IView__>, Std.Wrappers._IResult<_System._ITuple2<Dafny.ISequence<Dafny.Rune>, Std.JSON.Values._IJSON>, Std.JSON.Errors._IDeserializationError>>)((_1_d) => {
        return Std.JSON.Deserializer.__default.KeyValue((_1_d).dtor_t);
      })))(js), (js).dtor_data);
    }
    public static Std.Wrappers._IResult<Dafny.ISequence<Std.JSON.Values._IJSON>, Std.JSON.Errors._IDeserializationError> Array(Std.JSON.Grammar._IBracketed<Std.JSON.Utils.Views.Core._IView__, Std.JSON.Grammar._IValue, Std.JSON.Utils.Views.Core._IView__, Std.JSON.Utils.Views.Core._IView__> js) {
      return Std.Collections.Seq.__default.MapWithResult<Std.JSON.Grammar._ISuffixed<Std.JSON.Grammar._IValue, Std.JSON.Utils.Views.Core._IView__>, Std.JSON.Values._IJSON, Std.JSON.Errors._IDeserializationError>(Dafny.Helpers.Id<Func<Std.JSON.Grammar._IBracketed<Std.JSON.Utils.Views.Core._IView__, Std.JSON.Grammar._IValue, Std.JSON.Utils.Views.Core._IView__, Std.JSON.Utils.Views.Core._IView__>, Func<Std.JSON.Grammar._ISuffixed<Std.JSON.Grammar._IValue, Std.JSON.Utils.Views.Core._IView__>, Std.Wrappers._IResult<Std.JSON.Values._IJSON, Std.JSON.Errors._IDeserializationError>>>>((_0_js) => ((System.Func<Std.JSON.Grammar._ISuffixed<Std.JSON.Grammar._IValue, Std.JSON.Utils.Views.Core._IView__>, Std.Wrappers._IResult<Std.JSON.Values._IJSON, Std.JSON.Errors._IDeserializationError>>)((_1_d) => {
        return Std.JSON.Deserializer.__default.Value((_1_d).dtor_t);
      })))(js), (js).dtor_data);
    }
    public static Std.Wrappers._IResult<Std.JSON.Values._IJSON, Std.JSON.Errors._IDeserializationError> Value(Std.JSON.Grammar._IValue js) {
      Std.JSON.Grammar._IValue _source0 = js;
      {
        if (_source0.is_Null) {
          return Std.Wrappers.Result<Std.JSON.Values._IJSON, Std.JSON.Errors._IDeserializationError>.create_Success(Std.JSON.Values.JSON.create_Null());
        }
      }
      {
        if (_source0.is_Bool) {
          Std.JSON.Utils.Views.Core._IView__ _0_b = _source0.dtor_b;
          return Std.Wrappers.Result<Std.JSON.Values._IJSON, Std.JSON.Errors._IDeserializationError>.create_Success(Std.JSON.Values.JSON.create_Bool(Std.JSON.Deserializer.__default.Bool(_0_b)));
        }
      }
      {
        if (_source0.is_String) {
          Std.JSON.Grammar._Ijstring _1_str = _source0.dtor_str;
          Std.Wrappers._IResult<Dafny.ISequence<Dafny.Rune>, Std.JSON.Errors._IDeserializationError> _2_valueOrError0 = Std.JSON.Deserializer.__default.String(_1_str);
          if ((_2_valueOrError0).IsFailure()) {
            return (_2_valueOrError0).PropagateFailure<Std.JSON.Values._IJSON>();
          } else {
            Dafny.ISequence<Dafny.Rune> _3_s = (_2_valueOrError0).Extract();
            return Std.Wrappers.Result<Std.JSON.Values._IJSON, Std.JSON.Errors._IDeserializationError>.create_Success(Std.JSON.Values.JSON.create_String(_3_s));
          }
        }
      }
      {
        if (_source0.is_Number) {
          Std.JSON.Grammar._Ijnumber _4_dec = _source0.dtor_num;
          Std.Wrappers._IResult<Std.JSON.Values._IDecimal, Std.JSON.Errors._IDeserializationError> _5_valueOrError1 = Std.JSON.Deserializer.__default.Number(_4_dec);
          if ((_5_valueOrError1).IsFailure()) {
            return (_5_valueOrError1).PropagateFailure<Std.JSON.Values._IJSON>();
          } else {
            Std.JSON.Values._IDecimal _6_n = (_5_valueOrError1).Extract();
            return Std.Wrappers.Result<Std.JSON.Values._IJSON, Std.JSON.Errors._IDeserializationError>.create_Success(Std.JSON.Values.JSON.create_Number(_6_n));
          }
        }
      }
      {
        if (_source0.is_Object) {
          Std.JSON.Grammar._IBracketed<Std.JSON.Utils.Views.Core._IView__, Std.JSON.Grammar._IjKeyValue, Std.JSON.Utils.Views.Core._IView__, Std.JSON.Utils.Views.Core._IView__> _7_obj = _source0.dtor_obj;
          Std.Wrappers._IResult<Dafny.ISequence<_System._ITuple2<Dafny.ISequence<Dafny.Rune>, Std.JSON.Values._IJSON>>, Std.JSON.Errors._IDeserializationError> _8_valueOrError2 = Std.JSON.Deserializer.__default.Object(_7_obj);
          if ((_8_valueOrError2).IsFailure()) {
            return (_8_valueOrError2).PropagateFailure<Std.JSON.Values._IJSON>();
          } else {
            Dafny.ISequence<_System._ITuple2<Dafny.ISequence<Dafny.Rune>, Std.JSON.Values._IJSON>> _9_o = (_8_valueOrError2).Extract();
            return Std.Wrappers.Result<Std.JSON.Values._IJSON, Std.JSON.Errors._IDeserializationError>.create_Success(Std.JSON.Values.JSON.create_Object(_9_o));
          }
        }
      }
      {
        Std.JSON.Grammar._IBracketed<Std.JSON.Utils.Views.Core._IView__, Std.JSON.Grammar._IValue, Std.JSON.Utils.Views.Core._IView__, Std.JSON.Utils.Views.Core._IView__> _10_arr = _source0.dtor_arr;
        Std.Wrappers._IResult<Dafny.ISequence<Std.JSON.Values._IJSON>, Std.JSON.Errors._IDeserializationError> _11_valueOrError3 = Std.JSON.Deserializer.__default.Array(_10_arr);
        if ((_11_valueOrError3).IsFailure()) {
          return (_11_valueOrError3).PropagateFailure<Std.JSON.Values._IJSON>();
        } else {
          Dafny.ISequence<Std.JSON.Values._IJSON> _12_a = (_11_valueOrError3).Extract();
          return Std.Wrappers.Result<Std.JSON.Values._IJSON, Std.JSON.Errors._IDeserializationError>.create_Success(Std.JSON.Values.JSON.create_Array(_12_a));
        }
      }
    }
    public static Std.Wrappers._IResult<Std.JSON.Values._IJSON, Std.JSON.Errors._IDeserializationError> JSON(Std.JSON.Grammar._IStructural<Std.JSON.Grammar._IValue> js) {
      return Std.JSON.Deserializer.__default.Value((js).dtor_t);
    }
    public static Dafny.IMap<ushort,BigInteger> HEX__TABLE__16 { get {
      return Std.JSON.Deserializer.Uint16StrConversion.__default.charToDigit;
    } }
    public static Dafny.IMap<byte,BigInteger> DIGITS { get {
      return Std.JSON.ByteStrConversion.__default.charToDigit;
    } }
    public static byte MINUS { get {
      return (byte)((new Dafny.Rune('-')).Value);
    } }
  }
} // end of namespace Std.JSON.Deserializer
namespace Std.JSON.ConcreteSyntax.Spec {

  public partial class __default {
    public static Dafny.ISequence<byte> View(Std.JSON.Utils.Views.Core._IView__ v) {
      return (v).Bytes();
    }
    public static Dafny.ISequence<byte> Structural<__T>(Std.JSON.Grammar._IStructural<__T> self, Func<__T, Dafny.ISequence<byte>> fT)
    {
      return Dafny.Sequence<byte>.Concat(Dafny.Sequence<byte>.Concat(Std.JSON.ConcreteSyntax.Spec.__default.View((self).dtor_before), Dafny.Helpers.Id<Func<__T, Dafny.ISequence<byte>>>(fT)((self).dtor_t)), Std.JSON.ConcreteSyntax.Spec.__default.View((self).dtor_after));
    }
    public static Dafny.ISequence<byte> StructuralView(Std.JSON.Grammar._IStructural<Std.JSON.Utils.Views.Core._IView__> self) {
      return Std.JSON.ConcreteSyntax.Spec.__default.Structural<Std.JSON.Utils.Views.Core._IView__>(self, Std.JSON.ConcreteSyntax.Spec.__default.View);
    }
    public static Dafny.ISequence<byte> Maybe<__T>(Std.JSON.Grammar._IMaybe<__T> self, Func<__T, Dafny.ISequence<byte>> fT)
    {
      if ((self).is_Empty) {
        return Dafny.Sequence<byte>.FromElements();
      } else {
        return Dafny.Helpers.Id<Func<__T, Dafny.ISequence<byte>>>(fT)((self).dtor_t);
      }
    }
    public static Dafny.ISequence<byte> ConcatBytes<__T>(Dafny.ISequence<__T> ts, Func<__T, Dafny.ISequence<byte>> fT)
    {
      Dafny.ISequence<byte> _0___accumulator = Dafny.Sequence<byte>.FromElements();
    TAIL_CALL_START: ;
      if ((new BigInteger((ts).Count)).Sign == 0) {
        return Dafny.Sequence<byte>.Concat(_0___accumulator, Dafny.Sequence<byte>.FromElements());
      } else {
        _0___accumulator = Dafny.Sequence<byte>.Concat(_0___accumulator, Dafny.Helpers.Id<Func<__T, Dafny.ISequence<byte>>>(fT)((ts).Select(BigInteger.Zero)));
        Dafny.ISequence<__T> _in0 = (ts).Drop(BigInteger.One);
        Func<__T, Dafny.ISequence<byte>> _in1 = fT;
        ts = _in0;
        fT = _in1;
        goto TAIL_CALL_START;
      }
    }
    public static Dafny.ISequence<byte> Bracketed<__D, __S>(Std.JSON.Grammar._IBracketed<Std.JSON.Utils.Views.Core._IView__, __D, __S, Std.JSON.Utils.Views.Core._IView__> self, Func<Std.JSON.Grammar._ISuffixed<__D, __S>, Dafny.ISequence<byte>> fDatum)
    {
      return Dafny.Sequence<byte>.Concat(Dafny.Sequence<byte>.Concat(Std.JSON.ConcreteSyntax.Spec.__default.StructuralView((self).dtor_l), Std.JSON.ConcreteSyntax.Spec.__default.ConcatBytes<Std.JSON.Grammar._ISuffixed<__D, __S>>((self).dtor_data, fDatum)), Std.JSON.ConcreteSyntax.Spec.__default.StructuralView((self).dtor_r));
    }
    public static Dafny.ISequence<byte> KeyValue(Std.JSON.Grammar._IjKeyValue self) {
      return Dafny.Sequence<byte>.Concat(Dafny.Sequence<byte>.Concat(Std.JSON.ConcreteSyntax.Spec.__default.String((self).dtor_k), Std.JSON.ConcreteSyntax.Spec.__default.StructuralView((self).dtor_colon)), Std.JSON.ConcreteSyntax.Spec.__default.Value((self).dtor_v));
    }
    public static Dafny.ISequence<byte> Frac(Std.JSON.Grammar._Ijfrac self) {
      return Dafny.Sequence<byte>.Concat(Std.JSON.ConcreteSyntax.Spec.__default.View((self).dtor_period), Std.JSON.ConcreteSyntax.Spec.__default.View((self).dtor_num));
    }
    public static Dafny.ISequence<byte> Exp(Std.JSON.Grammar._Ijexp self) {
      return Dafny.Sequence<byte>.Concat(Dafny.Sequence<byte>.Concat(Std.JSON.ConcreteSyntax.Spec.__default.View((self).dtor_e), Std.JSON.ConcreteSyntax.Spec.__default.View((self).dtor_sign)), Std.JSON.ConcreteSyntax.Spec.__default.View((self).dtor_num));
    }
    public static Dafny.ISequence<byte> Number(Std.JSON.Grammar._Ijnumber self) {
      return Dafny.Sequence<byte>.Concat(Dafny.Sequence<byte>.Concat(Dafny.Sequence<byte>.Concat(Std.JSON.ConcreteSyntax.Spec.__default.View((self).dtor_minus), Std.JSON.ConcreteSyntax.Spec.__default.View((self).dtor_num)), Std.JSON.ConcreteSyntax.Spec.__default.Maybe<Std.JSON.Grammar._Ijfrac>((self).dtor_frac, Std.JSON.ConcreteSyntax.Spec.__default.Frac)), Std.JSON.ConcreteSyntax.Spec.__default.Maybe<Std.JSON.Grammar._Ijexp>((self).dtor_exp, Std.JSON.ConcreteSyntax.Spec.__default.Exp));
    }
    public static Dafny.ISequence<byte> String(Std.JSON.Grammar._Ijstring self) {
      return Dafny.Sequence<byte>.Concat(Dafny.Sequence<byte>.Concat(Std.JSON.ConcreteSyntax.Spec.__default.View((self).dtor_lq), Std.JSON.ConcreteSyntax.Spec.__default.View((self).dtor_contents)), Std.JSON.ConcreteSyntax.Spec.__default.View((self).dtor_rq));
    }
    public static Dafny.ISequence<byte> CommaSuffix(Std.JSON.Grammar._IMaybe<Std.JSON.Grammar._IStructural<Std.JSON.Utils.Views.Core._IView__>> c) {
      return Std.JSON.ConcreteSyntax.Spec.__default.Maybe<Std.JSON.Grammar._IStructural<Std.JSON.Utils.Views.Core._IView__>>(c, Std.JSON.ConcreteSyntax.Spec.__default.StructuralView);
    }
    public static Dafny.ISequence<byte> Member(Std.JSON.Grammar._ISuffixed<Std.JSON.Grammar._IjKeyValue, Std.JSON.Utils.Views.Core._IView__> self) {
      return Dafny.Sequence<byte>.Concat(Std.JSON.ConcreteSyntax.Spec.__default.KeyValue((self).dtor_t), Std.JSON.ConcreteSyntax.Spec.__default.CommaSuffix((self).dtor_suffix));
    }
    public static Dafny.ISequence<byte> Item(Std.JSON.Grammar._ISuffixed<Std.JSON.Grammar._IValue, Std.JSON.Utils.Views.Core._IView__> self) {
      return Dafny.Sequence<byte>.Concat(Std.JSON.ConcreteSyntax.Spec.__default.Value((self).dtor_t), Std.JSON.ConcreteSyntax.Spec.__default.CommaSuffix((self).dtor_suffix));
    }
    public static Dafny.ISequence<byte> Object(Std.JSON.Grammar._IBracketed<Std.JSON.Utils.Views.Core._IView__, Std.JSON.Grammar._IjKeyValue, Std.JSON.Utils.Views.Core._IView__, Std.JSON.Utils.Views.Core._IView__> obj) {
      return Std.JSON.ConcreteSyntax.Spec.__default.Bracketed<Std.JSON.Grammar._IjKeyValue, Std.JSON.Utils.Views.Core._IView__>(obj, Dafny.Helpers.Id<Func<Std.JSON.Grammar._IBracketed<Std.JSON.Utils.Views.Core._IView__, Std.JSON.Grammar._IjKeyValue, Std.JSON.Utils.Views.Core._IView__, Std.JSON.Utils.Views.Core._IView__>, Func<Std.JSON.Grammar._ISuffixed<Std.JSON.Grammar._IjKeyValue, Std.JSON.Utils.Views.Core._IView__>, Dafny.ISequence<byte>>>>((_0_obj) => ((System.Func<Std.JSON.Grammar._ISuffixed<Std.JSON.Grammar._IjKeyValue, Std.JSON.Utils.Views.Core._IView__>, Dafny.ISequence<byte>>)((_1_d) => {
        return Std.JSON.ConcreteSyntax.Spec.__default.Member(_1_d);
      })))(obj));
    }
    public static Dafny.ISequence<byte> Array(Std.JSON.Grammar._IBracketed<Std.JSON.Utils.Views.Core._IView__, Std.JSON.Grammar._IValue, Std.JSON.Utils.Views.Core._IView__, Std.JSON.Utils.Views.Core._IView__> arr) {
      return Std.JSON.ConcreteSyntax.Spec.__default.Bracketed<Std.JSON.Grammar._IValue, Std.JSON.Utils.Views.Core._IView__>(arr, Dafny.Helpers.Id<Func<Std.JSON.Grammar._IBracketed<Std.JSON.Utils.Views.Core._IView__, Std.JSON.Grammar._IValue, Std.JSON.Utils.Views.Core._IView__, Std.JSON.Utils.Views.Core._IView__>, Func<Std.JSON.Grammar._ISuffixed<Std.JSON.Grammar._IValue, Std.JSON.Utils.Views.Core._IView__>, Dafny.ISequence<byte>>>>((_0_arr) => ((System.Func<Std.JSON.Grammar._ISuffixed<Std.JSON.Grammar._IValue, Std.JSON.Utils.Views.Core._IView__>, Dafny.ISequence<byte>>)((_1_d) => {
        return Std.JSON.ConcreteSyntax.Spec.__default.Item(_1_d);
      })))(arr));
    }
    public static Dafny.ISequence<byte> Value(Std.JSON.Grammar._IValue self) {
      Std.JSON.Grammar._IValue _source0 = self;
      {
        if (_source0.is_Null) {
          Std.JSON.Utils.Views.Core._IView__ _0_n = _source0.dtor_n;
          return Std.JSON.ConcreteSyntax.Spec.__default.View(_0_n);
        }
      }
      {
        if (_source0.is_Bool) {
          Std.JSON.Utils.Views.Core._IView__ _1_b = _source0.dtor_b;
          return Std.JSON.ConcreteSyntax.Spec.__default.View(_1_b);
        }
      }
      {
        if (_source0.is_String) {
          Std.JSON.Grammar._Ijstring _2_str = _source0.dtor_str;
          return Std.JSON.ConcreteSyntax.Spec.__default.String(_2_str);
        }
      }
      {
        if (_source0.is_Number) {
          Std.JSON.Grammar._Ijnumber _3_num = _source0.dtor_num;
          return Std.JSON.ConcreteSyntax.Spec.__default.Number(_3_num);
        }
      }
      {
        if (_source0.is_Object) {
          Std.JSON.Grammar._IBracketed<Std.JSON.Utils.Views.Core._IView__, Std.JSON.Grammar._IjKeyValue, Std.JSON.Utils.Views.Core._IView__, Std.JSON.Utils.Views.Core._IView__> _4_obj = _source0.dtor_obj;
          return Std.JSON.ConcreteSyntax.Spec.__default.Object(_4_obj);
        }
      }
      {
        Std.JSON.Grammar._IBracketed<Std.JSON.Utils.Views.Core._IView__, Std.JSON.Grammar._IValue, Std.JSON.Utils.Views.Core._IView__, Std.JSON.Utils.Views.Core._IView__> _5_arr = _source0.dtor_arr;
        return Std.JSON.ConcreteSyntax.Spec.__default.Array(_5_arr);
      }
    }
    public static Dafny.ISequence<byte> JSON(Std.JSON.Grammar._IStructural<Std.JSON.Grammar._IValue> js) {
      return Std.JSON.ConcreteSyntax.Spec.__default.Structural<Std.JSON.Grammar._IValue>(js, Std.JSON.ConcreteSyntax.Spec.__default.Value);
    }
  }
} // end of namespace Std.JSON.ConcreteSyntax.Spec
namespace Std.JSON.ConcreteSyntax.SpecProperties {

} // end of namespace Std.JSON.ConcreteSyntax.SpecProperties
namespace Std.JSON.ConcreteSyntax {

} // end of namespace Std.JSON.ConcreteSyntax
namespace Std.JSON.ZeroCopy.Serializer {

  public partial class __default {
    public static Std.Wrappers._IResult<byte[], Std.JSON.Errors._ISerializationError> Serialize(Std.JSON.Grammar._IStructural<Std.JSON.Grammar._IValue> js)
    {
      Std.Wrappers._IResult<byte[], Std.JSON.Errors._ISerializationError> rbs = Std.Wrappers.Result<byte[], Std.JSON.Errors._ISerializationError>.Default(new byte[0]);
      Std.JSON.Utils.Views.Writers._IWriter__ _0_writer;
      _0_writer = Std.JSON.ZeroCopy.Serializer.__default.Text(js);
      Std.Wrappers._IOutcomeResult<Std.JSON.Errors._ISerializationError> _1_valueOrError0 = Std.Wrappers.OutcomeResult<Std.JSON.Errors._ISerializationError>.Default();
      _1_valueOrError0 = Std.Wrappers.__default.Need<Std.JSON.Errors._ISerializationError>((_0_writer).Unsaturated_q, Std.JSON.Errors.SerializationError.create_OutOfMemory());
      if ((_1_valueOrError0).IsFailure()) {
        rbs = (_1_valueOrError0).PropagateFailure<byte[]>();
        return rbs;
      }
      byte[] _2_bs;
      byte[] _out0;
      _out0 = (_0_writer).ToArray();
      _2_bs = _out0;
      rbs = Std.Wrappers.Result<byte[], Std.JSON.Errors._ISerializationError>.create_Success(_2_bs);
      return rbs;
      return rbs;
    }
    public static Std.Wrappers._IResult<uint, Std.JSON.Errors._ISerializationError> SerializeTo(Std.JSON.Grammar._IStructural<Std.JSON.Grammar._IValue> js, byte[] dest)
    {
      Std.Wrappers._IResult<uint, Std.JSON.Errors._ISerializationError> len = Std.Wrappers.Result<uint, Std.JSON.Errors._ISerializationError>.Default(0);
      Std.JSON.Utils.Views.Writers._IWriter__ _0_writer;
      _0_writer = Std.JSON.ZeroCopy.Serializer.__default.Text(js);
      Std.Wrappers._IOutcomeResult<Std.JSON.Errors._ISerializationError> _1_valueOrError0 = Std.Wrappers.OutcomeResult<Std.JSON.Errors._ISerializationError>.Default();
      _1_valueOrError0 = Std.Wrappers.__default.Need<Std.JSON.Errors._ISerializationError>((_0_writer).Unsaturated_q, Std.JSON.Errors.SerializationError.create_OutOfMemory());
      if ((_1_valueOrError0).IsFailure()) {
        len = (_1_valueOrError0).PropagateFailure<uint>();
        return len;
      }
      Std.Wrappers._IOutcomeResult<Std.JSON.Errors._ISerializationError> _2_valueOrError1 = Std.Wrappers.OutcomeResult<Std.JSON.Errors._ISerializationError>.Default();
      _2_valueOrError1 = Std.Wrappers.__default.Need<Std.JSON.Errors._ISerializationError>((new BigInteger((_0_writer).dtor_length)) <= (new BigInteger((dest).Length)), Std.JSON.Errors.SerializationError.create_OutOfMemory());
      if ((_2_valueOrError1).IsFailure()) {
        len = (_2_valueOrError1).PropagateFailure<uint>();
        return len;
      }
      (_0_writer).CopyTo(dest);
      len = Std.Wrappers.Result<uint, Std.JSON.Errors._ISerializationError>.create_Success((_0_writer).dtor_length);
      return len;
      return len;
    }
    public static Std.JSON.Utils.Views.Writers._IWriter__ Text(Std.JSON.Grammar._IStructural<Std.JSON.Grammar._IValue> js) {
      return Std.JSON.ZeroCopy.Serializer.__default.JSON(js, Std.JSON.Utils.Views.Writers.Writer__.Empty);
    }
    public static Std.JSON.Utils.Views.Writers._IWriter__ JSON(Std.JSON.Grammar._IStructural<Std.JSON.Grammar._IValue> js, Std.JSON.Utils.Views.Writers._IWriter__ writer)
    {
      return (((writer).Append((js).dtor_before)).Then(Dafny.Helpers.Id<Func<Std.JSON.Grammar._IStructural<Std.JSON.Grammar._IValue>, Func<Std.JSON.Utils.Views.Writers._IWriter__, Std.JSON.Utils.Views.Writers._IWriter__>>>((_0_js) => ((System.Func<Std.JSON.Utils.Views.Writers._IWriter__, Std.JSON.Utils.Views.Writers._IWriter__>)((_1_wr) => {
        return Std.JSON.ZeroCopy.Serializer.__default.Value((_0_js).dtor_t, _1_wr);
      })))(js))).Append((js).dtor_after);
    }
    public static Std.JSON.Utils.Views.Writers._IWriter__ Value(Std.JSON.Grammar._IValue v, Std.JSON.Utils.Views.Writers._IWriter__ writer)
    {
      Std.JSON.Grammar._IValue _source0 = v;
      {
        if (_source0.is_Null) {
          Std.JSON.Utils.Views.Core._IView__ _0_n = _source0.dtor_n;
          Std.JSON.Utils.Views.Writers._IWriter__ _1_wr = (writer).Append(_0_n);
          return _1_wr;
        }
      }
      {
        if (_source0.is_Bool) {
          Std.JSON.Utils.Views.Core._IView__ _2_b = _source0.dtor_b;
          Std.JSON.Utils.Views.Writers._IWriter__ _3_wr = (writer).Append(_2_b);
          return _3_wr;
        }
      }
      {
        if (_source0.is_String) {
          Std.JSON.Grammar._Ijstring _4_str = _source0.dtor_str;
          Std.JSON.Utils.Views.Writers._IWriter__ _5_wr = Std.JSON.ZeroCopy.Serializer.__default.String(_4_str, writer);
          return _5_wr;
        }
      }
      {
        if (_source0.is_Number) {
          Std.JSON.Grammar._Ijnumber _6_num = _source0.dtor_num;
          Std.JSON.Utils.Views.Writers._IWriter__ _7_wr = Std.JSON.ZeroCopy.Serializer.__default.Number(_6_num, writer);
          return _7_wr;
        }
      }
      {
        if (_source0.is_Object) {
          Std.JSON.Grammar._IBracketed<Std.JSON.Utils.Views.Core._IView__, Std.JSON.Grammar._IjKeyValue, Std.JSON.Utils.Views.Core._IView__, Std.JSON.Utils.Views.Core._IView__> _8_obj = _source0.dtor_obj;
          Std.JSON.Utils.Views.Writers._IWriter__ _9_wr = Std.JSON.ZeroCopy.Serializer.__default.Object(_8_obj, writer);
          return _9_wr;
        }
      }
      {
        Std.JSON.Grammar._IBracketed<Std.JSON.Utils.Views.Core._IView__, Std.JSON.Grammar._IValue, Std.JSON.Utils.Views.Core._IView__, Std.JSON.Utils.Views.Core._IView__> _10_arr = _source0.dtor_arr;
        Std.JSON.Utils.Views.Writers._IWriter__ _11_wr = Std.JSON.ZeroCopy.Serializer.__default.Array(_10_arr, writer);
        return _11_wr;
      }
    }
    public static Std.JSON.Utils.Views.Writers._IWriter__ String(Std.JSON.Grammar._Ijstring str, Std.JSON.Utils.Views.Writers._IWriter__ writer)
    {
      return (((writer).Append((str).dtor_lq)).Append((str).dtor_contents)).Append((str).dtor_rq);
    }
    public static Std.JSON.Utils.Views.Writers._IWriter__ Number(Std.JSON.Grammar._Ijnumber num, Std.JSON.Utils.Views.Writers._IWriter__ writer)
    {
      Std.JSON.Utils.Views.Writers._IWriter__ _0_wr1 = ((writer).Append((num).dtor_minus)).Append((num).dtor_num);
      Std.JSON.Utils.Views.Writers._IWriter__ _1_wr2 = ((((num).dtor_frac).is_NonEmpty) ? (((_0_wr1).Append((((num).dtor_frac).dtor_t).dtor_period)).Append((((num).dtor_frac).dtor_t).dtor_num)) : (_0_wr1));
      Std.JSON.Utils.Views.Writers._IWriter__ _2_wr3 = ((((num).dtor_exp).is_NonEmpty) ? ((((_1_wr2).Append((((num).dtor_exp).dtor_t).dtor_e)).Append((((num).dtor_exp).dtor_t).dtor_sign)).Append((((num).dtor_exp).dtor_t).dtor_num)) : (_1_wr2));
      Std.JSON.Utils.Views.Writers._IWriter__ _3_wr = _2_wr3;
      return _3_wr;
    }
    public static Std.JSON.Utils.Views.Writers._IWriter__ StructuralView(Std.JSON.Grammar._IStructural<Std.JSON.Utils.Views.Core._IView__> st, Std.JSON.Utils.Views.Writers._IWriter__ writer)
    {
      return (((writer).Append((st).dtor_before)).Append((st).dtor_t)).Append((st).dtor_after);
    }
    public static Std.JSON.Utils.Views.Writers._IWriter__ Object(Std.JSON.Grammar._IBracketed<Std.JSON.Utils.Views.Core._IView__, Std.JSON.Grammar._IjKeyValue, Std.JSON.Utils.Views.Core._IView__, Std.JSON.Utils.Views.Core._IView__> obj, Std.JSON.Utils.Views.Writers._IWriter__ writer)
    {
      Std.JSON.Utils.Views.Writers._IWriter__ _0_wr = Std.JSON.ZeroCopy.Serializer.__default.StructuralView((obj).dtor_l, writer);
      Std.JSON.Utils.Views.Writers._IWriter__ _1_wr = Std.JSON.ZeroCopy.Serializer.__default.Members(obj, _0_wr);
      Std.JSON.Utils.Views.Writers._IWriter__ _2_wr = Std.JSON.ZeroCopy.Serializer.__default.StructuralView((obj).dtor_r, _1_wr);
      return _2_wr;
    }
    public static Std.JSON.Utils.Views.Writers._IWriter__ Array(Std.JSON.Grammar._IBracketed<Std.JSON.Utils.Views.Core._IView__, Std.JSON.Grammar._IValue, Std.JSON.Utils.Views.Core._IView__, Std.JSON.Utils.Views.Core._IView__> arr, Std.JSON.Utils.Views.Writers._IWriter__ writer)
    {
      Std.JSON.Utils.Views.Writers._IWriter__ _0_wr = Std.JSON.ZeroCopy.Serializer.__default.StructuralView((arr).dtor_l, writer);
      Std.JSON.Utils.Views.Writers._IWriter__ _1_wr = Std.JSON.ZeroCopy.Serializer.__default.Items(arr, _0_wr);
      Std.JSON.Utils.Views.Writers._IWriter__ _2_wr = Std.JSON.ZeroCopy.Serializer.__default.StructuralView((arr).dtor_r, _1_wr);
      return _2_wr;
    }
    public static Std.JSON.Utils.Views.Writers._IWriter__ Members(Std.JSON.Grammar._IBracketed<Std.JSON.Utils.Views.Core._IView__, Std.JSON.Grammar._IjKeyValue, Std.JSON.Utils.Views.Core._IView__, Std.JSON.Utils.Views.Core._IView__> obj, Std.JSON.Utils.Views.Writers._IWriter__ writer)
    {
      Std.JSON.Utils.Views.Writers._IWriter__ wr = Std.JSON.Utils.Views.Writers.Writer.Default();
      Std.JSON.Utils.Views.Writers._IWriter__ _out0;
      _out0 = Std.JSON.ZeroCopy.Serializer.__default.MembersImpl(obj, writer);
      wr = _out0;
      return wr;
    }
    public static Std.JSON.Utils.Views.Writers._IWriter__ Items(Std.JSON.Grammar._IBracketed<Std.JSON.Utils.Views.Core._IView__, Std.JSON.Grammar._IValue, Std.JSON.Utils.Views.Core._IView__, Std.JSON.Utils.Views.Core._IView__> arr, Std.JSON.Utils.Views.Writers._IWriter__ writer)
    {
      Std.JSON.Utils.Views.Writers._IWriter__ wr = Std.JSON.Utils.Views.Writers.Writer.Default();
      Std.JSON.Utils.Views.Writers._IWriter__ _out0;
      _out0 = Std.JSON.ZeroCopy.Serializer.__default.ItemsImpl(arr, writer);
      wr = _out0;
      return wr;
    }
    public static Std.JSON.Utils.Views.Writers._IWriter__ MembersImpl(Std.JSON.Grammar._IBracketed<Std.JSON.Utils.Views.Core._IView__, Std.JSON.Grammar._IjKeyValue, Std.JSON.Utils.Views.Core._IView__, Std.JSON.Utils.Views.Core._IView__> obj, Std.JSON.Utils.Views.Writers._IWriter__ writer)
    {
      Std.JSON.Utils.Views.Writers._IWriter__ wr = Std.JSON.Utils.Views.Writers.Writer.Default();
      wr = writer;
      Dafny.ISequence<Std.JSON.Grammar._ISuffixed<Std.JSON.Grammar._IjKeyValue, Std.JSON.Utils.Views.Core._IView__>> _0_members;
      _0_members = (obj).dtor_data;
      BigInteger _hi0 = new BigInteger((_0_members).Count);
      for (BigInteger _1_i = BigInteger.Zero; _1_i < _hi0; _1_i++) {
        wr = Std.JSON.ZeroCopy.Serializer.__default.Member((_0_members).Select(_1_i), wr);
      }
      return wr;
    }
    public static Std.JSON.Utils.Views.Writers._IWriter__ ItemsImpl(Std.JSON.Grammar._IBracketed<Std.JSON.Utils.Views.Core._IView__, Std.JSON.Grammar._IValue, Std.JSON.Utils.Views.Core._IView__, Std.JSON.Utils.Views.Core._IView__> arr, Std.JSON.Utils.Views.Writers._IWriter__ writer)
    {
      Std.JSON.Utils.Views.Writers._IWriter__ wr = Std.JSON.Utils.Views.Writers.Writer.Default();
      wr = writer;
      Dafny.ISequence<Std.JSON.Grammar._ISuffixed<Std.JSON.Grammar._IValue, Std.JSON.Utils.Views.Core._IView__>> _0_items;
      _0_items = (arr).dtor_data;
      BigInteger _hi0 = new BigInteger((_0_items).Count);
      for (BigInteger _1_i = BigInteger.Zero; _1_i < _hi0; _1_i++) {
        wr = Std.JSON.ZeroCopy.Serializer.__default.Item((_0_items).Select(_1_i), wr);
      }
      return wr;
    }
    public static Std.JSON.Utils.Views.Writers._IWriter__ Member(Std.JSON.Grammar._ISuffixed<Std.JSON.Grammar._IjKeyValue, Std.JSON.Utils.Views.Core._IView__> m, Std.JSON.Utils.Views.Writers._IWriter__ writer)
    {
      Std.JSON.Utils.Views.Writers._IWriter__ _0_wr = Std.JSON.ZeroCopy.Serializer.__default.String(((m).dtor_t).dtor_k, writer);
      Std.JSON.Utils.Views.Writers._IWriter__ _1_wr = Std.JSON.ZeroCopy.Serializer.__default.StructuralView(((m).dtor_t).dtor_colon, _0_wr);
      Std.JSON.Utils.Views.Writers._IWriter__ _2_wr = Std.JSON.ZeroCopy.Serializer.__default.Value(((m).dtor_t).dtor_v, _1_wr);
      Std.JSON.Utils.Views.Writers._IWriter__ _3_wr = ((((m).dtor_suffix).is_Empty) ? (_2_wr) : (Std.JSON.ZeroCopy.Serializer.__default.StructuralView(((m).dtor_suffix).dtor_t, _2_wr)));
      return _3_wr;
    }
    public static Std.JSON.Utils.Views.Writers._IWriter__ Item(Std.JSON.Grammar._ISuffixed<Std.JSON.Grammar._IValue, Std.JSON.Utils.Views.Core._IView__> m, Std.JSON.Utils.Views.Writers._IWriter__ writer)
    {
      Std.JSON.Utils.Views.Writers._IWriter__ _0_wr = Std.JSON.ZeroCopy.Serializer.__default.Value((m).dtor_t, writer);
      Std.JSON.Utils.Views.Writers._IWriter__ _1_wr = ((((m).dtor_suffix).is_Empty) ? (_0_wr) : (Std.JSON.ZeroCopy.Serializer.__default.StructuralView(((m).dtor_suffix).dtor_t, _0_wr)));
      return _1_wr;
    }
  }
} // end of namespace Std.JSON.ZeroCopy.Serializer
namespace Std.JSON.ZeroCopy.Deserializer.Core {

  public partial class __default {
    public static Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Utils.Views.Core._IView__>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>> Get(Std.JSON.Utils.Cursors._ICursor__ cs, Std.JSON.Errors._IDeserializationError err)
    {
      Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ICursor__, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>> _0_valueOrError0 = (cs).Get<Std.JSON.Errors._IDeserializationError>(err);
      if ((_0_valueOrError0).IsFailure()) {
        return (_0_valueOrError0).PropagateFailure<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Utils.Views.Core._IView__>>();
      } else {
        Std.JSON.Utils.Cursors._ICursor__ _1_cs = (_0_valueOrError0).Extract();
        return Std.Wrappers.Result<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Utils.Views.Core._IView__>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>>.create_Success((_1_cs).Split());
      }
    }
    public static Std.JSON.Utils.Cursors._ISplit<Std.JSON.Utils.Views.Core._IView__> WS(Std.JSON.Utils.Cursors._ICursor__ cs)
    {
      Std.JSON.Utils.Cursors._ISplit<Std.JSON.Utils.Views.Core._IView__> sp = Std.JSON.Utils.Cursors.Split<Std.JSON.Utils.Views.Core._IView__>.Default(Std.JSON.Grammar.jblanks.Default());
      uint _0_point_k;
      _0_point_k = (cs).dtor_point;
      uint _1_end;
      _1_end = (cs).dtor_end;
      while (((_0_point_k) < (_1_end)) && (Std.JSON.Grammar.__default.Blank_q(((cs).dtor_s).Select(_0_point_k)))) {
        _0_point_k = (_0_point_k) + (1U);
      }
      sp = (Std.JSON.Utils.Cursors.Cursor__.create((cs).dtor_s, (cs).dtor_beg, _0_point_k, (cs).dtor_end)).Split();
      return sp;
      return sp;
    }
    public static Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IStructural<__T>>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>> Structural<__T>(Std.JSON.Utils.Cursors._ICursor__ cs, Func<Std.JSON.Utils.Cursors._ICursor__, Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<__T>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>>> parser)
    {
      Std.JSON.Utils.Cursors._ISplit<Std.JSON.Utils.Views.Core._IView__> _let_tmp_rhs0 = Std.JSON.ZeroCopy.Deserializer.Core.__default.WS(cs);
      Std.JSON.Utils.Views.Core._IView__ _0_before = _let_tmp_rhs0.dtor_t;
      Std.JSON.Utils.Cursors._ICursor__ _1_cs = _let_tmp_rhs0.dtor_cs;
      Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<__T>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>> _2_valueOrError0 = Dafny.Helpers.Id<Func<Std.JSON.Utils.Cursors._ICursor__, Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<__T>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>>>>((parser))(_1_cs);
      if ((_2_valueOrError0).IsFailure()) {
        return (_2_valueOrError0).PropagateFailure<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IStructural<__T>>>();
      } else {
        Std.JSON.Utils.Cursors._ISplit<__T> _let_tmp_rhs1 = (_2_valueOrError0).Extract();
        __T _3_val = _let_tmp_rhs1.dtor_t;
        Std.JSON.Utils.Cursors._ICursor__ _4_cs = _let_tmp_rhs1.dtor_cs;
        Std.JSON.Utils.Cursors._ISplit<Std.JSON.Utils.Views.Core._IView__> _let_tmp_rhs2 = Std.JSON.ZeroCopy.Deserializer.Core.__default.WS(_4_cs);
        Std.JSON.Utils.Views.Core._IView__ _5_after = _let_tmp_rhs2.dtor_t;
        Std.JSON.Utils.Cursors._ICursor__ _6_cs = _let_tmp_rhs2.dtor_cs;
        return Std.Wrappers.Result<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IStructural<__T>>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>>.create_Success(Std.JSON.Utils.Cursors.Split<Std.JSON.Grammar._IStructural<__T>>.create(Std.JSON.Grammar.Structural<__T>.create(_0_before, _3_val, _5_after), _6_cs));
      }
    }
    public static Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IStructural<Std.JSON.Utils.Views.Core._IView__>> TryStructural(Std.JSON.Utils.Cursors._ICursor__ cs) {
      Std.JSON.Utils.Cursors._ISplit<Std.JSON.Utils.Views.Core._IView__> _let_tmp_rhs0 = Std.JSON.ZeroCopy.Deserializer.Core.__default.WS(cs);
      Std.JSON.Utils.Views.Core._IView__ _0_before = _let_tmp_rhs0.dtor_t;
      Std.JSON.Utils.Cursors._ICursor__ _1_cs = _let_tmp_rhs0.dtor_cs;
      Std.JSON.Utils.Cursors._ISplit<Std.JSON.Utils.Views.Core._IView__> _let_tmp_rhs1 = ((_1_cs).SkipByte()).Split();
      Std.JSON.Utils.Views.Core._IView__ _2_val = _let_tmp_rhs1.dtor_t;
      Std.JSON.Utils.Cursors._ICursor__ _3_cs = _let_tmp_rhs1.dtor_cs;
      Std.JSON.Utils.Cursors._ISplit<Std.JSON.Utils.Views.Core._IView__> _let_tmp_rhs2 = Std.JSON.ZeroCopy.Deserializer.Core.__default.WS(_3_cs);
      Std.JSON.Utils.Views.Core._IView__ _4_after = _let_tmp_rhs2.dtor_t;
      Std.JSON.Utils.Cursors._ICursor__ _5_cs = _let_tmp_rhs2.dtor_cs;
      return Std.JSON.Utils.Cursors.Split<Std.JSON.Grammar._IStructural<Std.JSON.Utils.Views.Core._IView__>>.create(Std.JSON.Grammar.Structural<Std.JSON.Utils.Views.Core._IView__>.create(_0_before, _2_val, _4_after), _5_cs);
    }
    public static Func<Std.JSON.Utils.Views.Core._IView__, Dafny.ISequence<byte>> SpecView { get {
      return ((System.Func<Std.JSON.Utils.Views.Core._IView__, Dafny.ISequence<byte>>)((_0_v) => {
        return Std.JSON.ConcreteSyntax.Spec.__default.View(_0_v);
      }));
    } }
  }

  public partial class jopt {
    private static readonly Std.JSON.Utils.Views.Core._IView__ Witness = Std.JSON.Utils.Views.Core.View__.OfBytes(Dafny.Sequence<byte>.FromElements());
    public static Std.JSON.Utils.Views.Core._IView__ Default() {
      return Witness;
    }
    private static readonly Dafny.TypeDescriptor<Std.JSON.Utils.Views.Core._IView__> _TYPE = new Dafny.TypeDescriptor<Std.JSON.Utils.Views.Core._IView__>(Std.JSON.ZeroCopy.Deserializer.Core.jopt.Default());
    public static Dafny.TypeDescriptor<Std.JSON.Utils.Views.Core._IView__> _TypeDescriptor() {
      return _TYPE;
    }
  }

  public partial class ValueParser {
    private static readonly Dafny.TypeDescriptor<Func<Std.JSON.Utils.Cursors._ICursor__, Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IValue>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>>>> _TYPE = new Dafny.TypeDescriptor<Func<Std.JSON.Utils.Cursors._ICursor__, Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IValue>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>>>>(Std.JSON.Utils.Parsers.SubParser<Std.JSON.Grammar._IValue, Std.JSON.Errors._IDeserializationError>.Default());
    public static Dafny.TypeDescriptor<Func<Std.JSON.Utils.Cursors._ICursor__, Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IValue>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>>>> _TypeDescriptor() {
      return _TYPE;
    }
  }
} // end of namespace Std.JSON.ZeroCopy.Deserializer.Core
namespace Std.JSON.ZeroCopy.Deserializer.Strings {

  public partial class __default {
    public static Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ICursor__, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>> StringBody(Std.JSON.Utils.Cursors._ICursor__ cs)
    {
      Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ICursor__, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>> pr = Std.Wrappers.Result<Std.JSON.Utils.Cursors._ICursor__, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>>.Default(Std.JSON.Utils.Cursors.Cursor.Default());
      bool _0_escaped;
      _0_escaped = false;
      uint _hi0 = (cs).dtor_end;
      for (uint _1_point_k = (cs).dtor_point; _1_point_k < _hi0; _1_point_k++) {
        byte _2_byte;
        _2_byte = ((cs).dtor_s).Select(_1_point_k);
        if (((_2_byte) == ((byte)((new Dafny.Rune('\"')).Value))) && (!(_0_escaped))) {
          pr = Std.Wrappers.Result<Std.JSON.Utils.Cursors._ICursor__, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>>.create_Success(Std.JSON.Utils.Cursors.Cursor__.create((cs).dtor_s, (cs).dtor_beg, _1_point_k, (cs).dtor_end));
          return pr;
        } else if ((_2_byte) == ((byte)((new Dafny.Rune('\\')).Value))) {
          _0_escaped = !(_0_escaped);
        } else {
          _0_escaped = false;
        }
      }
      pr = Std.Wrappers.Result<Std.JSON.Utils.Cursors._ICursor__, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>>.create_Failure(Std.JSON.Utils.Cursors.CursorError<Std.JSON.Errors._IDeserializationError>.create_EOF());
      return pr;
      return pr;
    }
    public static Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Utils.Views.Core._IView__>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>> Quote(Std.JSON.Utils.Cursors._ICursor__ cs) {
      Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ICursor__, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>> _0_valueOrError0 = (cs).AssertChar<Std.JSON.Errors._IDeserializationError>(new Dafny.Rune('\"'));
      if ((_0_valueOrError0).IsFailure()) {
        return (_0_valueOrError0).PropagateFailure<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Utils.Views.Core._IView__>>();
      } else {
        Std.JSON.Utils.Cursors._ICursor__ _1_cs = (_0_valueOrError0).Extract();
        return Std.Wrappers.Result<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Utils.Views.Core._IView__>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>>.create_Success((_1_cs).Split());
      }
    }
    public static Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._Ijstring>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>> String(Std.JSON.Utils.Cursors._ICursor__ cs) {
      Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Utils.Views.Core._IView__>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>> _0_valueOrError0 = Std.JSON.ZeroCopy.Deserializer.Strings.__default.Quote(cs);
      if ((_0_valueOrError0).IsFailure()) {
        return (_0_valueOrError0).PropagateFailure<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._Ijstring>>();
      } else {
        Std.JSON.Utils.Cursors._ISplit<Std.JSON.Utils.Views.Core._IView__> _let_tmp_rhs0 = (_0_valueOrError0).Extract();
        Std.JSON.Utils.Views.Core._IView__ _1_lq = _let_tmp_rhs0.dtor_t;
        Std.JSON.Utils.Cursors._ICursor__ _2_cs = _let_tmp_rhs0.dtor_cs;
        Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ICursor__, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>> _3_valueOrError1 = Std.JSON.ZeroCopy.Deserializer.Strings.__default.StringBody(_2_cs);
        if ((_3_valueOrError1).IsFailure()) {
          return (_3_valueOrError1).PropagateFailure<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._Ijstring>>();
        } else {
          Std.JSON.Utils.Cursors._ICursor__ _4_contents = (_3_valueOrError1).Extract();
          Std.JSON.Utils.Cursors._ISplit<Std.JSON.Utils.Views.Core._IView__> _let_tmp_rhs1 = (_4_contents).Split();
          Std.JSON.Utils.Views.Core._IView__ _5_contents = _let_tmp_rhs1.dtor_t;
          Std.JSON.Utils.Cursors._ICursor__ _6_cs = _let_tmp_rhs1.dtor_cs;
          Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Utils.Views.Core._IView__>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>> _7_valueOrError2 = Std.JSON.ZeroCopy.Deserializer.Strings.__default.Quote(_6_cs);
          if ((_7_valueOrError2).IsFailure()) {
            return (_7_valueOrError2).PropagateFailure<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._Ijstring>>();
          } else {
            Std.JSON.Utils.Cursors._ISplit<Std.JSON.Utils.Views.Core._IView__> _let_tmp_rhs2 = (_7_valueOrError2).Extract();
            Std.JSON.Utils.Views.Core._IView__ _8_rq = _let_tmp_rhs2.dtor_t;
            Std.JSON.Utils.Cursors._ICursor__ _9_cs = _let_tmp_rhs2.dtor_cs;
            return Std.Wrappers.Result<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._Ijstring>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>>.create_Success(Std.JSON.Utils.Cursors.Split<Std.JSON.Grammar._Ijstring>.create(Std.JSON.Grammar.jstring.create(_1_lq, _5_contents, _8_rq), _9_cs));
          }
        }
      }
    }
  }
} // end of namespace Std.JSON.ZeroCopy.Deserializer.Strings
namespace Std.JSON.ZeroCopy.Deserializer.Numbers {

  public partial class __default {
    public static Std.JSON.Utils.Cursors._ISplit<Std.JSON.Utils.Views.Core._IView__> Digits(Std.JSON.Utils.Cursors._ICursor__ cs) {
      return ((cs).SkipWhile(Std.JSON.Grammar.__default.Digit_q)).Split();
    }
    public static Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Utils.Views.Core._IView__>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>> NonEmptyDigits(Std.JSON.Utils.Cursors._ICursor__ cs) {
      Std.JSON.Utils.Cursors._ISplit<Std.JSON.Utils.Views.Core._IView__> _0_sp = Std.JSON.ZeroCopy.Deserializer.Numbers.__default.Digits(cs);
      if (((_0_sp).dtor_t).Empty_q) {
        return Std.Wrappers.Result<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Utils.Views.Core._IView__>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>>.create_Failure(Std.JSON.Utils.Cursors.CursorError<Std.JSON.Errors._IDeserializationError>.create_OtherError(Std.JSON.Errors.DeserializationError.create_EmptyNumber()));
      } else {
        return Std.Wrappers.Result<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Utils.Views.Core._IView__>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>>.create_Success(_0_sp);
      }
    }
    public static Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Utils.Views.Core._IView__>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>> NonZeroInt(Std.JSON.Utils.Cursors._ICursor__ cs) {
      return Std.JSON.ZeroCopy.Deserializer.Numbers.__default.NonEmptyDigits(cs);
    }
    public static Std.JSON.Utils.Cursors._ISplit<Std.JSON.Utils.Views.Core._IView__> OptionalMinus(Std.JSON.Utils.Cursors._ICursor__ cs) {
      return ((cs).SkipIf(((System.Func<byte, bool>)((_0_c) => {
        return (_0_c) == ((byte)((new Dafny.Rune('-')).Value));
      })))).Split();
    }
    public static Std.JSON.Utils.Cursors._ISplit<Std.JSON.Utils.Views.Core._IView__> OptionalSign(Std.JSON.Utils.Cursors._ICursor__ cs) {
      return ((cs).SkipIf(((System.Func<byte, bool>)((_0_c) => {
        return ((_0_c) == ((byte)((new Dafny.Rune('-')).Value))) || ((_0_c) == ((byte)((new Dafny.Rune('+')).Value)));
      })))).Split();
    }
    public static Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Utils.Views.Core._IView__>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>> TrimmedInt(Std.JSON.Utils.Cursors._ICursor__ cs) {
      Std.JSON.Utils.Cursors._ISplit<Std.JSON.Utils.Views.Core._IView__> _0_sp = ((cs).SkipIf(((System.Func<byte, bool>)((_1_c) => {
        return (_1_c) == ((byte)((new Dafny.Rune('0')).Value));
      })))).Split();
      if (((_0_sp).dtor_t).Empty_q) {
        return Std.JSON.ZeroCopy.Deserializer.Numbers.__default.NonZeroInt((_0_sp).dtor_cs);
      } else {
        return Std.Wrappers.Result<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Utils.Views.Core._IView__>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>>.create_Success(_0_sp);
      }
    }
    public static Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IMaybe<Std.JSON.Grammar._Ijexp>>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>> Exp(Std.JSON.Utils.Cursors._ICursor__ cs) {
      Std.JSON.Utils.Cursors._ISplit<Std.JSON.Utils.Views.Core._IView__> _let_tmp_rhs0 = ((cs).SkipIf(((System.Func<byte, bool>)((_0_c) => {
        return ((_0_c) == ((byte)((new Dafny.Rune('e')).Value))) || ((_0_c) == ((byte)((new Dafny.Rune('E')).Value)));
      })))).Split();
      Std.JSON.Utils.Views.Core._IView__ _1_e = _let_tmp_rhs0.dtor_t;
      Std.JSON.Utils.Cursors._ICursor__ _2_cs = _let_tmp_rhs0.dtor_cs;
      if ((_1_e).Empty_q) {
        return Std.Wrappers.Result<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IMaybe<Std.JSON.Grammar._Ijexp>>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>>.create_Success(Std.JSON.Utils.Cursors.Split<Std.JSON.Grammar._IMaybe<Std.JSON.Grammar._Ijexp>>.create(Std.JSON.Grammar.Maybe<Std.JSON.Grammar._Ijexp>.create_Empty(), _2_cs));
      } else {
        Std.JSON.Utils.Cursors._ISplit<Std.JSON.Utils.Views.Core._IView__> _let_tmp_rhs1 = Std.JSON.ZeroCopy.Deserializer.Numbers.__default.OptionalSign(_2_cs);
        Std.JSON.Utils.Views.Core._IView__ _3_sign = _let_tmp_rhs1.dtor_t;
        Std.JSON.Utils.Cursors._ICursor__ _4_cs = _let_tmp_rhs1.dtor_cs;
        Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Utils.Views.Core._IView__>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>> _5_valueOrError0 = Std.JSON.ZeroCopy.Deserializer.Numbers.__default.NonEmptyDigits(_4_cs);
        if ((_5_valueOrError0).IsFailure()) {
          return (_5_valueOrError0).PropagateFailure<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IMaybe<Std.JSON.Grammar._Ijexp>>>();
        } else {
          Std.JSON.Utils.Cursors._ISplit<Std.JSON.Utils.Views.Core._IView__> _let_tmp_rhs2 = (_5_valueOrError0).Extract();
          Std.JSON.Utils.Views.Core._IView__ _6_num = _let_tmp_rhs2.dtor_t;
          Std.JSON.Utils.Cursors._ICursor__ _7_cs = _let_tmp_rhs2.dtor_cs;
          return Std.Wrappers.Result<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IMaybe<Std.JSON.Grammar._Ijexp>>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>>.create_Success(Std.JSON.Utils.Cursors.Split<Std.JSON.Grammar._IMaybe<Std.JSON.Grammar._Ijexp>>.create(Std.JSON.Grammar.Maybe<Std.JSON.Grammar._Ijexp>.create_NonEmpty(Std.JSON.Grammar.jexp.create(_1_e, _3_sign, _6_num)), _7_cs));
        }
      }
    }
    public static Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IMaybe<Std.JSON.Grammar._Ijfrac>>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>> Frac(Std.JSON.Utils.Cursors._ICursor__ cs) {
      Std.JSON.Utils.Cursors._ISplit<Std.JSON.Utils.Views.Core._IView__> _let_tmp_rhs0 = ((cs).SkipIf(((System.Func<byte, bool>)((_0_c) => {
        return (_0_c) == ((byte)((new Dafny.Rune('.')).Value));
      })))).Split();
      Std.JSON.Utils.Views.Core._IView__ _1_period = _let_tmp_rhs0.dtor_t;
      Std.JSON.Utils.Cursors._ICursor__ _2_cs = _let_tmp_rhs0.dtor_cs;
      if ((_1_period).Empty_q) {
        return Std.Wrappers.Result<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IMaybe<Std.JSON.Grammar._Ijfrac>>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>>.create_Success(Std.JSON.Utils.Cursors.Split<Std.JSON.Grammar._IMaybe<Std.JSON.Grammar._Ijfrac>>.create(Std.JSON.Grammar.Maybe<Std.JSON.Grammar._Ijfrac>.create_Empty(), _2_cs));
      } else {
        Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Utils.Views.Core._IView__>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>> _3_valueOrError0 = Std.JSON.ZeroCopy.Deserializer.Numbers.__default.NonEmptyDigits(_2_cs);
        if ((_3_valueOrError0).IsFailure()) {
          return (_3_valueOrError0).PropagateFailure<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IMaybe<Std.JSON.Grammar._Ijfrac>>>();
        } else {
          Std.JSON.Utils.Cursors._ISplit<Std.JSON.Utils.Views.Core._IView__> _let_tmp_rhs1 = (_3_valueOrError0).Extract();
          Std.JSON.Utils.Views.Core._IView__ _4_num = _let_tmp_rhs1.dtor_t;
          Std.JSON.Utils.Cursors._ICursor__ _5_cs = _let_tmp_rhs1.dtor_cs;
          return Std.Wrappers.Result<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IMaybe<Std.JSON.Grammar._Ijfrac>>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>>.create_Success(Std.JSON.Utils.Cursors.Split<Std.JSON.Grammar._IMaybe<Std.JSON.Grammar._Ijfrac>>.create(Std.JSON.Grammar.Maybe<Std.JSON.Grammar._Ijfrac>.create_NonEmpty(Std.JSON.Grammar.jfrac.create(_1_period, _4_num)), _5_cs));
        }
      }
    }
    public static Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._Ijnumber> NumberFromParts(Std.JSON.Utils.Cursors._ISplit<Std.JSON.Utils.Views.Core._IView__> minus, Std.JSON.Utils.Cursors._ISplit<Std.JSON.Utils.Views.Core._IView__> num, Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IMaybe<Std.JSON.Grammar._Ijfrac>> frac, Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IMaybe<Std.JSON.Grammar._Ijexp>> exp)
    {
      Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._Ijnumber> _0_sp = Std.JSON.Utils.Cursors.Split<Std.JSON.Grammar._Ijnumber>.create(Std.JSON.Grammar.jnumber.create((minus).dtor_t, (num).dtor_t, (frac).dtor_t, (exp).dtor_t), (exp).dtor_cs);
      return _0_sp;
    }
    public static Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._Ijnumber>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>> Number(Std.JSON.Utils.Cursors._ICursor__ cs) {
      Std.JSON.Utils.Cursors._ISplit<Std.JSON.Utils.Views.Core._IView__> _0_minus = Std.JSON.ZeroCopy.Deserializer.Numbers.__default.OptionalMinus(cs);
      Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Utils.Views.Core._IView__>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>> _1_valueOrError0 = Std.JSON.ZeroCopy.Deserializer.Numbers.__default.TrimmedInt((_0_minus).dtor_cs);
      if ((_1_valueOrError0).IsFailure()) {
        return (_1_valueOrError0).PropagateFailure<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._Ijnumber>>();
      } else {
        Std.JSON.Utils.Cursors._ISplit<Std.JSON.Utils.Views.Core._IView__> _2_num = (_1_valueOrError0).Extract();
        Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IMaybe<Std.JSON.Grammar._Ijfrac>>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>> _3_valueOrError1 = Std.JSON.ZeroCopy.Deserializer.Numbers.__default.Frac((_2_num).dtor_cs);
        if ((_3_valueOrError1).IsFailure()) {
          return (_3_valueOrError1).PropagateFailure<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._Ijnumber>>();
        } else {
          Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IMaybe<Std.JSON.Grammar._Ijfrac>> _4_frac = (_3_valueOrError1).Extract();
          Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IMaybe<Std.JSON.Grammar._Ijexp>>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>> _5_valueOrError2 = Std.JSON.ZeroCopy.Deserializer.Numbers.__default.Exp((_4_frac).dtor_cs);
          if ((_5_valueOrError2).IsFailure()) {
            return (_5_valueOrError2).PropagateFailure<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._Ijnumber>>();
          } else {
            Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IMaybe<Std.JSON.Grammar._Ijexp>> _6_exp = (_5_valueOrError2).Extract();
            return Std.Wrappers.Result<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._Ijnumber>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>>.create_Success(Std.JSON.ZeroCopy.Deserializer.Numbers.__default.NumberFromParts(_0_minus, _2_num, _4_frac, _6_exp));
          }
        }
      }
    }
  }
} // end of namespace Std.JSON.ZeroCopy.Deserializer.Numbers
namespace Std.JSON.ZeroCopy.Deserializer.ObjectParams {

  public partial class __default {
    public static Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Utils.Views.Core._IView__>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>> Colon(Std.JSON.Utils.Cursors._ICursor__ cs) {
      Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ICursor__, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>> _0_valueOrError0 = (cs).AssertChar<Std.JSON.Errors._IDeserializationError>(new Dafny.Rune(':'));
      if ((_0_valueOrError0).IsFailure()) {
        return (_0_valueOrError0).PropagateFailure<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Utils.Views.Core._IView__>>();
      } else {
        Std.JSON.Utils.Cursors._ICursor__ _1_cs = (_0_valueOrError0).Extract();
        return Std.Wrappers.Result<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Utils.Views.Core._IView__>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>>.create_Success((_1_cs).Split());
      }
    }
    public static Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IjKeyValue> KeyValueFromParts(Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._Ijstring> k, Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IStructural<Std.JSON.Utils.Views.Core._IView__>> colon, Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IValue> v)
    {
      Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IjKeyValue> _0_sp = Std.JSON.Utils.Cursors.Split<Std.JSON.Grammar._IjKeyValue>.create(Std.JSON.Grammar.jKeyValue.create((k).dtor_t, (colon).dtor_t, (v).dtor_t), (v).dtor_cs);
      return _0_sp;
    }
    public static Dafny.ISequence<byte> ElementSpec(Std.JSON.Grammar._IjKeyValue t) {
      return Std.JSON.ConcreteSyntax.Spec.__default.KeyValue(t);
    }
    public static Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IjKeyValue>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>> Element(Std.JSON.Utils.Cursors._ICursor__ cs, Func<Std.JSON.Utils.Cursors._ICursor__, Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IValue>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>>> json)
    {
      Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._Ijstring>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>> _0_valueOrError0 = Std.JSON.ZeroCopy.Deserializer.Strings.__default.String(cs);
      if ((_0_valueOrError0).IsFailure()) {
        return (_0_valueOrError0).PropagateFailure<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IjKeyValue>>();
      } else {
        Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._Ijstring> _1_k = (_0_valueOrError0).Extract();
        Func<Std.JSON.Utils.Cursors._ICursor__, Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Utils.Views.Core._IView__>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>>> _2_p = Std.JSON.ZeroCopy.Deserializer.ObjectParams.__default.Colon;
        Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IStructural<Std.JSON.Utils.Views.Core._IView__>>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>> _3_valueOrError1 = Std.JSON.ZeroCopy.Deserializer.Core.__default.Structural<Std.JSON.Utils.Views.Core._IView__>((_1_k).dtor_cs, _2_p);
        if ((_3_valueOrError1).IsFailure()) {
          return (_3_valueOrError1).PropagateFailure<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IjKeyValue>>();
        } else {
          Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IStructural<Std.JSON.Utils.Views.Core._IView__>> _4_colon = (_3_valueOrError1).Extract();
          Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IValue>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>> _5_valueOrError2 = Dafny.Helpers.Id<Func<Std.JSON.Utils.Cursors._ICursor__, Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IValue>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>>>>((json))((_4_colon).dtor_cs);
          if ((_5_valueOrError2).IsFailure()) {
            return (_5_valueOrError2).PropagateFailure<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IjKeyValue>>();
          } else {
            Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IValue> _6_v = (_5_valueOrError2).Extract();
            Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IjKeyValue> _7_kv = Std.JSON.ZeroCopy.Deserializer.ObjectParams.__default.KeyValueFromParts(_1_k, _4_colon, _6_v);
            return Std.Wrappers.Result<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IjKeyValue>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>>.create_Success(_7_kv);
          }
        }
      }
    }
    public static byte OPEN { get {
      return (byte)((new Dafny.Rune('{')).Value);
    } }
    public static byte CLOSE { get {
      return (byte)((new Dafny.Rune('}')).Value);
    } }
  }
} // end of namespace Std.JSON.ZeroCopy.Deserializer.ObjectParams
namespace Std.JSON.ZeroCopy.Deserializer.Objects {

  public partial class __default {
    public static Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IBracketed<Std.JSON.Utils.Views.Core._IView__, Std.JSON.Grammar._IjKeyValue, Std.JSON.Utils.Views.Core._IView__, Std.JSON.Utils.Views.Core._IView__>>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>> Object(Std.JSON.Utils.Cursors._ICursor__ cs, Func<Std.JSON.Utils.Cursors._ICursor__, Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IValue>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>>> json)
    {
      Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IBracketed<Std.JSON.Utils.Views.Core._IView__, Std.JSON.Grammar._IjKeyValue, Std.JSON.Utils.Views.Core._IView__, Std.JSON.Utils.Views.Core._IView__>>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>> _0_valueOrError0 = Std.JSON.ZeroCopy.Deserializer.Objects.__default.Bracketed(cs, json);
      if ((_0_valueOrError0).IsFailure()) {
        return (_0_valueOrError0).PropagateFailure<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IBracketed<Std.JSON.Utils.Views.Core._IView__, Std.JSON.Grammar._IjKeyValue, Std.JSON.Utils.Views.Core._IView__, Std.JSON.Utils.Views.Core._IView__>>>();
      } else {
        Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IBracketed<Std.JSON.Utils.Views.Core._IView__, Std.JSON.Grammar._IjKeyValue, Std.JSON.Utils.Views.Core._IView__, Std.JSON.Utils.Views.Core._IView__>> _1_sp = (_0_valueOrError0).Extract();
        return Std.Wrappers.Result<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IBracketed<Std.JSON.Utils.Views.Core._IView__, Std.JSON.Grammar._IjKeyValue, Std.JSON.Utils.Views.Core._IView__, Std.JSON.Utils.Views.Core._IView__>>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>>.create_Success(_1_sp);
      }
    }
    public static Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Utils.Views.Core._IView__>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>> Open(Std.JSON.Utils.Cursors._ICursor__ cs) {
      Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ICursor__, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>> _0_valueOrError0 = (cs).AssertByte<Std.JSON.Errors._IDeserializationError>(Std.JSON.ZeroCopy.Deserializer.ObjectParams.__default.OPEN);
      if ((_0_valueOrError0).IsFailure()) {
        return (_0_valueOrError0).PropagateFailure<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Utils.Views.Core._IView__>>();
      } else {
        Std.JSON.Utils.Cursors._ICursor__ _1_cs = (_0_valueOrError0).Extract();
        return Std.Wrappers.Result<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Utils.Views.Core._IView__>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>>.create_Success((_1_cs).Split());
      }
    }
    public static Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Utils.Views.Core._IView__>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>> Close(Std.JSON.Utils.Cursors._ICursor__ cs) {
      Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ICursor__, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>> _0_valueOrError0 = (cs).AssertByte<Std.JSON.Errors._IDeserializationError>(Std.JSON.ZeroCopy.Deserializer.ObjectParams.__default.CLOSE);
      if ((_0_valueOrError0).IsFailure()) {
        return (_0_valueOrError0).PropagateFailure<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Utils.Views.Core._IView__>>();
      } else {
        Std.JSON.Utils.Cursors._ICursor__ _1_cs = (_0_valueOrError0).Extract();
        return Std.Wrappers.Result<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Utils.Views.Core._IView__>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>>.create_Success((_1_cs).Split());
      }
    }
    public static Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IBracketed<Std.JSON.Utils.Views.Core._IView__, Std.JSON.Grammar._IjKeyValue, Std.JSON.Utils.Views.Core._IView__, Std.JSON.Utils.Views.Core._IView__>> BracketedFromParts(Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IStructural<Std.JSON.Utils.Views.Core._IView__>> open, Std.JSON.Utils.Cursors._ISplit<Dafny.ISequence<Std.JSON.Grammar._ISuffixed<Std.JSON.Grammar._IjKeyValue, Std.JSON.Utils.Views.Core._IView__>>> elems, Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IStructural<Std.JSON.Utils.Views.Core._IView__>> close)
    {
      Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IBracketed<Std.JSON.Utils.Views.Core._IView__, Std.JSON.Grammar._IjKeyValue, Std.JSON.Utils.Views.Core._IView__, Std.JSON.Utils.Views.Core._IView__>> _0_sp = Std.JSON.Utils.Cursors.Split<Std.JSON.Grammar._IBracketed<Std.JSON.Utils.Views.Core._IView__, Std.JSON.Grammar._IjKeyValue, Std.JSON.Utils.Views.Core._IView__, Std.JSON.Utils.Views.Core._IView__>>.create(Std.JSON.Grammar.Bracketed<Std.JSON.Utils.Views.Core._IView__, Std.JSON.Grammar._IjKeyValue, Std.JSON.Utils.Views.Core._IView__, Std.JSON.Utils.Views.Core._IView__>.create((open).dtor_t, (elems).dtor_t, (close).dtor_t), (close).dtor_cs);
      return _0_sp;
    }
    public static Std.JSON.Utils.Cursors._ISplit<Dafny.ISequence<Std.JSON.Grammar._ISuffixed<Std.JSON.Grammar._IjKeyValue, Std.JSON.Utils.Views.Core._IView__>>> AppendWithSuffix(Std.JSON.Utils.Cursors._ISplit<Dafny.ISequence<Std.JSON.Grammar._ISuffixed<Std.JSON.Grammar._IjKeyValue, Std.JSON.Utils.Views.Core._IView__>>> elems, Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IjKeyValue> elem, Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IStructural<Std.JSON.Utils.Views.Core._IView__>> sep)
    {
      Std.JSON.Grammar._ISuffixed<Std.JSON.Grammar._IjKeyValue, Std.JSON.Utils.Views.Core._IView__> _0_suffixed = Std.JSON.Grammar.Suffixed<Std.JSON.Grammar._IjKeyValue, Std.JSON.Utils.Views.Core._IView__>.create((elem).dtor_t, Std.JSON.Grammar.Maybe<Std.JSON.Grammar._IStructural<Std.JSON.Utils.Views.Core._IView__>>.create_NonEmpty((sep).dtor_t));
      Std.JSON.Utils.Cursors._ISplit<Dafny.ISequence<Std.JSON.Grammar._ISuffixed<Std.JSON.Grammar._IjKeyValue, Std.JSON.Utils.Views.Core._IView__>>> _1_elems_k = Std.JSON.Utils.Cursors.Split<Dafny.ISequence<Std.JSON.Grammar._ISuffixed<Std.JSON.Grammar._IjKeyValue, Std.JSON.Utils.Views.Core._IView__>>>.create(Dafny.Sequence<Std.JSON.Grammar._ISuffixed<Std.JSON.Grammar._IjKeyValue, Std.JSON.Utils.Views.Core._IView__>>.Concat((elems).dtor_t, Dafny.Sequence<Std.JSON.Grammar._ISuffixed<Std.JSON.Grammar._IjKeyValue, Std.JSON.Utils.Views.Core._IView__>>.FromElements(_0_suffixed)), (sep).dtor_cs);
      return _1_elems_k;
    }
    public static Std.JSON.Utils.Cursors._ISplit<Dafny.ISequence<Std.JSON.Grammar._ISuffixed<Std.JSON.Grammar._IjKeyValue, Std.JSON.Utils.Views.Core._IView__>>> AppendLast(Std.JSON.Utils.Cursors._ISplit<Dafny.ISequence<Std.JSON.Grammar._ISuffixed<Std.JSON.Grammar._IjKeyValue, Std.JSON.Utils.Views.Core._IView__>>> elems, Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IjKeyValue> elem, Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IStructural<Std.JSON.Utils.Views.Core._IView__>> sep)
    {
      Std.JSON.Grammar._ISuffixed<Std.JSON.Grammar._IjKeyValue, Std.JSON.Utils.Views.Core._IView__> _0_suffixed = Std.JSON.Grammar.Suffixed<Std.JSON.Grammar._IjKeyValue, Std.JSON.Utils.Views.Core._IView__>.create((elem).dtor_t, Std.JSON.Grammar.Maybe<Std.JSON.Grammar._IStructural<Std.JSON.Utils.Views.Core._IView__>>.create_Empty());
      Std.JSON.Utils.Cursors._ISplit<Dafny.ISequence<Std.JSON.Grammar._ISuffixed<Std.JSON.Grammar._IjKeyValue, Std.JSON.Utils.Views.Core._IView__>>> _1_elems_k = Std.JSON.Utils.Cursors.Split<Dafny.ISequence<Std.JSON.Grammar._ISuffixed<Std.JSON.Grammar._IjKeyValue, Std.JSON.Utils.Views.Core._IView__>>>.create(Dafny.Sequence<Std.JSON.Grammar._ISuffixed<Std.JSON.Grammar._IjKeyValue, Std.JSON.Utils.Views.Core._IView__>>.Concat((elems).dtor_t, Dafny.Sequence<Std.JSON.Grammar._ISuffixed<Std.JSON.Grammar._IjKeyValue, Std.JSON.Utils.Views.Core._IView__>>.FromElements(_0_suffixed)), (elem).dtor_cs);
      return _1_elems_k;
    }
    public static Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IBracketed<Std.JSON.Utils.Views.Core._IView__, Std.JSON.Grammar._IjKeyValue, Std.JSON.Utils.Views.Core._IView__, Std.JSON.Utils.Views.Core._IView__>>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>> Elements(Func<Std.JSON.Utils.Cursors._ICursor__, Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IValue>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>>> json, Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IStructural<Std.JSON.Utils.Views.Core._IView__>> open, Std.JSON.Utils.Cursors._ISplit<Dafny.ISequence<Std.JSON.Grammar._ISuffixed<Std.JSON.Grammar._IjKeyValue, Std.JSON.Utils.Views.Core._IView__>>> elems)
    {
    TAIL_CALL_START: ;
      Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IjKeyValue>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>> _0_valueOrError0 = Std.JSON.ZeroCopy.Deserializer.ObjectParams.__default.Element((elems).dtor_cs, json);
      if ((_0_valueOrError0).IsFailure()) {
        return (_0_valueOrError0).PropagateFailure<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IBracketed<Std.JSON.Utils.Views.Core._IView__, Std.JSON.Grammar._IjKeyValue, Std.JSON.Utils.Views.Core._IView__, Std.JSON.Utils.Views.Core._IView__>>>();
      } else {
        Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IjKeyValue> _1_elem = (_0_valueOrError0).Extract();
        if (((_1_elem).dtor_cs).EOF_q) {
          return Std.Wrappers.Result<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IBracketed<Std.JSON.Utils.Views.Core._IView__, Std.JSON.Grammar._IjKeyValue, Std.JSON.Utils.Views.Core._IView__, Std.JSON.Utils.Views.Core._IView__>>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>>.create_Failure(Std.JSON.Utils.Cursors.CursorError<Std.JSON.Errors._IDeserializationError>.create_EOF());
        } else {
          Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IStructural<Std.JSON.Utils.Views.Core._IView__>> _2_sep = Std.JSON.ZeroCopy.Deserializer.Core.__default.TryStructural((_1_elem).dtor_cs);
          short _3_s0 = (((_2_sep).dtor_t).dtor_t).Peek();
          if (((_3_s0) == ((short)(Std.JSON.ZeroCopy.Deserializer.Objects.__default.SEPARATOR))) && (((((_2_sep).dtor_t).dtor_t).Length()) == (1U))) {
            Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IStructural<Std.JSON.Utils.Views.Core._IView__>> _4_sep = _2_sep;
            Std.JSON.Utils.Cursors._ISplit<Dafny.ISequence<Std.JSON.Grammar._ISuffixed<Std.JSON.Grammar._IjKeyValue, Std.JSON.Utils.Views.Core._IView__>>> _5_elems = Std.JSON.ZeroCopy.Deserializer.Objects.__default.AppendWithSuffix(elems, _1_elem, _4_sep);
            Func<Std.JSON.Utils.Cursors._ICursor__, Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IValue>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>>> _in0 = json;
            Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IStructural<Std.JSON.Utils.Views.Core._IView__>> _in1 = open;
            Std.JSON.Utils.Cursors._ISplit<Dafny.ISequence<Std.JSON.Grammar._ISuffixed<Std.JSON.Grammar._IjKeyValue, Std.JSON.Utils.Views.Core._IView__>>> _in2 = _5_elems;
            json = _in0;
            open = _in1;
            elems = _in2;
            goto TAIL_CALL_START;
          } else if (((_3_s0) == ((short)(Std.JSON.ZeroCopy.Deserializer.ObjectParams.__default.CLOSE))) && (((((_2_sep).dtor_t).dtor_t).Length()) == (1U))) {
            Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IStructural<Std.JSON.Utils.Views.Core._IView__>> _6_sep = _2_sep;
            Std.JSON.Utils.Cursors._ISplit<Dafny.ISequence<Std.JSON.Grammar._ISuffixed<Std.JSON.Grammar._IjKeyValue, Std.JSON.Utils.Views.Core._IView__>>> _7_elems_k = Std.JSON.ZeroCopy.Deserializer.Objects.__default.AppendLast(elems, _1_elem, _6_sep);
            Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IBracketed<Std.JSON.Utils.Views.Core._IView__, Std.JSON.Grammar._IjKeyValue, Std.JSON.Utils.Views.Core._IView__, Std.JSON.Utils.Views.Core._IView__>> _8_bracketed = Std.JSON.ZeroCopy.Deserializer.Objects.__default.BracketedFromParts(open, _7_elems_k, _6_sep);
            return Std.Wrappers.Result<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IBracketed<Std.JSON.Utils.Views.Core._IView__, Std.JSON.Grammar._IjKeyValue, Std.JSON.Utils.Views.Core._IView__, Std.JSON.Utils.Views.Core._IView__>>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>>.create_Success(_8_bracketed);
          } else {
            byte _9_separator = Std.JSON.ZeroCopy.Deserializer.Objects.__default.SEPARATOR;
            Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IBracketed<Std.JSON.Utils.Views.Core._IView__, Std.JSON.Grammar._IjKeyValue, Std.JSON.Utils.Views.Core._IView__, Std.JSON.Utils.Views.Core._IView__>>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>> _10_pr = Std.Wrappers.Result<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IBracketed<Std.JSON.Utils.Views.Core._IView__, Std.JSON.Grammar._IjKeyValue, Std.JSON.Utils.Views.Core._IView__, Std.JSON.Utils.Views.Core._IView__>>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>>.create_Failure(Std.JSON.Utils.Cursors.CursorError<Std.JSON.Errors._IDeserializationError>.create_ExpectingAnyByte(Dafny.Sequence<byte>.FromElements(Std.JSON.ZeroCopy.Deserializer.ObjectParams.__default.CLOSE, _9_separator), _3_s0));
            return _10_pr;
          }
        }
      }
    }
    public static Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IBracketed<Std.JSON.Utils.Views.Core._IView__, Std.JSON.Grammar._IjKeyValue, Std.JSON.Utils.Views.Core._IView__, Std.JSON.Utils.Views.Core._IView__>>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>> Bracketed(Std.JSON.Utils.Cursors._ICursor__ cs, Func<Std.JSON.Utils.Cursors._ICursor__, Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IValue>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>>> json)
    {
      Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IStructural<Std.JSON.Utils.Views.Core._IView__>>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>> _0_valueOrError0 = Std.JSON.ZeroCopy.Deserializer.Core.__default.Structural<Std.JSON.Utils.Views.Core._IView__>(cs, Std.JSON.ZeroCopy.Deserializer.Objects.__default.Open);
      if ((_0_valueOrError0).IsFailure()) {
        return (_0_valueOrError0).PropagateFailure<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IBracketed<Std.JSON.Utils.Views.Core._IView__, Std.JSON.Grammar._IjKeyValue, Std.JSON.Utils.Views.Core._IView__, Std.JSON.Utils.Views.Core._IView__>>>();
      } else {
        Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IStructural<Std.JSON.Utils.Views.Core._IView__>> _1_open = (_0_valueOrError0).Extract();
        Std.JSON.Utils.Cursors._ISplit<Dafny.ISequence<Std.JSON.Grammar._ISuffixed<Std.JSON.Grammar._IjKeyValue, Std.JSON.Utils.Views.Core._IView__>>> _2_elems = Std.JSON.Utils.Cursors.Split<Dafny.ISequence<Std.JSON.Grammar._ISuffixed<Std.JSON.Grammar._IjKeyValue, Std.JSON.Utils.Views.Core._IView__>>>.create(Dafny.Sequence<Std.JSON.Grammar._ISuffixed<Std.JSON.Grammar._IjKeyValue, Std.JSON.Utils.Views.Core._IView__>>.FromElements(), (_1_open).dtor_cs);
        if ((((_1_open).dtor_cs).Peek()) == ((short)(Std.JSON.ZeroCopy.Deserializer.ObjectParams.__default.CLOSE))) {
          Func<Std.JSON.Utils.Cursors._ICursor__, Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Utils.Views.Core._IView__>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>>> _3_p = Std.JSON.ZeroCopy.Deserializer.Objects.__default.Close;
          Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IStructural<Std.JSON.Utils.Views.Core._IView__>>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>> _4_valueOrError1 = Std.JSON.ZeroCopy.Deserializer.Core.__default.Structural<Std.JSON.Utils.Views.Core._IView__>((_1_open).dtor_cs, _3_p);
          if ((_4_valueOrError1).IsFailure()) {
            return (_4_valueOrError1).PropagateFailure<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IBracketed<Std.JSON.Utils.Views.Core._IView__, Std.JSON.Grammar._IjKeyValue, Std.JSON.Utils.Views.Core._IView__, Std.JSON.Utils.Views.Core._IView__>>>();
          } else {
            Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IStructural<Std.JSON.Utils.Views.Core._IView__>> _5_close = (_4_valueOrError1).Extract();
            return Std.Wrappers.Result<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IBracketed<Std.JSON.Utils.Views.Core._IView__, Std.JSON.Grammar._IjKeyValue, Std.JSON.Utils.Views.Core._IView__, Std.JSON.Utils.Views.Core._IView__>>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>>.create_Success(Std.JSON.ZeroCopy.Deserializer.Objects.__default.BracketedFromParts(_1_open, _2_elems, _5_close));
          }
        } else {
          return Std.JSON.ZeroCopy.Deserializer.Objects.__default.Elements(json, _1_open, _2_elems);
        }
      }
    }
    public static Func<Std.JSON.Utils.Views.Core._IView__, Dafny.ISequence<byte>> SpecViewOpen { get {
      return Std.JSON.ZeroCopy.Deserializer.Core.__default.SpecView;
    } }
    public static Func<Std.JSON.Utils.Views.Core._IView__, Dafny.ISequence<byte>> SpecViewClose { get {
      return Std.JSON.ZeroCopy.Deserializer.Core.__default.SpecView;
    } }
    public static byte SEPARATOR { get {
      return (byte)((new Dafny.Rune(',')).Value);
    } }
  }

  public partial class jopen {
    private static readonly Std.JSON.Utils.Views.Core._IView__ Witness = Std.JSON.Utils.Views.Core.View__.OfBytes(Dafny.Sequence<byte>.FromElements(Std.JSON.ZeroCopy.Deserializer.ObjectParams.__default.OPEN));
    public static Std.JSON.Utils.Views.Core._IView__ Default() {
      return Witness;
    }
    private static readonly Dafny.TypeDescriptor<Std.JSON.Utils.Views.Core._IView__> _TYPE = new Dafny.TypeDescriptor<Std.JSON.Utils.Views.Core._IView__>(Std.JSON.ZeroCopy.Deserializer.Objects.jopen.Default());
    public static Dafny.TypeDescriptor<Std.JSON.Utils.Views.Core._IView__> _TypeDescriptor() {
      return _TYPE;
    }
  }

  public partial class jclose {
    private static readonly Std.JSON.Utils.Views.Core._IView__ Witness = Std.JSON.Utils.Views.Core.View__.OfBytes(Dafny.Sequence<byte>.FromElements(Std.JSON.ZeroCopy.Deserializer.ObjectParams.__default.CLOSE));
    public static Std.JSON.Utils.Views.Core._IView__ Default() {
      return Witness;
    }
    private static readonly Dafny.TypeDescriptor<Std.JSON.Utils.Views.Core._IView__> _TYPE = new Dafny.TypeDescriptor<Std.JSON.Utils.Views.Core._IView__>(Std.JSON.ZeroCopy.Deserializer.Objects.jclose.Default());
    public static Dafny.TypeDescriptor<Std.JSON.Utils.Views.Core._IView__> _TypeDescriptor() {
      return _TYPE;
    }
  }
} // end of namespace Std.JSON.ZeroCopy.Deserializer.Objects
namespace Std.JSON.ZeroCopy.Deserializer.ArrayParams {

  public partial class __default {
    public static Dafny.ISequence<byte> ElementSpec(Std.JSON.Grammar._IValue t) {
      return Std.JSON.ConcreteSyntax.Spec.__default.Value(t);
    }
    public static Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IValue>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>> Element(Std.JSON.Utils.Cursors._ICursor__ cs, Func<Std.JSON.Utils.Cursors._ICursor__, Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IValue>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>>> json)
    {
      return Dafny.Helpers.Id<Func<Std.JSON.Utils.Cursors._ICursor__, Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IValue>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>>>>((json))(cs);
    }
    public static byte OPEN { get {
      return (byte)((new Dafny.Rune('[')).Value);
    } }
    public static byte CLOSE { get {
      return (byte)((new Dafny.Rune(']')).Value);
    } }
  }
} // end of namespace Std.JSON.ZeroCopy.Deserializer.ArrayParams
namespace Std.JSON.ZeroCopy.Deserializer.Arrays {

  public partial class __default {
    public static Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IBracketed<Std.JSON.Utils.Views.Core._IView__, Std.JSON.Grammar._IValue, Std.JSON.Utils.Views.Core._IView__, Std.JSON.Utils.Views.Core._IView__>>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>> Array(Std.JSON.Utils.Cursors._ICursor__ cs, Func<Std.JSON.Utils.Cursors._ICursor__, Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IValue>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>>> json)
    {
      Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IBracketed<Std.JSON.Utils.Views.Core._IView__, Std.JSON.Grammar._IValue, Std.JSON.Utils.Views.Core._IView__, Std.JSON.Utils.Views.Core._IView__>>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>> _0_valueOrError0 = Std.JSON.ZeroCopy.Deserializer.Arrays.__default.Bracketed(cs, json);
      if ((_0_valueOrError0).IsFailure()) {
        return (_0_valueOrError0).PropagateFailure<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IBracketed<Std.JSON.Utils.Views.Core._IView__, Std.JSON.Grammar._IValue, Std.JSON.Utils.Views.Core._IView__, Std.JSON.Utils.Views.Core._IView__>>>();
      } else {
        Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IBracketed<Std.JSON.Utils.Views.Core._IView__, Std.JSON.Grammar._IValue, Std.JSON.Utils.Views.Core._IView__, Std.JSON.Utils.Views.Core._IView__>> _1_sp = (_0_valueOrError0).Extract();
        return Std.Wrappers.Result<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IBracketed<Std.JSON.Utils.Views.Core._IView__, Std.JSON.Grammar._IValue, Std.JSON.Utils.Views.Core._IView__, Std.JSON.Utils.Views.Core._IView__>>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>>.create_Success(_1_sp);
      }
    }
    public static Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Utils.Views.Core._IView__>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>> Open(Std.JSON.Utils.Cursors._ICursor__ cs) {
      Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ICursor__, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>> _0_valueOrError0 = (cs).AssertByte<Std.JSON.Errors._IDeserializationError>(Std.JSON.ZeroCopy.Deserializer.ArrayParams.__default.OPEN);
      if ((_0_valueOrError0).IsFailure()) {
        return (_0_valueOrError0).PropagateFailure<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Utils.Views.Core._IView__>>();
      } else {
        Std.JSON.Utils.Cursors._ICursor__ _1_cs = (_0_valueOrError0).Extract();
        return Std.Wrappers.Result<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Utils.Views.Core._IView__>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>>.create_Success((_1_cs).Split());
      }
    }
    public static Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Utils.Views.Core._IView__>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>> Close(Std.JSON.Utils.Cursors._ICursor__ cs) {
      Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ICursor__, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>> _0_valueOrError0 = (cs).AssertByte<Std.JSON.Errors._IDeserializationError>(Std.JSON.ZeroCopy.Deserializer.ArrayParams.__default.CLOSE);
      if ((_0_valueOrError0).IsFailure()) {
        return (_0_valueOrError0).PropagateFailure<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Utils.Views.Core._IView__>>();
      } else {
        Std.JSON.Utils.Cursors._ICursor__ _1_cs = (_0_valueOrError0).Extract();
        return Std.Wrappers.Result<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Utils.Views.Core._IView__>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>>.create_Success((_1_cs).Split());
      }
    }
    public static Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IBracketed<Std.JSON.Utils.Views.Core._IView__, Std.JSON.Grammar._IValue, Std.JSON.Utils.Views.Core._IView__, Std.JSON.Utils.Views.Core._IView__>> BracketedFromParts(Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IStructural<Std.JSON.Utils.Views.Core._IView__>> open, Std.JSON.Utils.Cursors._ISplit<Dafny.ISequence<Std.JSON.Grammar._ISuffixed<Std.JSON.Grammar._IValue, Std.JSON.Utils.Views.Core._IView__>>> elems, Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IStructural<Std.JSON.Utils.Views.Core._IView__>> close)
    {
      Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IBracketed<Std.JSON.Utils.Views.Core._IView__, Std.JSON.Grammar._IValue, Std.JSON.Utils.Views.Core._IView__, Std.JSON.Utils.Views.Core._IView__>> _0_sp = Std.JSON.Utils.Cursors.Split<Std.JSON.Grammar._IBracketed<Std.JSON.Utils.Views.Core._IView__, Std.JSON.Grammar._IValue, Std.JSON.Utils.Views.Core._IView__, Std.JSON.Utils.Views.Core._IView__>>.create(Std.JSON.Grammar.Bracketed<Std.JSON.Utils.Views.Core._IView__, Std.JSON.Grammar._IValue, Std.JSON.Utils.Views.Core._IView__, Std.JSON.Utils.Views.Core._IView__>.create((open).dtor_t, (elems).dtor_t, (close).dtor_t), (close).dtor_cs);
      return _0_sp;
    }
    public static Std.JSON.Utils.Cursors._ISplit<Dafny.ISequence<Std.JSON.Grammar._ISuffixed<Std.JSON.Grammar._IValue, Std.JSON.Utils.Views.Core._IView__>>> AppendWithSuffix(Std.JSON.Utils.Cursors._ISplit<Dafny.ISequence<Std.JSON.Grammar._ISuffixed<Std.JSON.Grammar._IValue, Std.JSON.Utils.Views.Core._IView__>>> elems, Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IValue> elem, Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IStructural<Std.JSON.Utils.Views.Core._IView__>> sep)
    {
      Std.JSON.Grammar._ISuffixed<Std.JSON.Grammar._IValue, Std.JSON.Utils.Views.Core._IView__> _0_suffixed = Std.JSON.Grammar.Suffixed<Std.JSON.Grammar._IValue, Std.JSON.Utils.Views.Core._IView__>.create((elem).dtor_t, Std.JSON.Grammar.Maybe<Std.JSON.Grammar._IStructural<Std.JSON.Utils.Views.Core._IView__>>.create_NonEmpty((sep).dtor_t));
      Std.JSON.Utils.Cursors._ISplit<Dafny.ISequence<Std.JSON.Grammar._ISuffixed<Std.JSON.Grammar._IValue, Std.JSON.Utils.Views.Core._IView__>>> _1_elems_k = Std.JSON.Utils.Cursors.Split<Dafny.ISequence<Std.JSON.Grammar._ISuffixed<Std.JSON.Grammar._IValue, Std.JSON.Utils.Views.Core._IView__>>>.create(Dafny.Sequence<Std.JSON.Grammar._ISuffixed<Std.JSON.Grammar._IValue, Std.JSON.Utils.Views.Core._IView__>>.Concat((elems).dtor_t, Dafny.Sequence<Std.JSON.Grammar._ISuffixed<Std.JSON.Grammar._IValue, Std.JSON.Utils.Views.Core._IView__>>.FromElements(_0_suffixed)), (sep).dtor_cs);
      return _1_elems_k;
    }
    public static Std.JSON.Utils.Cursors._ISplit<Dafny.ISequence<Std.JSON.Grammar._ISuffixed<Std.JSON.Grammar._IValue, Std.JSON.Utils.Views.Core._IView__>>> AppendLast(Std.JSON.Utils.Cursors._ISplit<Dafny.ISequence<Std.JSON.Grammar._ISuffixed<Std.JSON.Grammar._IValue, Std.JSON.Utils.Views.Core._IView__>>> elems, Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IValue> elem, Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IStructural<Std.JSON.Utils.Views.Core._IView__>> sep)
    {
      Std.JSON.Grammar._ISuffixed<Std.JSON.Grammar._IValue, Std.JSON.Utils.Views.Core._IView__> _0_suffixed = Std.JSON.Grammar.Suffixed<Std.JSON.Grammar._IValue, Std.JSON.Utils.Views.Core._IView__>.create((elem).dtor_t, Std.JSON.Grammar.Maybe<Std.JSON.Grammar._IStructural<Std.JSON.Utils.Views.Core._IView__>>.create_Empty());
      Std.JSON.Utils.Cursors._ISplit<Dafny.ISequence<Std.JSON.Grammar._ISuffixed<Std.JSON.Grammar._IValue, Std.JSON.Utils.Views.Core._IView__>>> _1_elems_k = Std.JSON.Utils.Cursors.Split<Dafny.ISequence<Std.JSON.Grammar._ISuffixed<Std.JSON.Grammar._IValue, Std.JSON.Utils.Views.Core._IView__>>>.create(Dafny.Sequence<Std.JSON.Grammar._ISuffixed<Std.JSON.Grammar._IValue, Std.JSON.Utils.Views.Core._IView__>>.Concat((elems).dtor_t, Dafny.Sequence<Std.JSON.Grammar._ISuffixed<Std.JSON.Grammar._IValue, Std.JSON.Utils.Views.Core._IView__>>.FromElements(_0_suffixed)), (elem).dtor_cs);
      return _1_elems_k;
    }
    public static Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IBracketed<Std.JSON.Utils.Views.Core._IView__, Std.JSON.Grammar._IValue, Std.JSON.Utils.Views.Core._IView__, Std.JSON.Utils.Views.Core._IView__>>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>> Elements(Func<Std.JSON.Utils.Cursors._ICursor__, Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IValue>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>>> json, Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IStructural<Std.JSON.Utils.Views.Core._IView__>> open, Std.JSON.Utils.Cursors._ISplit<Dafny.ISequence<Std.JSON.Grammar._ISuffixed<Std.JSON.Grammar._IValue, Std.JSON.Utils.Views.Core._IView__>>> elems)
    {
    TAIL_CALL_START: ;
      Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IValue>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>> _0_valueOrError0 = Std.JSON.ZeroCopy.Deserializer.ArrayParams.__default.Element((elems).dtor_cs, json);
      if ((_0_valueOrError0).IsFailure()) {
        return (_0_valueOrError0).PropagateFailure<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IBracketed<Std.JSON.Utils.Views.Core._IView__, Std.JSON.Grammar._IValue, Std.JSON.Utils.Views.Core._IView__, Std.JSON.Utils.Views.Core._IView__>>>();
      } else {
        Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IValue> _1_elem = (_0_valueOrError0).Extract();
        if (((_1_elem).dtor_cs).EOF_q) {
          return Std.Wrappers.Result<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IBracketed<Std.JSON.Utils.Views.Core._IView__, Std.JSON.Grammar._IValue, Std.JSON.Utils.Views.Core._IView__, Std.JSON.Utils.Views.Core._IView__>>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>>.create_Failure(Std.JSON.Utils.Cursors.CursorError<Std.JSON.Errors._IDeserializationError>.create_EOF());
        } else {
          Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IStructural<Std.JSON.Utils.Views.Core._IView__>> _2_sep = Std.JSON.ZeroCopy.Deserializer.Core.__default.TryStructural((_1_elem).dtor_cs);
          short _3_s0 = (((_2_sep).dtor_t).dtor_t).Peek();
          if (((_3_s0) == ((short)(Std.JSON.ZeroCopy.Deserializer.Arrays.__default.SEPARATOR))) && (((((_2_sep).dtor_t).dtor_t).Length()) == (1U))) {
            Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IStructural<Std.JSON.Utils.Views.Core._IView__>> _4_sep = _2_sep;
            Std.JSON.Utils.Cursors._ISplit<Dafny.ISequence<Std.JSON.Grammar._ISuffixed<Std.JSON.Grammar._IValue, Std.JSON.Utils.Views.Core._IView__>>> _5_elems = Std.JSON.ZeroCopy.Deserializer.Arrays.__default.AppendWithSuffix(elems, _1_elem, _4_sep);
            Func<Std.JSON.Utils.Cursors._ICursor__, Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IValue>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>>> _in0 = json;
            Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IStructural<Std.JSON.Utils.Views.Core._IView__>> _in1 = open;
            Std.JSON.Utils.Cursors._ISplit<Dafny.ISequence<Std.JSON.Grammar._ISuffixed<Std.JSON.Grammar._IValue, Std.JSON.Utils.Views.Core._IView__>>> _in2 = _5_elems;
            json = _in0;
            open = _in1;
            elems = _in2;
            goto TAIL_CALL_START;
          } else if (((_3_s0) == ((short)(Std.JSON.ZeroCopy.Deserializer.ArrayParams.__default.CLOSE))) && (((((_2_sep).dtor_t).dtor_t).Length()) == (1U))) {
            Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IStructural<Std.JSON.Utils.Views.Core._IView__>> _6_sep = _2_sep;
            Std.JSON.Utils.Cursors._ISplit<Dafny.ISequence<Std.JSON.Grammar._ISuffixed<Std.JSON.Grammar._IValue, Std.JSON.Utils.Views.Core._IView__>>> _7_elems_k = Std.JSON.ZeroCopy.Deserializer.Arrays.__default.AppendLast(elems, _1_elem, _6_sep);
            Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IBracketed<Std.JSON.Utils.Views.Core._IView__, Std.JSON.Grammar._IValue, Std.JSON.Utils.Views.Core._IView__, Std.JSON.Utils.Views.Core._IView__>> _8_bracketed = Std.JSON.ZeroCopy.Deserializer.Arrays.__default.BracketedFromParts(open, _7_elems_k, _6_sep);
            return Std.Wrappers.Result<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IBracketed<Std.JSON.Utils.Views.Core._IView__, Std.JSON.Grammar._IValue, Std.JSON.Utils.Views.Core._IView__, Std.JSON.Utils.Views.Core._IView__>>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>>.create_Success(_8_bracketed);
          } else {
            byte _9_separator = Std.JSON.ZeroCopy.Deserializer.Arrays.__default.SEPARATOR;
            Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IBracketed<Std.JSON.Utils.Views.Core._IView__, Std.JSON.Grammar._IValue, Std.JSON.Utils.Views.Core._IView__, Std.JSON.Utils.Views.Core._IView__>>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>> _10_pr = Std.Wrappers.Result<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IBracketed<Std.JSON.Utils.Views.Core._IView__, Std.JSON.Grammar._IValue, Std.JSON.Utils.Views.Core._IView__, Std.JSON.Utils.Views.Core._IView__>>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>>.create_Failure(Std.JSON.Utils.Cursors.CursorError<Std.JSON.Errors._IDeserializationError>.create_ExpectingAnyByte(Dafny.Sequence<byte>.FromElements(Std.JSON.ZeroCopy.Deserializer.ArrayParams.__default.CLOSE, _9_separator), _3_s0));
            return _10_pr;
          }
        }
      }
    }
    public static Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IBracketed<Std.JSON.Utils.Views.Core._IView__, Std.JSON.Grammar._IValue, Std.JSON.Utils.Views.Core._IView__, Std.JSON.Utils.Views.Core._IView__>>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>> Bracketed(Std.JSON.Utils.Cursors._ICursor__ cs, Func<Std.JSON.Utils.Cursors._ICursor__, Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IValue>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>>> json)
    {
      Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IStructural<Std.JSON.Utils.Views.Core._IView__>>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>> _0_valueOrError0 = Std.JSON.ZeroCopy.Deserializer.Core.__default.Structural<Std.JSON.Utils.Views.Core._IView__>(cs, Std.JSON.ZeroCopy.Deserializer.Arrays.__default.Open);
      if ((_0_valueOrError0).IsFailure()) {
        return (_0_valueOrError0).PropagateFailure<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IBracketed<Std.JSON.Utils.Views.Core._IView__, Std.JSON.Grammar._IValue, Std.JSON.Utils.Views.Core._IView__, Std.JSON.Utils.Views.Core._IView__>>>();
      } else {
        Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IStructural<Std.JSON.Utils.Views.Core._IView__>> _1_open = (_0_valueOrError0).Extract();
        Std.JSON.Utils.Cursors._ISplit<Dafny.ISequence<Std.JSON.Grammar._ISuffixed<Std.JSON.Grammar._IValue, Std.JSON.Utils.Views.Core._IView__>>> _2_elems = Std.JSON.Utils.Cursors.Split<Dafny.ISequence<Std.JSON.Grammar._ISuffixed<Std.JSON.Grammar._IValue, Std.JSON.Utils.Views.Core._IView__>>>.create(Dafny.Sequence<Std.JSON.Grammar._ISuffixed<Std.JSON.Grammar._IValue, Std.JSON.Utils.Views.Core._IView__>>.FromElements(), (_1_open).dtor_cs);
        if ((((_1_open).dtor_cs).Peek()) == ((short)(Std.JSON.ZeroCopy.Deserializer.ArrayParams.__default.CLOSE))) {
          Func<Std.JSON.Utils.Cursors._ICursor__, Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Utils.Views.Core._IView__>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>>> _3_p = Std.JSON.ZeroCopy.Deserializer.Arrays.__default.Close;
          Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IStructural<Std.JSON.Utils.Views.Core._IView__>>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>> _4_valueOrError1 = Std.JSON.ZeroCopy.Deserializer.Core.__default.Structural<Std.JSON.Utils.Views.Core._IView__>((_1_open).dtor_cs, _3_p);
          if ((_4_valueOrError1).IsFailure()) {
            return (_4_valueOrError1).PropagateFailure<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IBracketed<Std.JSON.Utils.Views.Core._IView__, Std.JSON.Grammar._IValue, Std.JSON.Utils.Views.Core._IView__, Std.JSON.Utils.Views.Core._IView__>>>();
          } else {
            Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IStructural<Std.JSON.Utils.Views.Core._IView__>> _5_close = (_4_valueOrError1).Extract();
            return Std.Wrappers.Result<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IBracketed<Std.JSON.Utils.Views.Core._IView__, Std.JSON.Grammar._IValue, Std.JSON.Utils.Views.Core._IView__, Std.JSON.Utils.Views.Core._IView__>>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>>.create_Success(Std.JSON.ZeroCopy.Deserializer.Arrays.__default.BracketedFromParts(_1_open, _2_elems, _5_close));
          }
        } else {
          return Std.JSON.ZeroCopy.Deserializer.Arrays.__default.Elements(json, _1_open, _2_elems);
        }
      }
    }
    public static Func<Std.JSON.Utils.Views.Core._IView__, Dafny.ISequence<byte>> SpecViewOpen { get {
      return Std.JSON.ZeroCopy.Deserializer.Core.__default.SpecView;
    } }
    public static Func<Std.JSON.Utils.Views.Core._IView__, Dafny.ISequence<byte>> SpecViewClose { get {
      return Std.JSON.ZeroCopy.Deserializer.Core.__default.SpecView;
    } }
    public static byte SEPARATOR { get {
      return (byte)((new Dafny.Rune(',')).Value);
    } }
  }

  public partial class jopen {
    private static readonly Std.JSON.Utils.Views.Core._IView__ Witness = Std.JSON.Utils.Views.Core.View__.OfBytes(Dafny.Sequence<byte>.FromElements(Std.JSON.ZeroCopy.Deserializer.ArrayParams.__default.OPEN));
    public static Std.JSON.Utils.Views.Core._IView__ Default() {
      return Witness;
    }
    private static readonly Dafny.TypeDescriptor<Std.JSON.Utils.Views.Core._IView__> _TYPE = new Dafny.TypeDescriptor<Std.JSON.Utils.Views.Core._IView__>(Std.JSON.ZeroCopy.Deserializer.Arrays.jopen.Default());
    public static Dafny.TypeDescriptor<Std.JSON.Utils.Views.Core._IView__> _TypeDescriptor() {
      return _TYPE;
    }
  }

  public partial class jclose {
    private static readonly Std.JSON.Utils.Views.Core._IView__ Witness = Std.JSON.Utils.Views.Core.View__.OfBytes(Dafny.Sequence<byte>.FromElements(Std.JSON.ZeroCopy.Deserializer.ArrayParams.__default.CLOSE));
    public static Std.JSON.Utils.Views.Core._IView__ Default() {
      return Witness;
    }
    private static readonly Dafny.TypeDescriptor<Std.JSON.Utils.Views.Core._IView__> _TYPE = new Dafny.TypeDescriptor<Std.JSON.Utils.Views.Core._IView__>(Std.JSON.ZeroCopy.Deserializer.Arrays.jclose.Default());
    public static Dafny.TypeDescriptor<Std.JSON.Utils.Views.Core._IView__> _TypeDescriptor() {
      return _TYPE;
    }
  }
} // end of namespace Std.JSON.ZeroCopy.Deserializer.Arrays
namespace Std.JSON.ZeroCopy.Deserializer.Constants {

  public partial class __default {
    public static Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Utils.Views.Core._IView__>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>> Constant(Std.JSON.Utils.Cursors._ICursor__ cs, Dafny.ISequence<byte> expected)
    {
      Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ICursor__, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>> _0_valueOrError0 = (cs).AssertBytes<Std.JSON.Errors._IDeserializationError>(expected, 0U);
      if ((_0_valueOrError0).IsFailure()) {
        return (_0_valueOrError0).PropagateFailure<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Utils.Views.Core._IView__>>();
      } else {
        Std.JSON.Utils.Cursors._ICursor__ _1_cs = (_0_valueOrError0).Extract();
        return Std.Wrappers.Result<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Utils.Views.Core._IView__>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>>.create_Success((_1_cs).Split());
      }
    }
  }
} // end of namespace Std.JSON.ZeroCopy.Deserializer.Constants
namespace Std.JSON.ZeroCopy.Deserializer.Values {

  public partial class __default {
    public static Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IValue>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>> Value(Std.JSON.Utils.Cursors._ICursor__ cs) {
      short _0_c = (cs).Peek();
      if ((_0_c) == ((short)((new Dafny.Rune('{')).Value))) {
        Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IBracketed<Std.JSON.Utils.Views.Core._IView__, Std.JSON.Grammar._IjKeyValue, Std.JSON.Utils.Views.Core._IView__, Std.JSON.Utils.Views.Core._IView__>>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>> _1_valueOrError0 = Std.JSON.ZeroCopy.Deserializer.Objects.__default.Object(cs, Std.JSON.ZeroCopy.Deserializer.Values.__default.ValueParser(cs));
        if ((_1_valueOrError0).IsFailure()) {
          return (_1_valueOrError0).PropagateFailure<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IValue>>();
        } else {
          Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IBracketed<Std.JSON.Utils.Views.Core._IView__, Std.JSON.Grammar._IjKeyValue, Std.JSON.Utils.Views.Core._IView__, Std.JSON.Utils.Views.Core._IView__>> _let_tmp_rhs0 = (_1_valueOrError0).Extract();
          Std.JSON.Grammar._IBracketed<Std.JSON.Utils.Views.Core._IView__, Std.JSON.Grammar._IjKeyValue, Std.JSON.Utils.Views.Core._IView__, Std.JSON.Utils.Views.Core._IView__> _2_obj = _let_tmp_rhs0.dtor_t;
          Std.JSON.Utils.Cursors._ICursor__ _3_cs_k = _let_tmp_rhs0.dtor_cs;
          Std.JSON.Grammar._IValue _4_v = Std.JSON.Grammar.Value.create_Object(_2_obj);
          Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IValue> _5_sp = Std.JSON.Utils.Cursors.Split<Std.JSON.Grammar._IValue>.create(_4_v, _3_cs_k);
          return Std.Wrappers.Result<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IValue>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>>.create_Success(_5_sp);
        }
      } else if ((_0_c) == ((short)((new Dafny.Rune('[')).Value))) {
        Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IBracketed<Std.JSON.Utils.Views.Core._IView__, Std.JSON.Grammar._IValue, Std.JSON.Utils.Views.Core._IView__, Std.JSON.Utils.Views.Core._IView__>>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>> _6_valueOrError1 = Std.JSON.ZeroCopy.Deserializer.Arrays.__default.Array(cs, Std.JSON.ZeroCopy.Deserializer.Values.__default.ValueParser(cs));
        if ((_6_valueOrError1).IsFailure()) {
          return (_6_valueOrError1).PropagateFailure<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IValue>>();
        } else {
          Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IBracketed<Std.JSON.Utils.Views.Core._IView__, Std.JSON.Grammar._IValue, Std.JSON.Utils.Views.Core._IView__, Std.JSON.Utils.Views.Core._IView__>> _let_tmp_rhs1 = (_6_valueOrError1).Extract();
          Std.JSON.Grammar._IBracketed<Std.JSON.Utils.Views.Core._IView__, Std.JSON.Grammar._IValue, Std.JSON.Utils.Views.Core._IView__, Std.JSON.Utils.Views.Core._IView__> _7_arr = _let_tmp_rhs1.dtor_t;
          Std.JSON.Utils.Cursors._ICursor__ _8_cs_k = _let_tmp_rhs1.dtor_cs;
          Std.JSON.Grammar._IValue _9_v = Std.JSON.Grammar.Value.create_Array(_7_arr);
          Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IValue> _10_sp = Std.JSON.Utils.Cursors.Split<Std.JSON.Grammar._IValue>.create(_9_v, _8_cs_k);
          return Std.Wrappers.Result<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IValue>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>>.create_Success(_10_sp);
        }
      } else if ((_0_c) == ((short)((new Dafny.Rune('\"')).Value))) {
        Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._Ijstring>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>> _11_valueOrError2 = Std.JSON.ZeroCopy.Deserializer.Strings.__default.String(cs);
        if ((_11_valueOrError2).IsFailure()) {
          return (_11_valueOrError2).PropagateFailure<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IValue>>();
        } else {
          Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._Ijstring> _let_tmp_rhs2 = (_11_valueOrError2).Extract();
          Std.JSON.Grammar._Ijstring _12_str = _let_tmp_rhs2.dtor_t;
          Std.JSON.Utils.Cursors._ICursor__ _13_cs_k = _let_tmp_rhs2.dtor_cs;
          return Std.Wrappers.Result<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IValue>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>>.create_Success(Std.JSON.Utils.Cursors.Split<Std.JSON.Grammar._IValue>.create(Std.JSON.Grammar.Value.create_String(_12_str), _13_cs_k));
        }
      } else if ((_0_c) == ((short)((new Dafny.Rune('t')).Value))) {
        Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Utils.Views.Core._IView__>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>> _14_valueOrError3 = Std.JSON.ZeroCopy.Deserializer.Constants.__default.Constant(cs, Std.JSON.Grammar.__default.TRUE);
        if ((_14_valueOrError3).IsFailure()) {
          return (_14_valueOrError3).PropagateFailure<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IValue>>();
        } else {
          Std.JSON.Utils.Cursors._ISplit<Std.JSON.Utils.Views.Core._IView__> _let_tmp_rhs3 = (_14_valueOrError3).Extract();
          Std.JSON.Utils.Views.Core._IView__ _15_cst = _let_tmp_rhs3.dtor_t;
          Std.JSON.Utils.Cursors._ICursor__ _16_cs_k = _let_tmp_rhs3.dtor_cs;
          return Std.Wrappers.Result<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IValue>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>>.create_Success(Std.JSON.Utils.Cursors.Split<Std.JSON.Grammar._IValue>.create(Std.JSON.Grammar.Value.create_Bool(_15_cst), _16_cs_k));
        }
      } else if ((_0_c) == ((short)((new Dafny.Rune('f')).Value))) {
        Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Utils.Views.Core._IView__>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>> _17_valueOrError4 = Std.JSON.ZeroCopy.Deserializer.Constants.__default.Constant(cs, Std.JSON.Grammar.__default.FALSE);
        if ((_17_valueOrError4).IsFailure()) {
          return (_17_valueOrError4).PropagateFailure<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IValue>>();
        } else {
          Std.JSON.Utils.Cursors._ISplit<Std.JSON.Utils.Views.Core._IView__> _let_tmp_rhs4 = (_17_valueOrError4).Extract();
          Std.JSON.Utils.Views.Core._IView__ _18_cst = _let_tmp_rhs4.dtor_t;
          Std.JSON.Utils.Cursors._ICursor__ _19_cs_k = _let_tmp_rhs4.dtor_cs;
          return Std.Wrappers.Result<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IValue>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>>.create_Success(Std.JSON.Utils.Cursors.Split<Std.JSON.Grammar._IValue>.create(Std.JSON.Grammar.Value.create_Bool(_18_cst), _19_cs_k));
        }
      } else if ((_0_c) == ((short)((new Dafny.Rune('n')).Value))) {
        Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Utils.Views.Core._IView__>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>> _20_valueOrError5 = Std.JSON.ZeroCopy.Deserializer.Constants.__default.Constant(cs, Std.JSON.Grammar.__default.NULL);
        if ((_20_valueOrError5).IsFailure()) {
          return (_20_valueOrError5).PropagateFailure<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IValue>>();
        } else {
          Std.JSON.Utils.Cursors._ISplit<Std.JSON.Utils.Views.Core._IView__> _let_tmp_rhs5 = (_20_valueOrError5).Extract();
          Std.JSON.Utils.Views.Core._IView__ _21_cst = _let_tmp_rhs5.dtor_t;
          Std.JSON.Utils.Cursors._ICursor__ _22_cs_k = _let_tmp_rhs5.dtor_cs;
          return Std.Wrappers.Result<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IValue>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>>.create_Success(Std.JSON.Utils.Cursors.Split<Std.JSON.Grammar._IValue>.create(Std.JSON.Grammar.Value.create_Null(_21_cst), _22_cs_k));
        }
      } else {
        Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._Ijnumber>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>> _23_valueOrError6 = Std.JSON.ZeroCopy.Deserializer.Numbers.__default.Number(cs);
        if ((_23_valueOrError6).IsFailure()) {
          return (_23_valueOrError6).PropagateFailure<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IValue>>();
        } else {
          Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._Ijnumber> _let_tmp_rhs6 = (_23_valueOrError6).Extract();
          Std.JSON.Grammar._Ijnumber _24_num = _let_tmp_rhs6.dtor_t;
          Std.JSON.Utils.Cursors._ICursor__ _25_cs_k = _let_tmp_rhs6.dtor_cs;
          Std.JSON.Grammar._IValue _26_v = Std.JSON.Grammar.Value.create_Number(_24_num);
          Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IValue> _27_sp = Std.JSON.Utils.Cursors.Split<Std.JSON.Grammar._IValue>.create(_26_v, _25_cs_k);
          return Std.Wrappers.Result<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IValue>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>>.create_Success(_27_sp);
        }
      }
    }
    public static Func<Std.JSON.Utils.Cursors._ICursor__, Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IValue>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>>> ValueParser(Std.JSON.Utils.Cursors._ICursor__ cs) {
      Func<Std.JSON.Utils.Cursors._ICursor__, bool> _0_pre = Dafny.Helpers.Id<Func<Std.JSON.Utils.Cursors._ICursor__, Func<Std.JSON.Utils.Cursors._ICursor__, bool>>>((_1_cs) => ((System.Func<Std.JSON.Utils.Cursors._ICursor__, bool>)((_2_ps_k) => {
        return ((_2_ps_k).Length()) < ((_1_cs).Length());
      })))(cs);
      Func<Std.JSON.Utils.Cursors._ICursor__, Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IValue>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>>> _3_fn = Dafny.Helpers.Id<Func<Func<Std.JSON.Utils.Cursors._ICursor__, bool>, Func<Std.JSON.Utils.Cursors._ICursor__, Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IValue>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>>>>>((_4_pre) => ((System.Func<Std.JSON.Utils.Cursors._ICursor__, Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IValue>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>>>)((_5_ps_k) => {
        return Std.JSON.ZeroCopy.Deserializer.Values.__default.Value(_5_ps_k);
      })))(_0_pre);
      return _3_fn;
    }
  }
} // end of namespace Std.JSON.ZeroCopy.Deserializer.Values
namespace Std.JSON.ZeroCopy.Deserializer.API {

  public partial class __default {
    public static Std.JSON.Errors._IDeserializationError LiftCursorError(Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError> err) {
      Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError> _source0 = err;
      {
        if (_source0.is_EOF) {
          return Std.JSON.Errors.DeserializationError.create_ReachedEOF();
        }
      }
      {
        if (_source0.is_ExpectingByte) {
          byte _0_expected = _source0.dtor_expected;
          short _1_b = _source0.dtor_b;
          return Std.JSON.Errors.DeserializationError.create_ExpectingByte(_0_expected, _1_b);
        }
      }
      {
        if (_source0.is_ExpectingAnyByte) {
          Dafny.ISequence<byte> _2_expected__sq = _source0.dtor_expected__sq;
          short _3_b = _source0.dtor_b;
          return Std.JSON.Errors.DeserializationError.create_ExpectingAnyByte(_2_expected__sq, _3_b);
        }
      }
      {
        Std.JSON.Errors._IDeserializationError _4_err = _source0.dtor_err;
        return _4_err;
      }
    }
    public static Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IStructural<Std.JSON.Grammar._IValue>>, Std.JSON.Errors._IDeserializationError> JSON(Std.JSON.Utils.Cursors._ICursor__ cs) {
      return Std.Wrappers.Result<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IStructural<Std.JSON.Grammar._IValue>>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>>.MapFailure<Std.JSON.Errors._IDeserializationError>(Std.JSON.ZeroCopy.Deserializer.Core.__default.Structural<Std.JSON.Grammar._IValue>(cs, Std.JSON.ZeroCopy.Deserializer.Values.__default.Value), Std.JSON.ZeroCopy.Deserializer.API.__default.LiftCursorError);
    }
    public static Std.Wrappers._IResult<Std.JSON.Grammar._IStructural<Std.JSON.Grammar._IValue>, Std.JSON.Errors._IDeserializationError> Text(Std.JSON.Utils.Views.Core._IView__ v) {
      Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IStructural<Std.JSON.Grammar._IValue>>, Std.JSON.Errors._IDeserializationError> _0_valueOrError0 = Std.JSON.ZeroCopy.Deserializer.API.__default.JSON(Std.JSON.Utils.Cursors.Cursor__.OfView(v));
      if ((_0_valueOrError0).IsFailure()) {
        return (_0_valueOrError0).PropagateFailure<Std.JSON.Grammar._IStructural<Std.JSON.Grammar._IValue>>();
      } else {
        Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IStructural<Std.JSON.Grammar._IValue>> _let_tmp_rhs0 = (_0_valueOrError0).Extract();
        Std.JSON.Grammar._IStructural<Std.JSON.Grammar._IValue> _1_text = _let_tmp_rhs0.dtor_t;
        Std.JSON.Utils.Cursors._ICursor__ _2_cs = _let_tmp_rhs0.dtor_cs;
        Std.Wrappers._IOutcomeResult<Std.JSON.Errors._IDeserializationError> _3_valueOrError1 = Std.Wrappers.__default.Need<Std.JSON.Errors._IDeserializationError>((_2_cs).EOF_q, Std.JSON.Errors.DeserializationError.create_ExpectingEOF());
        if ((_3_valueOrError1).IsFailure()) {
          return (_3_valueOrError1).PropagateFailure<Std.JSON.Grammar._IStructural<Std.JSON.Grammar._IValue>>();
        } else {
          return Std.Wrappers.Result<Std.JSON.Grammar._IStructural<Std.JSON.Grammar._IValue>, Std.JSON.Errors._IDeserializationError>.create_Success(_1_text);
        }
      }
    }
    public static Std.Wrappers._IResult<Std.JSON.Grammar._IStructural<Std.JSON.Grammar._IValue>, Std.JSON.Errors._IDeserializationError> OfBytes(Dafny.ISequence<byte> bs) {
      Std.Wrappers._IOutcomeResult<Std.JSON.Errors._IDeserializationError> _0_valueOrError0 = Std.Wrappers.__default.Need<Std.JSON.Errors._IDeserializationError>((new BigInteger((bs).Count)) < (Std.BoundedInts.__default.TWO__TO__THE__32), Std.JSON.Errors.DeserializationError.create_IntOverflow());
      if ((_0_valueOrError0).IsFailure()) {
        return (_0_valueOrError0).PropagateFailure<Std.JSON.Grammar._IStructural<Std.JSON.Grammar._IValue>>();
      } else {
        return Std.JSON.ZeroCopy.Deserializer.API.__default.Text(Std.JSON.Utils.Views.Core.View__.OfBytes(bs));
      }
    }
  }
} // end of namespace Std.JSON.ZeroCopy.Deserializer.API
namespace Std.JSON.ZeroCopy.Deserializer {

} // end of namespace Std.JSON.ZeroCopy.Deserializer
namespace Std.JSON.ZeroCopy.API {

  public partial class __default {
    public static Std.Wrappers._IResult<Dafny.ISequence<byte>, Std.JSON.Errors._ISerializationError> Serialize(Std.JSON.Grammar._IStructural<Std.JSON.Grammar._IValue> js) {
      return Std.Wrappers.Result<Dafny.ISequence<byte>, Std.JSON.Errors._ISerializationError>.create_Success((Std.JSON.ZeroCopy.Serializer.__default.Text(js)).Bytes());
    }
    public static Std.Wrappers._IResult<byte[], Std.JSON.Errors._ISerializationError> SerializeAlloc(Std.JSON.Grammar._IStructural<Std.JSON.Grammar._IValue> js)
    {
      Std.Wrappers._IResult<byte[], Std.JSON.Errors._ISerializationError> bs = Std.Wrappers.Result<byte[], Std.JSON.Errors._ISerializationError>.Default(new byte[0]);
      Std.Wrappers._IResult<byte[], Std.JSON.Errors._ISerializationError> _out0;
      _out0 = Std.JSON.ZeroCopy.Serializer.__default.Serialize(js);
      bs = _out0;
      return bs;
    }
    public static Std.Wrappers._IResult<uint, Std.JSON.Errors._ISerializationError> SerializeInto(Std.JSON.Grammar._IStructural<Std.JSON.Grammar._IValue> js, byte[] bs)
    {
      Std.Wrappers._IResult<uint, Std.JSON.Errors._ISerializationError> len = Std.Wrappers.Result<uint, Std.JSON.Errors._ISerializationError>.Default(0);
      Std.Wrappers._IResult<uint, Std.JSON.Errors._ISerializationError> _out0;
      _out0 = Std.JSON.ZeroCopy.Serializer.__default.SerializeTo(js, bs);
      len = _out0;
      return len;
    }
    public static Std.Wrappers._IResult<Std.JSON.Grammar._IStructural<Std.JSON.Grammar._IValue>, Std.JSON.Errors._IDeserializationError> Deserialize(Dafny.ISequence<byte> bs) {
      return Std.JSON.ZeroCopy.Deserializer.API.__default.OfBytes(bs);
    }
  }
} // end of namespace Std.JSON.ZeroCopy.API
namespace Std.JSON.ZeroCopy {

} // end of namespace Std.JSON.ZeroCopy
namespace Std.JSON.API {

  public partial class __default {
    public static Std.Wrappers._IResult<Dafny.ISequence<byte>, Std.JSON.Errors._ISerializationError> Serialize(Std.JSON.Values._IJSON js) {
      Std.Wrappers._IResult<Std.JSON.Grammar._IStructural<Std.JSON.Grammar._IValue>, Std.JSON.Errors._ISerializationError> _0_valueOrError0 = Std.JSON.Serializer.__default.JSON(js);
      if ((_0_valueOrError0).IsFailure()) {
        return (_0_valueOrError0).PropagateFailure<Dafny.ISequence<byte>>();
      } else {
        Std.JSON.Grammar._IStructural<Std.JSON.Grammar._IValue> _1_js = (_0_valueOrError0).Extract();
        return Std.JSON.ZeroCopy.API.__default.Serialize(_1_js);
      }
    }
    public static Std.Wrappers._IResult<byte[], Std.JSON.Errors._ISerializationError> SerializeAlloc(Std.JSON.Values._IJSON js)
    {
      Std.Wrappers._IResult<byte[], Std.JSON.Errors._ISerializationError> bs = Std.Wrappers.Result<byte[], Std.JSON.Errors._ISerializationError>.Default(new byte[0]);
      Std.Wrappers._IResult<Std.JSON.Grammar._IStructural<Std.JSON.Grammar._IValue>, Std.JSON.Errors._ISerializationError> _0_valueOrError0 = Std.Wrappers.Result<Std.JSON.Grammar._IStructural<Std.JSON.Grammar._IValue>, Std.JSON.Errors._ISerializationError>.Default(Std.JSON.Grammar.Structural<Std.JSON.Grammar._IValue>.Default(Std.JSON.Grammar.Value.Default()));
      _0_valueOrError0 = Std.JSON.Serializer.__default.JSON(js);
      if ((_0_valueOrError0).IsFailure()) {
        bs = (_0_valueOrError0).PropagateFailure<byte[]>();
        return bs;
      }
      Std.JSON.Grammar._IStructural<Std.JSON.Grammar._IValue> _1_js;
      _1_js = (_0_valueOrError0).Extract();
      Std.Wrappers._IResult<byte[], Std.JSON.Errors._ISerializationError> _out0;
      _out0 = Std.JSON.ZeroCopy.API.__default.SerializeAlloc(_1_js);
      bs = _out0;
      return bs;
    }
    public static Std.Wrappers._IResult<uint, Std.JSON.Errors._ISerializationError> SerializeInto(Std.JSON.Values._IJSON js, byte[] bs)
    {
      Std.Wrappers._IResult<uint, Std.JSON.Errors._ISerializationError> len = Std.Wrappers.Result<uint, Std.JSON.Errors._ISerializationError>.Default(0);
      Std.Wrappers._IResult<Std.JSON.Grammar._IStructural<Std.JSON.Grammar._IValue>, Std.JSON.Errors._ISerializationError> _0_valueOrError0 = Std.Wrappers.Result<Std.JSON.Grammar._IStructural<Std.JSON.Grammar._IValue>, Std.JSON.Errors._ISerializationError>.Default(Std.JSON.Grammar.Structural<Std.JSON.Grammar._IValue>.Default(Std.JSON.Grammar.Value.Default()));
      _0_valueOrError0 = Std.JSON.Serializer.__default.JSON(js);
      if ((_0_valueOrError0).IsFailure()) {
        len = (_0_valueOrError0).PropagateFailure<uint>();
        return len;
      }
      Std.JSON.Grammar._IStructural<Std.JSON.Grammar._IValue> _1_js;
      _1_js = (_0_valueOrError0).Extract();
      Std.Wrappers._IResult<uint, Std.JSON.Errors._ISerializationError> _out0;
      _out0 = Std.JSON.ZeroCopy.API.__default.SerializeInto(_1_js, bs);
      len = _out0;
      return len;
    }
    public static Std.Wrappers._IResult<Std.JSON.Values._IJSON, Std.JSON.Errors._IDeserializationError> Deserialize(Dafny.ISequence<byte> bs) {
      Std.Wrappers._IResult<Std.JSON.Grammar._IStructural<Std.JSON.Grammar._IValue>, Std.JSON.Errors._IDeserializationError> _0_valueOrError0 = Std.JSON.ZeroCopy.API.__default.Deserialize(bs);
      if ((_0_valueOrError0).IsFailure()) {
        return (_0_valueOrError0).PropagateFailure<Std.JSON.Values._IJSON>();
      } else {
        Std.JSON.Grammar._IStructural<Std.JSON.Grammar._IValue> _1_js = (_0_valueOrError0).Extract();
        return Std.JSON.Deserializer.__default.JSON(_1_js);
      }
    }
  }
} // end of namespace Std.JSON.API
namespace Std.JSON {

} // end of namespace Std.JSON
namespace Std {

} // end of namespace Std
namespace ReadBytesFromFile {

  public partial class __default {
    public static void Test()
    {
      ReadBytesFromFile.__default.theMain(Dafny.Sequence<Dafny.Rune>.UnicodeFromString("/Users/pari/pcc-llms/filesystems-api/Standard-fileIO/data.txt"), Dafny.Sequence<Dafny.Rune>.UnicodeFromString(""));
    }
    public static void theMain(Dafny.ISequence<Dafny.Rune> dataPath, Dafny.ISequence<Dafny.Rune> expectedErrorPrefix)
    {
      {
        Dafny.ISequence<Dafny.Rune> _0_expectedStr;
        _0_expectedStr = Dafny.Sequence<Dafny.Rune>.UnicodeFromString("Hello world");
        Dafny.ISequence<BigInteger> _1_expectedBytes;
        _1_expectedBytes = ((System.Func<Dafny.ISequence<BigInteger>>) (() => {
          BigInteger dim10 = new BigInteger((_0_expectedStr).Count);
          var arr10 = new BigInteger[Dafny.Helpers.ToIntChecked(dim10, "array size exceeds memory limit")];
          for (int i10 = 0; i10 < dim10; i10++) {
            var _2_i = (BigInteger) i10;
            arr10[(int)(_2_i)] = new BigInteger(((_0_expectedStr).Select(_2_i)).Value);
          }
          return Dafny.Sequence<BigInteger>.FromArray(arr10);
        }))();
        Std.Wrappers._IResult<Dafny.ISequence<byte>, Dafny.ISequence<Dafny.Rune>> _3_res;
        Std.Wrappers._IResult<Dafny.ISequence<byte>, Dafny.ISequence<Dafny.Rune>> _out0;
        _out0 = Std.FileIO.__default.ReadBytesFromFile(dataPath);
        _3_res = _out0;
        if (!((_3_res).is_Success)) {
          throw new Dafny.HaltException("ReadBytesFromFile.dfy(23,6): " + Dafny.Sequence<Dafny.Rune>.Concat(Dafny.Sequence<Dafny.Rune>.UnicodeFromString("unexpected failure: "), (_3_res).dtor_error).ToVerbatimString(false));}
        Dafny.ISequence<BigInteger> _4_readBytes;
        _4_readBytes = ((System.Func<Dafny.ISequence<BigInteger>>) (() => {
          BigInteger dim11 = new BigInteger(((_3_res).dtor_value).Count);
          var arr11 = new BigInteger[Dafny.Helpers.ToIntChecked(dim11, "array size exceeds memory limit")];
          for (int i11 = 0; i11 < dim11; i11++) {
            var _5_i = (BigInteger) i11;
            arr11[(int)(_5_i)] = new BigInteger(((_3_res).dtor_value).Select(_5_i));
          }
          return Dafny.Sequence<BigInteger>.FromArray(arr11);
        }))();
        if (!((_4_readBytes).Equals(_1_expectedBytes))) {
          throw new Dafny.HaltException("ReadBytesFromFile.dfy(26,6): " + Dafny.Sequence<Dafny.Rune>.UnicodeFromString("read unexpected byte sequence").ToVerbatimString(false));}
      }
      {
        Std.Wrappers._IResult<Dafny.ISequence<byte>, Dafny.ISequence<Dafny.Rune>> _6_res;
        Std.Wrappers._IResult<Dafny.ISequence<byte>, Dafny.ISequence<Dafny.Rune>> _out1;
        _out1 = Std.FileIO.__default.ReadBytesFromFile(Dafny.Sequence<Dafny.Rune>.UnicodeFromString(""));
        _6_res = _out1;
        if (!((_6_res).is_Failure)) {
          throw new Dafny.HaltException("ReadBytesFromFile.dfy(32,6): " + Dafny.Sequence<Dafny.Rune>.UnicodeFromString("unexpected success").ToVerbatimString(false));}
        if (!(Dafny.Sequence<Dafny.Rune>.IsPrefixOf(expectedErrorPrefix, (_6_res).dtor_error))) {
          throw new Dafny.HaltException("ReadBytesFromFile.dfy(33,6): " + Dafny.Sequence<Dafny.Rune>.Concat(Dafny.Sequence<Dafny.Rune>.UnicodeFromString("unexpected error message: "), (_6_res).dtor_error).ToVerbatimString(false));}
      }
    }
  }
} // end of namespace ReadBytesFromFile
namespace _module {

  public partial class __default {
    public static void __Test____Main__(Dafny.ISequence<Dafny.ISequence<Dafny.Rune>> __noArgsParameter)
    {
      bool _0_success;
      _0_success = true;
      Dafny.Helpers.Print((Dafny.Sequence<Dafny.Rune>.UnicodeFromString(@"ReadBytesFromFile.Test: ")).ToVerbatimString(false));
      try {
        {
          ReadBytesFromFile.__default.Test();
          {
            Dafny.Helpers.Print((Dafny.Sequence<Dafny.Rune>.UnicodeFromString(@"PASSED
")).ToVerbatimString(false));
          }
        }
      }
      catch (Dafny.HaltException e) {
        var _1_haltMessage = Dafny.Sequence<Dafny.Rune>.UnicodeFromString(e.Message);
        {
          Dafny.Helpers.Print((Dafny.Sequence<Dafny.Rune>.UnicodeFromString(@"FAILED
	")).ToVerbatimString(false));
          Dafny.Helpers.Print((_1_haltMessage).ToVerbatimString(false));
          Dafny.Helpers.Print((Dafny.Sequence<Dafny.Rune>.UnicodeFromString(@"
")).ToVerbatimString(false));
          _0_success = false;
        }
      }
      if (!(_0_success)) {
        throw new Dafny.HaltException("ReadBytesFromFile.dfy(6,0): " + Dafny.Sequence<Dafny.Rune>.UnicodeFromString(@"Test failures occurred: see above.
").ToVerbatimString(false));}
    }
  }
} // end of namespace _module
class __CallToMain {
  public static void Main(string[] args) {
    Dafny.Helpers.WithHaltHandling(() => _module.__default.__Test____Main__(Dafny.Sequence<Dafny.ISequence<Dafny.Rune>>.UnicodeFromMainArguments(args)));
  }
}
